2022-12-16 10:10:49,973:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-12-16 10:10:49,973:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-12-16 10:10:49,973:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-12-16 10:10:49,973:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-12-16 10:10:51,579:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2022-12-16 10:12:33,020:INFO:PyCaret ClassificationExperiment
2022-12-16 10:12:33,020:INFO:Logging name: clf-default-name
2022-12-16 10:12:33,020:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2022-12-16 10:12:33,020:INFO:version 3.0.0.rc4
2022-12-16 10:12:33,020:INFO:Initializing setup()
2022-12-16 10:12:33,020:INFO:self.USI: f797
2022-12-16 10:12:33,021:INFO:self.variable_keys: {'fix_imbalance', 'fold_groups_param', 'fold_shuffle_param', '_ml_usecase', 'display_container', 'n_jobs_param', 'exp_name_log', 'target_param', 'pipeline', 'seed', 'exp_id', '_all_models_internal', 'X_test', 'X_train', '_all_metrics', 'gpu_param', 'y_train', 'y_test', '_is_multiclass', 'y', 'logging_param', 'master_model_container', '_available_plots', 'html_param', 'X', '_all_models', 'memory', 'USI', 'log_plots_param', '_gpu_n_jobs_param', 'variable_keys', 'idx', 'fold_generator', 'data'}
2022-12-16 10:12:33,021:INFO:Checking environment
2022-12-16 10:12:33,021:INFO:python_version: 3.10.7
2022-12-16 10:12:33,021:INFO:python_build: ('tags/v3.10.7:6cc6b13', 'Sep  5 2022 14:08:36')
2022-12-16 10:12:33,021:INFO:machine: AMD64
2022-12-16 10:12:33,050:INFO:platform: Windows-10-10.0.22621-SP0
2022-12-16 10:12:33,051:INFO:Memory: svmem(total=8361132032, available=578424832, percent=93.1, used=7782707200, free=578424832)
2022-12-16 10:12:33,051:INFO:Physical Core: 4
2022-12-16 10:12:33,051:INFO:Logical Core: 8
2022-12-16 10:12:33,051:INFO:Checking libraries
2022-12-16 10:12:33,052:INFO:System:
2022-12-16 10:12:33,052:INFO:    python: 3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]
2022-12-16 10:12:33,052:INFO:executable: C:\Users\S_05_\AppData\Local\Programs\Python\Python310\python.exe
2022-12-16 10:12:33,052:INFO:   machine: Windows-10-10.0.22621-SP0
2022-12-16 10:12:33,052:INFO:PyCaret required dependencies:
2022-12-16 10:12:33,052:INFO:                 pip: 22.3.1
2022-12-16 10:12:33,052:INFO:          setuptools: 63.2.0
2022-12-16 10:12:33,052:INFO:             pycaret: 3.0.0rc4
2022-12-16 10:12:33,052:INFO:             IPython: 8.6.0
2022-12-16 10:12:33,052:INFO:          ipywidgets: 8.0.3
2022-12-16 10:12:33,052:INFO:                tqdm: 4.64.1
2022-12-16 10:12:33,052:INFO:               numpy: 1.22.4
2022-12-16 10:12:33,052:INFO:              pandas: 1.4.4
2022-12-16 10:12:33,053:INFO:              jinja2: 3.1.2
2022-12-16 10:12:33,053:INFO:               scipy: 1.8.1
2022-12-16 10:12:33,053:INFO:              joblib: 1.2.0
2022-12-16 10:12:33,053:INFO:             sklearn: 1.1.3
2022-12-16 10:12:33,053:INFO:                pyod: 1.0.6
2022-12-16 10:12:33,053:INFO:            imblearn: 0.10.0
2022-12-16 10:12:33,053:INFO:   category_encoders: 2.5.1.post0
2022-12-16 10:12:33,053:INFO:            lightgbm: 3.3.3
2022-12-16 10:12:33,053:INFO:               numba: 0.55.2
2022-12-16 10:12:33,053:INFO:            requests: 2.28.1
2022-12-16 10:12:33,053:INFO:          matplotlib: 3.6.2
2022-12-16 10:12:33,053:INFO:          scikitplot: 0.3.7
2022-12-16 10:12:33,053:INFO:         yellowbrick: 1.5
2022-12-16 10:12:33,053:INFO:              plotly: 5.11.0
2022-12-16 10:12:33,054:INFO:             kaleido: 0.2.1
2022-12-16 10:12:33,054:INFO:         statsmodels: 0.13.5
2022-12-16 10:12:33,054:INFO:              sktime: 0.13.4
2022-12-16 10:12:33,054:INFO:               tbats: 1.1.2
2022-12-16 10:12:33,054:INFO:            pmdarima: 1.8.5
2022-12-16 10:12:33,054:INFO:              psutil: 5.9.3
2022-12-16 10:12:33,054:INFO:PyCaret optional dependencies:
2022-12-16 10:12:33,084:INFO:                shap: Not installed
2022-12-16 10:12:33,084:INFO:           interpret: Not installed
2022-12-16 10:12:33,084:INFO:                umap: Not installed
2022-12-16 10:12:33,084:INFO:    pandas_profiling: 3.5.0
2022-12-16 10:12:33,084:INFO:  explainerdashboard: Not installed
2022-12-16 10:12:33,084:INFO:             autoviz: Not installed
2022-12-16 10:12:33,084:INFO:           fairlearn: Not installed
2022-12-16 10:12:33,084:INFO:             xgboost: Not installed
2022-12-16 10:12:33,084:INFO:            catboost: Not installed
2022-12-16 10:12:33,084:INFO:              kmodes: Not installed
2022-12-16 10:12:33,085:INFO:             mlxtend: Not installed
2022-12-16 10:12:33,085:INFO:       statsforecast: Not installed
2022-12-16 10:12:33,085:INFO:        tune_sklearn: Not installed
2022-12-16 10:12:33,085:INFO:                 ray: Not installed
2022-12-16 10:12:33,085:INFO:            hyperopt: Not installed
2022-12-16 10:12:33,085:INFO:              optuna: Not installed
2022-12-16 10:12:33,085:INFO:               skopt: Not installed
2022-12-16 10:12:33,085:INFO:              mlflow: Not installed
2022-12-16 10:12:33,085:INFO:              gradio: Not installed
2022-12-16 10:12:33,085:INFO:             fastapi: Not installed
2022-12-16 10:12:33,085:INFO:             uvicorn: Not installed
2022-12-16 10:12:33,085:INFO:              m2cgen: Not installed
2022-12-16 10:12:33,085:INFO:           evidently: Not installed
2022-12-16 10:12:33,085:INFO:                nltk: Not installed
2022-12-16 10:12:33,085:INFO:            pyLDAvis: Not installed
2022-12-16 10:12:33,085:INFO:              gensim: Not installed
2022-12-16 10:12:33,086:INFO:               spacy: Not installed
2022-12-16 10:12:33,086:INFO:           wordcloud: Not installed
2022-12-16 10:12:33,086:INFO:            textblob: Not installed
2022-12-16 10:12:33,086:INFO:               fugue: Not installed
2022-12-16 10:12:33,086:INFO:           streamlit: 1.15.2
2022-12-16 10:12:33,086:INFO:             prophet: Not installed
2022-12-16 10:12:33,086:INFO:None
2022-12-16 10:12:33,086:INFO:Set up data.
2022-12-16 10:12:33,100:INFO:Set up train/test split.
2022-12-16 10:15:33,845:INFO:PyCaret RegressionExperiment
2022-12-16 10:15:33,845:INFO:Logging name: reg-default-name
2022-12-16 10:15:33,845:INFO:ML Usecase: MLUsecase.REGRESSION
2022-12-16 10:15:33,845:INFO:version 3.0.0.rc4
2022-12-16 10:15:33,845:INFO:Initializing setup()
2022-12-16 10:15:33,845:INFO:self.USI: 05bf
2022-12-16 10:15:33,845:INFO:self.variable_keys: {'fold_groups_param', 'fold_shuffle_param', 'transform_target_param', '_ml_usecase', 'display_container', 'n_jobs_param', 'exp_name_log', 'target_param', 'pipeline', 'seed', 'exp_id', '_all_models_internal', 'X_test', 'X_train', '_all_metrics', 'gpu_param', 'y_train', 'y_test', 'y', 'logging_param', 'master_model_container', '_available_plots', 'html_param', 'X', '_all_models', 'memory', 'USI', 'transform_target_method_param', 'log_plots_param', '_gpu_n_jobs_param', 'variable_keys', 'idx', 'fold_generator', 'data'}
2022-12-16 10:15:33,845:INFO:Checking environment
2022-12-16 10:15:33,845:INFO:python_version: 3.10.7
2022-12-16 10:15:33,845:INFO:python_build: ('tags/v3.10.7:6cc6b13', 'Sep  5 2022 14:08:36')
2022-12-16 10:15:33,845:INFO:machine: AMD64
2022-12-16 10:15:33,845:INFO:platform: Windows-10-10.0.22621-SP0
2022-12-16 10:15:33,846:INFO:Memory: svmem(total=8361132032, available=1074245632, percent=87.2, used=7286886400, free=1074245632)
2022-12-16 10:15:33,846:INFO:Physical Core: 4
2022-12-16 10:15:33,846:INFO:Logical Core: 8
2022-12-16 10:15:33,846:INFO:Checking libraries
2022-12-16 10:15:33,846:INFO:System:
2022-12-16 10:15:33,846:INFO:    python: 3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]
2022-12-16 10:15:33,846:INFO:executable: C:\Users\S_05_\AppData\Local\Programs\Python\Python310\python.exe
2022-12-16 10:15:33,846:INFO:   machine: Windows-10-10.0.22621-SP0
2022-12-16 10:15:33,846:INFO:PyCaret required dependencies:
2022-12-16 10:15:33,846:INFO:                 pip: 22.3.1
2022-12-16 10:15:33,847:INFO:          setuptools: 63.2.0
2022-12-16 10:15:33,847:INFO:             pycaret: 3.0.0rc4
2022-12-16 10:15:33,847:INFO:             IPython: 8.6.0
2022-12-16 10:15:33,847:INFO:          ipywidgets: 8.0.3
2022-12-16 10:15:33,847:INFO:                tqdm: 4.64.1
2022-12-16 10:15:33,847:INFO:               numpy: 1.22.4
2022-12-16 10:15:33,847:INFO:              pandas: 1.4.4
2022-12-16 10:15:33,847:INFO:              jinja2: 3.1.2
2022-12-16 10:15:33,847:INFO:               scipy: 1.8.1
2022-12-16 10:15:33,847:INFO:              joblib: 1.2.0
2022-12-16 10:15:33,848:INFO:             sklearn: 1.1.3
2022-12-16 10:15:33,848:INFO:                pyod: 1.0.6
2022-12-16 10:15:33,848:INFO:            imblearn: 0.10.0
2022-12-16 10:15:33,848:INFO:   category_encoders: 2.5.1.post0
2022-12-16 10:15:33,848:INFO:            lightgbm: 3.3.3
2022-12-16 10:15:33,848:INFO:               numba: 0.55.2
2022-12-16 10:15:33,848:INFO:            requests: 2.28.1
2022-12-16 10:15:33,848:INFO:          matplotlib: 3.6.2
2022-12-16 10:15:33,848:INFO:          scikitplot: 0.3.7
2022-12-16 10:15:33,848:INFO:         yellowbrick: 1.5
2022-12-16 10:15:33,848:INFO:              plotly: 5.11.0
2022-12-16 10:15:33,848:INFO:             kaleido: 0.2.1
2022-12-16 10:15:33,848:INFO:         statsmodels: 0.13.5
2022-12-16 10:15:33,849:INFO:              sktime: 0.13.4
2022-12-16 10:15:33,849:INFO:               tbats: 1.1.2
2022-12-16 10:15:33,849:INFO:            pmdarima: 1.8.5
2022-12-16 10:15:33,849:INFO:              psutil: 5.9.3
2022-12-16 10:15:33,849:INFO:PyCaret optional dependencies:
2022-12-16 10:15:33,849:INFO:                shap: Not installed
2022-12-16 10:15:33,849:INFO:           interpret: Not installed
2022-12-16 10:15:33,850:INFO:                umap: Not installed
2022-12-16 10:15:33,850:INFO:    pandas_profiling: 3.5.0
2022-12-16 10:15:33,850:INFO:  explainerdashboard: Not installed
2022-12-16 10:15:33,850:INFO:             autoviz: Not installed
2022-12-16 10:15:33,850:INFO:           fairlearn: Not installed
2022-12-16 10:15:33,850:INFO:             xgboost: Not installed
2022-12-16 10:15:33,850:INFO:            catboost: Not installed
2022-12-16 10:15:33,850:INFO:              kmodes: Not installed
2022-12-16 10:15:33,850:INFO:             mlxtend: Not installed
2022-12-16 10:15:33,850:INFO:       statsforecast: Not installed
2022-12-16 10:15:33,850:INFO:        tune_sklearn: Not installed
2022-12-16 10:15:33,850:INFO:                 ray: Not installed
2022-12-16 10:15:33,850:INFO:            hyperopt: Not installed
2022-12-16 10:15:33,851:INFO:              optuna: Not installed
2022-12-16 10:15:33,851:INFO:               skopt: Not installed
2022-12-16 10:15:33,851:INFO:              mlflow: Not installed
2022-12-16 10:15:33,851:INFO:              gradio: Not installed
2022-12-16 10:15:33,851:INFO:             fastapi: Not installed
2022-12-16 10:15:33,851:INFO:             uvicorn: Not installed
2022-12-16 10:15:33,851:INFO:              m2cgen: Not installed
2022-12-16 10:15:33,851:INFO:           evidently: Not installed
2022-12-16 10:15:33,851:INFO:                nltk: Not installed
2022-12-16 10:15:33,851:INFO:            pyLDAvis: Not installed
2022-12-16 10:15:33,851:INFO:              gensim: Not installed
2022-12-16 10:15:33,851:INFO:               spacy: Not installed
2022-12-16 10:15:33,851:INFO:           wordcloud: Not installed
2022-12-16 10:15:33,851:INFO:            textblob: Not installed
2022-12-16 10:15:33,851:INFO:               fugue: Not installed
2022-12-16 10:15:33,851:INFO:           streamlit: 1.15.2
2022-12-16 10:15:33,851:INFO:             prophet: Not installed
2022-12-16 10:15:33,851:INFO:None
2022-12-16 10:15:33,852:INFO:Set up data.
2022-12-16 10:15:33,859:INFO:Set up train/test split.
2022-12-16 10:15:33,864:INFO:Set up index.
2022-12-16 10:15:33,864:INFO:Set up folding strategy.
2022-12-16 10:15:33,864:INFO:Assigning column types.
2022-12-16 10:15:33,868:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-12-16 10:15:33,869:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-12-16 10:15:33,876:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-16 10:15:33,882:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-16 10:15:33,959:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-16 10:15:34,009:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-16 10:15:34,009:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:15:34,087:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:15:34,088:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-12-16 10:15:34,093:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-16 10:15:34,098:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-16 10:15:34,159:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-16 10:15:34,207:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-16 10:15:34,208:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:15:34,208:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:15:34,208:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-12-16 10:15:34,214:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-16 10:15:34,218:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-16 10:15:34,279:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-16 10:15:34,331:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-16 10:15:34,331:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:15:34,332:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:15:34,336:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-16 10:15:34,340:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-16 10:15:34,397:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-16 10:15:34,444:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-16 10:15:34,445:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:15:34,445:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:15:34,445:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-12-16 10:15:34,455:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-16 10:15:34,521:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-16 10:15:34,571:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-16 10:15:34,571:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:15:34,571:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:15:34,581:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-16 10:15:34,645:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-16 10:15:34,696:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-16 10:15:34,697:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:15:34,697:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:15:34,698:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-12-16 10:15:34,772:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-16 10:15:34,850:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-16 10:15:34,851:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:15:34,852:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:15:34,987:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-16 10:15:35,082:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-16 10:15:35,083:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:15:35,083:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:15:35,084:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-12-16 10:15:35,181:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-16 10:15:35,266:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:15:35,267:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:15:35,395:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-16 10:15:35,479:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:15:35,479:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:15:35,479:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-12-16 10:15:35,638:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:15:35,639:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:15:35,800:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:15:35,801:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:15:35,804:INFO:Preparing preprocessing pipeline...
2022-12-16 10:15:35,805:INFO:Set up simple imputation.
2022-12-16 10:15:35,805:INFO:Set up variance threshold.
2022-12-16 10:15:35,908:INFO:Finished creating preprocessing pipeline.
2022-12-16 10:15:35,920:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\S_05_\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Unnamed: 0', 'radio', 'newspaper',
                                             'sales'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))])
2022-12-16 10:15:35,920:INFO:Creating final display dataframe.
2022-12-16 10:15:36,278:INFO:Setup display_container:                Description             Value
0               Session id              3331
1                   Target                TV
2              Target type        Regression
3               Data shape          (200, 5)
4         Train data shape          (139, 5)
5          Test data shape           (61, 5)
6         Numeric features                 4
7               Preprocess              True
8          Imputation type            simple
9       Numeric imputation              mean
10  Categorical imputation          constant
11  Low variance threshold                 0
12          Fold Generator             KFold
13             Fold Number                10
14                CPU Jobs                -1
15                 Use GPU             False
16          Log Experiment             False
17         Experiment Name  reg-default-name
18                     USI              05bf
2022-12-16 10:15:36,516:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:15:36,516:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:15:36,658:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:15:36,659:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:15:36,673:INFO:setup() successfully completed in 2.83s...............
2022-12-16 10:15:36,737:INFO:Initializing compare_models()
2022-12-16 10:15:36,737:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000228062CF6D0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000228062CF6D0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-12-16 10:15:36,738:INFO:Checking exceptions
2022-12-16 10:15:36,745:INFO:Preparing display monitor
2022-12-16 10:15:36,760:INFO:Initializing Linear Regression
2022-12-16 10:15:36,761:INFO:Total runtime is 1.6629695892333984e-05 minutes
2022-12-16 10:15:36,762:INFO:SubProcess create_model() called ==================================
2022-12-16 10:15:36,764:INFO:Initializing create_model()
2022-12-16 10:15:36,764:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000228062CF6D0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000228073FD210>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:15:36,764:INFO:Checking exceptions
2022-12-16 10:15:36,767:INFO:Importing libraries
2022-12-16 10:15:36,767:INFO:Copying training dataset
2022-12-16 10:15:36,771:INFO:Defining folds
2022-12-16 10:15:36,772:INFO:Declaring metric variables
2022-12-16 10:15:36,775:INFO:Importing untrained model
2022-12-16 10:15:36,780:INFO:Linear Regression Imported successfully
2022-12-16 10:15:36,782:INFO:Starting cross validation
2022-12-16 10:15:36,809:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:15:47,789:INFO:Calculating mean and std
2022-12-16 10:15:47,791:INFO:Creating metrics dataframe
2022-12-16 10:15:47,796:INFO:Uploading results into container
2022-12-16 10:15:47,797:INFO:Uploading model into container now
2022-12-16 10:15:47,797:INFO:master_model_container: 1
2022-12-16 10:15:47,797:INFO:display_container: 2
2022-12-16 10:15:47,798:INFO:LinearRegression(n_jobs=-1)
2022-12-16 10:15:47,798:INFO:create_model() successfully completed......................................
2022-12-16 10:15:47,971:INFO:SubProcess create_model() end ==================================
2022-12-16 10:15:47,971:INFO:Creating metrics dataframe
2022-12-16 10:15:47,984:INFO:Initializing Lasso Regression
2022-12-16 10:15:47,984:INFO:Total runtime is 0.1870760718981425 minutes
2022-12-16 10:15:47,984:INFO:SubProcess create_model() called ==================================
2022-12-16 10:15:47,985:INFO:Initializing create_model()
2022-12-16 10:15:47,985:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000228062CF6D0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000228073FD210>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:15:47,985:INFO:Checking exceptions
2022-12-16 10:15:47,989:INFO:Importing libraries
2022-12-16 10:15:47,989:INFO:Copying training dataset
2022-12-16 10:15:47,994:INFO:Defining folds
2022-12-16 10:15:47,994:INFO:Declaring metric variables
2022-12-16 10:15:47,995:INFO:Importing untrained model
2022-12-16 10:15:47,995:INFO:Lasso Regression Imported successfully
2022-12-16 10:15:47,996:INFO:Starting cross validation
2022-12-16 10:15:47,997:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:15:48,275:INFO:Calculating mean and std
2022-12-16 10:15:48,275:INFO:Creating metrics dataframe
2022-12-16 10:15:48,281:INFO:Uploading results into container
2022-12-16 10:15:48,283:INFO:Uploading model into container now
2022-12-16 10:15:48,283:INFO:master_model_container: 2
2022-12-16 10:15:48,283:INFO:display_container: 2
2022-12-16 10:15:48,284:INFO:Lasso(random_state=3331)
2022-12-16 10:15:48,284:INFO:create_model() successfully completed......................................
2022-12-16 10:15:48,441:INFO:SubProcess create_model() end ==================================
2022-12-16 10:15:48,441:INFO:Creating metrics dataframe
2022-12-16 10:15:48,449:INFO:Initializing Ridge Regression
2022-12-16 10:15:48,449:INFO:Total runtime is 0.19482919375101723 minutes
2022-12-16 10:15:48,449:INFO:SubProcess create_model() called ==================================
2022-12-16 10:15:48,449:INFO:Initializing create_model()
2022-12-16 10:15:48,450:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000228062CF6D0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000228073FD210>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:15:48,450:INFO:Checking exceptions
2022-12-16 10:15:48,452:INFO:Importing libraries
2022-12-16 10:15:48,452:INFO:Copying training dataset
2022-12-16 10:15:48,455:INFO:Defining folds
2022-12-16 10:15:48,455:INFO:Declaring metric variables
2022-12-16 10:15:48,456:INFO:Importing untrained model
2022-12-16 10:15:48,456:INFO:Ridge Regression Imported successfully
2022-12-16 10:15:48,457:INFO:Starting cross validation
2022-12-16 10:15:48,458:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:15:48,622:INFO:Calculating mean and std
2022-12-16 10:15:48,623:INFO:Creating metrics dataframe
2022-12-16 10:15:48,626:INFO:Uploading results into container
2022-12-16 10:15:48,626:INFO:Uploading model into container now
2022-12-16 10:15:48,627:INFO:master_model_container: 3
2022-12-16 10:15:48,627:INFO:display_container: 2
2022-12-16 10:15:48,627:INFO:Ridge(random_state=3331)
2022-12-16 10:15:48,627:INFO:create_model() successfully completed......................................
2022-12-16 10:15:48,798:INFO:SubProcess create_model() end ==================================
2022-12-16 10:15:48,799:INFO:Creating metrics dataframe
2022-12-16 10:15:48,815:INFO:Initializing Elastic Net
2022-12-16 10:15:48,816:INFO:Total runtime is 0.20093766848246256 minutes
2022-12-16 10:15:48,816:INFO:SubProcess create_model() called ==================================
2022-12-16 10:15:48,817:INFO:Initializing create_model()
2022-12-16 10:15:48,817:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000228062CF6D0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000228073FD210>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:15:48,818:INFO:Checking exceptions
2022-12-16 10:15:48,822:INFO:Importing libraries
2022-12-16 10:15:48,823:INFO:Copying training dataset
2022-12-16 10:15:48,831:INFO:Defining folds
2022-12-16 10:15:48,831:INFO:Declaring metric variables
2022-12-16 10:15:48,832:INFO:Importing untrained model
2022-12-16 10:15:48,832:INFO:Elastic Net Imported successfully
2022-12-16 10:15:48,833:INFO:Starting cross validation
2022-12-16 10:15:48,834:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:15:49,008:INFO:Calculating mean and std
2022-12-16 10:15:49,010:INFO:Creating metrics dataframe
2022-12-16 10:15:49,016:INFO:Uploading results into container
2022-12-16 10:15:49,018:INFO:Uploading model into container now
2022-12-16 10:15:49,019:INFO:master_model_container: 4
2022-12-16 10:15:49,019:INFO:display_container: 2
2022-12-16 10:15:49,020:INFO:ElasticNet(random_state=3331)
2022-12-16 10:15:49,020:INFO:create_model() successfully completed......................................
2022-12-16 10:15:49,186:INFO:SubProcess create_model() end ==================================
2022-12-16 10:15:49,186:INFO:Creating metrics dataframe
2022-12-16 10:15:49,190:INFO:Initializing Least Angle Regression
2022-12-16 10:15:49,190:INFO:Total runtime is 0.20716765721638997 minutes
2022-12-16 10:15:49,191:INFO:SubProcess create_model() called ==================================
2022-12-16 10:15:49,191:INFO:Initializing create_model()
2022-12-16 10:15:49,191:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000228062CF6D0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000228073FD210>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:15:49,191:INFO:Checking exceptions
2022-12-16 10:15:49,192:INFO:Importing libraries
2022-12-16 10:15:49,193:INFO:Copying training dataset
2022-12-16 10:15:49,195:INFO:Defining folds
2022-12-16 10:15:49,195:INFO:Declaring metric variables
2022-12-16 10:15:49,195:INFO:Importing untrained model
2022-12-16 10:15:49,195:INFO:Least Angle Regression Imported successfully
2022-12-16 10:15:49,196:INFO:Starting cross validation
2022-12-16 10:15:49,196:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:15:49,258:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:15:49,262:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:15:49,275:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:15:49,282:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:15:49,303:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:15:49,304:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:15:49,326:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:15:49,332:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:15:49,333:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:15:49,340:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:15:49,360:INFO:Calculating mean and std
2022-12-16 10:15:49,360:INFO:Creating metrics dataframe
2022-12-16 10:15:49,365:INFO:Uploading results into container
2022-12-16 10:15:49,366:INFO:Uploading model into container now
2022-12-16 10:15:49,367:INFO:master_model_container: 5
2022-12-16 10:15:49,367:INFO:display_container: 2
2022-12-16 10:15:49,367:INFO:Lars(random_state=3331)
2022-12-16 10:15:49,367:INFO:create_model() successfully completed......................................
2022-12-16 10:15:49,507:INFO:SubProcess create_model() end ==================================
2022-12-16 10:15:49,507:INFO:Creating metrics dataframe
2022-12-16 10:15:49,514:INFO:Initializing Lasso Least Angle Regression
2022-12-16 10:15:49,514:INFO:Total runtime is 0.21258090337117513 minutes
2022-12-16 10:15:49,515:INFO:SubProcess create_model() called ==================================
2022-12-16 10:15:49,515:INFO:Initializing create_model()
2022-12-16 10:15:49,515:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000228062CF6D0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000228073FD210>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:15:49,515:INFO:Checking exceptions
2022-12-16 10:15:49,517:INFO:Importing libraries
2022-12-16 10:15:49,517:INFO:Copying training dataset
2022-12-16 10:15:49,520:INFO:Defining folds
2022-12-16 10:15:49,521:INFO:Declaring metric variables
2022-12-16 10:15:49,521:INFO:Importing untrained model
2022-12-16 10:15:49,522:INFO:Lasso Least Angle Regression Imported successfully
2022-12-16 10:15:49,523:INFO:Starting cross validation
2022-12-16 10:15:49,526:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:15:49,593:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-16 10:15:49,611:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-16 10:15:49,615:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-16 10:15:49,627:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-16 10:15:49,679:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-16 10:15:49,668:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-16 10:15:49,760:INFO:Calculating mean and std
2022-12-16 10:15:49,761:INFO:Creating metrics dataframe
2022-12-16 10:15:49,767:INFO:Uploading results into container
2022-12-16 10:15:49,768:INFO:Uploading model into container now
2022-12-16 10:15:49,769:INFO:master_model_container: 6
2022-12-16 10:15:49,769:INFO:display_container: 2
2022-12-16 10:15:49,769:INFO:LassoLars(random_state=3331)
2022-12-16 10:15:49,769:INFO:create_model() successfully completed......................................
2022-12-16 10:15:49,900:INFO:SubProcess create_model() end ==================================
2022-12-16 10:15:49,900:INFO:Creating metrics dataframe
2022-12-16 10:15:49,905:INFO:Initializing Orthogonal Matching Pursuit
2022-12-16 10:15:49,905:INFO:Total runtime is 0.21909639835357667 minutes
2022-12-16 10:15:49,906:INFO:SubProcess create_model() called ==================================
2022-12-16 10:15:49,906:INFO:Initializing create_model()
2022-12-16 10:15:49,906:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000228062CF6D0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000228073FD210>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:15:49,906:INFO:Checking exceptions
2022-12-16 10:15:49,908:INFO:Importing libraries
2022-12-16 10:15:49,908:INFO:Copying training dataset
2022-12-16 10:15:49,910:INFO:Defining folds
2022-12-16 10:15:49,910:INFO:Declaring metric variables
2022-12-16 10:15:49,910:INFO:Importing untrained model
2022-12-16 10:15:49,910:INFO:Orthogonal Matching Pursuit Imported successfully
2022-12-16 10:15:49,911:INFO:Starting cross validation
2022-12-16 10:15:49,911:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:15:49,949:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:15:49,957:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:15:49,969:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:15:49,983:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:15:49,999:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:15:50,013:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:15:50,027:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:15:50,037:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:15:50,049:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:15:50,056:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:15:50,069:INFO:Calculating mean and std
2022-12-16 10:15:50,070:INFO:Creating metrics dataframe
2022-12-16 10:15:50,074:INFO:Uploading results into container
2022-12-16 10:15:50,075:INFO:Uploading model into container now
2022-12-16 10:15:50,075:INFO:master_model_container: 7
2022-12-16 10:15:50,075:INFO:display_container: 2
2022-12-16 10:15:50,076:INFO:OrthogonalMatchingPursuit()
2022-12-16 10:15:50,076:INFO:create_model() successfully completed......................................
2022-12-16 10:15:50,183:INFO:SubProcess create_model() end ==================================
2022-12-16 10:15:50,183:INFO:Creating metrics dataframe
2022-12-16 10:15:50,187:INFO:Initializing Bayesian Ridge
2022-12-16 10:15:50,187:INFO:Total runtime is 0.22379294633865357 minutes
2022-12-16 10:15:50,187:INFO:SubProcess create_model() called ==================================
2022-12-16 10:15:50,187:INFO:Initializing create_model()
2022-12-16 10:15:50,187:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000228062CF6D0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000228073FD210>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:15:50,187:INFO:Checking exceptions
2022-12-16 10:15:50,189:INFO:Importing libraries
2022-12-16 10:15:50,189:INFO:Copying training dataset
2022-12-16 10:15:50,191:INFO:Defining folds
2022-12-16 10:15:50,191:INFO:Declaring metric variables
2022-12-16 10:15:50,192:INFO:Importing untrained model
2022-12-16 10:15:50,192:INFO:Bayesian Ridge Imported successfully
2022-12-16 10:15:50,193:INFO:Starting cross validation
2022-12-16 10:15:50,194:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:15:50,320:INFO:Calculating mean and std
2022-12-16 10:15:50,321:INFO:Creating metrics dataframe
2022-12-16 10:15:50,324:INFO:Uploading results into container
2022-12-16 10:15:50,324:INFO:Uploading model into container now
2022-12-16 10:15:50,324:INFO:master_model_container: 8
2022-12-16 10:15:50,324:INFO:display_container: 2
2022-12-16 10:15:50,325:INFO:BayesianRidge()
2022-12-16 10:15:50,325:INFO:create_model() successfully completed......................................
2022-12-16 10:15:50,432:INFO:SubProcess create_model() end ==================================
2022-12-16 10:15:50,432:INFO:Creating metrics dataframe
2022-12-16 10:15:50,436:INFO:Initializing Passive Aggressive Regressor
2022-12-16 10:15:50,436:INFO:Total runtime is 0.22794756094614665 minutes
2022-12-16 10:15:50,436:INFO:SubProcess create_model() called ==================================
2022-12-16 10:15:50,436:INFO:Initializing create_model()
2022-12-16 10:15:50,437:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000228062CF6D0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000228073FD210>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:15:50,437:INFO:Checking exceptions
2022-12-16 10:15:50,438:INFO:Importing libraries
2022-12-16 10:15:50,438:INFO:Copying training dataset
2022-12-16 10:15:50,440:INFO:Defining folds
2022-12-16 10:15:50,440:INFO:Declaring metric variables
2022-12-16 10:15:50,440:INFO:Importing untrained model
2022-12-16 10:15:50,440:INFO:Passive Aggressive Regressor Imported successfully
2022-12-16 10:15:50,442:INFO:Starting cross validation
2022-12-16 10:15:50,442:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:15:50,586:INFO:Calculating mean and std
2022-12-16 10:15:50,586:INFO:Creating metrics dataframe
2022-12-16 10:15:50,590:INFO:Uploading results into container
2022-12-16 10:15:50,590:INFO:Uploading model into container now
2022-12-16 10:15:50,591:INFO:master_model_container: 9
2022-12-16 10:15:50,591:INFO:display_container: 2
2022-12-16 10:15:50,591:INFO:PassiveAggressiveRegressor(random_state=3331)
2022-12-16 10:15:50,591:INFO:create_model() successfully completed......................................
2022-12-16 10:15:50,700:INFO:SubProcess create_model() end ==================================
2022-12-16 10:15:50,700:INFO:Creating metrics dataframe
2022-12-16 10:15:50,704:INFO:Initializing Huber Regressor
2022-12-16 10:15:50,704:INFO:Total runtime is 0.2324029843012492 minutes
2022-12-16 10:15:50,704:INFO:SubProcess create_model() called ==================================
2022-12-16 10:15:50,704:INFO:Initializing create_model()
2022-12-16 10:15:50,705:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000228062CF6D0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000228073FD210>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:15:50,705:INFO:Checking exceptions
2022-12-16 10:15:50,706:INFO:Importing libraries
2022-12-16 10:15:50,706:INFO:Copying training dataset
2022-12-16 10:15:50,708:INFO:Defining folds
2022-12-16 10:15:50,708:INFO:Declaring metric variables
2022-12-16 10:15:50,708:INFO:Importing untrained model
2022-12-16 10:15:50,709:INFO:Huber Regressor Imported successfully
2022-12-16 10:15:50,709:INFO:Starting cross validation
2022-12-16 10:15:50,710:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:15:50,867:INFO:Calculating mean and std
2022-12-16 10:15:50,870:INFO:Creating metrics dataframe
2022-12-16 10:15:50,875:INFO:Uploading results into container
2022-12-16 10:15:50,876:INFO:Uploading model into container now
2022-12-16 10:15:50,876:INFO:master_model_container: 10
2022-12-16 10:15:50,876:INFO:display_container: 2
2022-12-16 10:15:50,877:INFO:HuberRegressor()
2022-12-16 10:15:50,877:INFO:create_model() successfully completed......................................
2022-12-16 10:15:50,982:INFO:SubProcess create_model() end ==================================
2022-12-16 10:15:50,982:INFO:Creating metrics dataframe
2022-12-16 10:15:50,987:INFO:Initializing K Neighbors Regressor
2022-12-16 10:15:50,987:INFO:Total runtime is 0.23712995847066246 minutes
2022-12-16 10:15:50,987:INFO:SubProcess create_model() called ==================================
2022-12-16 10:15:50,987:INFO:Initializing create_model()
2022-12-16 10:15:50,988:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000228062CF6D0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000228073FD210>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:15:50,988:INFO:Checking exceptions
2022-12-16 10:15:50,989:INFO:Importing libraries
2022-12-16 10:15:50,989:INFO:Copying training dataset
2022-12-16 10:15:50,991:INFO:Defining folds
2022-12-16 10:15:50,991:INFO:Declaring metric variables
2022-12-16 10:15:50,992:INFO:Importing untrained model
2022-12-16 10:15:50,992:INFO:K Neighbors Regressor Imported successfully
2022-12-16 10:15:50,992:INFO:Starting cross validation
2022-12-16 10:15:50,993:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:15:51,148:INFO:Calculating mean and std
2022-12-16 10:15:51,148:INFO:Creating metrics dataframe
2022-12-16 10:15:51,151:INFO:Uploading results into container
2022-12-16 10:15:51,152:INFO:Uploading model into container now
2022-12-16 10:15:51,152:INFO:master_model_container: 11
2022-12-16 10:15:51,152:INFO:display_container: 2
2022-12-16 10:15:51,152:INFO:KNeighborsRegressor(n_jobs=-1)
2022-12-16 10:15:51,152:INFO:create_model() successfully completed......................................
2022-12-16 10:15:51,258:INFO:SubProcess create_model() end ==================================
2022-12-16 10:15:51,258:INFO:Creating metrics dataframe
2022-12-16 10:15:51,264:INFO:Initializing Decision Tree Regressor
2022-12-16 10:15:51,264:INFO:Total runtime is 0.24174463351567588 minutes
2022-12-16 10:15:51,264:INFO:SubProcess create_model() called ==================================
2022-12-16 10:15:51,264:INFO:Initializing create_model()
2022-12-16 10:15:51,264:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000228062CF6D0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000228073FD210>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:15:51,264:INFO:Checking exceptions
2022-12-16 10:15:51,266:INFO:Importing libraries
2022-12-16 10:15:51,266:INFO:Copying training dataset
2022-12-16 10:15:51,268:INFO:Defining folds
2022-12-16 10:15:51,268:INFO:Declaring metric variables
2022-12-16 10:15:51,269:INFO:Importing untrained model
2022-12-16 10:15:51,269:INFO:Decision Tree Regressor Imported successfully
2022-12-16 10:15:51,269:INFO:Starting cross validation
2022-12-16 10:15:51,270:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:15:51,407:INFO:Calculating mean and std
2022-12-16 10:15:51,408:INFO:Creating metrics dataframe
2022-12-16 10:15:51,411:INFO:Uploading results into container
2022-12-16 10:15:51,411:INFO:Uploading model into container now
2022-12-16 10:15:51,411:INFO:master_model_container: 12
2022-12-16 10:15:51,412:INFO:display_container: 2
2022-12-16 10:15:51,412:INFO:DecisionTreeRegressor(random_state=3331)
2022-12-16 10:15:51,412:INFO:create_model() successfully completed......................................
2022-12-16 10:15:51,519:INFO:SubProcess create_model() end ==================================
2022-12-16 10:15:51,520:INFO:Creating metrics dataframe
2022-12-16 10:15:51,524:INFO:Initializing Random Forest Regressor
2022-12-16 10:15:51,524:INFO:Total runtime is 0.24607998927434288 minutes
2022-12-16 10:15:51,524:INFO:SubProcess create_model() called ==================================
2022-12-16 10:15:51,524:INFO:Initializing create_model()
2022-12-16 10:15:51,524:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000228062CF6D0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000228073FD210>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:15:51,524:INFO:Checking exceptions
2022-12-16 10:15:51,526:INFO:Importing libraries
2022-12-16 10:15:51,526:INFO:Copying training dataset
2022-12-16 10:15:51,528:INFO:Defining folds
2022-12-16 10:15:51,528:INFO:Declaring metric variables
2022-12-16 10:15:51,528:INFO:Importing untrained model
2022-12-16 10:15:51,528:INFO:Random Forest Regressor Imported successfully
2022-12-16 10:15:51,529:INFO:Starting cross validation
2022-12-16 10:15:51,529:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:15:52,130:INFO:Calculating mean and std
2022-12-16 10:15:52,130:INFO:Creating metrics dataframe
2022-12-16 10:15:52,133:INFO:Uploading results into container
2022-12-16 10:15:52,134:INFO:Uploading model into container now
2022-12-16 10:15:52,134:INFO:master_model_container: 13
2022-12-16 10:15:52,135:INFO:display_container: 2
2022-12-16 10:15:52,135:INFO:RandomForestRegressor(n_jobs=-1, random_state=3331)
2022-12-16 10:15:52,135:INFO:create_model() successfully completed......................................
2022-12-16 10:15:52,242:INFO:SubProcess create_model() end ==================================
2022-12-16 10:15:52,244:INFO:Creating metrics dataframe
2022-12-16 10:15:52,321:INFO:Initializing Extra Trees Regressor
2022-12-16 10:15:52,322:INFO:Total runtime is 0.2593675573666891 minutes
2022-12-16 10:15:52,325:INFO:SubProcess create_model() called ==================================
2022-12-16 10:15:52,328:INFO:Initializing create_model()
2022-12-16 10:15:52,329:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000228062CF6D0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000228073FD210>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:15:52,330:INFO:Checking exceptions
2022-12-16 10:15:52,347:INFO:Importing libraries
2022-12-16 10:15:52,348:INFO:Copying training dataset
2022-12-16 10:15:52,379:INFO:Defining folds
2022-12-16 10:15:52,380:INFO:Declaring metric variables
2022-12-16 10:15:52,384:INFO:Importing untrained model
2022-12-16 10:15:52,396:INFO:Extra Trees Regressor Imported successfully
2022-12-16 10:15:52,401:INFO:Starting cross validation
2022-12-16 10:15:52,417:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:15:54,139:INFO:Calculating mean and std
2022-12-16 10:15:54,140:INFO:Creating metrics dataframe
2022-12-16 10:15:54,143:INFO:Uploading results into container
2022-12-16 10:15:54,143:INFO:Uploading model into container now
2022-12-16 10:15:54,143:INFO:master_model_container: 14
2022-12-16 10:15:54,144:INFO:display_container: 2
2022-12-16 10:15:54,144:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=3331)
2022-12-16 10:15:54,144:INFO:create_model() successfully completed......................................
2022-12-16 10:15:54,247:INFO:SubProcess create_model() end ==================================
2022-12-16 10:15:54,247:INFO:Creating metrics dataframe
2022-12-16 10:15:54,253:INFO:Initializing AdaBoost Regressor
2022-12-16 10:15:54,253:INFO:Total runtime is 0.29155563116073613 minutes
2022-12-16 10:15:54,253:INFO:SubProcess create_model() called ==================================
2022-12-16 10:15:54,253:INFO:Initializing create_model()
2022-12-16 10:15:54,253:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000228062CF6D0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000228073FD210>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:15:54,253:INFO:Checking exceptions
2022-12-16 10:15:54,255:INFO:Importing libraries
2022-12-16 10:15:54,255:INFO:Copying training dataset
2022-12-16 10:15:54,258:INFO:Defining folds
2022-12-16 10:15:54,258:INFO:Declaring metric variables
2022-12-16 10:15:54,258:INFO:Importing untrained model
2022-12-16 10:15:54,258:INFO:AdaBoost Regressor Imported successfully
2022-12-16 10:15:54,259:INFO:Starting cross validation
2022-12-16 10:15:54,260:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:15:54,579:INFO:Calculating mean and std
2022-12-16 10:15:54,591:INFO:Creating metrics dataframe
2022-12-16 10:15:54,595:INFO:Uploading results into container
2022-12-16 10:15:54,597:INFO:Uploading model into container now
2022-12-16 10:15:54,597:INFO:master_model_container: 15
2022-12-16 10:15:54,597:INFO:display_container: 2
2022-12-16 10:15:54,597:INFO:AdaBoostRegressor(random_state=3331)
2022-12-16 10:15:54,597:INFO:create_model() successfully completed......................................
2022-12-16 10:15:54,703:INFO:SubProcess create_model() end ==================================
2022-12-16 10:15:54,703:INFO:Creating metrics dataframe
2022-12-16 10:15:54,707:INFO:Initializing Gradient Boosting Regressor
2022-12-16 10:15:54,707:INFO:Total runtime is 0.299130396048228 minutes
2022-12-16 10:15:54,708:INFO:SubProcess create_model() called ==================================
2022-12-16 10:15:54,708:INFO:Initializing create_model()
2022-12-16 10:15:54,708:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000228062CF6D0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000228073FD210>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:15:54,708:INFO:Checking exceptions
2022-12-16 10:15:54,709:INFO:Importing libraries
2022-12-16 10:15:54,709:INFO:Copying training dataset
2022-12-16 10:15:54,711:INFO:Defining folds
2022-12-16 10:15:54,711:INFO:Declaring metric variables
2022-12-16 10:15:54,711:INFO:Importing untrained model
2022-12-16 10:15:54,711:INFO:Gradient Boosting Regressor Imported successfully
2022-12-16 10:15:54,712:INFO:Starting cross validation
2022-12-16 10:15:54,712:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:15:54,957:INFO:Calculating mean and std
2022-12-16 10:15:54,957:INFO:Creating metrics dataframe
2022-12-16 10:15:54,962:INFO:Uploading results into container
2022-12-16 10:15:54,962:INFO:Uploading model into container now
2022-12-16 10:15:54,963:INFO:master_model_container: 16
2022-12-16 10:15:54,963:INFO:display_container: 2
2022-12-16 10:15:54,963:INFO:GradientBoostingRegressor(random_state=3331)
2022-12-16 10:15:54,963:INFO:create_model() successfully completed......................................
2022-12-16 10:15:55,073:INFO:SubProcess create_model() end ==================================
2022-12-16 10:15:55,073:INFO:Creating metrics dataframe
2022-12-16 10:15:55,077:INFO:Initializing Light Gradient Boosting Machine
2022-12-16 10:15:55,077:INFO:Total runtime is 0.3052886883417766 minutes
2022-12-16 10:15:55,077:INFO:SubProcess create_model() called ==================================
2022-12-16 10:15:55,078:INFO:Initializing create_model()
2022-12-16 10:15:55,078:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000228062CF6D0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000228073FD210>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:15:55,078:INFO:Checking exceptions
2022-12-16 10:15:55,079:INFO:Importing libraries
2022-12-16 10:15:55,079:INFO:Copying training dataset
2022-12-16 10:15:55,082:INFO:Defining folds
2022-12-16 10:15:55,082:INFO:Declaring metric variables
2022-12-16 10:15:55,082:INFO:Importing untrained model
2022-12-16 10:15:55,083:INFO:Light Gradient Boosting Machine Imported successfully
2022-12-16 10:15:55,083:INFO:Starting cross validation
2022-12-16 10:15:55,084:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:15:55,251:WARNING:create_model() for lightgbm raised an exception or returned all 0.0, trying without fit_kwargs:
2022-12-16 10:15:55,253:WARNING:Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 793, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1522, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1114, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 216, in fit
    _fit_one(self._final_estimator, X, y, **fit_params_last_step)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 54, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\lightgbm\sklearn.py", line 895, in fit
    super().fit(X, y, sample_weight=sample_weight, init_score=init_score,
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\lightgbm\sklearn.py", line 748, in fit
    self._Booster = train(
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\lightgbm\engine.py", line 271, in train
    booster = Booster(params=params, train_set=train_set)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\lightgbm\basic.py", line 2605, in __init__
    train_set.construct()
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\lightgbm\basic.py", line 1815, in construct
    self._lazy_init(self.data, label=self.label,
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\lightgbm\basic.py", line 1573, in _lazy_init
    return self.set_feature_name(feature_name)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\lightgbm\basic.py", line 2142, in set_feature_name
    _safe_call(_LIB.LGBM_DatasetSetFeatureNames(
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\lightgbm\basic.py", line 125, in _safe_call
    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))
lightgbm.basic.LightGBMError: Do not support special JSON characters in feature name.


2022-12-16 10:15:55,254:INFO:Initializing create_model()
2022-12-16 10:15:55,254:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000228062CF6D0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000228073FD210>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:15:55,254:INFO:Checking exceptions
2022-12-16 10:15:55,257:INFO:Importing libraries
2022-12-16 10:15:55,258:INFO:Copying training dataset
2022-12-16 10:15:55,262:INFO:Defining folds
2022-12-16 10:15:55,263:INFO:Declaring metric variables
2022-12-16 10:15:55,263:INFO:Importing untrained model
2022-12-16 10:15:55,263:INFO:Light Gradient Boosting Machine Imported successfully
2022-12-16 10:15:55,263:INFO:Starting cross validation
2022-12-16 10:15:55,264:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:15:55,389:ERROR:create_model() for lightgbm raised an exception or returned all 0.0:
2022-12-16 10:15:55,390:ERROR:Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 793, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1522, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1114, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 216, in fit
    _fit_one(self._final_estimator, X, y, **fit_params_last_step)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 54, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\lightgbm\sklearn.py", line 895, in fit
    super().fit(X, y, sample_weight=sample_weight, init_score=init_score,
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\lightgbm\sklearn.py", line 748, in fit
    self._Booster = train(
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\lightgbm\engine.py", line 271, in train
    booster = Booster(params=params, train_set=train_set)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\lightgbm\basic.py", line 2605, in __init__
    train_set.construct()
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\lightgbm\basic.py", line 1815, in construct
    self._lazy_init(self.data, label=self.label,
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\lightgbm\basic.py", line 1573, in _lazy_init
    return self.set_feature_name(feature_name)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\lightgbm\basic.py", line 2142, in set_feature_name
    _safe_call(_LIB.LGBM_DatasetSetFeatureNames(
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\lightgbm\basic.py", line 125, in _safe_call
    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))
lightgbm.basic.LightGBMError: Do not support special JSON characters in feature name.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 809, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1522, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1114, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 216, in fit
    _fit_one(self._final_estimator, X, y, **fit_params_last_step)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 54, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\lightgbm\sklearn.py", line 895, in fit
    super().fit(X, y, sample_weight=sample_weight, init_score=init_score,
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\lightgbm\sklearn.py", line 748, in fit
    self._Booster = train(
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\lightgbm\engine.py", line 271, in train
    booster = Booster(params=params, train_set=train_set)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\lightgbm\basic.py", line 2605, in __init__
    train_set.construct()
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\lightgbm\basic.py", line 1815, in construct
    self._lazy_init(self.data, label=self.label,
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\lightgbm\basic.py", line 1573, in _lazy_init
    return self.set_feature_name(feature_name)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\lightgbm\basic.py", line 2142, in set_feature_name
    _safe_call(_LIB.LGBM_DatasetSetFeatureNames(
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\lightgbm\basic.py", line 125, in _safe_call
    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))
lightgbm.basic.LightGBMError: Do not support special JSON characters in feature name.


2022-12-16 10:15:55,390:INFO:Initializing Dummy Regressor
2022-12-16 10:15:55,391:INFO:Total runtime is 0.31052042245864875 minutes
2022-12-16 10:15:55,391:INFO:SubProcess create_model() called ==================================
2022-12-16 10:15:55,392:INFO:Initializing create_model()
2022-12-16 10:15:55,392:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000228062CF6D0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000228073FD210>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:15:55,392:INFO:Checking exceptions
2022-12-16 10:15:55,394:INFO:Importing libraries
2022-12-16 10:15:55,394:INFO:Copying training dataset
2022-12-16 10:15:55,398:INFO:Defining folds
2022-12-16 10:15:55,398:INFO:Declaring metric variables
2022-12-16 10:15:55,398:INFO:Importing untrained model
2022-12-16 10:15:55,398:INFO:Dummy Regressor Imported successfully
2022-12-16 10:15:55,399:INFO:Starting cross validation
2022-12-16 10:15:55,399:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:15:55,524:INFO:Calculating mean and std
2022-12-16 10:15:55,525:INFO:Creating metrics dataframe
2022-12-16 10:15:55,527:INFO:Uploading results into container
2022-12-16 10:15:55,528:INFO:Uploading model into container now
2022-12-16 10:15:55,528:INFO:master_model_container: 17
2022-12-16 10:15:55,528:INFO:display_container: 2
2022-12-16 10:15:55,528:INFO:DummyRegressor()
2022-12-16 10:15:55,529:INFO:create_model() successfully completed......................................
2022-12-16 10:15:55,629:INFO:SubProcess create_model() end ==================================
2022-12-16 10:15:55,629:INFO:Creating metrics dataframe
2022-12-16 10:15:55,635:INFO:Initializing create_model()
2022-12-16 10:15:55,635:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000228062CF6D0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=3331), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:15:55,635:INFO:Checking exceptions
2022-12-16 10:15:55,637:INFO:Importing libraries
2022-12-16 10:15:55,637:INFO:Copying training dataset
2022-12-16 10:15:55,638:INFO:Defining folds
2022-12-16 10:15:55,638:INFO:Declaring metric variables
2022-12-16 10:15:55,638:INFO:Importing untrained model
2022-12-16 10:15:55,638:INFO:Declaring custom model
2022-12-16 10:15:55,638:INFO:Extra Trees Regressor Imported successfully
2022-12-16 10:15:55,640:INFO:Cross validation set to False
2022-12-16 10:15:55,640:INFO:Fitting Model
2022-12-16 10:15:55,781:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=3331)
2022-12-16 10:15:55,781:INFO:create_model() successfully completed......................................
2022-12-16 10:15:55,901:INFO:master_model_container: 17
2022-12-16 10:15:55,901:INFO:display_container: 2
2022-12-16 10:15:55,902:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=3331)
2022-12-16 10:15:55,902:INFO:compare_models() successfully completed......................................
2022-12-16 10:17:04,322:INFO:PyCaret ClassificationExperiment
2022-12-16 10:17:04,322:INFO:Logging name: clf-default-name
2022-12-16 10:17:04,323:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2022-12-16 10:17:04,324:INFO:version 3.0.0.rc4
2022-12-16 10:17:04,324:INFO:Initializing setup()
2022-12-16 10:17:04,324:INFO:self.USI: 271a
2022-12-16 10:17:04,325:INFO:self.variable_keys: {'fix_imbalance', 'fold_groups_param', 'fold_shuffle_param', '_ml_usecase', 'display_container', 'n_jobs_param', 'exp_name_log', 'target_param', 'pipeline', 'seed', 'exp_id', '_all_models_internal', 'X_test', 'X_train', '_all_metrics', 'gpu_param', 'y_train', 'y_test', '_is_multiclass', 'y', 'logging_param', 'master_model_container', '_available_plots', 'html_param', 'X', '_all_models', 'memory', 'USI', 'log_plots_param', '_gpu_n_jobs_param', 'variable_keys', 'idx', 'fold_generator', 'data'}
2022-12-16 10:17:04,325:INFO:Checking environment
2022-12-16 10:17:04,325:INFO:python_version: 3.10.7
2022-12-16 10:17:04,325:INFO:python_build: ('tags/v3.10.7:6cc6b13', 'Sep  5 2022 14:08:36')
2022-12-16 10:17:04,325:INFO:machine: AMD64
2022-12-16 10:17:04,325:INFO:platform: Windows-10-10.0.22621-SP0
2022-12-16 10:17:04,326:INFO:Memory: svmem(total=8361132032, available=452751360, percent=94.6, used=7908380672, free=452751360)
2022-12-16 10:17:04,326:INFO:Physical Core: 4
2022-12-16 10:17:04,326:INFO:Logical Core: 8
2022-12-16 10:17:04,326:INFO:Checking libraries
2022-12-16 10:17:04,326:INFO:System:
2022-12-16 10:17:04,326:INFO:    python: 3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]
2022-12-16 10:17:04,326:INFO:executable: C:\Users\S_05_\AppData\Local\Programs\Python\Python310\python.exe
2022-12-16 10:17:04,326:INFO:   machine: Windows-10-10.0.22621-SP0
2022-12-16 10:17:04,326:INFO:PyCaret required dependencies:
2022-12-16 10:17:04,326:INFO:                 pip: 22.3.1
2022-12-16 10:17:04,326:INFO:          setuptools: 63.2.0
2022-12-16 10:17:04,326:INFO:             pycaret: 3.0.0rc4
2022-12-16 10:17:04,326:INFO:             IPython: 8.6.0
2022-12-16 10:17:04,327:INFO:          ipywidgets: 8.0.3
2022-12-16 10:17:04,327:INFO:                tqdm: 4.64.1
2022-12-16 10:17:04,327:INFO:               numpy: 1.22.4
2022-12-16 10:17:04,327:INFO:              pandas: 1.4.4
2022-12-16 10:17:04,327:INFO:              jinja2: 3.1.2
2022-12-16 10:17:04,327:INFO:               scipy: 1.8.1
2022-12-16 10:17:04,327:INFO:              joblib: 1.2.0
2022-12-16 10:17:04,327:INFO:             sklearn: 1.1.3
2022-12-16 10:17:04,327:INFO:                pyod: 1.0.6
2022-12-16 10:17:04,327:INFO:            imblearn: 0.10.0
2022-12-16 10:17:04,327:INFO:   category_encoders: 2.5.1.post0
2022-12-16 10:17:04,327:INFO:            lightgbm: 3.3.3
2022-12-16 10:17:04,327:INFO:               numba: 0.55.2
2022-12-16 10:17:04,327:INFO:            requests: 2.28.1
2022-12-16 10:17:04,327:INFO:          matplotlib: 3.6.2
2022-12-16 10:17:04,327:INFO:          scikitplot: 0.3.7
2022-12-16 10:17:04,327:INFO:         yellowbrick: 1.5
2022-12-16 10:17:04,327:INFO:              plotly: 5.11.0
2022-12-16 10:17:04,327:INFO:             kaleido: 0.2.1
2022-12-16 10:17:04,327:INFO:         statsmodels: 0.13.5
2022-12-16 10:17:04,328:INFO:              sktime: 0.13.4
2022-12-16 10:17:04,328:INFO:               tbats: 1.1.2
2022-12-16 10:17:04,328:INFO:            pmdarima: 1.8.5
2022-12-16 10:17:04,328:INFO:              psutil: 5.9.3
2022-12-16 10:17:04,328:INFO:PyCaret optional dependencies:
2022-12-16 10:17:04,328:INFO:                shap: Not installed
2022-12-16 10:17:04,328:INFO:           interpret: Not installed
2022-12-16 10:17:04,328:INFO:                umap: Not installed
2022-12-16 10:17:04,328:INFO:    pandas_profiling: 3.5.0
2022-12-16 10:17:04,328:INFO:  explainerdashboard: Not installed
2022-12-16 10:17:04,328:INFO:             autoviz: Not installed
2022-12-16 10:17:04,328:INFO:           fairlearn: Not installed
2022-12-16 10:17:04,328:INFO:             xgboost: Not installed
2022-12-16 10:17:04,328:INFO:            catboost: Not installed
2022-12-16 10:17:04,328:INFO:              kmodes: Not installed
2022-12-16 10:17:04,329:INFO:             mlxtend: Not installed
2022-12-16 10:17:04,329:INFO:       statsforecast: Not installed
2022-12-16 10:17:04,329:INFO:        tune_sklearn: Not installed
2022-12-16 10:17:04,329:INFO:                 ray: Not installed
2022-12-16 10:17:04,329:INFO:            hyperopt: Not installed
2022-12-16 10:17:04,329:INFO:              optuna: Not installed
2022-12-16 10:17:04,329:INFO:               skopt: Not installed
2022-12-16 10:17:04,329:INFO:              mlflow: Not installed
2022-12-16 10:17:04,329:INFO:              gradio: Not installed
2022-12-16 10:17:04,329:INFO:             fastapi: Not installed
2022-12-16 10:17:04,329:INFO:             uvicorn: Not installed
2022-12-16 10:17:04,329:INFO:              m2cgen: Not installed
2022-12-16 10:17:04,329:INFO:           evidently: Not installed
2022-12-16 10:17:04,329:INFO:                nltk: Not installed
2022-12-16 10:17:04,329:INFO:            pyLDAvis: Not installed
2022-12-16 10:17:04,329:INFO:              gensim: Not installed
2022-12-16 10:17:04,329:INFO:               spacy: Not installed
2022-12-16 10:17:04,329:INFO:           wordcloud: Not installed
2022-12-16 10:17:04,329:INFO:            textblob: Not installed
2022-12-16 10:17:04,329:INFO:               fugue: Not installed
2022-12-16 10:17:04,329:INFO:           streamlit: 1.15.2
2022-12-16 10:17:04,330:INFO:             prophet: Not installed
2022-12-16 10:17:04,330:INFO:None
2022-12-16 10:17:04,330:INFO:Set up data.
2022-12-16 10:17:04,337:INFO:Set up train/test split.
2022-12-16 10:17:06,451:INFO:PyCaret ClassificationExperiment
2022-12-16 10:17:06,452:INFO:Logging name: clf-default-name
2022-12-16 10:17:06,452:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2022-12-16 10:17:06,452:INFO:version 3.0.0.rc4
2022-12-16 10:17:06,452:INFO:Initializing setup()
2022-12-16 10:17:06,452:INFO:self.USI: 0058
2022-12-16 10:17:06,453:INFO:self.variable_keys: {'fix_imbalance', 'fold_groups_param', 'fold_shuffle_param', '_ml_usecase', 'display_container', 'n_jobs_param', 'exp_name_log', 'target_param', 'pipeline', 'seed', 'exp_id', '_all_models_internal', 'X_test', 'X_train', '_all_metrics', 'gpu_param', 'y_train', 'y_test', '_is_multiclass', 'y', 'logging_param', 'master_model_container', '_available_plots', 'html_param', 'X', '_all_models', 'memory', 'USI', 'log_plots_param', '_gpu_n_jobs_param', 'variable_keys', 'idx', 'fold_generator', 'data'}
2022-12-16 10:17:06,453:INFO:Checking environment
2022-12-16 10:17:06,453:INFO:python_version: 3.10.7
2022-12-16 10:17:06,453:INFO:python_build: ('tags/v3.10.7:6cc6b13', 'Sep  5 2022 14:08:36')
2022-12-16 10:17:06,453:INFO:machine: AMD64
2022-12-16 10:17:06,453:INFO:platform: Windows-10-10.0.22621-SP0
2022-12-16 10:17:06,453:INFO:Memory: svmem(total=8361132032, available=454782976, percent=94.6, used=7906349056, free=454782976)
2022-12-16 10:17:06,453:INFO:Physical Core: 4
2022-12-16 10:17:06,453:INFO:Logical Core: 8
2022-12-16 10:17:06,453:INFO:Checking libraries
2022-12-16 10:17:06,453:INFO:System:
2022-12-16 10:17:06,453:INFO:    python: 3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]
2022-12-16 10:17:06,454:INFO:executable: C:\Users\S_05_\AppData\Local\Programs\Python\Python310\python.exe
2022-12-16 10:17:06,454:INFO:   machine: Windows-10-10.0.22621-SP0
2022-12-16 10:17:06,454:INFO:PyCaret required dependencies:
2022-12-16 10:17:06,454:INFO:                 pip: 22.3.1
2022-12-16 10:17:06,454:INFO:          setuptools: 63.2.0
2022-12-16 10:17:06,454:INFO:             pycaret: 3.0.0rc4
2022-12-16 10:17:06,454:INFO:             IPython: 8.6.0
2022-12-16 10:17:06,454:INFO:          ipywidgets: 8.0.3
2022-12-16 10:17:06,454:INFO:                tqdm: 4.64.1
2022-12-16 10:17:06,454:INFO:               numpy: 1.22.4
2022-12-16 10:17:06,454:INFO:              pandas: 1.4.4
2022-12-16 10:17:06,455:INFO:              jinja2: 3.1.2
2022-12-16 10:17:06,455:INFO:               scipy: 1.8.1
2022-12-16 10:17:06,455:INFO:              joblib: 1.2.0
2022-12-16 10:17:06,455:INFO:             sklearn: 1.1.3
2022-12-16 10:17:06,455:INFO:                pyod: 1.0.6
2022-12-16 10:17:06,455:INFO:            imblearn: 0.10.0
2022-12-16 10:17:06,455:INFO:   category_encoders: 2.5.1.post0
2022-12-16 10:17:06,455:INFO:            lightgbm: 3.3.3
2022-12-16 10:17:06,455:INFO:               numba: 0.55.2
2022-12-16 10:17:06,456:INFO:            requests: 2.28.1
2022-12-16 10:17:06,456:INFO:          matplotlib: 3.6.2
2022-12-16 10:17:06,456:INFO:          scikitplot: 0.3.7
2022-12-16 10:17:06,456:INFO:         yellowbrick: 1.5
2022-12-16 10:17:06,456:INFO:              plotly: 5.11.0
2022-12-16 10:17:06,456:INFO:             kaleido: 0.2.1
2022-12-16 10:17:06,456:INFO:         statsmodels: 0.13.5
2022-12-16 10:17:06,456:INFO:              sktime: 0.13.4
2022-12-16 10:17:06,456:INFO:               tbats: 1.1.2
2022-12-16 10:17:06,456:INFO:            pmdarima: 1.8.5
2022-12-16 10:17:06,457:INFO:              psutil: 5.9.3
2022-12-16 10:17:06,457:INFO:PyCaret optional dependencies:
2022-12-16 10:17:06,457:INFO:                shap: Not installed
2022-12-16 10:17:06,457:INFO:           interpret: Not installed
2022-12-16 10:17:06,458:INFO:                umap: Not installed
2022-12-16 10:17:06,458:INFO:    pandas_profiling: 3.5.0
2022-12-16 10:17:06,458:INFO:  explainerdashboard: Not installed
2022-12-16 10:17:06,458:INFO:             autoviz: Not installed
2022-12-16 10:17:06,458:INFO:           fairlearn: Not installed
2022-12-16 10:17:06,458:INFO:             xgboost: Not installed
2022-12-16 10:17:06,458:INFO:            catboost: Not installed
2022-12-16 10:17:06,458:INFO:              kmodes: Not installed
2022-12-16 10:17:06,554:INFO:             mlxtend: Not installed
2022-12-16 10:17:06,554:INFO:       statsforecast: Not installed
2022-12-16 10:17:06,554:INFO:        tune_sklearn: Not installed
2022-12-16 10:17:06,556:INFO:                 ray: Not installed
2022-12-16 10:17:06,556:INFO:            hyperopt: Not installed
2022-12-16 10:17:06,556:INFO:              optuna: Not installed
2022-12-16 10:17:06,556:INFO:               skopt: Not installed
2022-12-16 10:17:06,556:INFO:              mlflow: Not installed
2022-12-16 10:17:06,556:INFO:              gradio: Not installed
2022-12-16 10:17:06,556:INFO:             fastapi: Not installed
2022-12-16 10:17:06,556:INFO:             uvicorn: Not installed
2022-12-16 10:17:06,556:INFO:              m2cgen: Not installed
2022-12-16 10:17:06,556:INFO:           evidently: Not installed
2022-12-16 10:17:06,556:INFO:                nltk: Not installed
2022-12-16 10:17:06,557:INFO:            pyLDAvis: Not installed
2022-12-16 10:17:06,557:INFO:              gensim: Not installed
2022-12-16 10:17:06,557:INFO:               spacy: Not installed
2022-12-16 10:17:06,557:INFO:           wordcloud: Not installed
2022-12-16 10:17:06,557:INFO:            textblob: Not installed
2022-12-16 10:17:06,558:INFO:               fugue: Not installed
2022-12-16 10:17:06,558:INFO:           streamlit: 1.15.2
2022-12-16 10:17:06,558:INFO:             prophet: Not installed
2022-12-16 10:17:06,558:INFO:None
2022-12-16 10:17:06,559:INFO:Set up data.
2022-12-16 10:17:06,564:INFO:Set up train/test split.
2022-12-16 10:17:14,763:INFO:PyCaret ClassificationExperiment
2022-12-16 10:17:14,764:INFO:Logging name: clf-default-name
2022-12-16 10:17:14,764:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2022-12-16 10:17:14,765:INFO:version 3.0.0.rc4
2022-12-16 10:17:14,765:INFO:Initializing setup()
2022-12-16 10:17:14,767:INFO:self.USI: ebe3
2022-12-16 10:17:14,767:INFO:self.variable_keys: {'fix_imbalance', 'fold_groups_param', 'fold_shuffle_param', '_ml_usecase', 'display_container', 'n_jobs_param', 'exp_name_log', 'target_param', 'pipeline', 'seed', 'exp_id', '_all_models_internal', 'X_test', 'X_train', '_all_metrics', 'gpu_param', 'y_train', 'y_test', '_is_multiclass', 'y', 'logging_param', 'master_model_container', '_available_plots', 'html_param', 'X', '_all_models', 'memory', 'USI', 'log_plots_param', '_gpu_n_jobs_param', 'variable_keys', 'idx', 'fold_generator', 'data'}
2022-12-16 10:17:14,767:INFO:Checking environment
2022-12-16 10:17:14,768:INFO:python_version: 3.10.7
2022-12-16 10:17:14,768:INFO:python_build: ('tags/v3.10.7:6cc6b13', 'Sep  5 2022 14:08:36')
2022-12-16 10:17:14,769:INFO:machine: AMD64
2022-12-16 10:17:14,769:INFO:platform: Windows-10-10.0.22621-SP0
2022-12-16 10:17:14,769:INFO:Memory: svmem(total=8361132032, available=483508224, percent=94.2, used=7877623808, free=483508224)
2022-12-16 10:17:14,770:INFO:Physical Core: 4
2022-12-16 10:17:14,770:INFO:Logical Core: 8
2022-12-16 10:17:14,770:INFO:Checking libraries
2022-12-16 10:17:14,770:INFO:System:
2022-12-16 10:17:14,770:INFO:    python: 3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]
2022-12-16 10:17:14,770:INFO:executable: C:\Users\S_05_\AppData\Local\Programs\Python\Python310\python.exe
2022-12-16 10:17:14,770:INFO:   machine: Windows-10-10.0.22621-SP0
2022-12-16 10:17:14,770:INFO:PyCaret required dependencies:
2022-12-16 10:17:14,770:INFO:                 pip: 22.3.1
2022-12-16 10:17:14,771:INFO:          setuptools: 63.2.0
2022-12-16 10:17:14,771:INFO:             pycaret: 3.0.0rc4
2022-12-16 10:17:14,771:INFO:             IPython: 8.6.0
2022-12-16 10:17:14,771:INFO:          ipywidgets: 8.0.3
2022-12-16 10:17:14,771:INFO:                tqdm: 4.64.1
2022-12-16 10:17:14,771:INFO:               numpy: 1.22.4
2022-12-16 10:17:14,771:INFO:              pandas: 1.4.4
2022-12-16 10:17:14,771:INFO:              jinja2: 3.1.2
2022-12-16 10:17:14,772:INFO:               scipy: 1.8.1
2022-12-16 10:17:14,772:INFO:              joblib: 1.2.0
2022-12-16 10:17:14,772:INFO:             sklearn: 1.1.3
2022-12-16 10:17:14,772:INFO:                pyod: 1.0.6
2022-12-16 10:17:14,772:INFO:            imblearn: 0.10.0
2022-12-16 10:17:14,772:INFO:   category_encoders: 2.5.1.post0
2022-12-16 10:17:14,772:INFO:            lightgbm: 3.3.3
2022-12-16 10:17:14,772:INFO:               numba: 0.55.2
2022-12-16 10:17:14,772:INFO:            requests: 2.28.1
2022-12-16 10:17:14,772:INFO:          matplotlib: 3.6.2
2022-12-16 10:17:14,772:INFO:          scikitplot: 0.3.7
2022-12-16 10:17:14,772:INFO:         yellowbrick: 1.5
2022-12-16 10:17:14,772:INFO:              plotly: 5.11.0
2022-12-16 10:17:14,772:INFO:             kaleido: 0.2.1
2022-12-16 10:17:14,772:INFO:         statsmodels: 0.13.5
2022-12-16 10:17:14,774:INFO:              sktime: 0.13.4
2022-12-16 10:17:14,774:INFO:               tbats: 1.1.2
2022-12-16 10:17:14,774:INFO:            pmdarima: 1.8.5
2022-12-16 10:17:14,774:INFO:              psutil: 5.9.3
2022-12-16 10:17:14,774:INFO:PyCaret optional dependencies:
2022-12-16 10:17:14,774:INFO:                shap: Not installed
2022-12-16 10:17:14,774:INFO:           interpret: Not installed
2022-12-16 10:17:14,774:INFO:                umap: Not installed
2022-12-16 10:17:14,775:INFO:    pandas_profiling: 3.5.0
2022-12-16 10:17:14,775:INFO:  explainerdashboard: Not installed
2022-12-16 10:17:14,775:INFO:             autoviz: Not installed
2022-12-16 10:17:14,775:INFO:           fairlearn: Not installed
2022-12-16 10:17:14,775:INFO:             xgboost: Not installed
2022-12-16 10:17:14,775:INFO:            catboost: Not installed
2022-12-16 10:17:14,775:INFO:              kmodes: Not installed
2022-12-16 10:17:14,775:INFO:             mlxtend: Not installed
2022-12-16 10:17:14,775:INFO:       statsforecast: Not installed
2022-12-16 10:17:14,775:INFO:        tune_sklearn: Not installed
2022-12-16 10:17:14,775:INFO:                 ray: Not installed
2022-12-16 10:17:14,775:INFO:            hyperopt: Not installed
2022-12-16 10:17:14,775:INFO:              optuna: Not installed
2022-12-16 10:17:14,775:INFO:               skopt: Not installed
2022-12-16 10:17:14,775:INFO:              mlflow: Not installed
2022-12-16 10:17:14,775:INFO:              gradio: Not installed
2022-12-16 10:17:14,776:INFO:             fastapi: Not installed
2022-12-16 10:17:14,776:INFO:             uvicorn: Not installed
2022-12-16 10:17:14,776:INFO:              m2cgen: Not installed
2022-12-16 10:17:14,776:INFO:           evidently: Not installed
2022-12-16 10:17:14,776:INFO:                nltk: Not installed
2022-12-16 10:17:14,776:INFO:            pyLDAvis: Not installed
2022-12-16 10:17:14,776:INFO:              gensim: Not installed
2022-12-16 10:17:14,776:INFO:               spacy: Not installed
2022-12-16 10:17:14,776:INFO:           wordcloud: Not installed
2022-12-16 10:17:14,776:INFO:            textblob: Not installed
2022-12-16 10:17:14,776:INFO:               fugue: Not installed
2022-12-16 10:17:14,776:INFO:           streamlit: 1.15.2
2022-12-16 10:17:14,776:INFO:             prophet: Not installed
2022-12-16 10:17:14,776:INFO:None
2022-12-16 10:17:14,776:INFO:Set up data.
2022-12-16 10:17:14,786:INFO:Set up train/test split.
2022-12-16 10:17:33,859:INFO:PyCaret ClassificationExperiment
2022-12-16 10:17:33,860:INFO:Logging name: clf-default-name
2022-12-16 10:17:33,860:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2022-12-16 10:17:33,860:INFO:version 3.0.0.rc4
2022-12-16 10:17:33,860:INFO:Initializing setup()
2022-12-16 10:17:33,860:INFO:self.USI: e145
2022-12-16 10:17:33,860:INFO:self.variable_keys: {'fix_imbalance', 'fold_groups_param', 'fold_shuffle_param', '_ml_usecase', 'display_container', 'n_jobs_param', 'exp_name_log', 'target_param', 'pipeline', 'seed', 'exp_id', '_all_models_internal', 'X_test', 'X_train', '_all_metrics', 'gpu_param', 'y_train', 'y_test', '_is_multiclass', 'y', 'logging_param', 'master_model_container', '_available_plots', 'html_param', 'X', '_all_models', 'memory', 'USI', 'log_plots_param', '_gpu_n_jobs_param', 'variable_keys', 'idx', 'fold_generator', 'data'}
2022-12-16 10:17:33,861:INFO:Checking environment
2022-12-16 10:17:33,861:INFO:python_version: 3.10.7
2022-12-16 10:17:33,862:INFO:python_build: ('tags/v3.10.7:6cc6b13', 'Sep  5 2022 14:08:36')
2022-12-16 10:17:33,862:INFO:machine: AMD64
2022-12-16 10:17:33,862:INFO:platform: Windows-10-10.0.22621-SP0
2022-12-16 10:17:33,862:INFO:Memory: svmem(total=8361132032, available=531329024, percent=93.6, used=7829803008, free=531329024)
2022-12-16 10:17:33,862:INFO:Physical Core: 4
2022-12-16 10:17:33,862:INFO:Logical Core: 8
2022-12-16 10:17:33,862:INFO:Checking libraries
2022-12-16 10:17:33,862:INFO:System:
2022-12-16 10:17:33,862:INFO:    python: 3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]
2022-12-16 10:17:33,862:INFO:executable: C:\Users\S_05_\AppData\Local\Programs\Python\Python310\python.exe
2022-12-16 10:17:33,862:INFO:   machine: Windows-10-10.0.22621-SP0
2022-12-16 10:17:33,862:INFO:PyCaret required dependencies:
2022-12-16 10:17:33,862:INFO:                 pip: 22.3.1
2022-12-16 10:17:33,863:INFO:          setuptools: 63.2.0
2022-12-16 10:17:33,863:INFO:             pycaret: 3.0.0rc4
2022-12-16 10:17:33,863:INFO:             IPython: 8.6.0
2022-12-16 10:17:33,863:INFO:          ipywidgets: 8.0.3
2022-12-16 10:17:33,863:INFO:                tqdm: 4.64.1
2022-12-16 10:17:33,863:INFO:               numpy: 1.22.4
2022-12-16 10:17:33,863:INFO:              pandas: 1.4.4
2022-12-16 10:17:33,863:INFO:              jinja2: 3.1.2
2022-12-16 10:17:33,863:INFO:               scipy: 1.8.1
2022-12-16 10:17:33,863:INFO:              joblib: 1.2.0
2022-12-16 10:17:33,863:INFO:             sklearn: 1.1.3
2022-12-16 10:17:33,863:INFO:                pyod: 1.0.6
2022-12-16 10:17:33,863:INFO:            imblearn: 0.10.0
2022-12-16 10:17:33,863:INFO:   category_encoders: 2.5.1.post0
2022-12-16 10:17:33,863:INFO:            lightgbm: 3.3.3
2022-12-16 10:17:33,863:INFO:               numba: 0.55.2
2022-12-16 10:17:33,863:INFO:            requests: 2.28.1
2022-12-16 10:17:33,863:INFO:          matplotlib: 3.6.2
2022-12-16 10:17:33,863:INFO:          scikitplot: 0.3.7
2022-12-16 10:17:33,863:INFO:         yellowbrick: 1.5
2022-12-16 10:17:33,863:INFO:              plotly: 5.11.0
2022-12-16 10:17:33,864:INFO:             kaleido: 0.2.1
2022-12-16 10:17:33,864:INFO:         statsmodels: 0.13.5
2022-12-16 10:17:33,864:INFO:              sktime: 0.13.4
2022-12-16 10:17:33,864:INFO:               tbats: 1.1.2
2022-12-16 10:17:33,864:INFO:            pmdarima: 1.8.5
2022-12-16 10:17:33,864:INFO:              psutil: 5.9.3
2022-12-16 10:17:33,864:INFO:PyCaret optional dependencies:
2022-12-16 10:17:33,864:INFO:                shap: Not installed
2022-12-16 10:17:33,864:INFO:           interpret: Not installed
2022-12-16 10:17:33,864:INFO:                umap: Not installed
2022-12-16 10:17:33,864:INFO:    pandas_profiling: 3.5.0
2022-12-16 10:17:33,864:INFO:  explainerdashboard: Not installed
2022-12-16 10:17:33,864:INFO:             autoviz: Not installed
2022-12-16 10:17:33,864:INFO:           fairlearn: Not installed
2022-12-16 10:17:33,864:INFO:             xgboost: Not installed
2022-12-16 10:17:33,864:INFO:            catboost: Not installed
2022-12-16 10:17:33,864:INFO:              kmodes: Not installed
2022-12-16 10:17:33,865:INFO:             mlxtend: Not installed
2022-12-16 10:17:33,865:INFO:       statsforecast: Not installed
2022-12-16 10:17:33,865:INFO:        tune_sklearn: Not installed
2022-12-16 10:17:33,865:INFO:                 ray: Not installed
2022-12-16 10:17:33,865:INFO:            hyperopt: Not installed
2022-12-16 10:17:33,865:INFO:              optuna: Not installed
2022-12-16 10:17:33,865:INFO:               skopt: Not installed
2022-12-16 10:17:33,865:INFO:              mlflow: Not installed
2022-12-16 10:17:33,865:INFO:              gradio: Not installed
2022-12-16 10:17:33,865:INFO:             fastapi: Not installed
2022-12-16 10:17:33,866:INFO:             uvicorn: Not installed
2022-12-16 10:17:33,867:INFO:              m2cgen: Not installed
2022-12-16 10:17:33,867:INFO:           evidently: Not installed
2022-12-16 10:17:33,867:INFO:                nltk: Not installed
2022-12-16 10:17:33,868:INFO:            pyLDAvis: Not installed
2022-12-16 10:17:33,868:INFO:              gensim: Not installed
2022-12-16 10:17:33,868:INFO:               spacy: Not installed
2022-12-16 10:17:33,868:INFO:           wordcloud: Not installed
2022-12-16 10:17:33,868:INFO:            textblob: Not installed
2022-12-16 10:17:33,868:INFO:               fugue: Not installed
2022-12-16 10:17:33,868:INFO:           streamlit: 1.15.2
2022-12-16 10:17:33,868:INFO:             prophet: Not installed
2022-12-16 10:17:33,868:INFO:None
2022-12-16 10:17:33,868:INFO:Set up data.
2022-12-16 10:17:33,892:INFO:Set up train/test split.
2022-12-16 10:17:37,415:INFO:PyCaret ClassificationExperiment
2022-12-16 10:17:37,416:INFO:Logging name: clf-default-name
2022-12-16 10:17:37,416:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2022-12-16 10:17:37,416:INFO:version 3.0.0.rc4
2022-12-16 10:17:37,417:INFO:Initializing setup()
2022-12-16 10:17:37,417:INFO:self.USI: 7609
2022-12-16 10:17:37,417:INFO:self.variable_keys: {'fix_imbalance', 'fold_groups_param', 'fold_shuffle_param', '_ml_usecase', 'display_container', 'n_jobs_param', 'exp_name_log', 'target_param', 'pipeline', 'seed', 'exp_id', '_all_models_internal', 'X_test', 'X_train', '_all_metrics', 'gpu_param', 'y_train', 'y_test', '_is_multiclass', 'y', 'logging_param', 'master_model_container', '_available_plots', 'html_param', 'X', '_all_models', 'memory', 'USI', 'log_plots_param', '_gpu_n_jobs_param', 'variable_keys', 'idx', 'fold_generator', 'data'}
2022-12-16 10:17:37,417:INFO:Checking environment
2022-12-16 10:17:37,417:INFO:python_version: 3.10.7
2022-12-16 10:17:37,417:INFO:python_build: ('tags/v3.10.7:6cc6b13', 'Sep  5 2022 14:08:36')
2022-12-16 10:17:37,417:INFO:machine: AMD64
2022-12-16 10:17:37,417:INFO:platform: Windows-10-10.0.22621-SP0
2022-12-16 10:17:37,417:INFO:Memory: svmem(total=8361132032, available=546537472, percent=93.5, used=7814594560, free=546537472)
2022-12-16 10:17:37,417:INFO:Physical Core: 4
2022-12-16 10:17:37,417:INFO:Logical Core: 8
2022-12-16 10:17:37,417:INFO:Checking libraries
2022-12-16 10:17:37,417:INFO:System:
2022-12-16 10:17:37,417:INFO:    python: 3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]
2022-12-16 10:17:37,417:INFO:executable: C:\Users\S_05_\AppData\Local\Programs\Python\Python310\python.exe
2022-12-16 10:17:37,418:INFO:   machine: Windows-10-10.0.22621-SP0
2022-12-16 10:17:37,418:INFO:PyCaret required dependencies:
2022-12-16 10:17:37,418:INFO:                 pip: 22.3.1
2022-12-16 10:17:37,418:INFO:          setuptools: 63.2.0
2022-12-16 10:17:37,418:INFO:             pycaret: 3.0.0rc4
2022-12-16 10:17:37,418:INFO:             IPython: 8.6.0
2022-12-16 10:17:37,418:INFO:          ipywidgets: 8.0.3
2022-12-16 10:17:37,418:INFO:                tqdm: 4.64.1
2022-12-16 10:17:37,418:INFO:               numpy: 1.22.4
2022-12-16 10:17:37,418:INFO:              pandas: 1.4.4
2022-12-16 10:17:37,418:INFO:              jinja2: 3.1.2
2022-12-16 10:17:37,418:INFO:               scipy: 1.8.1
2022-12-16 10:17:37,418:INFO:              joblib: 1.2.0
2022-12-16 10:17:37,418:INFO:             sklearn: 1.1.3
2022-12-16 10:17:37,418:INFO:                pyod: 1.0.6
2022-12-16 10:17:37,418:INFO:            imblearn: 0.10.0
2022-12-16 10:17:37,418:INFO:   category_encoders: 2.5.1.post0
2022-12-16 10:17:37,419:INFO:            lightgbm: 3.3.3
2022-12-16 10:17:37,419:INFO:               numba: 0.55.2
2022-12-16 10:17:37,419:INFO:            requests: 2.28.1
2022-12-16 10:17:37,419:INFO:          matplotlib: 3.6.2
2022-12-16 10:17:37,419:INFO:          scikitplot: 0.3.7
2022-12-16 10:17:37,419:INFO:         yellowbrick: 1.5
2022-12-16 10:17:37,419:INFO:              plotly: 5.11.0
2022-12-16 10:17:37,419:INFO:             kaleido: 0.2.1
2022-12-16 10:17:37,419:INFO:         statsmodels: 0.13.5
2022-12-16 10:17:37,419:INFO:              sktime: 0.13.4
2022-12-16 10:17:37,419:INFO:               tbats: 1.1.2
2022-12-16 10:17:37,419:INFO:            pmdarima: 1.8.5
2022-12-16 10:17:37,419:INFO:              psutil: 5.9.3
2022-12-16 10:17:37,419:INFO:PyCaret optional dependencies:
2022-12-16 10:17:37,419:INFO:                shap: Not installed
2022-12-16 10:17:37,420:INFO:           interpret: Not installed
2022-12-16 10:17:37,420:INFO:                umap: Not installed
2022-12-16 10:17:37,420:INFO:    pandas_profiling: 3.5.0
2022-12-16 10:17:37,420:INFO:  explainerdashboard: Not installed
2022-12-16 10:17:37,420:INFO:             autoviz: Not installed
2022-12-16 10:17:37,420:INFO:           fairlearn: Not installed
2022-12-16 10:17:37,420:INFO:             xgboost: Not installed
2022-12-16 10:17:37,420:INFO:            catboost: Not installed
2022-12-16 10:17:37,420:INFO:              kmodes: Not installed
2022-12-16 10:17:37,420:INFO:             mlxtend: Not installed
2022-12-16 10:17:37,420:INFO:       statsforecast: Not installed
2022-12-16 10:17:37,420:INFO:        tune_sklearn: Not installed
2022-12-16 10:17:37,420:INFO:                 ray: Not installed
2022-12-16 10:17:37,420:INFO:            hyperopt: Not installed
2022-12-16 10:17:37,420:INFO:              optuna: Not installed
2022-12-16 10:17:37,421:INFO:               skopt: Not installed
2022-12-16 10:17:37,421:INFO:              mlflow: Not installed
2022-12-16 10:17:37,421:INFO:              gradio: Not installed
2022-12-16 10:17:37,421:INFO:             fastapi: Not installed
2022-12-16 10:17:37,421:INFO:             uvicorn: Not installed
2022-12-16 10:17:37,421:INFO:              m2cgen: Not installed
2022-12-16 10:17:37,421:INFO:           evidently: Not installed
2022-12-16 10:17:37,421:INFO:                nltk: Not installed
2022-12-16 10:17:37,421:INFO:            pyLDAvis: Not installed
2022-12-16 10:17:37,421:INFO:              gensim: Not installed
2022-12-16 10:17:37,421:INFO:               spacy: Not installed
2022-12-16 10:17:37,421:INFO:           wordcloud: Not installed
2022-12-16 10:17:37,421:INFO:            textblob: Not installed
2022-12-16 10:17:37,421:INFO:               fugue: Not installed
2022-12-16 10:17:37,421:INFO:           streamlit: 1.15.2
2022-12-16 10:17:37,421:INFO:             prophet: Not installed
2022-12-16 10:17:37,421:INFO:None
2022-12-16 10:17:37,421:INFO:Set up data.
2022-12-16 10:17:37,427:INFO:Set up train/test split.
2022-12-16 10:17:46,101:INFO:PyCaret ClassificationExperiment
2022-12-16 10:17:46,101:INFO:Logging name: clf-default-name
2022-12-16 10:17:46,102:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2022-12-16 10:17:46,103:INFO:version 3.0.0.rc4
2022-12-16 10:17:46,103:INFO:Initializing setup()
2022-12-16 10:17:46,104:INFO:self.USI: 1812
2022-12-16 10:17:46,104:INFO:self.variable_keys: {'fix_imbalance', 'fold_groups_param', 'fold_shuffle_param', '_ml_usecase', 'display_container', 'n_jobs_param', 'exp_name_log', 'target_param', 'pipeline', 'seed', 'exp_id', '_all_models_internal', 'X_test', 'X_train', '_all_metrics', 'gpu_param', 'y_train', 'y_test', '_is_multiclass', 'y', 'logging_param', 'master_model_container', '_available_plots', 'html_param', 'X', '_all_models', 'memory', 'USI', 'log_plots_param', '_gpu_n_jobs_param', 'variable_keys', 'idx', 'fold_generator', 'data'}
2022-12-16 10:17:46,104:INFO:Checking environment
2022-12-16 10:17:46,104:INFO:python_version: 3.10.7
2022-12-16 10:17:46,104:INFO:python_build: ('tags/v3.10.7:6cc6b13', 'Sep  5 2022 14:08:36')
2022-12-16 10:17:46,104:INFO:machine: AMD64
2022-12-16 10:17:46,105:INFO:platform: Windows-10-10.0.22621-SP0
2022-12-16 10:17:46,105:INFO:Memory: svmem(total=8361132032, available=571916288, percent=93.2, used=7789215744, free=571916288)
2022-12-16 10:17:46,105:INFO:Physical Core: 4
2022-12-16 10:17:46,106:INFO:Logical Core: 8
2022-12-16 10:17:46,106:INFO:Checking libraries
2022-12-16 10:17:46,106:INFO:System:
2022-12-16 10:17:46,106:INFO:    python: 3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]
2022-12-16 10:17:46,106:INFO:executable: C:\Users\S_05_\AppData\Local\Programs\Python\Python310\python.exe
2022-12-16 10:17:46,106:INFO:   machine: Windows-10-10.0.22621-SP0
2022-12-16 10:17:46,106:INFO:PyCaret required dependencies:
2022-12-16 10:17:46,106:INFO:                 pip: 22.3.1
2022-12-16 10:17:46,107:INFO:          setuptools: 63.2.0
2022-12-16 10:17:46,107:INFO:             pycaret: 3.0.0rc4
2022-12-16 10:17:46,107:INFO:             IPython: 8.6.0
2022-12-16 10:17:46,107:INFO:          ipywidgets: 8.0.3
2022-12-16 10:17:46,107:INFO:                tqdm: 4.64.1
2022-12-16 10:17:46,107:INFO:               numpy: 1.22.4
2022-12-16 10:17:46,107:INFO:              pandas: 1.4.4
2022-12-16 10:17:46,107:INFO:              jinja2: 3.1.2
2022-12-16 10:17:46,107:INFO:               scipy: 1.8.1
2022-12-16 10:17:46,108:INFO:              joblib: 1.2.0
2022-12-16 10:17:46,108:INFO:             sklearn: 1.1.3
2022-12-16 10:17:46,108:INFO:                pyod: 1.0.6
2022-12-16 10:17:46,108:INFO:            imblearn: 0.10.0
2022-12-16 10:17:46,108:INFO:   category_encoders: 2.5.1.post0
2022-12-16 10:17:46,108:INFO:            lightgbm: 3.3.3
2022-12-16 10:17:46,108:INFO:               numba: 0.55.2
2022-12-16 10:17:46,108:INFO:            requests: 2.28.1
2022-12-16 10:17:46,109:INFO:          matplotlib: 3.6.2
2022-12-16 10:17:46,109:INFO:          scikitplot: 0.3.7
2022-12-16 10:17:46,109:INFO:         yellowbrick: 1.5
2022-12-16 10:17:46,109:INFO:              plotly: 5.11.0
2022-12-16 10:17:46,109:INFO:             kaleido: 0.2.1
2022-12-16 10:17:46,109:INFO:         statsmodels: 0.13.5
2022-12-16 10:17:46,109:INFO:              sktime: 0.13.4
2022-12-16 10:17:46,109:INFO:               tbats: 1.1.2
2022-12-16 10:17:46,109:INFO:            pmdarima: 1.8.5
2022-12-16 10:17:46,109:INFO:              psutil: 5.9.3
2022-12-16 10:17:46,109:INFO:PyCaret optional dependencies:
2022-12-16 10:17:46,109:INFO:                shap: Not installed
2022-12-16 10:17:46,110:INFO:           interpret: Not installed
2022-12-16 10:17:46,110:INFO:                umap: Not installed
2022-12-16 10:17:46,110:INFO:    pandas_profiling: 3.5.0
2022-12-16 10:17:46,110:INFO:  explainerdashboard: Not installed
2022-12-16 10:17:46,110:INFO:             autoviz: Not installed
2022-12-16 10:17:46,110:INFO:           fairlearn: Not installed
2022-12-16 10:17:46,110:INFO:             xgboost: Not installed
2022-12-16 10:17:46,110:INFO:            catboost: Not installed
2022-12-16 10:17:46,110:INFO:              kmodes: Not installed
2022-12-16 10:17:46,110:INFO:             mlxtend: Not installed
2022-12-16 10:17:46,110:INFO:       statsforecast: Not installed
2022-12-16 10:17:46,110:INFO:        tune_sklearn: Not installed
2022-12-16 10:17:46,110:INFO:                 ray: Not installed
2022-12-16 10:17:46,110:INFO:            hyperopt: Not installed
2022-12-16 10:17:46,110:INFO:              optuna: Not installed
2022-12-16 10:17:46,110:INFO:               skopt: Not installed
2022-12-16 10:17:46,110:INFO:              mlflow: Not installed
2022-12-16 10:17:46,110:INFO:              gradio: Not installed
2022-12-16 10:17:46,110:INFO:             fastapi: Not installed
2022-12-16 10:17:46,110:INFO:             uvicorn: Not installed
2022-12-16 10:17:46,111:INFO:              m2cgen: Not installed
2022-12-16 10:17:46,111:INFO:           evidently: Not installed
2022-12-16 10:17:46,111:INFO:                nltk: Not installed
2022-12-16 10:17:46,111:INFO:            pyLDAvis: Not installed
2022-12-16 10:17:46,111:INFO:              gensim: Not installed
2022-12-16 10:17:46,111:INFO:               spacy: Not installed
2022-12-16 10:17:46,111:INFO:           wordcloud: Not installed
2022-12-16 10:17:46,111:INFO:            textblob: Not installed
2022-12-16 10:17:46,111:INFO:               fugue: Not installed
2022-12-16 10:17:46,111:INFO:           streamlit: 1.15.2
2022-12-16 10:17:46,111:INFO:             prophet: Not installed
2022-12-16 10:17:46,112:INFO:None
2022-12-16 10:17:46,112:INFO:Set up data.
2022-12-16 10:17:46,120:INFO:Set up train/test split.
2022-12-16 10:17:48,401:INFO:PyCaret ClassificationExperiment
2022-12-16 10:17:48,401:INFO:Logging name: clf-default-name
2022-12-16 10:17:48,402:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2022-12-16 10:17:48,402:INFO:version 3.0.0.rc4
2022-12-16 10:17:48,402:INFO:Initializing setup()
2022-12-16 10:17:48,402:INFO:self.USI: 1e1b
2022-12-16 10:17:48,403:INFO:self.variable_keys: {'fix_imbalance', 'fold_groups_param', 'fold_shuffle_param', '_ml_usecase', 'display_container', 'n_jobs_param', 'exp_name_log', 'target_param', 'pipeline', 'seed', 'exp_id', '_all_models_internal', 'X_test', 'X_train', '_all_metrics', 'gpu_param', 'y_train', 'y_test', '_is_multiclass', 'y', 'logging_param', 'master_model_container', '_available_plots', 'html_param', 'X', '_all_models', 'memory', 'USI', 'log_plots_param', '_gpu_n_jobs_param', 'variable_keys', 'idx', 'fold_generator', 'data'}
2022-12-16 10:17:48,403:INFO:Checking environment
2022-12-16 10:17:48,403:INFO:python_version: 3.10.7
2022-12-16 10:17:48,403:INFO:python_build: ('tags/v3.10.7:6cc6b13', 'Sep  5 2022 14:08:36')
2022-12-16 10:17:48,403:INFO:machine: AMD64
2022-12-16 10:17:48,403:INFO:platform: Windows-10-10.0.22621-SP0
2022-12-16 10:17:48,403:INFO:Memory: svmem(total=8361132032, available=553398272, percent=93.4, used=7807733760, free=553398272)
2022-12-16 10:17:48,404:INFO:Physical Core: 4
2022-12-16 10:17:48,404:INFO:Logical Core: 8
2022-12-16 10:17:48,404:INFO:Checking libraries
2022-12-16 10:17:48,404:INFO:System:
2022-12-16 10:17:48,404:INFO:    python: 3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]
2022-12-16 10:17:48,404:INFO:executable: C:\Users\S_05_\AppData\Local\Programs\Python\Python310\python.exe
2022-12-16 10:17:48,404:INFO:   machine: Windows-10-10.0.22621-SP0
2022-12-16 10:17:48,404:INFO:PyCaret required dependencies:
2022-12-16 10:17:48,405:INFO:                 pip: 22.3.1
2022-12-16 10:17:48,405:INFO:          setuptools: 63.2.0
2022-12-16 10:17:48,405:INFO:             pycaret: 3.0.0rc4
2022-12-16 10:17:48,405:INFO:             IPython: 8.6.0
2022-12-16 10:17:48,405:INFO:          ipywidgets: 8.0.3
2022-12-16 10:17:48,405:INFO:                tqdm: 4.64.1
2022-12-16 10:17:48,405:INFO:               numpy: 1.22.4
2022-12-16 10:17:48,405:INFO:              pandas: 1.4.4
2022-12-16 10:17:48,405:INFO:              jinja2: 3.1.2
2022-12-16 10:17:48,405:INFO:               scipy: 1.8.1
2022-12-16 10:17:48,406:INFO:              joblib: 1.2.0
2022-12-16 10:17:48,406:INFO:             sklearn: 1.1.3
2022-12-16 10:17:48,406:INFO:                pyod: 1.0.6
2022-12-16 10:17:48,406:INFO:            imblearn: 0.10.0
2022-12-16 10:17:48,406:INFO:   category_encoders: 2.5.1.post0
2022-12-16 10:17:48,406:INFO:            lightgbm: 3.3.3
2022-12-16 10:17:48,406:INFO:               numba: 0.55.2
2022-12-16 10:17:48,406:INFO:            requests: 2.28.1
2022-12-16 10:17:48,406:INFO:          matplotlib: 3.6.2
2022-12-16 10:17:48,406:INFO:          scikitplot: 0.3.7
2022-12-16 10:17:48,406:INFO:         yellowbrick: 1.5
2022-12-16 10:17:48,407:INFO:              plotly: 5.11.0
2022-12-16 10:17:48,407:INFO:             kaleido: 0.2.1
2022-12-16 10:17:48,407:INFO:         statsmodels: 0.13.5
2022-12-16 10:17:48,407:INFO:              sktime: 0.13.4
2022-12-16 10:17:48,407:INFO:               tbats: 1.1.2
2022-12-16 10:17:48,407:INFO:            pmdarima: 1.8.5
2022-12-16 10:17:48,407:INFO:              psutil: 5.9.3
2022-12-16 10:17:48,407:INFO:PyCaret optional dependencies:
2022-12-16 10:17:48,407:INFO:                shap: Not installed
2022-12-16 10:17:48,407:INFO:           interpret: Not installed
2022-12-16 10:17:48,407:INFO:                umap: Not installed
2022-12-16 10:17:48,407:INFO:    pandas_profiling: 3.5.0
2022-12-16 10:17:48,407:INFO:  explainerdashboard: Not installed
2022-12-16 10:17:48,407:INFO:             autoviz: Not installed
2022-12-16 10:17:48,408:INFO:           fairlearn: Not installed
2022-12-16 10:17:48,408:INFO:             xgboost: Not installed
2022-12-16 10:17:48,408:INFO:            catboost: Not installed
2022-12-16 10:17:48,408:INFO:              kmodes: Not installed
2022-12-16 10:17:48,408:INFO:             mlxtend: Not installed
2022-12-16 10:17:48,408:INFO:       statsforecast: Not installed
2022-12-16 10:17:48,408:INFO:        tune_sklearn: Not installed
2022-12-16 10:17:48,408:INFO:                 ray: Not installed
2022-12-16 10:17:48,408:INFO:            hyperopt: Not installed
2022-12-16 10:17:48,408:INFO:              optuna: Not installed
2022-12-16 10:17:48,408:INFO:               skopt: Not installed
2022-12-16 10:17:48,408:INFO:              mlflow: Not installed
2022-12-16 10:17:48,408:INFO:              gradio: Not installed
2022-12-16 10:17:48,408:INFO:             fastapi: Not installed
2022-12-16 10:17:48,408:INFO:             uvicorn: Not installed
2022-12-16 10:17:48,408:INFO:              m2cgen: Not installed
2022-12-16 10:17:48,408:INFO:           evidently: Not installed
2022-12-16 10:17:48,409:INFO:                nltk: Not installed
2022-12-16 10:17:48,409:INFO:            pyLDAvis: Not installed
2022-12-16 10:17:48,409:INFO:              gensim: Not installed
2022-12-16 10:17:48,409:INFO:               spacy: Not installed
2022-12-16 10:17:48,409:INFO:           wordcloud: Not installed
2022-12-16 10:17:48,409:INFO:            textblob: Not installed
2022-12-16 10:17:48,409:INFO:               fugue: Not installed
2022-12-16 10:17:48,409:INFO:           streamlit: 1.15.2
2022-12-16 10:17:48,409:INFO:             prophet: Not installed
2022-12-16 10:17:48,409:INFO:None
2022-12-16 10:17:48,409:INFO:Set up data.
2022-12-16 10:17:48,420:INFO:Set up train/test split.
2022-12-16 10:27:30,148:INFO:PyCaret ClassificationExperiment
2022-12-16 10:27:30,148:INFO:Logging name: clf-default-name
2022-12-16 10:27:30,148:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2022-12-16 10:27:30,148:INFO:version 3.0.0.rc4
2022-12-16 10:27:30,148:INFO:Initializing setup()
2022-12-16 10:27:30,148:INFO:self.USI: 4a77
2022-12-16 10:27:30,148:INFO:self.variable_keys: {'fix_imbalance', 'fold_groups_param', 'fold_shuffle_param', '_ml_usecase', 'display_container', 'n_jobs_param', 'exp_name_log', 'target_param', 'pipeline', 'seed', 'exp_id', '_all_models_internal', 'X_test', 'X_train', '_all_metrics', 'gpu_param', 'y_train', 'y_test', '_is_multiclass', 'y', 'logging_param', 'master_model_container', '_available_plots', 'html_param', 'X', '_all_models', 'memory', 'USI', 'log_plots_param', '_gpu_n_jobs_param', 'variable_keys', 'idx', 'fold_generator', 'data'}
2022-12-16 10:27:30,148:INFO:Checking environment
2022-12-16 10:27:30,149:INFO:python_version: 3.10.7
2022-12-16 10:27:30,149:INFO:python_build: ('tags/v3.10.7:6cc6b13', 'Sep  5 2022 14:08:36')
2022-12-16 10:27:30,149:INFO:machine: AMD64
2022-12-16 10:27:30,149:INFO:platform: Windows-10-10.0.22621-SP0
2022-12-16 10:27:30,150:INFO:Memory: svmem(total=8361132032, available=1333252096, percent=84.1, used=7027879936, free=1333252096)
2022-12-16 10:27:30,150:INFO:Physical Core: 4
2022-12-16 10:27:30,150:INFO:Logical Core: 8
2022-12-16 10:27:30,150:INFO:Checking libraries
2022-12-16 10:27:30,150:INFO:System:
2022-12-16 10:27:30,150:INFO:    python: 3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]
2022-12-16 10:27:30,150:INFO:executable: C:\Users\S_05_\AppData\Local\Programs\Python\Python310\python.exe
2022-12-16 10:27:30,150:INFO:   machine: Windows-10-10.0.22621-SP0
2022-12-16 10:27:30,150:INFO:PyCaret required dependencies:
2022-12-16 10:27:30,151:INFO:                 pip: 22.3.1
2022-12-16 10:27:30,151:INFO:          setuptools: 63.2.0
2022-12-16 10:27:30,151:INFO:             pycaret: 3.0.0rc4
2022-12-16 10:27:30,151:INFO:             IPython: 8.6.0
2022-12-16 10:27:30,151:INFO:          ipywidgets: 8.0.3
2022-12-16 10:27:30,151:INFO:                tqdm: 4.64.1
2022-12-16 10:27:30,152:INFO:               numpy: 1.22.4
2022-12-16 10:27:30,152:INFO:              pandas: 1.4.4
2022-12-16 10:27:30,152:INFO:              jinja2: 3.1.2
2022-12-16 10:27:30,152:INFO:               scipy: 1.8.1
2022-12-16 10:27:30,152:INFO:              joblib: 1.2.0
2022-12-16 10:27:30,152:INFO:             sklearn: 1.1.3
2022-12-16 10:27:30,152:INFO:                pyod: 1.0.6
2022-12-16 10:27:30,152:INFO:            imblearn: 0.10.0
2022-12-16 10:27:30,152:INFO:   category_encoders: 2.5.1.post0
2022-12-16 10:27:30,152:INFO:            lightgbm: 3.3.3
2022-12-16 10:27:30,152:INFO:               numba: 0.55.2
2022-12-16 10:27:30,152:INFO:            requests: 2.28.1
2022-12-16 10:27:30,152:INFO:          matplotlib: 3.6.2
2022-12-16 10:27:30,152:INFO:          scikitplot: 0.3.7
2022-12-16 10:27:30,152:INFO:         yellowbrick: 1.5
2022-12-16 10:27:30,152:INFO:              plotly: 5.11.0
2022-12-16 10:27:30,152:INFO:             kaleido: 0.2.1
2022-12-16 10:27:30,152:INFO:         statsmodels: 0.13.5
2022-12-16 10:27:30,152:INFO:              sktime: 0.13.4
2022-12-16 10:27:30,152:INFO:               tbats: 1.1.2
2022-12-16 10:27:30,152:INFO:            pmdarima: 1.8.5
2022-12-16 10:27:30,153:INFO:              psutil: 5.9.3
2022-12-16 10:27:30,153:INFO:PyCaret optional dependencies:
2022-12-16 10:27:30,153:INFO:                shap: Not installed
2022-12-16 10:27:30,153:INFO:           interpret: Not installed
2022-12-16 10:27:30,153:INFO:                umap: Not installed
2022-12-16 10:27:30,153:INFO:    pandas_profiling: 3.5.0
2022-12-16 10:27:30,153:INFO:  explainerdashboard: Not installed
2022-12-16 10:27:30,153:INFO:             autoviz: Not installed
2022-12-16 10:27:30,153:INFO:           fairlearn: Not installed
2022-12-16 10:27:30,153:INFO:             xgboost: Not installed
2022-12-16 10:27:30,154:INFO:            catboost: Not installed
2022-12-16 10:27:30,154:INFO:              kmodes: Not installed
2022-12-16 10:27:30,154:INFO:             mlxtend: Not installed
2022-12-16 10:27:30,154:INFO:       statsforecast: Not installed
2022-12-16 10:27:30,154:INFO:        tune_sklearn: Not installed
2022-12-16 10:27:30,154:INFO:                 ray: Not installed
2022-12-16 10:27:30,154:INFO:            hyperopt: Not installed
2022-12-16 10:27:30,154:INFO:              optuna: Not installed
2022-12-16 10:27:30,154:INFO:               skopt: Not installed
2022-12-16 10:27:30,154:INFO:              mlflow: Not installed
2022-12-16 10:27:30,154:INFO:              gradio: Not installed
2022-12-16 10:27:30,154:INFO:             fastapi: Not installed
2022-12-16 10:27:30,154:INFO:             uvicorn: Not installed
2022-12-16 10:27:30,154:INFO:              m2cgen: Not installed
2022-12-16 10:27:30,154:INFO:           evidently: Not installed
2022-12-16 10:27:30,154:INFO:                nltk: Not installed
2022-12-16 10:27:30,154:INFO:            pyLDAvis: Not installed
2022-12-16 10:27:30,154:INFO:              gensim: Not installed
2022-12-16 10:27:30,155:INFO:               spacy: Not installed
2022-12-16 10:27:30,155:INFO:           wordcloud: Not installed
2022-12-16 10:27:30,155:INFO:            textblob: Not installed
2022-12-16 10:27:30,155:INFO:               fugue: Not installed
2022-12-16 10:27:30,155:INFO:           streamlit: 1.15.2
2022-12-16 10:27:30,155:INFO:             prophet: Not installed
2022-12-16 10:27:30,155:INFO:None
2022-12-16 10:27:30,156:INFO:Set up data.
2022-12-16 10:30:12,468:INFO:PyCaret RegressionExperiment
2022-12-16 10:30:12,469:INFO:Logging name: reg-default-name
2022-12-16 10:30:12,469:INFO:ML Usecase: MLUsecase.REGRESSION
2022-12-16 10:30:12,469:INFO:version 3.0.0.rc4
2022-12-16 10:30:12,469:INFO:Initializing setup()
2022-12-16 10:30:12,469:INFO:self.USI: fbe3
2022-12-16 10:30:12,469:INFO:self.variable_keys: {'fold_groups_param', 'fold_shuffle_param', 'transform_target_param', '_ml_usecase', 'display_container', 'n_jobs_param', 'exp_name_log', 'target_param', 'pipeline', 'seed', 'exp_id', '_all_models_internal', 'X_test', 'X_train', '_all_metrics', 'gpu_param', 'y_train', 'y_test', 'y', 'logging_param', 'master_model_container', '_available_plots', 'html_param', 'X', '_all_models', 'memory', 'USI', 'transform_target_method_param', 'log_plots_param', '_gpu_n_jobs_param', 'variable_keys', 'idx', 'fold_generator', 'data'}
2022-12-16 10:30:12,470:INFO:Checking environment
2022-12-16 10:30:12,470:INFO:python_version: 3.10.7
2022-12-16 10:30:12,470:INFO:python_build: ('tags/v3.10.7:6cc6b13', 'Sep  5 2022 14:08:36')
2022-12-16 10:30:12,471:INFO:machine: AMD64
2022-12-16 10:30:12,471:INFO:platform: Windows-10-10.0.22621-SP0
2022-12-16 10:30:12,472:INFO:Memory: svmem(total=8361132032, available=669478912, percent=92.0, used=7691653120, free=669478912)
2022-12-16 10:30:12,472:INFO:Physical Core: 4
2022-12-16 10:30:12,473:INFO:Logical Core: 8
2022-12-16 10:30:12,473:INFO:Checking libraries
2022-12-16 10:30:12,473:INFO:System:
2022-12-16 10:30:12,473:INFO:    python: 3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]
2022-12-16 10:30:12,473:INFO:executable: C:\Users\S_05_\AppData\Local\Programs\Python\Python310\python.exe
2022-12-16 10:30:12,473:INFO:   machine: Windows-10-10.0.22621-SP0
2022-12-16 10:30:12,473:INFO:PyCaret required dependencies:
2022-12-16 10:30:12,473:INFO:                 pip: 22.3.1
2022-12-16 10:30:12,474:INFO:          setuptools: 63.2.0
2022-12-16 10:30:12,474:INFO:             pycaret: 3.0.0rc4
2022-12-16 10:30:12,474:INFO:             IPython: 8.6.0
2022-12-16 10:30:12,474:INFO:          ipywidgets: 8.0.3
2022-12-16 10:30:12,474:INFO:                tqdm: 4.64.1
2022-12-16 10:30:12,474:INFO:               numpy: 1.22.4
2022-12-16 10:30:12,474:INFO:              pandas: 1.4.4
2022-12-16 10:30:12,474:INFO:              jinja2: 3.1.2
2022-12-16 10:30:12,474:INFO:               scipy: 1.8.1
2022-12-16 10:30:12,474:INFO:              joblib: 1.2.0
2022-12-16 10:30:12,474:INFO:             sklearn: 1.1.3
2022-12-16 10:30:12,474:INFO:                pyod: 1.0.6
2022-12-16 10:30:12,474:INFO:            imblearn: 0.10.0
2022-12-16 10:30:12,474:INFO:   category_encoders: 2.5.1.post0
2022-12-16 10:30:12,474:INFO:            lightgbm: 3.3.3
2022-12-16 10:30:12,475:INFO:               numba: 0.55.2
2022-12-16 10:30:12,475:INFO:            requests: 2.28.1
2022-12-16 10:30:12,475:INFO:          matplotlib: 3.6.2
2022-12-16 10:30:12,475:INFO:          scikitplot: 0.3.7
2022-12-16 10:30:12,475:INFO:         yellowbrick: 1.5
2022-12-16 10:30:12,475:INFO:              plotly: 5.11.0
2022-12-16 10:30:12,475:INFO:             kaleido: 0.2.1
2022-12-16 10:30:12,475:INFO:         statsmodels: 0.13.5
2022-12-16 10:30:12,475:INFO:              sktime: 0.13.4
2022-12-16 10:30:12,475:INFO:               tbats: 1.1.2
2022-12-16 10:30:12,475:INFO:            pmdarima: 1.8.5
2022-12-16 10:30:12,475:INFO:              psutil: 5.9.3
2022-12-16 10:30:12,476:INFO:PyCaret optional dependencies:
2022-12-16 10:30:12,476:INFO:                shap: Not installed
2022-12-16 10:30:12,476:INFO:           interpret: Not installed
2022-12-16 10:30:12,476:INFO:                umap: Not installed
2022-12-16 10:30:12,476:INFO:    pandas_profiling: 3.5.0
2022-12-16 10:30:12,476:INFO:  explainerdashboard: Not installed
2022-12-16 10:30:12,476:INFO:             autoviz: Not installed
2022-12-16 10:30:12,476:INFO:           fairlearn: Not installed
2022-12-16 10:30:12,476:INFO:             xgboost: Not installed
2022-12-16 10:30:12,476:INFO:            catboost: Not installed
2022-12-16 10:30:12,477:INFO:              kmodes: Not installed
2022-12-16 10:30:12,477:INFO:             mlxtend: Not installed
2022-12-16 10:30:12,477:INFO:       statsforecast: Not installed
2022-12-16 10:30:12,477:INFO:        tune_sklearn: Not installed
2022-12-16 10:30:12,477:INFO:                 ray: Not installed
2022-12-16 10:30:12,477:INFO:            hyperopt: Not installed
2022-12-16 10:30:12,477:INFO:              optuna: Not installed
2022-12-16 10:30:12,477:INFO:               skopt: Not installed
2022-12-16 10:30:12,477:INFO:              mlflow: Not installed
2022-12-16 10:30:12,478:INFO:              gradio: Not installed
2022-12-16 10:30:12,478:INFO:             fastapi: Not installed
2022-12-16 10:30:12,478:INFO:             uvicorn: Not installed
2022-12-16 10:30:12,478:INFO:              m2cgen: Not installed
2022-12-16 10:30:12,478:INFO:           evidently: Not installed
2022-12-16 10:30:12,478:INFO:                nltk: Not installed
2022-12-16 10:30:12,478:INFO:            pyLDAvis: Not installed
2022-12-16 10:30:12,478:INFO:              gensim: Not installed
2022-12-16 10:30:12,478:INFO:               spacy: Not installed
2022-12-16 10:30:12,478:INFO:           wordcloud: Not installed
2022-12-16 10:30:12,478:INFO:            textblob: Not installed
2022-12-16 10:30:12,478:INFO:               fugue: Not installed
2022-12-16 10:30:12,479:INFO:           streamlit: 1.15.2
2022-12-16 10:30:12,479:INFO:             prophet: Not installed
2022-12-16 10:30:12,479:INFO:None
2022-12-16 10:30:12,479:INFO:Set up data.
2022-12-16 10:35:43,105:INFO:PyCaret RegressionExperiment
2022-12-16 10:35:43,106:INFO:Logging name: reg-default-name
2022-12-16 10:35:43,107:INFO:ML Usecase: MLUsecase.REGRESSION
2022-12-16 10:35:43,108:INFO:version 3.0.0.rc4
2022-12-16 10:35:43,108:INFO:Initializing setup()
2022-12-16 10:35:43,108:INFO:self.USI: ab4f
2022-12-16 10:35:43,108:INFO:self.variable_keys: {'fold_groups_param', 'fold_shuffle_param', 'transform_target_param', '_ml_usecase', 'display_container', 'n_jobs_param', 'exp_name_log', 'target_param', 'pipeline', 'seed', 'exp_id', '_all_models_internal', 'X_test', 'X_train', '_all_metrics', 'gpu_param', 'y_train', 'y_test', 'y', 'logging_param', 'master_model_container', '_available_plots', 'html_param', 'X', '_all_models', 'memory', 'USI', 'transform_target_method_param', 'log_plots_param', '_gpu_n_jobs_param', 'variable_keys', 'idx', 'fold_generator', 'data'}
2022-12-16 10:35:43,108:INFO:Checking environment
2022-12-16 10:35:43,108:INFO:python_version: 3.10.7
2022-12-16 10:35:43,108:INFO:python_build: ('tags/v3.10.7:6cc6b13', 'Sep  5 2022 14:08:36')
2022-12-16 10:35:43,108:INFO:machine: AMD64
2022-12-16 10:35:43,108:INFO:platform: Windows-10-10.0.22621-SP0
2022-12-16 10:35:43,108:INFO:Memory: svmem(total=8361132032, available=2243227648, percent=73.2, used=6117904384, free=2243227648)
2022-12-16 10:35:43,109:INFO:Physical Core: 4
2022-12-16 10:35:43,109:INFO:Logical Core: 8
2022-12-16 10:35:43,109:INFO:Checking libraries
2022-12-16 10:35:43,109:INFO:System:
2022-12-16 10:35:43,109:INFO:    python: 3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]
2022-12-16 10:35:43,109:INFO:executable: C:\Users\S_05_\AppData\Local\Programs\Python\Python310\python.exe
2022-12-16 10:35:43,109:INFO:   machine: Windows-10-10.0.22621-SP0
2022-12-16 10:35:43,109:INFO:PyCaret required dependencies:
2022-12-16 10:35:43,109:INFO:                 pip: 22.3.1
2022-12-16 10:35:43,109:INFO:          setuptools: 63.2.0
2022-12-16 10:35:43,109:INFO:             pycaret: 3.0.0rc4
2022-12-16 10:35:43,109:INFO:             IPython: 8.6.0
2022-12-16 10:35:43,109:INFO:          ipywidgets: 8.0.3
2022-12-16 10:35:43,109:INFO:                tqdm: 4.64.1
2022-12-16 10:35:43,109:INFO:               numpy: 1.22.4
2022-12-16 10:35:43,110:INFO:              pandas: 1.4.4
2022-12-16 10:35:43,110:INFO:              jinja2: 3.1.2
2022-12-16 10:35:43,110:INFO:               scipy: 1.8.1
2022-12-16 10:35:43,110:INFO:              joblib: 1.2.0
2022-12-16 10:35:43,110:INFO:             sklearn: 1.1.3
2022-12-16 10:35:43,110:INFO:                pyod: 1.0.6
2022-12-16 10:35:43,110:INFO:            imblearn: 0.10.0
2022-12-16 10:35:43,110:INFO:   category_encoders: 2.5.1.post0
2022-12-16 10:35:43,110:INFO:            lightgbm: 3.3.3
2022-12-16 10:35:43,110:INFO:               numba: 0.55.2
2022-12-16 10:35:43,110:INFO:            requests: 2.28.1
2022-12-16 10:35:43,110:INFO:          matplotlib: 3.6.2
2022-12-16 10:35:43,118:INFO:          scikitplot: 0.3.7
2022-12-16 10:35:43,118:INFO:         yellowbrick: 1.5
2022-12-16 10:35:43,118:INFO:              plotly: 5.11.0
2022-12-16 10:35:43,118:INFO:             kaleido: 0.2.1
2022-12-16 10:35:43,118:INFO:         statsmodels: 0.13.5
2022-12-16 10:35:43,119:INFO:              sktime: 0.13.4
2022-12-16 10:35:43,119:INFO:               tbats: 1.1.2
2022-12-16 10:35:43,119:INFO:            pmdarima: 1.8.5
2022-12-16 10:35:43,119:INFO:              psutil: 5.9.3
2022-12-16 10:35:43,119:INFO:PyCaret optional dependencies:
2022-12-16 10:35:43,119:INFO:                shap: Not installed
2022-12-16 10:35:43,119:INFO:           interpret: Not installed
2022-12-16 10:35:43,120:INFO:                umap: Not installed
2022-12-16 10:35:43,120:INFO:    pandas_profiling: 3.5.0
2022-12-16 10:35:43,120:INFO:  explainerdashboard: Not installed
2022-12-16 10:35:43,120:INFO:             autoviz: Not installed
2022-12-16 10:35:43,120:INFO:           fairlearn: Not installed
2022-12-16 10:35:43,120:INFO:             xgboost: Not installed
2022-12-16 10:35:43,121:INFO:            catboost: Not installed
2022-12-16 10:35:43,121:INFO:              kmodes: Not installed
2022-12-16 10:35:43,121:INFO:             mlxtend: Not installed
2022-12-16 10:35:43,121:INFO:       statsforecast: Not installed
2022-12-16 10:35:43,121:INFO:        tune_sklearn: Not installed
2022-12-16 10:35:43,121:INFO:                 ray: Not installed
2022-12-16 10:35:43,121:INFO:            hyperopt: Not installed
2022-12-16 10:35:43,121:INFO:              optuna: Not installed
2022-12-16 10:35:43,121:INFO:               skopt: Not installed
2022-12-16 10:35:43,121:INFO:              mlflow: Not installed
2022-12-16 10:35:43,121:INFO:              gradio: Not installed
2022-12-16 10:35:43,121:INFO:             fastapi: Not installed
2022-12-16 10:35:43,121:INFO:             uvicorn: Not installed
2022-12-16 10:35:43,121:INFO:              m2cgen: Not installed
2022-12-16 10:35:43,122:INFO:           evidently: Not installed
2022-12-16 10:35:43,122:INFO:                nltk: Not installed
2022-12-16 10:35:43,122:INFO:            pyLDAvis: Not installed
2022-12-16 10:35:43,122:INFO:              gensim: Not installed
2022-12-16 10:35:43,122:INFO:               spacy: Not installed
2022-12-16 10:35:43,122:INFO:           wordcloud: Not installed
2022-12-16 10:35:43,122:INFO:            textblob: Not installed
2022-12-16 10:35:43,122:INFO:               fugue: Not installed
2022-12-16 10:35:43,122:INFO:           streamlit: 1.15.2
2022-12-16 10:35:43,122:INFO:             prophet: Not installed
2022-12-16 10:35:43,122:INFO:None
2022-12-16 10:35:43,122:INFO:Set up data.
2022-12-16 10:35:43,180:INFO:Set up train/test split.
2022-12-16 10:35:43,201:INFO:Set up index.
2022-12-16 10:35:43,203:INFO:Set up folding strategy.
2022-12-16 10:35:43,203:INFO:Assigning column types.
2022-12-16 10:35:43,212:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-12-16 10:35:43,212:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-12-16 10:35:43,222:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-16 10:35:43,229:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-16 10:35:43,330:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-16 10:35:43,402:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-16 10:35:43,403:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:35:43,403:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:35:43,403:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-12-16 10:35:43,409:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-16 10:35:43,414:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-16 10:35:43,546:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-16 10:35:43,622:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-16 10:35:43,623:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:35:43,623:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:35:43,624:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-12-16 10:35:43,634:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-16 10:35:43,640:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-16 10:35:43,700:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-16 10:35:43,747:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-16 10:35:43,748:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:35:43,748:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:35:43,754:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-16 10:35:43,760:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-16 10:35:43,825:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-16 10:35:43,872:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-16 10:35:43,872:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:35:43,873:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:35:43,873:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-12-16 10:35:43,882:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-16 10:35:43,969:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-16 10:35:44,041:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-16 10:35:44,041:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:35:44,041:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:35:44,051:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-16 10:35:44,178:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-16 10:35:44,245:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-16 10:35:44,246:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:35:44,246:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:35:44,246:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-12-16 10:35:44,353:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-16 10:35:44,422:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-16 10:35:44,423:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:35:44,423:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:35:44,556:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-16 10:35:44,636:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-16 10:35:44,636:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:35:44,637:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:35:44,637:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-12-16 10:35:44,738:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-16 10:35:44,826:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:35:44,827:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:35:44,932:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-16 10:35:44,998:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:35:44,998:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:35:44,998:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-12-16 10:35:45,168:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:35:45,458:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:35:45,704:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:35:45,705:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:35:45,707:INFO:Preparing preprocessing pipeline...
2022-12-16 10:35:45,710:INFO:Set up label encoding.
2022-12-16 10:35:45,710:INFO:Set up simple imputation.
2022-12-16 10:35:45,719:INFO:Set up encoding of categorical features.
2022-12-16 10:35:45,719:INFO:Set up variance threshold.
2022-12-16 10:35:48,242:INFO:Finished creating preprocessing pipeline.
2022-12-16 10:35:48,262:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\S_05_\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Accident_severity'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Age_band_of_driver',
                                             'Sex_of_driver',
                                             'Veh...
                                    transformer=LeaveOneOutEncoder(cols=['Driving_experience',
                                                                         'Lanes_or_Medians',
                                                                         'Types_of_Junction',
                                                                         'Road_surface_type',
                                                                         'Weather_conditions',
                                                                         'Type_of_collision',
                                                                         'Vehicle_movement',
                                                                         'Pedestrian_movement',
                                                                         'Cause_of_accident'],
                                                                   handle_missing='return_nan',
                                                                   random_state=5099))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))])
2022-12-16 10:35:48,262:INFO:Creating final display dataframe.
2022-12-16 10:35:56,884:INFO:Setup display_container:                  Description              Value
0                 Session id               5099
1                     Target  Educational_level
2                Target type         Regression
3                 Data shape        (12316, 27)
4           Train data shape         (8621, 27)
5            Test data shape         (3695, 27)
6           Numeric features                  1
7       Categorical features                 13
8                 Preprocess               True
9            Imputation type             simple
10        Numeric imputation               mean
11    Categorical imputation           constant
12  Maximum one-hot encoding                  5
13           Encoding method               None
14    Low variance threshold                  0
15            Fold Generator              KFold
16               Fold Number                 10
17                  CPU Jobs                 -1
18                   Use GPU              False
19            Log Experiment              False
20           Experiment Name   reg-default-name
21                       USI               ab4f
2022-12-16 10:35:57,079:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:35:57,079:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:35:57,222:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:35:57,223:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:35:57,233:INFO:setup() successfully completed in 14.13s...............
2022-12-16 10:35:57,246:INFO:Initializing compare_models()
2022-12-16 10:35:57,246:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002281239F8E0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002281239F8E0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-12-16 10:35:57,246:INFO:Checking exceptions
2022-12-16 10:35:57,251:INFO:Preparing display monitor
2022-12-16 10:35:57,258:INFO:Initializing Linear Regression
2022-12-16 10:35:57,258:INFO:Total runtime is 0.0 minutes
2022-12-16 10:35:57,259:INFO:SubProcess create_model() called ==================================
2022-12-16 10:35:57,260:INFO:Initializing create_model()
2022-12-16 10:35:57,260:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002281239F8E0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022810EC8B20>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:35:57,260:INFO:Checking exceptions
2022-12-16 10:35:57,266:INFO:Importing libraries
2022-12-16 10:35:57,266:INFO:Copying training dataset
2022-12-16 10:35:57,273:INFO:Defining folds
2022-12-16 10:35:57,273:INFO:Declaring metric variables
2022-12-16 10:35:57,274:INFO:Importing untrained model
2022-12-16 10:35:57,275:INFO:Linear Regression Imported successfully
2022-12-16 10:35:57,276:INFO:Starting cross validation
2022-12-16 10:35:57,282:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:36:05,763:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-12-16 10:36:05,779:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-12-16 10:36:05,784:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-12-16 10:36:05,861:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-12-16 10:36:05,942:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-12-16 10:36:06,051:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-12-16 10:36:06,059:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-12-16 10:36:06,108:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-12-16 10:36:07,662:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-12-16 10:36:07,668:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-12-16 10:36:07,863:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-12-16 10:36:07,951:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-12-16 10:36:07,971:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-12-16 10:36:08,063:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-12-16 10:36:08,134:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-12-16 10:36:08,298:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-12-16 10:36:09,251:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.5546875  1.8046875  1.8203125  1.91015625 2.046875   2.14453125
 2.66796875 2.796875   2.8125     2.82421875 2.83203125 2.8515625
 2.859375   2.86328125 2.8671875  2.87890625 2.8828125  2.91015625
 2.9140625  2.91796875 2.921875   2.92578125 2.9375     2.9453125
 2.95703125 2.9609375  2.96484375 2.96875    2.97265625 2.9765625
 2.98046875 2.984375   2.98828125 2.9921875  2.99609375 3.00390625
 3.0078125  3.01171875 3.015625   3.01953125 3.0234375  3.02734375
 3.03125    3.03515625 3.0390625  3.04296875 3.046875   3.05078125
 3.0546875  3.05859375 3.0625     3.06640625 3.0703125  3.07421875
 3.078125   3.08203125 3.0859375  3.08984375 3.09375    3.09765625
 3.1015625  3.10546875 3.109375   3.11328125 3.1171875  3.12109375
 3.125      3.12890625 3.1328125  3.13671875 3.140625   3.14453125
 3.1484375  3.15234375 3.15625    3.16015625 3.1640625  3.16796875
 3.171875   3.17578125 3.1796875  3.18359375 3.1875     3.19140625
 3.1953125  3.19921875 3.203125   3.20703125 3.2109375  3.21484375
 3.21875    3.22265625 3.2265625  3.23046875 3.234375   3.23828125
 3.2421875  3.24609375 3.25       3.25390625 3.2578125  3.26171875
 3.265625   3.26953125 3.2734375  3.27734375 3.28125    3.28515625
 3.2890625  3.29296875 3.296875   3.30078125 3.3046875  3.30859375
 3.3125     3.31640625 3.3203125  3.32421875 3.328125   3.33203125
 3.3359375  3.33984375 3.34375    3.34765625 3.3515625  3.35546875
 3.359375   3.36328125 3.3671875  3.37109375 3.375      3.37890625
 3.3828125  3.38671875 3.390625   3.39453125 3.3984375  3.40234375
 3.40625    3.41015625 3.4140625  3.41796875 3.421875   3.42578125
 3.4296875  3.43359375 3.4375     3.44140625 3.44921875 3.453125
 3.45703125 3.4609375  3.46875    3.47265625 3.4765625  3.48828125
 3.4921875  3.49609375 3.5        3.50390625 3.5078125  3.51171875
 3.51953125 3.53125    3.54296875 3.5625     3.578125   3.58203125
 3.5859375  3.58984375 3.609375   3.625      3.62890625 3.6484375
 3.65625    3.6640625  3.7421875  3.74609375 3.7734375  3.78125
 3.8203125  3.828125   3.83984375 3.85546875 3.8671875  3.87109375
 3.89453125 3.8984375  3.91015625 4.00390625 4.09375    4.1171875
 4.12890625 4.1328125  4.14453125 4.1640625  4.1875     4.34765625
 4.39453125 4.44921875 4.55859375 4.56640625 4.5703125  4.7109375
 4.72265625 4.73046875 4.75390625 4.76171875 4.765625   4.76953125
 4.7734375  4.7890625  4.79296875 4.80078125 4.8046875  4.80859375
 4.8125     4.828125   4.85546875 4.86328125 4.87109375 4.8828125
 4.8984375  4.90625    4.94140625 4.9453125  4.94921875 4.96875
 4.99609375]

  warnings.warn(

2022-12-16 10:36:09,340:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.625     1.6484375 1.71875   1.7421875 1.75      1.765625  1.9765625
 2.3125    2.625     2.7734375 2.78125   2.796875  2.8046875 2.8203125
 2.828125  2.8359375 2.84375   2.8515625 2.859375  2.8671875 2.875
 2.8828125 2.890625  2.8984375 2.90625   2.9140625 2.921875  2.9296875
 2.9375    2.9453125 2.953125  2.9609375 2.96875   2.9765625 2.984375
 2.9921875 3.0078125 3.015625  3.0234375 3.03125   3.0390625 3.046875
 3.0546875 3.0625    3.0703125 3.078125  3.0859375 3.09375   3.1015625
 3.109375  3.1171875 3.125     3.1328125 3.140625  3.1484375 3.15625
 3.1640625 3.171875  3.1796875 3.1875    3.1953125 3.203125  3.2109375
 3.21875   3.2265625 3.234375  3.2421875 3.25      3.2578125 3.265625
 3.2734375 3.28125   3.2890625 3.296875  3.3046875 3.3125    3.3203125
 3.328125  3.3359375 3.34375   3.3515625 3.359375  3.3671875 3.375
 3.3828125 3.390625  3.3984375 3.40625   3.4140625 3.421875  3.4296875
 3.4375    3.4453125 3.4609375 3.46875   3.4765625 3.4921875 3.5
 3.5078125 3.515625  3.546875  3.5546875 3.5625    3.5703125 3.578125
 3.59375   3.6015625 3.625     3.8046875 3.8125    3.8203125 3.8671875
 3.875     3.890625  3.8984375 3.9140625 3.9375    3.984375  3.9921875
 4.140625  4.2265625 4.3046875 4.390625  4.4765625 4.5390625 4.59375
 4.6015625 4.609375  4.625     4.6328125 4.640625  4.6484375 4.65625
 4.6640625 4.6796875 4.6875    4.703125  4.7265625 4.75      4.7578125
 4.78125   4.8203125]

  warnings.warn(

2022-12-16 10:36:09,490:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.84375   1.890625  1.9140625 1.9609375 1.96875   2.15625   2.578125
 2.640625  2.65625   2.71875   2.734375  2.75      2.78125   2.796875
 2.8046875 2.8125    2.8203125 2.828125  2.8359375 2.84375   2.8515625
 2.859375  2.8671875 2.875     2.8828125 2.890625  2.8984375 2.90625
 2.9140625 2.921875  2.9296875 2.9375    2.9453125 2.953125  2.9609375
 2.96875   2.9765625 2.984375  2.9921875 3.0078125 3.015625  3.0234375
 3.03125   3.0390625 3.046875  3.0546875 3.0625    3.0703125 3.078125
 3.0859375 3.09375   3.1015625 3.109375  3.1171875 3.125     3.1328125
 3.140625  3.1484375 3.15625   3.1640625 3.171875  3.1796875 3.1875
 3.1953125 3.203125  3.2109375 3.21875   3.2265625 3.234375  3.2421875
 3.25      3.2578125 3.265625  3.2734375 3.28125   3.2890625 3.296875
 3.3046875 3.3125    3.3203125 3.328125  3.3359375 3.34375   3.3515625
 3.359375  3.375     3.3828125 3.390625  3.3984375 3.40625   3.4140625
 3.421875  3.4296875 3.4375    3.4453125 3.453125  3.4609375 3.46875
 3.4765625 3.484375  3.4921875 3.5       3.515625  3.5390625 3.5546875
 3.5625    3.578125  3.5859375 3.59375   3.6328125 3.640625  3.65625
 3.6953125 3.7109375 3.7578125 3.765625  3.7890625 3.796875  3.8125
 3.8203125 3.828125  3.8359375 3.84375   3.8515625 3.890625  3.9296875
 3.984375  4.0546875 4.0625    4.21875   4.265625  4.5859375 4.640625
 4.6484375 4.65625   4.6640625 4.6796875 4.6953125 4.703125  4.7109375
 4.71875   4.734375  4.7421875 4.75      4.765625  4.7734375 4.78125
 4.796875  4.8125    4.8203125 4.8828125 4.9375    4.953125  5.046875 ]

  warnings.warn(

2022-12-16 10:36:09,584:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.625      1.8359375  1.8828125  1.8984375  1.99609375 2.12890625
 2.4921875  2.5234375  2.76171875 2.84375    2.84765625 2.86328125
 2.88671875 2.91796875 2.9375     2.94140625 2.9453125  2.94921875
 2.95703125 2.9609375  2.96484375 2.96875    2.97265625 2.9765625
 2.98046875 2.984375   2.98828125 2.9921875  2.99609375 3.00390625
 3.0078125  3.01171875 3.015625   3.01953125 3.0234375  3.02734375
 3.03125    3.03515625 3.0390625  3.046875   3.05078125 3.0546875
 3.05859375 3.0625     3.06640625 3.0703125  3.07421875 3.078125
 3.08203125 3.0859375  3.08984375 3.09375    3.09765625 3.1015625
 3.10546875 3.109375   3.11328125 3.1171875  3.12109375 3.125
 3.12890625 3.1328125  3.13671875 3.140625   3.14453125 3.1484375
 3.15234375 3.15625    3.16015625 3.1640625  3.16796875 3.171875
 3.17578125 3.1796875  3.18359375 3.1875     3.19140625 3.1953125
 3.19921875 3.203125   3.20703125 3.2109375  3.21484375 3.21875
 3.22265625 3.2265625  3.23046875 3.234375   3.23828125 3.2421875
 3.24609375 3.25       3.25390625 3.2578125  3.26171875 3.265625
 3.26953125 3.2734375  3.27734375 3.28125    3.28515625 3.2890625
 3.29296875 3.296875   3.30078125 3.3046875  3.30859375 3.3125
 3.31640625 3.3203125  3.32421875 3.328125   3.33203125 3.3359375
 3.33984375 3.34375    3.34765625 3.3515625  3.35546875 3.359375
 3.36328125 3.3671875  3.37109375 3.375      3.37890625 3.3828125
 3.38671875 3.390625   3.39453125 3.3984375  3.40234375 3.40625
 3.4140625  3.41796875 3.421875   3.42578125 3.4296875  3.43359375
 3.453125   3.45703125 3.4609375  3.51953125 3.5234375  3.54296875
 3.56640625 3.57421875 3.59375    3.6015625  3.6171875  3.625
 3.66015625 3.6640625  3.671875   3.6875     3.73828125 3.765625
 3.7890625  3.79296875 3.8046875  3.81640625 3.828125   3.83203125
 3.84375    3.8515625  3.859375   3.86328125 3.8671875  3.92578125
 3.98828125 4.00390625 4.01953125 4.10546875 4.12109375 4.12890625
 4.2265625  4.34375    4.67578125 4.703125   4.70703125 4.71875
 4.73828125 4.7421875  4.74609375 4.76171875 4.765625   4.76953125
 4.7734375  4.78125    4.79296875 4.796875   4.8046875  4.80859375
 4.8125     4.81640625 4.82421875 4.828125   4.8359375  4.83984375
 4.84765625 4.875      4.87890625 4.90625    4.9453125 ]

  warnings.warn(

2022-12-16 10:36:09,618:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.76953125 1.92382812 1.94335938 1.94726562 1.96484375 2.00976562
 2.02539062 2.04492188 2.06054688 2.09570312 2.20507812 2.79296875
 2.80273438 2.8046875  2.81835938 2.8203125  2.828125   2.8515625
 2.86914062 2.875      2.8984375  2.9453125  2.94726562 2.953125
 2.95898438 2.96289062 2.96875    2.97265625 2.9765625  2.97851562
 2.98242188 2.984375   2.98828125 2.99023438 2.9921875  3.00195312
 3.00390625 3.00585938 3.0078125  3.00976562 3.01171875 3.01367188
 3.015625   3.01953125 3.02148438 3.0234375  3.02539062 3.02734375
 3.02929688 3.03125    3.03320312 3.03515625 3.0390625  3.04101562
 3.04296875 3.04492188 3.046875   3.05078125 3.05273438 3.0546875
 3.05664062 3.05859375 3.06054688 3.06445312 3.0703125  3.07226562
 3.07421875 3.07617188 3.08007812 3.08203125 3.08398438 3.0859375
 3.08984375 3.09179688 3.09375    3.09570312 3.09765625 3.09960938
 3.1015625  3.10351562 3.10742188 3.109375   3.11132812 3.11328125
 3.11523438 3.1171875  3.11914062 3.12109375 3.12304688 3.125
 3.12695312 3.12890625 3.13085938 3.1328125  3.13476562 3.13671875
 3.13867188 3.140625   3.14257812 3.14453125 3.14648438 3.1484375
 3.15039062 3.15234375 3.15429688 3.15625    3.15820312 3.16015625
 3.16210938 3.1640625  3.16601562 3.16796875 3.16992188 3.171875
 3.17382812 3.17578125 3.17773438 3.1796875  3.18164062 3.18359375
 3.18554688 3.1875     3.18945312 3.19140625 3.19335938 3.1953125
 3.19726562 3.19921875 3.20117188 3.203125   3.20507812 3.20703125
 3.20898438 3.2109375  3.21289062 3.21484375 3.21679688 3.21875
 3.22070312 3.22265625 3.22460938 3.2265625  3.22851562 3.23046875
 3.23242188 3.234375   3.23632812 3.23828125 3.24023438 3.2421875
 3.24414062 3.24609375 3.24804688 3.25       3.25195312 3.25390625
 3.25585938 3.2578125  3.25976562 3.26171875 3.26367188 3.265625
 3.26757812 3.26953125 3.27148438 3.27539062 3.27734375 3.27929688
 3.28125    3.28320312 3.28515625 3.28710938 3.2890625  3.29101562
 3.29296875 3.296875   3.29882812 3.30078125 3.30273438 3.3046875
 3.30664062 3.31054688 3.3125     3.31445312 3.31640625 3.31835938
 3.32226562 3.32421875 3.32617188 3.328125   3.33203125 3.33398438
 3.3359375  3.33789062 3.33984375 3.34179688 3.34570312 3.34765625
 3.34960938 3.35351562 3.35546875 3.35742188 3.359375   3.36132812
 3.36328125 3.36523438 3.3671875  3.37109375 3.37304688 3.375
 3.37695312 3.38085938 3.3828125  3.38476562 3.38671875 3.38867188
 3.39257812 3.40039062 3.40234375 3.40625    3.40820312 3.41015625
 3.41796875 3.42578125 3.42773438 3.4296875  3.43945312 3.4453125
 3.45507812 3.45898438 3.4609375  3.46679688 3.46875    3.47851562
 3.48046875 3.48242188 3.48632812 3.49023438 3.49804688 3.5
 3.50390625 3.50585938 3.51367188 3.5234375  3.52734375 3.54296875
 3.6171875  3.65039062 3.66796875 3.671875   3.69921875 3.72851562
 3.734375   3.77929688 3.79101562 3.81640625 3.8203125  3.82421875
 3.82617188 3.85546875 3.85742188 3.91601562 3.93554688 3.94726562
 3.953125   3.95703125 3.96484375 4.14648438 4.1484375  4.17382812
 4.3515625  4.45507812 4.75585938 4.78125    4.78320312 4.78710938
 4.7890625  4.79101562 4.8046875  4.81054688 4.81640625 4.8203125
 4.82226562 4.82421875 4.82617188 4.8359375  4.84179688 4.84375
 4.84960938 4.85546875 4.85742188 4.859375   4.86523438 4.87109375
 4.87695312 4.88085938 4.8828125  4.88867188 4.90429688 4.91992188
 4.92382812 4.95898438 4.96484375 4.98828125]

  warnings.warn(

2022-12-16 10:36:09,707:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.625    1.640625 1.65625  1.828125 1.859375 1.890625 1.90625  1.921875
 1.9375   1.953125 2.171875 2.5      2.71875  2.859375 2.875    2.921875
 2.9375   2.953125 2.96875  2.984375 3.015625 3.03125  3.046875 3.0625
 3.078125 3.09375  3.109375 3.125    3.140625 3.15625  3.171875 3.1875
 3.203125 3.21875  3.234375 3.25     3.265625 3.28125  3.296875 3.3125
 3.328125 3.34375  3.359375 3.375    3.390625 3.40625  3.421875 3.4375
 3.453125 3.46875  3.484375 3.5      3.515625 3.546875 3.59375  3.609375
 3.640625 3.78125  3.796875 3.8125   3.828125 3.875    3.984375 4.015625
 4.21875  4.234375 4.40625  4.484375 4.796875 4.828125 4.84375  4.859375
 4.875    4.890625 4.90625  4.921875 4.9375   4.953125 5.015625 5.046875
 5.171875 5.328125]

  warnings.warn(

2022-12-16 10:36:09,750:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.65625   1.8046875 1.8515625 1.8671875 1.875     1.9453125 2.109375
 2.21875   2.7109375 2.71875   2.734375  2.765625  2.7734375 2.78125
 2.7890625 2.8046875 2.8203125 2.828125  2.8359375 2.84375   2.8515625
 2.859375  2.8671875 2.875     2.890625  2.8984375 2.90625   2.9140625
 2.921875  2.9296875 2.9375    2.9453125 2.953125  2.9609375 2.96875
 2.9765625 2.984375  2.9921875 3.0078125 3.015625  3.0234375 3.03125
 3.0390625 3.046875  3.0546875 3.0625    3.0703125 3.078125  3.0859375
 3.09375   3.1015625 3.109375  3.1171875 3.125     3.1328125 3.140625
 3.1484375 3.15625   3.1640625 3.171875  3.1796875 3.1875    3.1953125
 3.203125  3.2109375 3.21875   3.2265625 3.234375  3.2421875 3.25
 3.2578125 3.265625  3.2734375 3.28125   3.2890625 3.296875  3.3046875
 3.3125    3.328125  3.3359375 3.34375   3.3515625 3.359375  3.3671875
 3.375     3.3828125 3.390625  3.3984375 3.40625   3.4140625 3.421875
 3.4296875 3.4375    3.4453125 3.453125  3.4609375 3.46875   3.4765625
 3.484375  3.4921875 3.5       3.546875  3.5703125 3.578125  3.5859375
 3.6171875 3.625     3.6328125 3.6484375 3.6796875 3.6875    3.6953125
 3.703125  3.71875   3.75      3.7734375 3.796875  3.8125    3.8203125
 3.828125  3.8359375 3.84375   3.8515625 3.8828125 3.890625  4.0234375
 4.0546875 4.0703125 4.0859375 4.21875   4.5078125 4.546875  4.609375
 4.640625  4.671875  4.6796875 4.6875    4.703125  4.7109375 4.71875
 4.7265625 4.734375  4.7421875 4.75      4.7578125 4.765625  4.7734375
 4.78125   4.8125    4.8203125 4.828125  4.8984375 4.9140625 4.9296875
 5.0859375 5.2578125]

  warnings.warn(

2022-12-16 10:36:09,848:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.64746094 1.91796875 1.92773438 1.94726562 1.95507812 1.95703125
 1.95996094 1.984375   1.98535156 1.99902344 2.13964844 2.14648438
 2.79980469 2.80957031 2.83789062 2.86328125 2.86621094 2.8671875
 2.86914062 2.87402344 2.87597656 2.87695312 2.87792969 2.87890625
 2.88183594 2.88476562 2.88867188 2.89453125 2.89941406 2.90039062
 2.90136719 2.90625    2.91015625 2.91113281 2.91210938 2.9140625
 2.91503906 2.92285156 2.92578125 2.92675781 2.92773438 2.93066406
 2.93164062 2.93457031 2.93945312 2.94042969 2.94140625 2.94238281
 2.94335938 2.94433594 2.9453125  2.94628906 2.94726562 2.94824219
 2.95019531 2.95214844 2.953125   2.95605469 2.95800781 2.95898438
 2.9609375  2.96289062 2.96386719 2.96582031 2.96777344 2.96972656
 2.97167969 2.97363281 2.97558594 2.97851562 2.98046875 2.98144531
 2.98242188 2.98339844 2.984375   2.99023438 2.99511719 2.99804688
 2.99902344 3.00195312 3.00292969 3.00390625 3.00488281 3.00585938
 3.0078125  3.00878906 3.00976562 3.01074219 3.01953125 3.02050781
 3.02539062 3.03808594 3.0390625  3.04003906 3.04101562 3.04296875
 3.04980469 3.05371094 3.05664062 3.06152344 3.0625     3.06933594
 3.0703125  3.07324219 3.07519531 3.08007812 3.08300781 3.08496094
 3.0859375  3.08691406 3.08789062 3.09082031 3.09179688 3.09277344
 3.09375    3.09667969 3.09863281 3.09960938 3.10351562 3.10644531
 3.10839844 3.109375   3.11035156 3.11132812 3.11328125 3.11425781
 3.11523438 3.11621094 3.1171875  3.11816406 3.12011719 3.12109375
 3.12207031 3.12304688 3.12402344 3.125      3.12695312 3.12792969
 3.12890625 3.12988281 3.13085938 3.1328125  3.13378906 3.13476562
 3.13574219 3.13671875 3.13769531 3.13867188 3.140625   3.14160156
 3.14257812 3.14355469 3.14453125 3.14550781 3.14648438 3.14746094
 3.1484375  3.14941406 3.15039062 3.15136719 3.15234375 3.15332031
 3.15429688 3.15527344 3.15625    3.15722656 3.15820312 3.15917969
 3.16015625 3.16113281 3.16210938 3.16308594 3.1640625  3.16503906
 3.16601562 3.16699219 3.16796875 3.16894531 3.16992188 3.17089844
 3.171875   3.17285156 3.17382812 3.17480469 3.17578125 3.17675781
 3.17773438 3.17871094 3.1796875  3.18066406 3.18164062 3.18261719
 3.18359375 3.18457031 3.18554688 3.18652344 3.1875     3.18847656
 3.18945312 3.19042969 3.19140625 3.19238281 3.19335938 3.19433594
 3.1953125  3.19628906 3.19824219 3.19921875 3.20117188 3.20214844
 3.203125   3.20410156 3.20507812 3.20605469 3.20703125 3.20800781
 3.20898438 3.20996094 3.2109375  3.21191406 3.21289062 3.21386719
 3.21484375 3.21582031 3.21679688 3.21777344 3.21875    3.21972656
 3.22070312 3.22167969 3.22265625 3.22363281 3.22460938 3.22558594
 3.2265625  3.22753906 3.22851562 3.22949219 3.23046875 3.23144531
 3.23242188 3.23339844 3.234375   3.23535156 3.23632812 3.23730469
 3.23828125 3.23925781 3.24121094 3.2421875  3.24316406 3.24414062
 3.24511719 3.24609375 3.24707031 3.24804688 3.25       3.25097656
 3.25195312 3.25292969 3.25390625 3.25488281 3.25585938 3.25683594
 3.26074219 3.26269531 3.26367188 3.26464844 3.26660156 3.26757812
 3.26953125 3.27050781 3.27246094 3.2734375  3.27441406 3.27539062
 3.27636719 3.27734375 3.27832031 3.27929688 3.28027344 3.28222656
 3.28320312 3.28613281 3.28710938 3.2890625  3.29003906 3.29199219
 3.29394531 3.29492188 3.29589844 3.296875   3.29785156 3.29882812
 3.29980469 3.30078125 3.30273438 3.30371094 3.30859375 3.30957031
 3.3125     3.31542969 3.31640625 3.31738281 3.31933594 3.32226562
 3.32324219 3.32617188 3.32910156 3.33300781 3.33496094 3.3359375
 3.33789062 3.33886719 3.34375    3.34570312 3.34863281 3.3515625
 3.35253906 3.35546875 3.35644531 3.35742188 3.359375   3.36035156
 3.36132812 3.36230469 3.36621094 3.3671875  3.36816406 3.36914062
 3.37011719 3.37207031 3.37304688 3.375      3.37597656 3.37890625
 3.37988281 3.38183594 3.3828125  3.38378906 3.38476562 3.38964844
 3.390625   3.39355469 3.39453125 3.39648438 3.3984375  3.39941406
 3.40039062 3.40625    3.40722656 3.40917969 3.41308594 3.4140625
 3.41601562 3.41699219 3.421875   3.42285156 3.42382812 3.42675781
 3.4296875  3.43261719 3.43359375 3.43457031 3.4375     3.43847656
 3.44042969 3.44140625 3.44238281 3.44824219 3.45214844 3.45410156
 3.46191406 3.47363281 3.48632812 3.49511719 3.52734375 3.53222656
 3.54101562 3.546875   3.55078125 3.58300781 3.60742188 3.62402344
 3.65429688 3.66210938 3.66503906 3.66796875 3.703125   3.734375
 3.78710938 3.82617188 3.85253906 3.85742188 3.86523438 3.87402344
 3.8828125  3.88769531 3.89453125 3.91503906 3.91796875 3.92285156
 3.9375     3.94433594 3.97851562 3.97949219 3.99023438 4.07910156
 4.09472656 4.14160156 4.19824219 4.29882812 4.34570312 4.39355469
 4.51660156 4.5390625  4.68261719 4.75292969 4.76367188 4.77929688
 4.78320312 4.79199219 4.81835938 4.8203125  4.82226562 4.82324219
 4.82714844 4.82910156 4.83300781 4.8359375  4.83886719 4.84277344
 4.84375    4.84472656 4.84570312 4.84765625 4.85058594 4.85253906
 4.85351562 4.859375   4.87011719 4.87890625 4.890625   4.92382812
 4.92578125 4.94042969 4.95410156 4.97460938]

  warnings.warn(

2022-12-16 10:36:13,198:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.74609375 2.3203125  2.82421875 2.828125   2.8671875  2.87109375
 2.875      2.8828125  2.90625    2.91015625 2.9140625  2.91796875
 2.9296875  2.93359375 2.9375     2.94140625 2.9453125  2.94921875
 2.953125   2.95703125 2.9609375  2.96484375 2.96875    2.97265625
 2.9765625  2.98046875 2.984375   2.98828125 2.9921875  2.99609375
 3.00390625 3.0078125  3.01171875 3.015625   3.01953125 3.0234375
 3.02734375 3.03515625 3.0390625  3.04296875 3.046875   3.05859375
 3.0625     3.06640625 3.0703125  3.07421875 3.078125   3.08203125
 3.0859375  3.08984375 3.09375    3.09765625 3.1015625  3.10546875
 3.109375   3.11328125 3.1171875  3.12109375 3.125      3.12890625
 3.1328125  3.13671875 3.140625   3.14453125 3.1484375  3.15234375
 3.15625    3.16015625 3.1640625  3.16796875 3.171875   3.17578125
 3.1796875  3.18359375 3.1875     3.19140625 3.1953125  3.19921875
 3.203125   3.20703125 3.2109375  3.21484375 3.21875    3.22265625
 3.2265625  3.23046875 3.234375   3.23828125 3.2421875  3.24609375
 3.25       3.25390625 3.2578125  3.26171875 3.265625   3.26953125
 3.2734375  3.27734375 3.28125    3.28515625 3.2890625  3.29296875
 3.296875   3.30078125 3.3046875  3.30859375 3.3125     3.31640625
 3.3203125  3.32421875 3.328125   3.33203125 3.3359375  3.33984375
 3.34375    3.34765625 3.3515625  3.35546875 3.359375   3.36328125
 3.3671875  3.37109375 3.375      3.37890625 3.3828125  3.38671875
 3.390625   3.39453125 3.3984375  3.40234375 3.40625    3.41015625
 3.41796875 3.421875   3.42578125 3.4296875  3.43359375 3.44140625
 3.484375   3.48828125 3.49609375 3.515625   3.5546875  3.5625
 3.59765625 3.60546875 3.61328125 3.62890625 3.6796875  3.73828125
 3.7421875  3.75390625 3.76171875 3.76953125 3.78125    3.80078125
 3.81640625 3.84765625 4.15234375 4.16796875 4.18359375 4.3046875
 4.30859375 4.34375    4.546875   4.56640625 4.58203125 4.6328125
 4.68359375 4.70703125 4.72265625 4.73046875 4.734375   4.7421875
 4.74609375 4.75390625 4.7578125  4.76171875 4.765625   4.7734375
 4.77734375 4.78515625 4.7890625  4.79296875 4.80078125 4.8671875
 4.91015625 4.94140625 4.98828125]

  warnings.warn(

2022-12-16 10:36:13,217:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.47167969 1.48242188 1.76367188 1.78417969 1.81054688 1.82421875
 1.82617188 1.85449219 1.87792969 1.91015625 1.93554688 1.93652344
 1.94433594 2.05761719 2.2109375  2.36425781 2.41210938 2.48730469
 2.515625   2.54492188 2.55566406 2.640625   2.64355469 2.67089844
 2.70605469 2.7109375  2.71484375 2.71679688 2.72070312 2.72167969
 2.72753906 2.74121094 2.74316406 2.74511719 2.75       2.75488281
 2.76171875 2.77050781 2.7734375  2.77539062 2.78222656 2.78320312
 2.79101562 2.79296875 2.79394531 2.79492188 2.79882812 2.79980469
 2.80273438 2.80371094 2.8046875  2.80566406 2.80761719 2.80957031
 2.81054688 2.81152344 2.81347656 2.81445312 2.81542969 2.81640625
 2.81738281 2.81835938 2.81933594 2.8203125  2.82128906 2.82324219
 2.82421875 2.82910156 2.83007812 2.83105469 2.83203125 2.83398438
 2.83496094 2.83691406 2.83886719 2.83984375 2.84179688 2.84277344
 2.84375    2.84472656 2.84570312 2.84667969 2.84863281 2.8515625
 2.85253906 2.85351562 2.85449219 2.85644531 2.85839844 2.86035156
 2.86132812 2.86230469 2.86328125 2.86425781 2.86621094 2.8671875
 2.87109375 2.87207031 2.87402344 2.87597656 2.87792969 2.88085938
 2.89160156 2.89257812 2.89355469 2.89746094 2.90332031 2.9140625
 2.91601562 2.91992188 2.92773438 2.93554688 2.9453125  2.953125
 2.95703125 2.95800781 2.96777344 2.97070312 2.98242188 2.98632812
 2.99414062 2.99511719 2.99707031 3.00195312 3.00292969 3.01757812
 3.02734375 3.03027344 3.03125    3.03515625 3.03710938 3.03808594
 3.0390625  3.04101562 3.04199219 3.04492188 3.04589844 3.04882812
 3.05566406 3.06640625 3.06835938 3.07324219 3.07519531 3.08105469
 3.08300781 3.08496094 3.08789062 3.09375    3.09765625 3.10253906
 3.10351562 3.10546875 3.109375   3.11035156 3.11132812 3.11328125
 3.11523438 3.11621094 3.12109375 3.125      3.12597656 3.12695312
 3.12792969 3.12988281 3.13183594 3.1328125  3.13378906 3.13476562
 3.13574219 3.13769531 3.13867188 3.13964844 3.140625   3.14160156
 3.14355469 3.14453125 3.14648438 3.14746094 3.14941406 3.15136719
 3.15429688 3.15527344 3.15625    3.15820312 3.15917969 3.16113281
 3.16210938 3.16308594 3.1640625  3.16503906 3.16699219 3.16796875
 3.16894531 3.16992188 3.17089844 3.171875   3.17382812 3.17480469
 3.17578125 3.17675781 3.17773438 3.17871094 3.1796875  3.18066406
 3.18164062 3.18261719 3.18359375 3.18457031 3.18554688 3.18652344
 3.18847656 3.18945312 3.19042969 3.19140625 3.19238281 3.19335938
 3.19433594 3.1953125  3.19628906 3.19726562 3.19824219 3.20117188
 3.20214844 3.203125   3.20410156 3.20507812 3.20605469 3.20703125
 3.20800781 3.20898438 3.20996094 3.2109375  3.21191406 3.21289062
 3.21386719 3.21484375 3.21679688 3.21777344 3.21875    3.21972656
 3.22070312 3.22167969 3.22265625 3.22363281 3.22460938 3.22558594
 3.2265625  3.22753906 3.22851562 3.22949219 3.23046875 3.23144531
 3.23242188 3.23339844 3.234375   3.23535156 3.23730469 3.23828125
 3.23925781 3.24023438 3.24121094 3.2421875  3.24316406 3.24414062
 3.24511719 3.24609375 3.24707031 3.24804688 3.24902344 3.25
 3.25097656 3.25195312 3.25390625 3.25488281 3.25585938 3.25683594
 3.2578125  3.25878906 3.25976562 3.26171875 3.26269531 3.26367188
 3.26464844 3.265625   3.26660156 3.26757812 3.26855469 3.26953125
 3.27050781 3.27148438 3.27246094 3.27441406 3.27539062 3.27636719
 3.27832031 3.27929688 3.28125    3.28222656 3.28417969 3.28710938
 3.2890625  3.29003906 3.29101562 3.29199219 3.29296875 3.29394531
 3.29492188 3.29589844 3.296875   3.29785156 3.30078125 3.30175781
 3.30273438 3.30371094 3.3046875  3.30566406 3.30664062 3.30859375
 3.30957031 3.31054688 3.31152344 3.3125     3.31347656 3.31542969
 3.31738281 3.31835938 3.31933594 3.3203125  3.32128906 3.32324219
 3.32519531 3.32714844 3.328125   3.32910156 3.33105469 3.33203125
 3.33886719 3.34082031 3.34375    3.34667969 3.34765625 3.34863281
 3.34960938 3.35058594 3.3515625  3.35253906 3.35449219 3.35644531
 3.35839844 3.359375   3.36230469 3.36425781 3.36816406 3.36914062
 3.37011719 3.37207031 3.37597656 3.37695312 3.37792969 3.37890625
 3.37988281 3.38183594 3.38476562 3.38964844 3.39257812 3.39648438
 3.39746094 3.39941406 3.40136719 3.40332031 3.40722656 3.40820312
 3.40917969 3.41015625 3.41308594 3.4140625  3.41503906 3.41796875
 3.41894531 3.421875   3.42382812 3.42480469 3.42578125 3.42675781
 3.42871094 3.4296875  3.43066406 3.43359375 3.43457031 3.43652344
 3.4375     3.43847656 3.43945312 3.44042969 3.44238281 3.44433594
 3.45507812 3.45800781 3.46191406 3.46289062 3.46386719 3.46679688
 3.47167969 3.47265625 3.47460938 3.47753906 3.47851562 3.48046875
 3.48339844 3.48535156 3.48632812 3.48730469 3.49023438 3.49121094
 3.4921875  3.49511719 3.49902344 3.5        3.50097656 3.50292969
 3.50488281 3.50683594 3.50976562 3.51269531 3.51367188 3.52441406
 3.52539062 3.52636719 3.52734375 3.52832031 3.53125    3.53613281
 3.54785156 3.55664062 3.56542969 3.56640625 3.57128906 3.57519531
 3.57714844 3.5859375  3.59277344 3.59570312 3.59863281 3.67089844
 3.69238281 3.6953125  3.70019531 3.70214844 3.71386719 3.72460938
 3.83398438 3.86816406 3.87597656 3.88378906 3.89550781 3.89746094
 3.90039062 3.94433594 3.96386719 4.0390625  4.06445312 4.078125
 4.07910156 4.11035156 4.1484375  4.29394531 4.30371094 4.32421875
 4.43554688 4.69140625 4.71484375 4.73144531 4.73242188 4.75
 4.75878906 4.76953125 4.77050781 4.77734375 4.77929688 4.78125
 4.78515625 4.79101562 4.79199219 4.79394531 4.79589844 4.79785156
 4.79980469 4.80859375 4.83203125 4.85839844 4.86621094 4.87304688
 4.95996094 4.97265625 4.9921875  5.04980469 5.09667969]

  warnings.warn(

2022-12-16 10:36:13,219:INFO:Calculating mean and std
2022-12-16 10:36:13,221:INFO:Creating metrics dataframe
2022-12-16 10:36:13,227:INFO:Uploading results into container
2022-12-16 10:36:13,228:INFO:Uploading model into container now
2022-12-16 10:36:13,229:INFO:master_model_container: 1
2022-12-16 10:36:13,229:INFO:display_container: 2
2022-12-16 10:36:13,229:INFO:LinearRegression(n_jobs=-1)
2022-12-16 10:36:13,229:INFO:create_model() successfully completed......................................
2022-12-16 10:36:13,412:WARNING:create_model() for LinearRegression(n_jobs=-1) raised an exception or returned all 0.0, trying without fit_kwargs:
2022-12-16 10:36:13,420:WARNING:Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 795, in compare_models
    assert (
AssertionError

2022-12-16 10:36:13,420:INFO:Initializing create_model()
2022-12-16 10:36:13,420:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002281239F8E0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022810EC8B20>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:36:13,420:INFO:Checking exceptions
2022-12-16 10:36:13,424:INFO:Importing libraries
2022-12-16 10:36:13,424:INFO:Copying training dataset
2022-12-16 10:36:13,430:INFO:Defining folds
2022-12-16 10:36:13,431:INFO:Declaring metric variables
2022-12-16 10:36:13,431:INFO:Importing untrained model
2022-12-16 10:36:13,431:INFO:Linear Regression Imported successfully
2022-12-16 10:36:13,432:INFO:Starting cross validation
2022-12-16 10:36:13,434:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:36:16,149:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.65625   1.8046875 1.8515625 1.8671875 1.875     1.9453125 2.109375
 2.21875   2.7109375 2.71875   2.734375  2.765625  2.7734375 2.78125
 2.7890625 2.8046875 2.8203125 2.828125  2.8359375 2.84375   2.8515625
 2.859375  2.8671875 2.875     2.890625  2.8984375 2.90625   2.9140625
 2.921875  2.9296875 2.9375    2.9453125 2.953125  2.9609375 2.96875
 2.9765625 2.984375  2.9921875 3.0078125 3.015625  3.0234375 3.03125
 3.0390625 3.046875  3.0546875 3.0625    3.0703125 3.078125  3.0859375
 3.09375   3.1015625 3.109375  3.1171875 3.125     3.1328125 3.140625
 3.1484375 3.15625   3.1640625 3.171875  3.1796875 3.1875    3.1953125
 3.203125  3.2109375 3.21875   3.2265625 3.234375  3.2421875 3.25
 3.2578125 3.265625  3.2734375 3.28125   3.2890625 3.296875  3.3046875
 3.3125    3.328125  3.3359375 3.34375   3.3515625 3.359375  3.3671875
 3.375     3.3828125 3.390625  3.3984375 3.40625   3.4140625 3.421875
 3.4296875 3.4375    3.4453125 3.453125  3.4609375 3.46875   3.4765625
 3.484375  3.4921875 3.5       3.546875  3.5703125 3.578125  3.5859375
 3.6171875 3.625     3.6328125 3.6484375 3.6796875 3.6875    3.6953125
 3.703125  3.71875   3.75      3.7734375 3.796875  3.8125    3.8203125
 3.828125  3.8359375 3.84375   3.8515625 3.8828125 3.890625  4.0234375
 4.0546875 4.0703125 4.0859375 4.21875   4.5078125 4.546875  4.609375
 4.640625  4.671875  4.6796875 4.6875    4.703125  4.7109375 4.71875
 4.7265625 4.734375  4.7421875 4.75      4.7578125 4.765625  4.7734375
 4.78125   4.8125    4.8203125 4.828125  4.8984375 4.9140625 4.9296875
 5.0859375 5.2578125]

  warnings.warn(

2022-12-16 10:36:16,215:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.625      1.8359375  1.8828125  1.8984375  1.99609375 2.12890625
 2.4921875  2.5234375  2.76171875 2.84375    2.84765625 2.86328125
 2.88671875 2.91796875 2.9375     2.94140625 2.9453125  2.94921875
 2.95703125 2.9609375  2.96484375 2.96875    2.97265625 2.9765625
 2.98046875 2.984375   2.98828125 2.9921875  2.99609375 3.00390625
 3.0078125  3.01171875 3.015625   3.01953125 3.0234375  3.02734375
 3.03125    3.03515625 3.0390625  3.046875   3.05078125 3.0546875
 3.05859375 3.0625     3.06640625 3.0703125  3.07421875 3.078125
 3.08203125 3.0859375  3.08984375 3.09375    3.09765625 3.1015625
 3.10546875 3.109375   3.11328125 3.1171875  3.12109375 3.125
 3.12890625 3.1328125  3.13671875 3.140625   3.14453125 3.1484375
 3.15234375 3.15625    3.16015625 3.1640625  3.16796875 3.171875
 3.17578125 3.1796875  3.18359375 3.1875     3.19140625 3.1953125
 3.19921875 3.203125   3.20703125 3.2109375  3.21484375 3.21875
 3.22265625 3.2265625  3.23046875 3.234375   3.23828125 3.2421875
 3.24609375 3.25       3.25390625 3.2578125  3.26171875 3.265625
 3.26953125 3.2734375  3.27734375 3.28125    3.28515625 3.2890625
 3.29296875 3.296875   3.30078125 3.3046875  3.30859375 3.3125
 3.31640625 3.3203125  3.32421875 3.328125   3.33203125 3.3359375
 3.33984375 3.34375    3.34765625 3.3515625  3.35546875 3.359375
 3.36328125 3.3671875  3.37109375 3.375      3.37890625 3.3828125
 3.38671875 3.390625   3.39453125 3.3984375  3.40234375 3.40625
 3.4140625  3.41796875 3.421875   3.42578125 3.4296875  3.43359375
 3.453125   3.45703125 3.4609375  3.51953125 3.5234375  3.54296875
 3.56640625 3.57421875 3.59375    3.6015625  3.6171875  3.625
 3.66015625 3.6640625  3.671875   3.6875     3.73828125 3.765625
 3.7890625  3.79296875 3.8046875  3.81640625 3.828125   3.83203125
 3.84375    3.8515625  3.859375   3.86328125 3.8671875  3.92578125
 3.98828125 4.00390625 4.01953125 4.10546875 4.12109375 4.12890625
 4.2265625  4.34375    4.67578125 4.703125   4.70703125 4.71875
 4.73828125 4.7421875  4.74609375 4.76171875 4.765625   4.76953125
 4.7734375  4.78125    4.79296875 4.796875   4.8046875  4.80859375
 4.8125     4.81640625 4.82421875 4.828125   4.8359375  4.83984375
 4.84765625 4.875      4.87890625 4.90625    4.9453125 ]

  warnings.warn(

703125  4.7109375
 4.72265625 4.73046875 4.75390625 4.76171875 4.765625   4.76953125
 4.7734375  4.7890625  4.79296875 4.80078125 4.8046875  4.80859375
 4.8125     4.828125   4.85546875 4.86328125 4.87109375 4.8828125
 4.8984375  4.90625    4.94140625 4.9453125  4.94921875 4.96875
 4.99609375]

  warnings.warn(

2022-12-16 10:36:16,240:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.76953125 1.92382812 1.94335938 1.94726562 1.96484375 2.00976562
 2.02539062 2.04492188 2.06054688 2.09570312 2.20507812 2.79296875
 2.80273438 2.8046875  2.81835938 2.8203125  2.828125   2.8515625
 2.86914062 2.875      2.8984375  2.9453125  2.94726562 2.953125
 2.95898438 2.96289062 2.96875    2.97265625 2.9765625  2.97851562
 2.98242188 2.984375   2.98828125 2.99023438 2.9921875  3.00195312
 3.00390625 3.00585938 3.0078125  3.00976562 3.01171875 3.01367188
 3.015625   3.01953125 3.02148438 3.0234375  3.02539062 3.02734375
 3.02929688 3.03125    3.03320312 3.03515625 3.0390625  3.04101562
 3.04296875 3.04492188 3.046875   3.05078125 3.05273438 3.0546875
 3.05664062 3.05859375 3.06054688 3.06445312 3.0703125  3.07226562
 3.07421875 3.07617188 3.08007812 3.08203125 3.08398438 3.0859375
 3.08984375 3.09179688 3.09375    3.09570312 3.09765625 3.09960938
 3.1015625  3.10351562 3.10742188 3.109375   3.11132812 3.11328125
 3.11523438 3.1171875  3.11914062 3.12109375 3.12304688 3.125
 3.12695312 3.12890625 3.13085938 3.1328125  3.13476562 3.13671875
 3.13867188 3.140625   3.14257812 3.14453125 3.14648438 3.1484375
 3.15039062 3.15234375 3.15429688 3.15625    3.15820312 3.16015625
 3.16210938 3.1640625  3.16601562 3.16796875 3.16992188 3.171875
 3.17382812 3.17578125 3.17773438 3.1796875  3.18164062 3.18359375
 3.18554688 3.1875     3.18945312 3.19140625 3.19335938 3.1953125
 3.19726562 3.19921875 3.20117188 3.203125   3.20507812 3.20703125
 3.20898438 3.2109375  3.21289062 3.21484375 3.21679688 3.21875
 3.22070312 3.22265625 3.22460938 3.2265625  3.22851562 3.23046875
 3.23242188 3.234375   3.23632812 3.23828125 3.24023438 3.2421875
 3.24414062 3.24609375 3.24804688 3.25       3.25195312 3.25390625
 3.25585938 3.2578125  3.25976562 3.26171875 3.26367188 3.265625
 3.26757812 3.26953125 3.27148438 3.27539062 3.27734375 3.27929688
 3.28125    3.28320312 3.28515625 3.28710938 3.2890625  3.29101562
 3.29296875 3.296875   3.29882812 3.30078125 3.30273438 3.3046875
 3.30664062 3.31054688 3.3125     3.31445312 3.31640625 3.31835938
 3.32226562 3.32421875 3.32617188 3.328125   3.33203125 3.33398438
 3.3359375  3.33789062 3.33984375 3.34179688 3.34570312 3.34765625
 3.34960938 3.35351562 3.35546875 3.35742188 3.359375   3.36132812
 3.36328125 3.36523438 3.3671875  3.37109375 3.37304688 3.375
 3.37695312 3.38085938 3.3828125  3.38476562 3.38671875 3.38867188
 3.39257812 3.40039062 3.40234375 3.40625    3.40820312 3.41015625
 3.41796875 3.42578125 3.42773438 3.4296875  3.43945312 3.4453125
 3.45507812 3.45898438 3.4609375  3.46679688 3.46875    3.47851562
 3.48046875 3.48242188 3.48632812 3.49023438 3.49804688 3.5
 3.50390625 3.50585938 3.51367188 3.5234375  3.52734375 3.54296875
 3.6171875  3.65039062 3.66796875 3.671875   3.69921875 3.72851562
 3.734375   3.77929688 3.79101562 3.81640625 3.8203125  3.82421875
 3.82617188 3.85546875 3.85742188 3.91601562 3.93554688 3.94726562
 3.953125   3.95703125 3.96484375 4.14648438 4.1484375  4.17382812
 4.3515625  4.45507812 4.75585938 4.78125    4.78320312 4.78710938
 4.7890625  4.79101562 4.8046875  4.81054688 4.81640625 4.8203125
 4.82226562 4.82421875 4.82617188 4.8359375  4.84179688 4.84375
 4.84960938 4.85546875 4.85742188 4.859375   4.86523438 4.87109375
 4.87695312 4.88085938 4.8828125  4.88867188 4.90429688 4.91992188
 4.92382812 4.95898438 4.96484375 4.98828125]

  warnings.warn(

2022-12-16 10:36:16,328:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.625     1.6484375 1.71875   1.7421875 1.75      1.765625  1.9765625
 2.3125    2.625     2.7734375 2.78125   2.796875  2.8046875 2.8203125
 2.828125  2.8359375 2.84375   2.8515625 2.859375  2.8671875 2.875
 2.8828125 2.890625  2.8984375 2.90625   2.9140625 2.921875  2.9296875
 2.9375    2.9453125 2.953125  2.9609375 2.96875   2.9765625 2.984375
 2.9921875 3.0078125 3.015625  3.0234375 3.03125   3.0390625 3.046875
 3.0546875 3.0625    3.0703125 3.078125  3.0859375 3.09375   3.1015625
 3.109375  3.1171875 3.125     3.1328125 3.140625  3.1484375 3.15625
 3.1640625 3.171875  3.1796875 3.1875    3.1953125 3.203125  3.2109375
 3.21875   3.2265625 3.234375  3.2421875 3.25      3.2578125 3.265625
 3.2734375 3.28125   3.2890625 3.296875  3.3046875 3.3125    3.3203125
 3.328125  3.3359375 3.34375   3.3515625 3.359375  3.3671875 3.375
 3.3828125 3.390625  3.3984375 3.40625   3.4140625 3.421875  3.4296875
 3.4375    3.4453125 3.4609375 3.46875   3.4765625 3.4921875 3.5
 3.5078125 3.515625  3.546875  3.5546875 3.5625    3.5703125 3.578125
 3.59375   3.6015625 3.625     3.8046875 3.8125    3.8203125 3.8671875
 3.875     3.890625  3.8984375 3.9140625 3.9375    3.984375  3.9921875
 4.140625  4.2265625 4.3046875 4.390625  4.4765625 4.5390625 4.59375
 4.6015625 4.609375  4.625     4.6328125 4.640625  4.6484375 4.65625
 4.6640625 4.6796875 4.6875    4.703125  4.7265625 4.75      4.7578125
 4.78125   4.8203125]

  warnings.warn(

2022-12-16 10:36:16,331:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.84375   1.890625  1.9140625 1.9609375 1.96875   2.15625   2.578125
 2.640625  2.65625   2.71875   2.734375  2.75      2.78125   2.796875
 2.8046875 2.8125    2.8203125 2.828125  2.8359375 2.84375   2.8515625
 2.859375  2.8671875 2.875     2.8828125 2.890625  2.8984375 2.90625
 2.9140625 2.921875  2.9296875 2.9375    2.9453125 2.953125  2.9609375
 2.96875   2.9765625 2.984375  2.9921875 3.0078125 3.015625  3.0234375
 3.03125   3.0390625 3.046875  3.0546875 3.0625    3.0703125 3.078125
 3.0859375 3.09375   3.1015625 3.109375  3.1171875 3.125     3.1328125
 3.140625  3.1484375 3.15625   3.1640625 3.171875  3.1796875 3.1875
 3.1953125 3.203125  3.2109375 3.21875   3.2265625 3.234375  3.2421875
 3.25      3.2578125 3.265625  3.2734375 3.28125   3.2890625 3.296875
 3.3046875 3.3125    3.3203125 3.328125  3.3359375 3.34375   3.3515625
 3.359375  3.375     3.3828125 3.390625  3.3984375 3.40625   3.4140625
 3.421875  3.4296875 3.4375    3.4453125 3.453125  3.4609375 3.46875
 3.4765625 3.484375  3.4921875 3.5       3.515625  3.5390625 3.5546875
 3.5625    3.578125  3.5859375 3.59375   3.6328125 3.640625  3.65625
 3.6953125 3.7109375 3.7578125 3.765625  3.7890625 3.796875  3.8125
 3.8203125 3.828125  3.8359375 3.84375   3.8515625 3.890625  3.9296875
 3.984375  4.0546875 4.0625    4.21875   4.265625  4.5859375 4.640625
 4.6484375 4.65625   4.6640625 4.6796875 4.6953125 4.703125  4.7109375
 4.71875   4.734375  4.7421875 4.75      4.765625  4.7734375 4.78125
 4.796875  4.8125    4.8203125 4.8828125 4.9375    4.953125  5.046875 ]

  warnings.warn(

2022-12-16 10:36:16,348:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.64746094 1.91796875 1.92773438 1.94726562 1.95507812 1.95703125
 1.95996094 1.984375   1.98535156 1.99902344 2.13964844 2.14648438
 2.79980469 2.80957031 2.83789062 2.86328125 2.86621094 2.8671875
 2.86914062 2.87402344 2.87597656 2.87695312 2.87792969 2.87890625
 2.88183594 2.88476562 2.88867188 2.89453125 2.89941406 2.90039062
 2.90136719 2.90625    2.91015625 2.91113281 2.91210938 2.9140625
 2.91503906 2.92285156 2.92578125 2.92675781 2.92773438 2.93066406
 2.93164062 2.93457031 2.93945312 2.94042969 2.94140625 2.94238281
 2.94335938 2.94433594 2.9453125  2.94628906 2.94726562 2.94824219
 2.95019531 2.95214844 2.953125   2.95605469 2.95800781 2.95898438
 2.9609375  2.96289062 2.96386719 2.96582031 2.96777344 2.96972656
 2.97167969 2.97363281 2.97558594 2.97851562 2.98046875 2.98144531
 2.98242188 2.98339844 2.984375   2.99023438 2.99511719 2.99804688
 2.99902344 3.00195312 3.00292969 3.00390625 3.00488281 3.00585938
 3.0078125  3.00878906 3.00976562 3.01074219 3.01953125 3.02050781
 3.02539062 3.03808594 3.0390625  3.04003906 3.04101562 3.04296875
 3.04980469 3.05371094 3.05664062 3.06152344 3.0625     3.06933594
 3.0703125  3.07324219 3.07519531 3.08007812 3.08300781 3.08496094
 3.0859375  3.08691406 3.08789062 3.09082031 3.09179688 3.09277344
 3.09375    3.09667969 3.09863281 3.09960938 3.10351562 3.10644531
 3.10839844 3.109375   3.11035156 3.11132812 3.11328125 3.11425781
 3.11523438 3.11621094 3.1171875  3.11816406 3.12011719 3.12109375
 3.12207031 3.12304688 3.12402344 3.125      3.12695312 3.12792969
 3.12890625 3.12988281 3.13085938 3.1328125  3.13378906 3.13476562
 3.13574219 3.13671875 3.13769531 3.13867188 3.140625   3.14160156
 3.14257812 3.14355469 3.14453125 3.14550781 3.14648438 3.14746094
 3.1484375  3.14941406 3.15039062 3.15136719 3.15234375 3.15332031
 3.15429688 3.15527344 3.15625    3.15722656 3.15820312 3.15917969
 3.16015625 3.16113281 3.16210938 3.16308594 3.1640625  3.16503906
 3.16601562 3.16699219 3.16796875 3.16894531 3.16992188 3.17089844
 3.171875   3.17285156 3.17382812 3.17480469 3.17578125 3.17675781
 3.17773438 3.17871094 3.1796875  3.18066406 3.18164062 3.18261719
 3.18359375 3.18457031 3.18554688 3.18652344 3.1875     3.18847656
 3.18945312 3.19042969 3.19140625 3.19238281 3.19335938 3.19433594
 3.1953125  3.19628906 3.19824219 3.19921875 3.20117188 3.20214844
 3.203125   3.20410156 3.20507812 3.20605469 3.20703125 3.20800781
 3.20898438 3.20996094 3.2109375  3.21191406 3.21289062 3.21386719
 3.21484375 3.21582031 3.21679688 3.21777344 3.21875    3.21972656
 3.22070312 3.22167969 3.22265625 3.22363281 3.22460938 3.22558594
 3.2265625  3.22753906 3.22851562 3.22949219 3.23046875 3.23144531
 3.23242188 3.23339844 3.234375   3.23535156 3.23632812 3.23730469
 3.23828125 3.23925781 3.24121094 3.2421875  3.24316406 3.24414062
 3.24511719 3.24609375 3.24707031 3.24804688 3.25       3.25097656
 3.25195312 3.25292969 3.25390625 3.25488281 3.25585938 3.25683594
 3.26074219 3.26269531 3.26367188 3.26464844 3.26660156 3.26757812
 3.26953125 3.27050781 3.27246094 3.2734375  3.27441406 3.27539062
 3.27636719 3.27734375 3.27832031 3.27929688 3.28027344 3.28222656
 3.28320312 3.28613281 3.28710938 3.2890625  3.29003906 3.29199219
 3.29394531 3.29492188 3.29589844 3.296875   3.29785156 3.29882812
 3.29980469 3.30078125 3.30273438 3.30371094 3.30859375 3.30957031
 3.3125     3.31542969 3.31640625 3.31738281 3.31933594 3.32226562
 3.32324219 3.32617188 3.32910156 3.33300781 3.33496094 3.3359375
 3.33789062 3.33886719 3.34375    3.34570312 3.34863281 3.3515625
 3.35253906 3.35546875 3.35644531 3.35742188 3.359375   3.36035156
 3.36132812 3.36230469 3.36621094 3.3671875  3.36816406 3.36914062
 3.37011719 3.37207031 3.37304688 3.375      3.37597656 3.37890625
 3.37988281 3.38183594 3.3828125  3.38378906 3.38476562 3.38964844
 3.390625   3.39355469 3.39453125 3.39648438 3.3984375  3.39941406
 3.40039062 3.40625    3.40722656 3.40917969 3.41308594 3.4140625
 3.41601562 3.41699219 3.421875   3.42285156 3.42382812 3.42675781
 3.4296875  3.43261719 3.43359375 3.43457031 3.4375     3.43847656
 3.44042969 3.44140625 3.44238281 3.44824219 3.45214844 3.45410156
 3.46191406 3.47363281 3.48632812 3.49511719 3.52734375 3.53222656
 3.54101562 3.546875   3.55078125 3.58300781 3.60742188 3.62402344
 3.65429688 3.66210938 3.66503906 3.66796875 3.703125   3.734375
 3.78710938 3.82617188 3.85253906 3.85742188 3.86523438 3.87402344
 3.8828125  3.88769531 3.89453125 3.91503906 3.91796875 3.92285156
 3.9375     3.94433594 3.97851562 3.97949219 3.99023438 4.07910156
 4.09472656 4.14160156 4.19824219 4.29882812 4.34570312 4.39355469
 4.51660156 4.5390625  4.68261719 4.75292969 4.76367188 4.77929688
 4.78320312 4.79199219 4.81835938 4.8203125  4.82226562 4.82324219
 4.82714844 4.82910156 4.83300781 4.8359375  4.83886719 4.84277344
 4.84375    4.84472656 4.84570312 4.84765625 4.85058594 4.85253906
 4.85351562 4.859375   4.87011719 4.87890625 4.890625   4.92382812
 4.92578125 4.94042969 4.95410156 4.97460938]

  warnings.warn(

2022-12-16 10:36:17,603:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.74609375 2.3203125  2.82421875 2.828125   2.8671875  2.87109375
 2.875      2.8828125  2.90625    2.91015625 2.9140625  2.91796875
 2.9296875  2.93359375 2.9375     2.94140625 2.9453125  2.94921875
 2.953125   2.95703125 2.9609375  2.96484375 2.96875    2.97265625
 2.9765625  2.98046875 2.984375   2.98828125 2.9921875  2.99609375
 3.00390625 3.0078125  3.01171875 3.015625   3.01953125 3.0234375
 3.02734375 3.03515625 3.0390625  3.04296875 3.046875   3.05859375
 3.0625     3.06640625 3.0703125  3.07421875 3.078125   3.08203125
 3.0859375  3.08984375 3.09375    3.09765625 3.1015625  3.10546875
 3.109375   3.11328125 3.1171875  3.12109375 3.125      3.12890625
 3.1328125  3.13671875 3.140625   3.14453125 3.1484375  3.15234375
 3.15625    3.16015625 3.1640625  3.16796875 3.171875   3.17578125
 3.1796875  3.18359375 3.1875     3.19140625 3.1953125  3.19921875
 3.203125   3.20703125 3.2109375  3.21484375 3.21875    3.22265625
 3.2265625  3.23046875 3.234375   3.23828125 3.2421875  3.24609375
 3.25       3.25390625 3.2578125  3.26171875 3.265625   3.26953125
 3.2734375  3.27734375 3.28125    3.28515625 3.2890625  3.29296875
 3.296875   3.30078125 3.3046875  3.30859375 3.3125     3.31640625
 3.3203125  3.32421875 3.328125   3.33203125 3.3359375  3.33984375
 3.34375    3.34765625 3.3515625  3.35546875 3.359375   3.36328125
 3.3671875  3.37109375 3.375      3.37890625 3.3828125  3.38671875
 3.390625   3.39453125 3.3984375  3.40234375 3.40625    3.41015625
 3.41796875 3.421875   3.42578125 3.4296875  3.43359375 3.44140625
 3.484375   3.48828125 3.49609375 3.515625   3.5546875  3.5625
 3.59765625 3.60546875 3.61328125 3.62890625 3.6796875  3.73828125
 3.7421875  3.75390625 3.76171875 3.76953125 3.78125    3.80078125
 3.81640625 3.84765625 4.15234375 4.16796875 4.18359375 4.3046875
 4.30859375 4.34375    4.546875   4.56640625 4.58203125 4.6328125
 4.68359375 4.70703125 4.72265625 4.73046875 4.734375   4.7421875
 4.74609375 4.75390625 4.7578125  4.76171875 4.765625   4.7734375
 4.77734375 4.78515625 4.7890625  4.79296875 4.80078125 4.8671875
 4.91015625 4.94140625 4.98828125]

  warnings.warn(

2022-12-16 10:36:17,643:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.47167969 1.48242188 1.76367188 1.78417969 1.81054688 1.82421875
 1.82617188 1.85449219 1.87792969 1.91015625 1.93554688 1.93652344
 1.94433594 2.05761719 2.2109375  2.36425781 2.41210938 2.48730469
 2.515625   2.54492188 2.55566406 2.640625   2.64355469 2.67089844
 2.70605469 2.7109375  2.71484375 2.71679688 2.72070312 2.72167969
 2.72753906 2.74121094 2.74316406 2.74511719 2.75       2.75488281
 2.76171875 2.77050781 2.7734375  2.77539062 2.78222656 2.78320312
 2.79101562 2.79296875 2.79394531 2.79492188 2.79882812 2.79980469
 2.80273438 2.80371094 2.8046875  2.80566406 2.80761719 2.80957031
 2.81054688 2.81152344 2.81347656 2.81445312 2.81542969 2.81640625
 2.81738281 2.81835938 2.81933594 2.8203125  2.82128906 2.82324219
 2.82421875 2.82910156 2.83007812 2.83105469 2.83203125 2.83398438
 2.83496094 2.83691406 2.83886719 2.83984375 2.84179688 2.84277344
 2.84375    2.84472656 2.84570312 2.84667969 2.84863281 2.8515625
 2.85253906 2.85351562 2.85449219 2.85644531 2.85839844 2.86035156
 2.86132812 2.86230469 2.86328125 2.86425781 2.86621094 2.8671875
 2.87109375 2.87207031 2.87402344 2.87597656 2.87792969 2.88085938
 2.89160156 2.89257812 2.89355469 2.89746094 2.90332031 2.9140625
 2.91601562 2.91992188 2.92773438 2.93554688 2.9453125  2.953125
 2.95703125 2.95800781 2.96777344 2.97070312 2.98242188 2.98632812
 2.99414062 2.99511719 2.99707031 3.00195312 3.00292969 3.01757812
 3.02734375 3.03027344 3.03125    3.03515625 3.03710938 3.03808594
 3.0390625  3.04101562 3.04199219 3.04492188 3.04589844 3.04882812
 3.05566406 3.06640625 3.06835938 3.07324219 3.07519531 3.08105469
 3.08300781 3.08496094 3.08789062 3.09375    3.09765625 3.10253906
 3.10351562 3.10546875 3.109375   3.11035156 3.11132812 3.11328125
 3.11523438 3.11621094 3.12109375 3.125      3.12597656 3.12695312
 3.12792969 3.12988281 3.13183594 3.1328125  3.13378906 3.13476562
 3.13574219 3.13769531 3.13867188 3.13964844 3.140625   3.14160156
 3.14355469 3.14453125 3.14648438 3.14746094 3.14941406 3.15136719
 3.15429688 3.15527344 3.15625    3.15820312 3.15917969 3.16113281
 3.16210938 3.16308594 3.1640625  3.16503906 3.16699219 3.16796875
 3.16894531 3.16992188 3.17089844 3.171875   3.17382812 3.17480469
 3.17578125 3.17675781 3.17773438 3.17871094 3.1796875  3.18066406
 3.18164062 3.18261719 3.18359375 3.18457031 3.18554688 3.18652344
 3.18847656 3.18945312 3.19042969 3.19140625 3.19238281 3.19335938
 3.19433594 3.1953125  3.19628906 3.19726562 3.19824219 3.20117188
 3.20214844 3.203125   3.20410156 3.20507812 3.20605469 3.20703125
 3.20800781 3.20898438 3.20996094 3.2109375  3.21191406 3.21289062
 3.21386719 3.21484375 3.21679688 3.21777344 3.21875    3.21972656
 3.22070312 3.22167969 3.22265625 3.22363281 3.22460938 3.22558594
 3.2265625  3.22753906 3.22851562 3.22949219 3.23046875 3.23144531
 3.23242188 3.23339844 3.234375   3.23535156 3.23730469 3.23828125
 3.23925781 3.24023438 3.24121094 3.2421875  3.24316406 3.24414062
 3.24511719 3.24609375 3.24707031 3.24804688 3.24902344 3.25
 3.25097656 3.25195312 3.25390625 3.25488281 3.25585938 3.25683594
 3.2578125  3.25878906 3.25976562 3.26171875 3.26269531 3.26367188
 3.26464844 3.265625   3.26660156 3.26757812 3.26855469 3.26953125
 3.27050781 3.27148438 3.27246094 3.27441406 3.27539062 3.27636719
 3.27832031 3.27929688 3.28125    3.28222656 3.28417969 3.28710938
 3.2890625  3.29003906 3.29101562 3.29199219 3.29296875 3.29394531
 3.29492188 3.29589844 3.296875   3.29785156 3.30078125 3.30175781
 3.30273438 3.30371094 3.3046875  3.30566406 3.30664062 3.30859375
 3.30957031 3.31054688 3.31152344 3.3125     3.31347656 3.31542969
 3.31738281 3.31835938 3.31933594 3.3203125  3.32128906 3.32324219
 3.32519531 3.32714844 3.328125   3.32910156 3.33105469 3.33203125
 3.33886719 3.34082031 3.34375    3.34667969 3.34765625 3.34863281
 3.34960938 3.35058594 3.3515625  3.35253906 3.35449219 3.35644531
 3.35839844 3.359375   3.36230469 3.36425781 3.36816406 3.36914062
 3.37011719 3.37207031 3.37597656 3.37695312 3.37792969 3.37890625
 3.37988281 3.38183594 3.38476562 3.38964844 3.39257812 3.39648438
 3.39746094 3.39941406 3.40136719 3.40332031 3.40722656 3.40820312
 3.40917969 3.41015625 3.41308594 3.4140625  3.41503906 3.41796875
 3.41894531 3.421875   3.42382812 3.42480469 3.42578125 3.42675781
 3.42871094 3.4296875  3.43066406 3.43359375 3.43457031 3.43652344
 3.4375     3.43847656 3.43945312 3.44042969 3.44238281 3.44433594
 3.45507812 3.45800781 3.46191406 3.46289062 3.46386719 3.46679688
 3.47167969 3.47265625 3.47460938 3.47753906 3.47851562 3.48046875
 3.48339844 3.48535156 3.48632812 3.48730469 3.49023438 3.49121094
 3.4921875  3.49511719 3.49902344 3.5        3.50097656 3.50292969
 3.50488281 3.50683594 3.50976562 3.51269531 3.51367188 3.52441406
 3.52539062 3.52636719 3.52734375 3.52832031 3.53125    3.53613281
 3.54785156 3.55664062 3.56542969 3.56640625 3.57128906 3.57519531
 3.57714844 3.5859375  3.59277344 3.59570312 3.59863281 3.67089844
 3.69238281 3.6953125  3.70019531 3.70214844 3.71386719 3.72460938
 3.83398438 3.86816406 3.87597656 3.88378906 3.89550781 3.89746094
 3.90039062 3.94433594 3.96386719 4.0390625  4.06445312 4.078125
 4.07910156 4.11035156 4.1484375  4.29394531 4.30371094 4.32421875
 4.43554688 4.69140625 4.71484375 4.73144531 4.73242188 4.75
 4.75878906 4.76953125 4.77050781 4.77734375 4.77929688 4.78125
 4.78515625 4.79101562 4.79199219 4.79394531 4.79589844 4.79785156
 4.79980469 4.80859375 4.83203125 4.85839844 4.86621094 4.87304688
 4.95996094 4.97265625 4.9921875  5.04980469 5.09667969]

  warnings.warn(

2022-12-16 10:36:17,645:INFO:Calculating mean and std
2022-12-16 10:36:17,646:INFO:Creating metrics dataframe
2022-12-16 10:36:17,652:INFO:Uploading results into container
2022-12-16 10:36:17,653:INFO:Uploading model into container now
2022-12-16 10:36:17,654:INFO:master_model_container: 2
2022-12-16 10:36:17,654:INFO:display_container: 2
2022-12-16 10:36:17,654:INFO:LinearRegression(n_jobs=-1)
2022-12-16 10:36:17,654:INFO:create_model() successfully completed......................................
2022-12-16 10:36:17,848:ERROR:create_model() for LinearRegression(n_jobs=-1) raised an exception or returned all 0.0:
2022-12-16 10:36:17,849:ERROR:Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 795, in compare_models
    assert (
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 811, in compare_models
    assert (
AssertionError

2022-12-16 10:36:17,850:INFO:Initializing Lasso Regression
2022-12-16 10:36:17,850:INFO:Total runtime is 0.3431966503461202 minutes
2022-12-16 10:36:17,850:INFO:SubProcess create_model() called ==================================
2022-12-16 10:36:17,850:INFO:Initializing create_model()
2022-12-16 10:36:17,850:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002281239F8E0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022810EC8B20>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:36:17,851:INFO:Checking exceptions
2022-12-16 10:36:17,856:INFO:Importing libraries
2022-12-16 10:36:17,856:INFO:Copying training dataset
2022-12-16 10:36:17,864:INFO:Defining folds
2022-12-16 10:36:17,864:INFO:Declaring metric variables
2022-12-16 10:36:17,864:INFO:Importing untrained model
2022-12-16 10:36:17,865:INFO:Lasso Regression Imported successfully
2022-12-16 10:36:17,865:INFO:Starting cross validation
2022-12-16 10:36:17,868:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:36:19,699:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.2657559]

  warnings.warn(

2022-12-16 10:36:19,726:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.26859131]

  warnings.warn(

2022-12-16 10:36:20,039:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.26511148]

  warnings.warn(

2022-12-16 10:36:20,055:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.27104008]

  warnings.warn(

2022-12-16 10:36:20,072:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.26214718]

  warnings.warn(

2022-12-16 10:36:20,085:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.26446707]

  warnings.warn(

2022-12-16 10:36:21,412:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.26072948]

  warnings.warn(

2022-12-16 10:36:21,483:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.26562701]

  warnings.warn(

2022-12-16 10:36:21,485:INFO:Calculating mean and std
2022-12-16 10:36:21,487:INFO:Creating metrics dataframe
2022-12-16 10:36:21,493:INFO:Uploading results into container
2022-12-16 10:36:21,494:INFO:Uploading model into container now
2022-12-16 10:36:21,494:INFO:master_model_container: 3
2022-12-16 10:36:21,495:INFO:display_container: 2
2022-12-16 10:36:21,495:INFO:Lasso(random_state=5099)
2022-12-16 10:36:21,495:INFO:create_model() successfully completed......................................
2022-12-16 10:36:21,688:WARNING:create_model() for Lasso(random_state=5099) raised an exception or returned all 0.0, trying without fit_kwargs:
2022-12-16 10:36:21,689:WARNING:Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 795, in compare_models
    assert (
AssertionError

2022-12-16 10:36:21,689:INFO:Initializing create_model()
2022-12-16 10:36:21,689:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002281239F8E0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022810EC8B20>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:36:21,689:INFO:Checking exceptions
2022-12-16 10:36:21,694:INFO:Importing libraries
2022-12-16 10:36:21,694:INFO:Copying training dataset
2022-12-16 10:36:21,701:INFO:Defining folds
2022-12-16 10:36:21,702:INFO:Declaring metric variables
2022-12-16 10:36:21,702:INFO:Importing untrained model
2022-12-16 10:36:21,703:INFO:Lasso Regression Imported successfully
2022-12-16 10:36:21,703:INFO:Starting cross validation
2022-12-16 10:36:21,706:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:36:23,738:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.2657559]

  warnings.warn(

2022-12-16 10:36:23,783:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.27146172]

  warnings.warn(

2022-12-16 10:36:23,793:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.26859131]

  warnings.warn(

2022-12-16 10:36:23,898:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.26446707]

  warnings.warn(

2022-12-16 10:36:24,080:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.27104008]

  warnings.warn(

2022-12-16 10:36:24,132:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.26511148]

  warnings.warn(

2022-12-16 10:36:24,181:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.25673412]

  warnings.warn(

2022-12-16 10:36:24,208:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.26214718]

  warnings.warn(

2022-12-16 10:36:25,299:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.26072948]

  warnings.warn(

2022-12-16 10:36:25,348:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.26562701]

  warnings.warn(

2022-12-16 10:36:25,350:INFO:Calculating mean and std
2022-12-16 10:36:25,351:INFO:Creating metrics dataframe
2022-12-16 10:36:25,358:INFO:Uploading results into container
2022-12-16 10:36:25,359:INFO:Uploading model into container now
2022-12-16 10:36:25,360:INFO:master_model_container: 4
2022-12-16 10:36:25,360:INFO:display_container: 2
2022-12-16 10:36:25,361:INFO:Lasso(random_state=5099)
2022-12-16 10:36:25,361:INFO:create_model() successfully completed......................................
2022-12-16 10:36:25,547:ERROR:create_model() for Lasso(random_state=5099) raised an exception or returned all 0.0:
2022-12-16 10:36:25,548:ERROR:Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 795, in compare_models
    assert (
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 811, in compare_models
    assert (
AssertionError

2022-12-16 10:36:25,548:INFO:Initializing Ridge Regression
2022-12-16 10:36:25,548:INFO:Total runtime is 0.47150702079137163 minutes
2022-12-16 10:36:25,549:INFO:SubProcess create_model() called ==================================
2022-12-16 10:36:25,549:INFO:Initializing create_model()
2022-12-16 10:36:25,549:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002281239F8E0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022810EC8B20>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:36:25,549:INFO:Checking exceptions
2022-12-16 10:36:25,555:INFO:Importing libraries
2022-12-16 10:36:25,555:INFO:Copying training dataset
2022-12-16 10:36:25,564:INFO:Defining folds
2022-12-16 10:36:25,565:INFO:Declaring metric variables
2022-12-16 10:36:25,565:INFO:Importing untrained model
2022-12-16 10:36:25,566:INFO:Ridge Regression Imported successfully
2022-12-16 10:36:25,567:INFO:Starting cross validation
2022-12-16 10:36:25,571:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:36:27,589:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.60813772 1.86538539 1.87785333 1.93538255 2.04817109 2.18533858
 2.680479   2.83195425 2.83533904 2.86823343 2.89089396 2.91049326
 2.91797443 2.92452238 2.9248451  2.92615452 2.92652845 2.92984347
 2.93002569 2.93071676 2.93164748 2.93169979 2.93692293 2.94397019
 2.94553792 2.95002326 2.95181763 2.95578444 2.95707794 2.95799084
 2.95934378 2.96094584 2.96214188 2.96624817 2.96688083 2.96800521
 2.96805187 2.96965818 2.97064273 2.97439461 2.97572853 2.97599039
 2.97620114 2.97638947 2.97758965 2.97764728 2.98256439 2.98409097
 2.98655283 2.9886152  2.98981124 2.99258597 2.992741   2.99345016
 2.99369136 2.9953961  2.99760665 2.99830264 2.99950664 3.00134649
 3.00192585 3.0019456  3.00214901 3.00579019 3.00686478 3.00897467
 3.00931017 3.01080991 3.01134679 3.01169228 3.01206771 3.01207268
 3.01216561 3.01696238 3.01954436 3.01960978 3.0215378  3.0231229
 3.02438598 3.02445574 3.02537228 3.02650646 3.02670352 3.02736089
 3.02746928 3.02988561 3.03513703 3.03637612 3.03738523 3.03867448
 3.04233642 3.04327892 3.04356442 3.04668371 3.04813578 3.05075125
 3.0512259  3.05173474 3.0536179  3.05436631 3.05484889 3.05534011
 3.05567661 3.05651817 3.05663339 3.05786453 3.06108618 3.0621416
 3.0627262  3.06288002 3.06354569 3.06673335 3.06770109 3.06813637
 3.06851265 3.0685841  3.07025396 3.07102325 3.0726223  3.07387808
 3.0738845  3.07449387 3.07533183 3.07736843 3.07957004 3.08118437
 3.08122921 3.08176341 3.08204727 3.08254282 3.08460924 3.0848181
 3.08664127 3.08783237 3.08849934 3.08902067 3.08951457 3.09099037
 3.09198216 3.09206947 3.09353886 3.09406944 3.09454558 3.09598482
 3.09669835 3.09761373 3.09944643 3.09951153 3.0997301  3.10019393
 3.10389341 3.10421364 3.10563132 3.10624959 3.10628981 3.10688604
 3.10798573 3.10906165 3.11063625 3.11069259 3.11070117 3.1108972
 3.11129937 3.11132426 3.11179524 3.11181876 3.11225475 3.11278618
 3.11332568 3.11333115 3.11371276 3.11385206 3.11405169 3.11503317
 3.11584652 3.11603121 3.11793295 3.11799326 3.11805192 3.11837613
 3.11845736 3.11867118 3.11867152 3.11981785 3.12050145 3.12052876
 3.12112872 3.12114896 3.12179741 3.12417755 3.12431639 3.1246106
 3.12461094 3.12471982 3.12548561 3.12598756 3.12823056 3.12834134
 3.12844562 3.12852561 3.1285978  3.12985553 3.12992809 3.12993961
 3.12994069 3.13000657 3.13020169 3.13038964 3.13042638 3.13049475
 3.13059501 3.13140596 3.13190884 3.13203303 3.13213411 3.13217275
 3.13246051 3.13376615 3.13377394 3.13452073 3.1347208  3.13513135
 3.13532117 3.13536144 3.1364218  3.13708359 3.137395   3.13851405
 3.13854753 3.13901137 3.13938753 3.13978237 3.14143747 3.14156943
 3.14176693 3.14187604 3.14200609 3.14259185 3.14268521 3.14272275
 3.1429676  3.14350087 3.14368253 3.14434655 3.14439378 3.14541303
 3.14698868 3.14724519 3.14731257 3.14759238 3.1476817  3.14792974
 3.14808945 3.14820639 3.14843894 3.14845963 3.14897119 3.14897439
 3.14920686 3.14934796 3.14938974 3.15032091 3.15063128 3.15112451
 3.15121265 3.15172124 3.15191884 3.15245921 3.1526306  3.15264145
 3.15301807 3.15370648 3.15376185 3.15409557 3.15437944 3.15466653
 3.15468521 3.1548288  3.15483227 3.15545809 3.15565201 3.15570061
 3.15626496 3.15678041 3.15712244 3.15729551 3.15763834 3.15798732
 3.15802523 3.15832968 3.15837083 3.15857292 3.15859713 3.15887088
 3.15916044 3.15939821 3.15962937 3.15966443 3.15998969 3.16020564
 3.16024591 3.16071631 3.16094042 3.16116307 3.16133376 3.16253672
 3.16319861 3.16338805 3.1635211  3.16369067 3.16393179 3.16412682
 3.16418294 3.164605   3.16471388 3.16488478 3.16511669 3.16522157
 3.16694819 3.16711067 3.1677075  3.16803422 3.16812123 3.16837041
 3.16843736 3.16861856 3.16885043 3.16887429 3.16922952 3.1693673
 3.17035349 3.17047581 3.1706796  3.17115747 3.17196812 3.17238611
 3.17256708 3.17305905 3.17324164 3.17414265 3.17415564 3.17433208
 3.17436393 3.17451513 3.17462401 3.17481699 3.1756036  3.17657518
 3.1768293  3.17698481 3.17759023 3.17806084 3.17840124 3.17857618
 3.17912075 3.17934663 3.1795167  3.17996866 3.18004515 3.18044621
 3.18062589 3.18267964 3.18331696 3.18413132 3.18433051 3.18474446
 3.18521804 3.1864514  3.18660673 3.18663399 3.18674287 3.18690024
 3.18697126 3.18716177 3.18727286 3.18749323 3.18758719 3.18759167
 3.1882668  3.18835534 3.18887711 3.18907115 3.18919157 3.18929692
 3.18989397 3.19015391 3.190187   3.19028835 3.19047208 3.19048758
 3.19072048 3.19076998 3.190817   3.19082895 3.19088723 3.19094397
 3.19117737 3.19178771 3.19182656 3.19207279 3.1926206  3.19274485
 3.19285373 3.19311603 3.19322826 3.19326337 3.19339341 3.19379605
 3.19379639 3.19391697 3.19424763 3.1942954  3.19450199 3.19455555
 3.19497669 3.1951269  3.19513901 3.19557408 3.19578443 3.19702198
 3.19716114 3.1976009  3.19809372 3.19839435 3.19877219 3.1991067
 3.19922688 3.19948898 3.19960425 3.19968805 3.19991154 3.19999183
 3.20017146 3.20018501 3.20050173 3.20051682 3.20066438 3.20073641
 3.20082491 3.20120065 3.20155223 3.20186861 3.20214715 3.20327418
 3.20343198 3.20355387 3.20363345 3.20406836 3.20412088 3.20570585
 3.20604868 3.20624226 3.20631677 3.20662061 3.20662709 3.20671887
 3.20680457 3.20686072 3.20721101 3.20734867 3.20740607 3.20756719
 3.20766577 3.2079957  3.20814157 3.20879069 3.20910746 3.20932598
 3.20965788 3.20991274 3.20997487 3.21023432 3.21029558 3.21063389
 3.21088626 3.21096086 3.21196549 3.21198661 3.21237759 3.21254857
 3.21283589 3.21288133 3.21293411 3.21298734 3.21308259 3.21331446
 3.21359636 3.21379872 3.21388002 3.21408955 3.21412439 3.21427312
 3.21460302 3.21501122 3.21531517 3.21533637 3.21536461 3.21547349
 3.21563429 3.21567938 3.21586658 3.21595371 3.21606482 3.21614797
 3.21634518 3.21660098 3.21684701 3.21773018 3.21816645 3.2181994
 3.21824638 3.21829387 3.21877823 3.21904497 3.21917754 3.21935468
 3.21944137 3.21987942 3.21991676 3.22033598 3.22043542 3.22048649
 3.22077859 3.22083835 3.22085821 3.22113238 3.22145495 3.22154777
 3.2217113  3.22202265 3.22215007 3.22218269 3.22234548 3.2227909
 3.2227918  3.22410378 3.22500688 3.22501494 3.2250542  3.22555889
 3.2259455  3.22599062 3.22604213 3.22684436 3.22688929 3.22785116
 3.22865701 3.22869355 3.22931395 3.22973535 3.22988678 3.23026029
 3.2308316  3.23134137 3.23155221 3.23205321 3.23248934 3.23268486
 3.23275363 3.23276786 3.23353078 3.23356344 3.2337507  3.23430384
 3.23636662 3.23646443 3.23660869 3.2381137  3.2390548  3.23918722
 3.24027411 3.24105545 3.24134056 3.24265048 3.24266978 3.24341084
 3.24398111 3.2442872  3.2450526  3.24516385 3.24520606 3.2461347
 3.24704623 3.24814693 3.24821444 3.24824335 3.24834593 3.24907952
 3.24922914 3.24981586 3.25009024 3.25081449 3.25151033 3.25154092
 3.25223072 3.25244025 3.25254933 3.25321744 3.25322164 3.25335499
 3.25362017 3.25383814 3.25461975 3.25547703 3.25703901 3.25823249
 3.2596201  3.26052074 3.26090122 3.26105523 3.26138309 3.26155499
 3.26195869 3.26207242 3.2631474  3.26393054 3.26524215 3.26652991
 3.26744645 3.26770857 3.26796741 3.26868343 3.27054563 3.270895
 3.27121927 3.27136785 3.27236963 3.27302049 3.27306244 3.27356473
 3.27371324 3.27408948 3.2774527  3.2783047  3.2792718  3.28027449
 3.28068061 3.28194008 3.2824201  3.2827128  3.28323928 3.28370931
 3.28375668 3.28389016 3.28424956 3.28481721 3.28621403 3.28794785
 3.28875249 3.28876726 3.29061316 3.29078537 3.29130746 3.29214436
 3.29340203 3.29348468 3.29738588 3.29756658 3.29853177 3.29858906
 3.3018098  3.30285103 3.30290366 3.30304207 3.30318727 3.30418352
 3.30472163 3.30478648 3.30602973 3.30734687 3.30911624 3.30918939
 3.30966377 3.31012559 3.31586096 3.31624839 3.31740841 3.31813155
 3.3183963  3.31896008 3.31970949 3.31999102 3.32012007 3.32042691
 3.32507178 3.32742383 3.32771159 3.32862403 3.32988135 3.33011689
 3.33081181 3.33414138 3.33467857 3.33528606 3.33576804 3.33759191
 3.33984579 3.34119027 3.34387749 3.34420755 3.34438279 3.34591205
 3.34678052 3.34798374 3.34826096 3.34881419 3.34916039 3.34976849
 3.35060543 3.35333659 3.35344058 3.35351534 3.35830173 3.35879708
 3.35990446 3.36042744 3.36097521 3.3629573  3.36483004 3.36546847
 3.36722839 3.37432677 3.37663772 3.37733804 3.37737346 3.37773454
 3.3789795  3.38002067 3.38082588 3.38100605 3.38175541 3.38207186
 3.38259136 3.38496353 3.3864007  3.38691184 3.3887543  3.38879993
 3.38932636 3.38999541 3.39080393 3.39222471 3.39339388 3.39435104
 3.39478811 3.39511216 3.39746536 3.39752184 3.39939169 3.39970831
 3.40312663 3.40411827 3.40687988 3.40704513 3.40936715 3.40980878
 3.4099524  3.41057628 3.41206179 3.41486545 3.41607902 3.41759729
 3.42037616 3.42594792 3.43081064 3.43310856 3.43612756 3.43993376
 3.44466873 3.44507463 3.44970601 3.45067287 3.45461621 3.45560531
 3.46131604 3.46187109 3.46576013 3.46587446 3.46873798 3.46912985
 3.47991268 3.4819048  3.49457318 3.50368697 3.51342385 3.52992556
 3.53883771 3.54354945 3.54377251 3.54729788 3.56153185 3.56523467
 3.58004893 3.58627958 3.59586904 3.62076385 3.62591834 3.63932179
 3.647883   3.65698236 3.6887289  3.70330668 3.77811705 3.77954906
 3.79146957 3.79803623 3.8198288  3.82678576 3.84478135 3.84500654
 3.84932904 3.85103713 3.86139238 3.90487268 3.98115604 4.05235693
 4.06516769 4.13570447 4.14088939 4.14156772 4.14910417 4.2008167
 4.20874327 4.38352619 4.38691316 4.44293838 4.60328841 4.69557484
 4.72659408 4.75662129 4.76202529 4.77059558 4.79596711 4.79630118
 4.79853465 4.80365061 4.80562789 4.80592824 4.81266557 4.81615911
 4.81960944 4.82678461 4.82989776 4.83832166 4.85222212 4.85241449
 4.86183717 4.87329702 4.87546484 4.88063497 4.88134948 4.88465403
 4.90306089 4.90562134 4.91262746 4.91679623 4.95432286 4.96846487]

  warnings.warn(

2022-12-16 10:36:27,600:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.57267138 1.76276319 1.80507684 1.82442971 1.95324058 2.05321142
 2.44394199 2.44769165 2.85281155 2.87211543 2.90114154 2.91205009
 2.92735788 2.93208509 2.93507603 2.95238774 2.9533108  2.95405612
 2.95733193 2.96014151 2.96180219 2.96213402 2.96236712 2.96283924
 2.96372461 2.96497349 2.9675779  2.96881243 2.9711538  2.97165666
 2.97195541 2.97298252 2.97647512 2.97808982 2.97849002 2.97924499
 2.9805493  2.98130118 2.98193386 2.98203166 2.98248973 2.98253665
 2.98500995 2.9851651  2.98574107 2.98675728 2.98869978 2.98972199
 2.98975812 2.99049403 2.99197367 2.99379357 2.99414332 2.99806158
 3.00025297 3.00119969 3.00127794 3.00137667 3.00368454 3.00437044
 3.00512454 3.00512962 3.00563682 3.00565222 3.00727696 3.00758254
 3.00858732 3.00938953 3.00969735 3.0099527  3.01007771 3.01116086
 3.01267142 3.0142492  3.01514175 3.01546833 3.01704481 3.01819744
 3.01843024 3.01864373 3.01979148 3.01991714 3.02026571 3.02301333
 3.02337147 3.02581054 3.02964119 3.03044228 3.0305686  3.03072701
 3.03081178 3.03137315 3.03158445 3.03166547 3.03436765 3.03706904
 3.03731741 3.03855081 3.04017197 3.04263934 3.04843673 3.04927701
 3.04967587 3.0510663  3.05263933 3.05673425 3.05860936 3.06198174
 3.06319247 3.06585515 3.0660288  3.06687836 3.06699363 3.06719609
 3.07098682 3.07208056 3.08123997 3.08136705 3.08329381 3.08407542
 3.08429074 3.08451304 3.08573575 3.08575216 3.08577819 3.08619207
 3.08779396 3.08838017 3.08924278 3.09137476 3.09214688 3.09238755
 3.09348808 3.09361046 3.09559828 3.09618125 3.09825084 3.10071174
 3.10074076 3.10184255 3.10295719 3.10672032 3.1073097  3.10852805
 3.10910151 3.10915133 3.1102295  3.11157081 3.11207637 3.11227179
 3.11297739 3.11430503 3.1147409  3.11488578 3.115519   3.11603972
 3.11619934 3.11705171 3.11792183 3.11847686 3.11912337 3.11960483
 3.11967316 3.11967814 3.11975109 3.11982933 3.12017742 3.12021011
 3.12086358 3.12122602 3.12157919 3.12234803 3.12245594 3.12280163
 3.12314145 3.1233291  3.12334721 3.12371809 3.12388314 3.1244202
 3.12485825 3.12607685 3.12638025 3.1274468  3.12745355 3.12762685
 3.12784383 3.12800142 3.12803931 3.1285056  3.12851615 3.12868897
 3.1289348  3.12999682 3.13047904 3.13078397 3.13101781 3.13187579
 3.13203013 3.13204618 3.13227256 3.13284112 3.13333982 3.13344524
 3.13351469 3.13372523 3.1337497  3.13413341 3.13419616 3.13519584
 3.13547322 3.13571717 3.13628705 3.13630603 3.13637535 3.13683283
 3.13696651 3.13742057 3.13794328 3.13829975 3.13977698 3.13978685
 3.14099212 3.14110205 3.14142799 3.14178287 3.14229501 3.14254086
 3.14262992 3.14267584 3.14268254 3.1428789  3.14293782 3.14355366
 3.14366995 3.14382635 3.14385452 3.14389827 3.14439947 3.14479107
 3.1448934  3.14515486 3.14530249 3.14551038 3.14564214 3.14574569
 3.14589699 3.14601824 3.14616581 3.14620847 3.14639959 3.14657197
 3.14668991 3.14676788 3.14683545 3.14719981 3.14728499 3.14732401
 3.14745532 3.14779354 3.1479597  3.1483604  3.14862283 3.14864988
 3.14889385 3.14897879 3.14898155 3.14900625 3.14939772 3.14998653
 3.15035224 3.15049606 3.15049848 3.15075381 3.15088073 3.15091972
 3.15102579 3.15109921 3.15142549 3.15207874 3.15214791 3.15316681
 3.15349541 3.15419686 3.15454632 3.15545236 3.15577747 3.15606093
 3.1561428  3.15624714 3.15638012 3.15640903 3.15662757 3.15667003
 3.15676194 3.15681253 3.15718936 3.15741238 3.15747282 3.15784847
 3.15792166 3.15819889 3.15895266 3.15897727 3.15918191 3.15943448
 3.15959299 3.15964183 3.16071132 3.16097518 3.16119384 3.16236211
 3.16250188 3.16268262 3.1633541  3.16340815 3.16341648 3.16355948
 3.16369568 3.16410392 3.16438045 3.16527192 3.16534457 3.16543718
 3.16561643 3.16583159 3.16618576 3.1662447  3.16629763 3.16671981
 3.16680072 3.16700425 3.16769281 3.16782596 3.16790245 3.16790737
 3.16815907 3.16816966 3.16901547 3.16905372 3.16930785 3.1696214
 3.16981147 3.1700202  3.17059828 3.1706773  3.17082038 3.17092165
 3.17129382 3.17149597 3.17156578 3.17160752 3.17165025 3.17185149
 3.17203655 3.17216394 3.17218929 3.17228802 3.1723464  3.17258703
 3.17265027 3.17268409 3.17286638 3.17287761 3.17289191 3.17294847
 3.17309949 3.17341363 3.17352186 3.17357976 3.17371972 3.17373419
 3.1738216  3.17399478 3.17400596 3.1745108  3.17473025 3.17481638
 3.17484942 3.17502044 3.17502653 3.17523634 3.17528364 3.17534825
 3.17536438 3.17554174 3.17573802 3.17588036 3.17599552 3.17602845
 3.17638719 3.17669935 3.176708   3.17677191 3.17710381 3.1772099
 3.1772634  3.1774532  3.17762557 3.1777671  3.17785328 3.17788503
 3.17803334 3.17810101 3.1783634  3.17842274 3.17851275 3.17856982
 3.17859735 3.17939938 3.17941925 3.1795298  3.17982282 3.17998452
 3.18033916 3.18046041 3.18046421 3.18060758 3.18073435 3.18079145
 3.18079738 3.18084517 3.18108528 3.18111663 3.1811598  3.18145187
 3.18178407 3.18207197 3.18238495 3.18247351 3.18311926 3.18363986
 3.18375191 3.18400082 3.18448624 3.1845713  3.1858404  3.18585839
 3.18626507 3.18637268 3.18648484 3.18680415 3.18690231 3.18697341
 3.18698368 3.18702751 3.18714989 3.18721962 3.18725908 3.18745835
 3.18750617 3.18757144 3.18762752 3.18765995 3.18800693 3.18815164
 3.18816327 3.1882005  3.18821764 3.18853507 3.18857158 3.18906753
 3.1892266  3.18931231 3.18951047 3.18975671 3.19001968 3.19003377
 3.19023486 3.19132319 3.1915056  3.19178348 3.19182305 3.19189179
 3.19190698 3.19241374 3.19266597 3.19334074 3.19382872 3.19396262
 3.19411656 3.19433928 3.1947891  3.19495762 3.19501235 3.19539778
 3.19539859 3.19564752 3.19589537 3.19597389 3.19638296 3.19666527
 3.19697469 3.1970301  3.19732734 3.19734727 3.19734964 3.19748042
 3.19872218 3.19872712 3.19897186 3.19957744 3.19991551 3.1999271
 3.20012161 3.20017206 3.20052669 3.20059107 3.2007318  3.20099575
 3.20123064 3.20131927 3.20134855 3.20183435 3.20191634 3.20316616
 3.20362125 3.20403635 3.20410593 3.20416532 3.20432775 3.20471261
 3.20514145 3.20525859 3.20526999 3.20539409 3.20578084 3.20601203
 3.20624524 3.20671631 3.20696583 3.2071576  3.20722949 3.20794267
 3.20801727 3.20858763 3.20870775 3.20891033 3.20912372 3.20920427
 3.20947035 3.20965916 3.21090648 3.21162244 3.2127463  3.21412252
 3.21444447 3.21454883 3.21465746 3.21479968 3.21520365 3.21520805
 3.21524296 3.21628762 3.21635935 3.21657644 3.21746056 3.21764289
 3.2181883  3.21848109 3.21850049 3.21861186 3.2186924  3.21888432
 3.21933283 3.22001643 3.22018195 3.22088349 3.22126483 3.22236481
 3.22248463 3.22407327 3.22440892 3.22525308 3.22577784 3.22610323
 3.22621436 3.22635716 3.22679315 3.22745339 3.22764082 3.22830161
 3.22846424 3.22879545 3.22916123 3.22935755 3.23024331 3.23036787
 3.23074685 3.23136648 3.23150843 3.23220127 3.23256236 3.23275987
 3.23349998 3.2337747  3.23399654 3.23584004 3.23628384 3.23644613
 3.2370989  3.24019328 3.24043449 3.24155322 3.24370901 3.24482267
 3.24554121 3.24610651 3.24629873 3.24849356 3.24913651 3.24930265
 3.24975812 3.24976644 3.24984731 3.25033959 3.25077034 3.25327516
 3.25370054 3.25419159 3.25441911 3.25505743 3.2565606  3.25702868
 3.25925    3.25925689 3.2599881  3.26017918 3.26056197 3.26089213
 3.26093457 3.26129837 3.26137982 3.26173686 3.26289354 3.26316231
 3.26348081 3.2639071  3.26433659 3.26441999 3.26466628 3.26485076
 3.2672839  3.26752735 3.26770265 3.26833725 3.2698827  3.27127888
 3.27174741 3.27206415 3.27279939 3.27644326 3.27672288 3.27687147
 3.27697602 3.27734796 3.27790912 3.27836426 3.27887103 3.27915928
 3.27927055 3.27929845 3.27932192 3.27933206 3.28002964 3.28005699
 3.28066287 3.28117752 3.2819608  3.28212459 3.28369725 3.28409692
 3.28478489 3.28553479 3.28571112 3.28632369 3.28683426 3.28766398
 3.28863612 3.29087134 3.29200271 3.29233271 3.29449534 3.29506036
 3.29540626 3.29591848 3.29623078 3.29649078 3.29783569 3.29843591
 3.29851931 3.29911379 3.30009569 3.30047026 3.30243772 3.30310479
 3.30359934 3.30424303 3.30442166 3.30497884 3.30612503 3.31013094
 3.31099937 3.31260144 3.31469476 3.31491827 3.3200498  3.32103056
 3.32210868 3.32328088 3.32366862 3.32372318 3.32627386 3.32980205
 3.33185746 3.33238234 3.3325788  3.33442452 3.3361399  3.33850172
 3.3396512  3.34143913 3.3457625  3.34850976 3.348626   3.35351658
 3.35391694 3.35559738 3.35585685 3.35794743 3.35818477 3.3612568
 3.36262457 3.3629736  3.3636592  3.3641718  3.36598468 3.36645462
 3.36731398 3.36967866 3.37178712 3.37281326 3.37363013 3.37542964
 3.37723105 3.37754033 3.37856802 3.37898559 3.37961201 3.38346677
 3.38430592 3.38443965 3.38462842 3.3881719  3.3893555  3.39069334
 3.3938958  3.39490716 3.40725259 3.40826885 3.40827477 3.4116857
 3.42247813 3.42861666 3.43085665 3.43092351 3.44236519 3.44518464
 3.45419134 3.45456343 3.45672674 3.464413   3.46723307 3.4681179
 3.47564969 3.47758935 3.47872038 3.49454709 3.53817799 3.60951941
 3.61895422 3.62958027 3.63956014 3.65739921 3.66133016 3.66219532
 3.681949   3.69353831 3.75498102 3.77107838 3.77285621 3.7959146
 3.79790731 3.8023934  3.80344876 3.81344221 3.82111472 3.8230768
 3.82925871 3.82981355 3.8309971  3.83718223 3.84009801 3.84192371
 3.84352475 3.84538142 3.92672285 3.93045792 3.94038416 3.98820091
 4.14083166 4.14392331 4.16522894 4.23265708 4.38932965 4.73025156
 4.74338204 4.74750025 4.77786689 4.78505196 4.79871783 4.80282251
 4.80723795 4.80731591 4.81021832 4.81265441 4.81652717 4.81874932
 4.81926418 4.82115125 4.82129726 4.82181098 4.82233099 4.82394691
 4.82773661 4.82794796 4.8288748  4.82981845 4.83877053 4.83976398
 4.84203349 4.84689678 4.85166143 4.85455423 4.85785137 4.86060837
 4.8649157  4.86571678 4.86736844 4.88047277 4.91350207 4.91995793
 4.92094285 4.92961725]

  warnings.warn(

2022-12-16 10:36:27,625:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.56605908 1.57737565 1.59883032 1.75943017 1.8063374  1.84765592
 1.85005792 1.85082106 1.86331607 1.89127688 1.90932599 2.08211888
 2.41751095 2.69584087 2.8284921  2.8861273  2.89717356 2.90744379
 2.90992812 2.91050154 2.91705013 2.9181032  2.9245597  2.92499431
 2.92745609 2.93094639 2.93342509 2.93488398 2.93742051 2.94172212
 2.94357612 2.94770806 2.95001518 2.95140092 2.95328437 2.95382991
 2.96011779 2.96649014 2.96676042 2.9684109  2.97145046 2.97305251
 2.97562988 2.97578928 2.97840484 2.97989054 2.98158186 2.98264734
 2.98429401 2.98617993 2.98831005 2.9889229  2.98901329 2.99089726
 2.99114584 2.99213394 2.99221493 2.99251673 2.99394042 2.9962546
 2.99630551 2.99658283 2.99701845 2.99826784 2.99923067 2.99973141
 3.00039889 3.00048364 3.00098732 3.00112494 3.00147061 3.00149823
 3.0019802  3.00217877 3.0032408  3.00353107 3.00433942 3.0052922
 3.00585634 3.00745749 3.00846167 3.00950452 3.01056232 3.01212457
 3.01249584 3.01433019 3.01502123 3.01508083 3.0158471  3.02122949
 3.02255933 3.02352898 3.02493886 3.02503316 3.02512255 3.02548825
 3.02626045 3.0264441  3.02668158 3.02792915 3.02834211 3.03023879
 3.0304109  3.03095862 3.03273002 3.03412939 3.0341471  3.03570638
 3.03693597 3.03777752 3.03836166 3.03857088 3.03916989 3.03919223
 3.03926452 3.04085505 3.0414744  3.04200389 3.04236632 3.04492465
 3.04747343 3.04798198 3.04925559 3.04943072 3.04949813 3.04986586
 3.05005504 3.05046077 3.05116642 3.05249538 3.05282147 3.05323116
 3.05452704 3.05682982 3.05758118 3.05827132 3.0603653  3.06095983
 3.06184134 3.06251223 3.06261178 3.06379236 3.06408039 3.06607795
 3.06728895 3.06838209 3.06969718 3.07238999 3.07362853 3.07652208
 3.0767812  3.07731932 3.07841048 3.08094942 3.08113189 3.08116435
 3.08383158 3.08388753 3.08472632 3.08539748 3.08903699 3.08927715
 3.08979666 3.09072015 3.09174614 3.09211512 3.0926071  3.0937058
 3.09379395 3.09446811 3.09549363 3.09706568 3.09772528 3.09795181
 3.09814026 3.09891332 3.09907341 3.10089959 3.10112867 3.10237449
 3.10290922 3.1036292  3.10391845 3.10418379 3.10479179 3.10490268
 3.10498499 3.10549855 3.10603143 3.1061575  3.10696143 3.10890457
 3.10896916 3.10927182 3.10931903 3.10940254 3.10954788 3.11055465
 3.11117655 3.11148945 3.1118104  3.11203978 3.11216439 3.11268802
 3.11286763 3.11307249 3.11450515 3.11467767 3.11490048 3.11498423
 3.1153216  3.11600638 3.11632852 3.11635615 3.11791556 3.11874391
 3.11947005 3.12275573 3.122787   3.12312922 3.12451259 3.1245496
 3.12551295 3.12570329 3.12618855 3.12755929 3.12760223 3.12776563
 3.12807066 3.1290332  3.12985504 3.13051281 3.13076748 3.13129368
 3.13165627 3.1316856  3.13182453 3.13186243 3.13224291 3.13281703
 3.1331982  3.13325752 3.13352504 3.13524728 3.13594012 3.13656868
 3.1375272  3.13763645 3.13922675 3.13987155 3.14021539 3.14100298
 3.14127078 3.14178819 3.14234813 3.14273531 3.14346394 3.14392082
 3.14449207 3.1445792  3.14482779 3.14485062 3.14486848 3.14526596
 3.14607818 3.14616808 3.14652583 3.14678518 3.1469152  3.14731024
 3.14791425 3.14877333 3.14899068 3.14949172 3.15104939 3.1511197
 3.15142636 3.15143913 3.1517081  3.15187867 3.15194957 3.15254088
 3.15308394 3.15327165 3.15333672 3.15380136 3.1544974  3.15469511
 3.1547983  3.15488786 3.15596678 3.15663795 3.15678721 3.15707815
 3.15768632 3.15770598 3.15852731 3.15902766 3.15934174 3.15967866
 3.15996968 3.16008903 3.16022447 3.16044106 3.16065629 3.16113741
 3.16176357 3.16202809 3.16208938 3.16213634 3.1623819  3.16256143
 3.16354449 3.16394406 3.16397271 3.16397997 3.16406728 3.1641042
 3.16460599 3.16513543 3.165154   3.16533934 3.16625468 3.16652826
 3.1671519  3.16726859 3.16738071 3.16739736 3.16795653 3.16800249
 3.16805908 3.16816142 3.16820913 3.16823484 3.16883288 3.16891138
 3.1690216  3.16961368 3.16967365 3.16971795 3.16983081 3.16997357
 3.17003091 3.17006997 3.17031474 3.17039353 3.17080882 3.17085656
 3.17138641 3.17162618 3.17178612 3.17194493 3.17199989 3.17206438
 3.17208247 3.17260434 3.17266585 3.17275528 3.17338613 3.17374619
 3.17400128 3.17440153 3.17473076 3.17554879 3.17570539 3.17618847
 3.17620288 3.17636847 3.17678428 3.1771977  3.17727626 3.17729473
 3.17746899 3.17765362 3.17767296 3.17771414 3.17850976 3.1785542
 3.1793519  3.17936572 3.17951543 3.17955407 3.17972166 3.17996443
 3.18002306 3.1802294  3.1805539  3.18062159 3.18080828 3.18100159
 3.18135466 3.18169817 3.18225349 3.18319797 3.1832535  3.18355645
 3.18371286 3.18417133 3.18527842 3.18529656 3.18559235 3.18566917
 3.18569776 3.18578787 3.18586814 3.18624722 3.18676556 3.18733849
 3.18758713 3.1883932  3.18839943 3.18856937 3.18892661 3.1892574
 3.18957778 3.18972235 3.18975435 3.1904748  3.19062491 3.19066658
 3.19128411 3.19140594 3.19248077 3.19261305 3.19284226 3.19307444
 3.19370612 3.19496778 3.19515617 3.19525951 3.19583261 3.1960002
 3.19616302 3.19727384 3.19830288 3.19843568 3.1990865  3.1993474
 3.19955672 3.19985092 3.20017715 3.20046919 3.20048763 3.20051966
 3.20053618 3.20065858 3.20093286 3.20093385 3.20148284 3.20159551
 3.20181731 3.20205762 3.20274684 3.20296888 3.20301143 3.20304513
 3.20310743 3.20434808 3.20464712 3.20465555 3.20467841 3.20494806
 3.20501621 3.20550082 3.20551603 3.20559052 3.20586727 3.20593432
 3.20606504 3.20617173 3.20661002 3.20700205 3.20721269 3.20785845
 3.20800107 3.20856949 3.20910138 3.20918259 3.20920221 3.20929281
 3.20943727 3.21023201 3.21037631 3.21066641 3.21072826 3.2108298
 3.21083513 3.2110497  3.21208517 3.21210628 3.21225315 3.21271963
 3.21314618 3.21344842 3.21347344 3.21350291 3.21358943 3.21557515
 3.21562335 3.21572589 3.21603674 3.2160495  3.21618282 3.21798505
 3.21798707 3.21803744 3.2183731  3.21838512 3.2184086  3.21976465
 3.21982574 3.21996904 3.22082391 3.22082391 3.22093781 3.22216005
 3.22232654 3.22234215 3.22249197 3.22275119 3.22312379 3.22325242
 3.22336093 3.22342236 3.22355286 3.22363934 3.22384678 3.22414064
 3.22457408 3.22481343 3.22493516 3.22503388 3.22504588 3.22562874
 3.22604965 3.22618199 3.22633265 3.22715647 3.22738692 3.22774415
 3.22787678 3.22792356 3.22876211 3.22897395 3.22929448 3.22935114
 3.22975664 3.23031067 3.23035815 3.23079485 3.23119781 3.23135204
 3.23140126 3.23161254 3.23181071 3.23184368 3.2319188  3.23208194
 3.23222329 3.23237673 3.23324896 3.23340361 3.23349409 3.23350593
 3.23411227 3.23424884 3.23486692 3.23505942 3.23553776 3.23638075
 3.23701674 3.23712308 3.2374294  3.23757744 3.23807369 3.23810542
 3.23823668 3.23825655 3.23876041 3.23910115 3.23938475 3.2401055
 3.24016202 3.24019399 3.24068802 3.24083152 3.24105764 3.24106121
 3.24192555 3.24269529 3.24360377 3.24361947 3.24376902 3.24466826
 3.24468125 3.24491842 3.24612779 3.24620984 3.24653045 3.24657096
 3.24682835 3.24690027 3.24694607 3.24736573 3.24747267 3.24769213
 3.24797772 3.2487641  3.24997732 3.25022128 3.25112019 3.25120192
 3.25175305 3.25230371 3.25235749 3.25262501 3.25296788 3.25314541
 3.25332252 3.25399848 3.25425701 3.25713806 3.25727907 3.25790071
 3.25936081 3.25999132 3.26083851 3.26108661 3.26179282 3.26212649
 3.26233516 3.26277593 3.26283989 3.26421656 3.26422801 3.26451371
 3.26550943 3.26557459 3.26604326 3.26679851 3.26818041 3.26826001
 3.27102247 3.27136334 3.27211269 3.2721949  3.27334774 3.27378406
 3.27401804 3.27408105 3.274625   3.27546735 3.27563141 3.27617507
 3.27646547 3.27689454 3.27808273 3.27844815 3.2792899  3.27972902
 3.27990518 3.28028191 3.28031319 3.2804781  3.28094795 3.28148092
 3.28670262 3.28697296 3.28742019 3.28803371 3.28954518 3.29041724
 3.29060025 3.29100923 3.29102871 3.29174221 3.29371233 3.29570566
 3.29636346 3.29680409 3.29688723 3.29802992 3.29842604 3.29962479
 3.30341326 3.30555904 3.30606433 3.30688417 3.3076128  3.30790715
 3.30868495 3.31280189 3.31380625 3.31447571 3.3145603  3.31506468
 3.31522865 3.31677211 3.31761319 3.31903948 3.320448   3.32278086
 3.32298665 3.3261988  3.32642843 3.32683476 3.32697183 3.3331046
 3.33330879 3.33418524 3.3350675  3.33592648 3.3393752  3.33963355
 3.34062372 3.34184447 3.34268404 3.34276591 3.34500651 3.34580759
 3.34604276 3.34793437 3.34827704 3.34846901 3.34847322 3.34917583
 3.34942035 3.34979528 3.34996764 3.35002867 3.35076126 3.35125552
 3.35313913 3.35333007 3.3535855  3.35362232 3.35487833 3.35502014
 3.35837409 3.35924906 3.35954877 3.36007373 3.36202251 3.36260042
 3.36364555 3.36402584 3.36500592 3.36617719 3.36686511 3.36773735
 3.36928247 3.37044993 3.37094564 3.37160171 3.37197695 3.37347687
 3.37521315 3.37594114 3.37843607 3.37866549 3.3796871  3.38001101
 3.38044069 3.38381512 3.38430631 3.38568011 3.38630121 3.38674699
 3.38675428 3.38942413 3.38945986 3.39185641 3.3938263  3.39595038
 3.39616782 3.39747098 3.39865518 3.39870142 3.40016779 3.40155667
 3.40167243 3.40351137 3.41117141 3.41208011 3.41299366 3.41395556
 3.4166188  3.41840924 3.41976457 3.42112587 3.42522521 3.42565685
 3.42650393 3.42900648 3.43645312 3.45087728 3.45419384 3.45639271
 3.45860748 3.46648951 3.47146207 3.47752401 3.481481   3.50112942
 3.50275528 3.53249098 3.53861852 3.57036461 3.57392571 3.64240128
 3.64967921 3.72522628 3.77760254 3.78530809 3.78779546 3.79631138
 3.80443716 3.81858042 3.84327649 3.85809714 3.9207915  3.95756822
 4.16089864 4.17298151 4.17714505 4.5285242  4.61142691 4.77329157
 4.78863703 4.80298288 4.80382171 4.80421265 4.81047667 4.82171761
 4.82860923 4.8354694  4.8364791  4.84885305 4.84990138 4.85340349
 4.85443827 4.85497793 4.85531144 4.85752474 4.85965502 4.8638313
 4.87481214 4.87757297 4.88217918 4.89272965 4.92798206 4.93196625
 4.94741297 4.9487199  4.95762671 4.98184733 4.98212751 5.11426524]

  warnings.warn(

2022-12-16 10:36:27,626:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.68808594 1.86916625 1.9220191  1.93792895 1.94600065 1.97140397
 2.15499595 2.17301879 2.82413941 2.83015103 2.8462422  2.8629496
 2.91365589 2.91429042 2.91644713 2.92178867 2.92293848 2.92312732
 2.95100367 2.95642209 2.95912424 2.96118898 2.96244148 2.96295403
 2.97277189 2.97429214 2.97484283 2.97698869 2.97950917 2.9818062
 2.98197817 2.98269914 2.9830093  2.9879066  2.98841085 2.99012439
 2.99200082 2.99480941 2.99596865 2.99631659 2.99673572 2.99863148
 2.99920626 3.00064916 3.00271869 3.00282667 3.00363187 3.00553735
 3.00829818 3.00903998 3.0098128  3.0120565  3.0145687  3.01518986
 3.01548443 3.0172693  3.01738982 3.01745032 3.01827245 3.01840113
 3.01952727 3.01957778 3.01975072 3.01982321 3.02021082 3.02072457
 3.02138962 3.0217945  3.02211126 3.02289044 3.02418931 3.02629608
 3.02640333 3.02860673 3.0293411  3.02942816 3.02951513 3.0308759
 3.03129522 3.03258159 3.03473237 3.03754623 3.03828726 3.03869091
 3.03883281 3.03891225 3.03981875 3.03998429 3.04050938 3.04098858
 3.04182055 3.04196614 3.04213321 3.04219083 3.04240928 3.04321197
 3.04328175 3.04434413 3.0470241  3.04958791 3.04980556 3.05155608
 3.05264915 3.05348968 3.05350081 3.05357245 3.05410225 3.05578492
 3.05806766 3.05824626 3.05834197 3.05980153 3.05987485 3.06163068
 3.06163661 3.06210773 3.0628213  3.06288613 3.06341494 3.06356614
 3.06361254 3.06390878 3.06617727 3.06796637 3.06827881 3.06884148
 3.06913092 3.06917214 3.06927423 3.06947348 3.06960823 3.0709443
 3.07163443 3.07416343 3.0754534  3.07584578 3.0760512  3.07666444
 3.07671599 3.07769929 3.07840096 3.07846681 3.07897161 3.07961988
 3.07963996 3.07984803 3.08076198 3.08164773 3.08319222 3.08451168
 3.0856666  3.08568761 3.09069128 3.09091469 3.09460969 3.09531089
 3.09643757 3.09784707 3.0978841  3.09815717 3.09959922 3.0999139
 3.10086354 3.10104671 3.10151046 3.10327711 3.10365622 3.10560807
 3.10646239 3.1074129  3.1092626  3.11047275 3.11107826 3.11143591
 3.11182505 3.11458528 3.11580838 3.11622117 3.11649104 3.11653656
 3.11749503 3.11804863 3.11839351 3.11851801 3.11976054 3.12018229
 3.12101212 3.121332   3.12192343 3.12236032 3.12300518 3.1252082
 3.12528955 3.12592884 3.12618866 3.12676686 3.12692379 3.12714674
 3.12780152 3.12802674 3.1282353  3.12869205 3.12935687 3.12974962
 3.13128973 3.13188261 3.13244712 3.13245594 3.13286995 3.13387379
 3.13402772 3.13443689 3.13473614 3.13489661 3.13497541 3.13517382
 3.13588785 3.13592653 3.13703754 3.13810528 3.13837282 3.13859638
 3.13860546 3.1386088  3.13875133 3.13936384 3.13938968 3.13960801
 3.14029101 3.1406029  3.14138784 3.14154034 3.14159208 3.14194371
 3.14307246 3.14323775 3.14338428 3.14344539 3.14422417 3.14426015
 3.14432877 3.14559138 3.14705796 3.14720385 3.14735394 3.14747818
 3.14768736 3.147742   3.14834122 3.1487321  3.14880725 3.14900825
 3.1490489  3.14908546 3.14946276 3.1499683  3.15032404 3.1516451
 3.15181701 3.15183874 3.15189019 3.152122   3.15217015 3.1523551
 3.15235651 3.15245978 3.15274216 3.15285978 3.15353325 3.15390759
 3.15396781 3.15428555 3.15536764 3.15549803 3.15575467 3.15575827
 3.1564222  3.15645687 3.15655049 3.15682753 3.15691909 3.15708771
 3.15709572 3.15803863 3.15847009 3.15941532 3.15952449 3.15954439
 3.15963057 3.15984791 3.15990567 3.16021481 3.16031921 3.16060286
 3.16067442 3.16082281 3.16142198 3.16176068 3.1618921  3.16226772
 3.16238757 3.16268173 3.16283712 3.1629195  3.16343418 3.16360556
 3.16371966 3.16402244 3.16518446 3.16522986 3.1655712  3.16594724
 3.16616274 3.16637096 3.16661402 3.16687023 3.16715153 3.16724746
 3.16726115 3.16768492 3.16770809 3.16780206 3.1678497  3.1681991
 3.16839589 3.16849569 3.1686772  3.16880682 3.16902202 3.1695655
 3.16990782 3.16991081 3.17030574 3.17042603 3.17064617 3.17095958
 3.17099396 3.17100094 3.17162837 3.17164874 3.17218144 3.17231109
 3.17233343 3.17247347 3.17271827 3.17274589 3.17297897 3.17329741
 3.17338877 3.17373366 3.17395969 3.17397905 3.17401065 3.17429232
 3.17515105 3.1752475  3.17579523 3.17581883 3.17602278 3.17617946
 3.17621482 3.17680291 3.17684205 3.17711571 3.17726079 3.17733353
 3.17735891 3.17849574 3.17957111 3.17972752 3.17979124 3.17981421
 3.17981438 3.17983158 3.18002142 3.18002695 3.18004542 3.18117363
 3.18133747 3.18139526 3.18174252 3.18184007 3.18187428 3.1821765
 3.18273405 3.1827643  3.18319429 3.18356333 3.1837503  3.18430912
 3.18473995 3.18508708 3.18552873 3.18584488 3.18592711 3.18597836
 3.18606527 3.18618706 3.18656331 3.18662641 3.18672296 3.18673653
 3.18691576 3.1869655  3.18711497 3.18730312 3.18742187 3.18751607
 3.18757236 3.18796608 3.18804369 3.18820442 3.18838638 3.18866768
 3.18888328 3.18894304 3.18907567 3.18917697 3.18928635 3.1894265
 3.18956483 3.18998505 3.19011079 3.19025189 3.19052252 3.19083509
 3.1908633  3.19127145 3.1916451  3.19166641 3.19207996 3.192517
 3.19291548 3.19292165 3.19297089 3.19316898 3.19330414 3.19392607
 3.19466429 3.19479918 3.19512363 3.19619166 3.19640891 3.19654095
 3.19656122 3.19693482 3.1969972  3.19729936 3.19731434 3.19750861
 3.19767529 3.1977146  3.19780927 3.19809623 3.19843913 3.19867048
 3.19869523 3.19876221 3.19878711 3.19884692 3.19908268 3.1993124
 3.19943133 3.19949636 3.1997167  3.20003484 3.20005226 3.20008119
 3.20012657 3.20023401 3.20098272 3.20100752 3.2010464  3.20118092
 3.20126777 3.20143592 3.20150237 3.20157303 3.20219242 3.20223333
 3.20260742 3.20266326 3.20273004 3.20298997 3.20335663 3.20348069
 3.2039089  3.20393765 3.20398431 3.2041797  3.2043007  3.20489002
 3.20516133 3.2057612  3.20620792 3.20672225 3.20676893 3.20688002
 3.2075366  3.20778133 3.20802986 3.20819082 3.20891118 3.20930604
 3.20938432 3.20941945 3.20946698 3.20971212 3.21075879 3.2110556
 3.21110468 3.21127362 3.21155503 3.21164543 3.21207277 3.212123
 3.21217108 3.21243991 3.21246666 3.21295549 3.21336465 3.21399798
 3.21429481 3.21436472 3.2144844  3.21474747 3.21494267 3.21499604
 3.21544032 3.21576244 3.21583622 3.21585229 3.21590566 3.21624558
 3.21633448 3.21646548 3.21657312 3.21665449 3.21665842 3.21680018
 3.21706772 3.21727665 3.21742727 3.21889086 3.21911014 3.21970049
 3.21976821 3.21991844 3.21994207 3.22000091 3.22005425 3.2201854
 3.22026812 3.22036025 3.22061434 3.22102947 3.22162755 3.22239289
 3.22290085 3.2231841  3.2235912  3.22362117 3.22400399 3.22413282
 3.22473043 3.22572305 3.22709355 3.22785229 3.22806414 3.22879745
 3.231439   3.23163341 3.23192566 3.23229746 3.2324068  3.2326405
 3.23264354 3.23284545 3.23297434 3.23336603 3.23340112 3.23410537
 3.23482087 3.2351571  3.23523918 3.23628677 3.2367673  3.23714997
 3.23720813 3.23805515 3.23829804 3.23850608 3.24036644 3.24042503
 3.24071655 3.24084571 3.24319245 3.24331002 3.24349863 3.24378683
 3.24564867 3.24706875 3.24747264 3.24780219 3.24822463 3.24854047
 3.24997847 3.25033021 3.25085281 3.25164887 3.25170758 3.25237044
 3.25351707 3.25425073 3.25686851 3.2569936  3.2584809  3.25850064
 3.25852935 3.25974098 3.26005189 3.26203113 3.2625562  3.26377627
 3.26378493 3.26390194 3.26403456 3.26626606 3.26644749 3.26769919
 3.26926551 3.26993205 3.27017823 3.27048381 3.27207648 3.27382917
 3.27468897 3.27660803 3.27916452 3.27970774 3.2800642  3.28037549
 3.28098285 3.28201879 3.28681321 3.28871989 3.29091023 3.29218634
 3.29383909 3.29419352 3.29492869 3.29860933 3.29938558 3.3002613
 3.30080073 3.30252124 3.30273683 3.30499665 3.3076453  3.30787124
 3.3104947  3.31168795 3.31302229 3.31365978 3.31439996 3.31855258
 3.31857098 3.31930103 3.32164212 3.32184266 3.32238505 3.32241932
 3.32309532 3.32347323 3.32395271 3.32492346 3.32701594 3.32857163
 3.32989042 3.33126228 3.33133761 3.33198133 3.33297084 3.33317058
 3.3348328  3.33570555 3.33584909 3.33748317 3.33768607 3.33771773
 3.33819128 3.33863452 3.33891277 3.33992464 3.34001904 3.34011853
 3.34068666 3.34322261 3.34418447 3.3445701  3.34475433 3.34514746
 3.34639291 3.34720927 3.34727014 3.34997954 3.35113712 3.35196135
 3.35624069 3.35738781 3.35997354 3.36012644 3.36040529 3.36095212
 3.36126999 3.36324174 3.36408767 3.36493935 3.36518808 3.36784217
 3.36819692 3.36828938 3.37093642 3.37172255 3.37280987 3.37334881
 3.37453349 3.37484437 3.37503728 3.37506945 3.37560274 3.37701713
 3.37928394 3.37942945 3.37979606 3.37997319 3.38013289 3.38054138
 3.38200657 3.38267249 3.38335732 3.38495197 3.38847803 3.38921307
 3.39007726 3.39010176 3.39187074 3.39531137 3.39649454 3.39769795
 3.40125731 3.4024823  3.40256417 3.40468759 3.40501925 3.40521241
 3.40524322 3.40597618 3.40687986 3.40726171 3.40969037 3.41006148
 3.41155357 3.41747114 3.42127576 3.42128412 3.42207936 3.42258033
 3.42477347 3.43112164 3.44933713 3.45109114 3.45140917 3.45397212
 3.4614734  3.48403365 3.48805963 3.4895644  3.50721481 3.51766282
 3.54215376 3.55833463 3.56026785 3.60954357 3.62448267 3.64537437
 3.66292079 3.67121977 3.67674241 3.68804786 3.70091183 3.70408405
 3.71208226 3.73859734 3.75169399 3.77102185 3.79000996 3.79196673
 3.79792633 3.80389251 3.8058431  3.81638887 3.8186024  3.82916216
 3.83390314 3.84061309 3.84474397 3.85260458 3.85755167 3.8659055
 3.88968185 3.93769584 4.12994757 4.1403437  4.15700628 4.18392196
 4.32886173 4.52415219 4.62827597 4.70192606 4.7336355  4.75704531
 4.7721464  4.77378033 4.78133378 4.78258348 4.7848125  4.78941466
 4.79230952 4.79325948 4.79880363 4.80936048 4.81279686 4.81370583
 4.81464225 4.81531336 4.82310266 4.82441672 4.83243766 4.83484434
 4.83638426 4.83892394 4.84997254 4.85720332 4.85835769 4.85920071
 4.86154994 4.8664405  4.86822092 4.87380285 4.90970739 4.91806118
 4.91841685 4.93209775 4.93315423 5.03818009 5.20294305]

  warnings.warn(

2022-12-16 10:36:27,794:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.76226365 1.92588159 1.94390458 1.95009569 1.96349732 2.00983397
 2.0219521  2.03327507 2.05390017 2.08478706 2.20259741 2.79750467
 2.80515001 2.80747118 2.8192948  2.82824551 2.83496841 2.84779728
 2.86199491 2.87419848 2.88580941 2.93407502 2.93592695 2.94790705
 2.95128751 2.95372943 2.96066575 2.96436228 2.96636577 2.96716133
 2.97145476 2.97290075 2.97636651 2.97807212 2.97978342 2.98689604
 2.98894737 2.99005781 2.99113443 2.99188558 2.99432096 2.99463744
 2.99559917 2.99622445 2.99718445 2.99719016 2.99728607 2.99780015
 2.99836005 3.0013642  3.00159655 3.00519721 3.00566669 3.0063291
 3.00740553 3.0075877  3.00915215 3.01080727 3.01164567 3.01209584
 3.01220184 3.0130314  3.01640927 3.01852444 3.0196243  3.02150918
 3.02246346 3.0229232  3.02411913 3.02590007 3.02797951 3.02889866
 3.02893504 3.02919113 3.03072473 3.03262243 3.03372184 3.03399922
 3.03437997 3.03464875 3.03496467 3.03576687 3.03707095 3.03741386
 3.0397609  3.04074606 3.04212095 3.04297831 3.04298577 3.04364726
 3.04528366 3.04650271 3.04750004 3.04761482 3.05093433 3.05348485
 3.05519465 3.05762251 3.05867431 3.05905165 3.05925939 3.05971061
 3.0626567  3.06351545 3.06515782 3.06642657 3.06712801 3.07142045
 3.07583733 3.07643323 3.07859178 3.07919836 3.07952286 3.0810509
 3.08273344 3.08275962 3.08299667 3.0833254  3.08705336 3.08924398
 3.08985391 3.09084841 3.09376013 3.09464406 3.09510133 3.0981907
 3.10028769 3.10126939 3.1016832  3.10175668 3.10345575 3.10411435
 3.10426413 3.10438269 3.10486146 3.10516694 3.10563151 3.10671892
 3.10692345 3.10813505 3.10892758 3.10895943 3.10960301 3.11045078
 3.11067355 3.11101751 3.11141904 3.11232446 3.11272227 3.11348793
 3.11614378 3.11624367 3.11640085 3.11677482 3.11714065 3.11716874
 3.11753565 3.11875001 3.1198141  3.1205631  3.12144751 3.12149167
 3.12209156 3.12231593 3.12280861 3.12288754 3.12346634 3.12348719
 3.1240565  3.12438927 3.12468279 3.12471362 3.12536104 3.1261589
 3.12651806 3.12716871 3.12780021 3.12841942 3.12893622 3.12930809
 3.12936111 3.12937903 3.12938653 3.12984505 3.13023199 3.13053467
 3.13124411 3.13139289 3.13196274 3.13259017 3.13328415 3.13373692
 3.13376501 3.13409403 3.13418982 3.13436447 3.13470762 3.13504217
 3.13567998 3.13576067 3.13585934 3.13609227 3.13658706 3.13694716
 3.13748268 3.13769838 3.13813171 3.13823907 3.13845557 3.13851341
 3.13872941 3.13924367 3.13933418 3.13949558 3.13951635 3.13955691
 3.14066047 3.1409117  3.14135901 3.14194647 3.1422717  3.14242471
 3.14253535 3.14307301 3.14333427 3.14383291 3.14394612 3.14412774
 3.14418981 3.14445065 3.14449468 3.14491262 3.14500786 3.14565534
 3.14573481 3.14573929 3.14582296 3.14586963 3.14587976 3.14672013
 3.14706679 3.14731857 3.14732234 3.1476467  3.14786857 3.14791375
 3.14800717 3.14832311 3.14835288 3.14836497 3.14888922 3.14944166
 3.15032654 3.15109992 3.15123455 3.15174277 3.15175187 3.15224112
 3.15241373 3.15303427 3.15311245 3.15320546 3.15324899 3.15366254
 3.15394433 3.1540657  3.15414587 3.15422224 3.15458109 3.15483799
 3.15487937 3.15562022 3.15563112 3.15580048 3.15596172 3.15612543
 3.15681689 3.15686622 3.15777952 3.15826492 3.15889792 3.15893047
 3.15905211 3.15911455 3.15966866 3.15969335 3.16020042 3.16026629
 3.16041513 3.16100757 3.16144982 3.16202315 3.16202598 3.162183
 3.16242538 3.16254426 3.16261681 3.16271183 3.16297343 3.16301749
 3.16302569 3.16344258 3.16358099 3.16395104 3.16458763 3.16483502
 3.16505795 3.16513792 3.16515372 3.16528456 3.16588768 3.16642221
 3.16650725 3.16662522 3.16709564 3.16733047 3.16744811 3.16760291
 3.16768025 3.16769937 3.16771229 3.16800741 3.16823004 3.16891894
 3.16902216 3.16914792 3.16923548 3.1696612  3.17014043 3.17024356
 3.17053344 3.17132265 3.17165104 3.17182718 3.17186002 3.17207457
 3.17276233 3.17314856 3.17340516 3.17351554 3.17370508 3.17468616
 3.17484549 3.1749264  3.17564324 3.17575335 3.17628136 3.17649085
 3.17654417 3.17685989 3.17715216 3.17715275 3.17765793 3.17779314
 3.17812106 3.17884974 3.17928427 3.17936744 3.17952332 3.17962898
 3.17975236 3.1805384  3.18083138 3.18093352 3.1811774  3.18127831
 3.18145305 3.18203572 3.18228375 3.18247375 3.18269109 3.18276274
 3.18285466 3.18304194 3.18326761 3.1832766  3.18357008 3.18413126
 3.18453143 3.18505768 3.18507135 3.18540116 3.18586485 3.18607477
 3.18618587 3.18633042 3.18633054 3.1864718  3.18674726 3.18682091
 3.18791916 3.18800936 3.18842896 3.1886767  3.18889059 3.18897188
 3.18912883 3.18943293 3.18965173 3.18997276 3.19039217 3.19070612
 3.19108832 3.19143168 3.19150203 3.19164157 3.19181526 3.19203495
 3.19274283 3.19301135 3.19334456 3.19345405 3.19364977 3.19364988
 3.19399888 3.19536078 3.19577122 3.19599896 3.19659288 3.19707177
 3.19721196 3.19811894 3.19853564 3.19902429 3.19909605 3.19922065
 3.19933085 3.19973063 3.1998296  3.20052567 3.2011257  3.20114713
 3.20117497 3.20135057 3.2018494  3.20191446 3.20280997 3.20296434
 3.20299159 3.20330723 3.20405313 3.20449935 3.20501327 3.2050769
 3.20521605 3.20538154 3.20544813 3.20548346 3.2056984  3.20620227
 3.20621043 3.2065604  3.20664071 3.20669427 3.20705988 3.20715789
 3.20743797 3.20788687 3.20825967 3.20844752 3.20877841 3.20943108
 3.20962066 3.20988613 3.21044773 3.21054073 3.21058875 3.2108169
 3.21101295 3.2114482  3.21166682 3.21213279 3.21262611 3.21382325
 3.21394813 3.21422777 3.21435706 3.21445762 3.2144769  3.21461595
 3.21477843 3.21488864 3.21503676 3.21534107 3.21549397 3.21595465
 3.21600263 3.2161258  3.21620495 3.21651908 3.21685403 3.217462
 3.21822376 3.21843185 3.2184964  3.21911981 3.21977658 3.22048624
 3.22086486 3.22113894 3.22146962 3.22152125 3.2216356  3.22239853
 3.22287068 3.22423651 3.22426143 3.2246178  3.22558862 3.22567437
 3.22571088 3.22583548 3.22643259 3.22709561 3.22804458 3.2285058
 3.22895221 3.22946539 3.22985305 3.23007016 3.23035547 3.23049723
 3.23094366 3.23096088 3.23108023 3.23109381 3.23138636 3.23161302
 3.2332458  3.23459322 3.23502322 3.23528863 3.23533569 3.23564358
 3.23570473 3.23573755 3.23596597 3.23682439 3.23691439 3.23699692
 3.23703102 3.23826189 3.23831922 3.23844935 3.2386297  3.23873224
 3.23953914 3.23985969 3.24037216 3.2404846  3.24117908 3.24159884
 3.24207785 3.2424296  3.24273477 3.24284083 3.24389107 3.24400131
 3.24404177 3.24412455 3.2441701  3.2443596  3.24524342 3.24625467
 3.24628115 3.24649853 3.24726086 3.24824484 3.24866704 3.2487549
 3.24967634 3.25013807 3.25046151 3.25153942 3.25208785 3.25214399
 3.25239987 3.25266317 3.25303323 3.25417062 3.25423074 3.25512923
 3.25566318 3.25571387 3.25594932 3.25612105 3.25638735 3.25646961
 3.25694804 3.25711012 3.25821115 3.25865738 3.25940323 3.259854
 3.26007742 3.26008374 3.26194363 3.26229274 3.26252641 3.26285189
 3.2629757  3.26390185 3.26467789 3.26541045 3.26676239 3.26751171
 3.2697952  3.27025926 3.27099693 3.27104721 3.27121065 3.2715352
 3.27185343 3.27402401 3.27506958 3.27529463 3.27619643 3.27655823
 3.2769731  3.27710118 3.27734127 3.27794643 3.27931855 3.27989231
 3.28177721 3.28183549 3.28218269 3.28232404 3.2827389  3.28334188
 3.28355916 3.2836627  3.28387344 3.28459897 3.28546855 3.28668534
 3.28735003 3.28784615 3.28842154 3.28918812 3.2892171  3.29034632
 3.29055199 3.29066423 3.2909663  3.29128389 3.29150128 3.29188034
 3.29478391 3.29591592 3.296207   3.29771851 3.2984633  3.29939413
 3.29987221 3.30006674 3.30112441 3.30223242 3.30267576 3.30347087
 3.30387122 3.30548295 3.30600917 3.30775715 3.30958911 3.30988308
 3.31039061 3.31121598 3.31262153 3.31480367 3.31497419 3.31546339
 3.3161107  3.32036024 3.32085694 3.32094    3.32111922 3.32127791
 3.32180633 3.32181934 3.3231785  3.32329624 3.3272499  3.32735395
 3.32927816 3.33039953 3.3307438  3.33148639 3.3331391  3.33317855
 3.33367654 3.33433584 3.33686836 3.33831943 3.34124916 3.34303746
 3.34607193 3.3464385  3.34694788 3.34726859 3.35033643 3.35223186
 3.3526809  3.35269477 3.35306865 3.35388735 3.35620575 3.35655212
 3.35665561 3.35709774 3.35966477 3.36033763 3.36077388 3.36476954
 3.36509325 3.36684352 3.36768872 3.36842546 3.36939854 3.37026579
 3.37242895 3.37365158 3.37415794 3.37446793 3.37478114 3.37546562
 3.37608571 3.37663748 3.37672755 3.3787849  3.37951291 3.38192733
 3.38367813 3.38379103 3.38399291 3.38414158 3.3845546  3.38607894
 3.38718851 3.38758205 3.38777346 3.38783915 3.38879298 3.38880849
 3.38928715 3.39042489 3.39341841 3.39801782 3.39814798 3.40063032
 3.40088597 3.40095719 3.40238532 3.40323745 3.40576768 3.40707256
 3.41414497 3.41742616 3.42442652 3.42619801 3.42863291 3.42905027
 3.43357037 3.4365241  3.43805729 3.44935673 3.45162708 3.45590338
 3.45912136 3.47524506 3.47813861 3.48164842 3.48200507 3.48809801
 3.48881986 3.48963682 3.49100977 3.4955207  3.50338316 3.50569609
 3.5097049  3.51555308 3.51890173 3.52526249 3.52542598 3.54077999
 3.61370598 3.64595903 3.66249594 3.66766451 3.69334987 3.71961043
 3.72149789 3.76906123 3.80014318 3.80357571 3.83070097 3.83113165
 3.83663741 3.86133097 3.86177642 3.86223471 3.86464152 3.92075781
 3.94555275 3.94601775 3.95011757 3.96366373 3.96395275 4.11818528
 4.12079207 4.16177885 4.32892801 4.44810251 4.74432951 4.76354829
 4.76504845 4.77199385 4.77384085 4.77600629 4.78273537 4.79119429
 4.79764477 4.80087405 4.80124338 4.80176763 4.80212097 4.80312741
 4.80860154 4.81649865 4.81755977 4.81780812 4.81830185 4.81906676
 4.81910406 4.82335365 4.82440486 4.83088742 4.83158348 4.83312978
 4.8348839  4.83806621 4.84618509 4.84981924 4.85836699 4.86173895
 4.86323446 4.87568441 4.88734401 4.89322871 4.92835632 4.93298868
 4.95508111]

  warnings.warn(

2022-12-16 10:36:27,851:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.65469548 1.92672316 1.93709954 1.95953165 1.96030034 1.96179116
 1.98770457 1.98838418 2.00290839 2.01558313 2.14102525 2.17744726
 2.85190621 2.8694473  2.87182911 2.87287236 2.88036172 2.89599968
 2.89721357 2.89730817 2.8984551  2.89966213 2.90233622 2.90402516
 2.90549354 2.90593196 2.90603592 2.90741185 2.90816175 2.90980028
 2.91016106 2.91531371 2.91606933 2.91939623 2.92036599 2.9209326
 2.92451498 2.92534236 2.92737685 2.92810083 2.93012335 2.93283742
 2.94115605 2.94225965 2.9423291  2.94386674 2.94854729 2.94891473
 2.95205044 2.95238053 2.95473825 2.95522753 2.95524313 2.95543428
 2.9581449  2.95864832 2.95910803 2.95943039 2.95973028 2.96054005
 2.96070324 2.96149853 2.96311968 2.96511541 2.96548633 2.96680748
 2.96783713 2.96823153 2.97004969 2.97176306 2.97220564 2.97220975
 2.9734435  2.97349571 2.97715713 2.9778144  2.9786426  2.97883298
 2.97970879 2.98391398 2.98751254 2.98810344 2.98833048 2.98881194
 2.98938591 2.99132583 2.99538066 2.99585921 3.00138567 3.00359527
 3.00507093 3.0053093  3.0057306  3.007601   3.00795141 3.01039713
 3.01249833 3.01251969 3.01275643 3.01284065 3.01320828 3.01527472
 3.01567819 3.01889758 3.01927656 3.02405117 3.02681731 3.02870504
 3.02925428 3.03256599 3.03632185 3.03693937 3.03986225 3.05060069
 3.05213985 3.05471328 3.06055505 3.06150273 3.06653726 3.06706954
 3.07343821 3.07369556 3.07463992 3.07615244 3.07866541 3.08286221
 3.08659126 3.08702587 3.08720422 3.09089398 3.0918701  3.09668698
 3.09687212 3.09828806 3.0984853  3.10021275 3.10028686 3.10056677
 3.1009548  3.10198476 3.10218624 3.10287029 3.10448438 3.10607966
 3.10980913 3.11025461 3.11192109 3.11214974 3.11369637 3.11390569
 3.1142926  3.1144256  3.11485685 3.11700168 3.11765904 3.11840656
 3.11891324 3.11961586 3.11981303 3.12027129 3.12035034 3.12045661
 3.12200309 3.12200874 3.12244354 3.12314945 3.12380485 3.12400906
 3.12418695 3.12450823 3.12586999 3.12654131 3.12656965 3.12701213
 3.12732348 3.12777158 3.12854358 3.13005744 3.13026134 3.13228827
 3.13238146 3.13292934 3.13307693 3.13319038 3.13347945 3.13385997
 3.13392209 3.13499172 3.13589979 3.13619343 3.13676373 3.13686788
 3.13749191 3.13791246 3.13817564 3.13900353 3.13917833 3.13975441
 3.14042004 3.14085234 3.14176697 3.14181243 3.14206638 3.14235154
 3.14294835 3.14338638 3.14362375 3.14442686 3.14488955 3.14544257
 3.1456436  3.14579655 3.14605076 3.14618287 3.14655097 3.14671974
 3.14675385 3.14676573 3.14706064 3.14834689 3.14893561 3.149313
 3.14972405 3.1499152  3.15022852 3.15032411 3.1506426  3.15129678
 3.15137846 3.15164371 3.15219113 3.15223338 3.15235868 3.15238897
 3.15244169 3.15297683 3.15304508 3.15325573 3.15352894 3.15389179
 3.1542051  3.15506792 3.15511893 3.15540061 3.15561753 3.15617182
 3.15720976 3.15730035 3.15802346 3.15815903 3.1581734  3.15928861
 3.15939472 3.15955857 3.15966294 3.15968106 3.15969234 3.15972983
 3.15975113 3.15996816 3.16024489 3.16074484 3.16104753 3.16153705
 3.1619255  3.16204963 3.16275289 3.16295383 3.16300086 3.16304175
 3.16306058 3.16316781 3.16319444 3.16327351 3.16329005 3.16366676
 3.1639278  3.16402574 3.16507452 3.16509366 3.16521197 3.16541875
 3.1659639  3.16602319 3.16610381 3.16616776 3.16693478 3.16752414
 3.16758627 3.16759825 3.16806614 3.16809796 3.1683965  3.16858123
 3.16876498 3.16912074 3.16919214 3.16931919 3.16937146 3.16960234
 3.17035453 3.17065457 3.17076855 3.17096805 3.17169635 3.17172455
 3.1717891  3.1723653  3.17262737 3.17262934 3.17281394 3.17283322
 3.17302869 3.17307016 3.17357152 3.17377029 3.17416633 3.1744316
 3.17486546 3.17502327 3.1752515  3.17588485 3.17591565 3.17614829
 3.17617848 3.17661253 3.17680243 3.17694148 3.17715231 3.17763347
 3.1776646  3.17790522 3.17821531 3.17840847 3.17859161 3.17868085
 3.17870983 3.17930871 3.17975774 3.17986472 3.18004437 3.18043177
 3.18050588 3.18063411 3.18064387 3.1807052  3.18084624 3.18096416
 3.18118128 3.1814069  3.18145117 3.18164582 3.18171542 3.18240726
 3.18246213 3.18246338 3.18272272 3.18272679 3.18278035 3.18287845
 3.18290535 3.18299332 3.18307125 3.18313256 3.18324522 3.18341161
 3.1834737  3.18391079 3.18406608 3.18409114 3.1841507  3.18429129
 3.1845615  3.18478179 3.1847911  3.18479423 3.18492662 3.18496765
 3.1850111  3.18531587 3.18657497 3.18662928 3.18731686 3.18738949
 3.18761726 3.18824083 3.18829557 3.18884596 3.18914926 3.18925217
 3.1892625  3.18932628 3.18949632 3.18950469 3.18967121 3.18982669
 3.18996964 3.19040348 3.19083339 3.19102925 3.19114866 3.19123205
 3.19173408 3.19181455 3.19204932 3.19220378 3.19236778 3.1925238
 3.19296395 3.19307196 3.19312129 3.19329867 3.19342449 3.19348146
 3.19350242 3.19360102 3.19361107 3.19378177 3.19393235 3.19432014
 3.19460218 3.19462486 3.19465909 3.19473903 3.19480466 3.19482204
 3.19533649 3.19546492 3.19559698 3.19569395 3.19579488 3.19621304
 3.19659749 3.19670333 3.19712319 3.19787858 3.19791555 3.19795794
 3.19802474 3.19811472 3.19860317 3.19882318 3.19884021 3.19901868
 3.19917819 3.19962037 3.19972295 3.19981939 3.20050208 3.20059371
 3.20062911 3.20112645 3.20114534 3.2012763  3.20214584 3.20222192
 3.20241569 3.2030581  3.20318502 3.20341806 3.20351371 3.20380724
 3.20401581 3.20433251 3.20434165 3.20454015 3.20470379 3.20498791
 3.20504464 3.20507457 3.20525696 3.20546085 3.20551747 3.20579476
 3.20580128 3.20583752 3.20600814 3.20745387 3.20762937 3.20841853
 3.20844018 3.2086845  3.20898077 3.20955758 3.20964681 3.20978123
 3.20981727 3.20992986 3.20994701 3.21013921 3.21044118 3.21060733
 3.21061512 3.21065901 3.21069045 3.21120082 3.21125953 3.21162474
 3.21194894 3.21210545 3.21216842 3.21269817 3.21273049 3.21334854
 3.21368405 3.21432782 3.21471317 3.21472622 3.21479897 3.21490186
 3.21548549 3.21582675 3.21592936 3.2160706  3.21612044 3.21638418
 3.21650597 3.21662157 3.21669967 3.21681585 3.21686796 3.21688796
 3.21787632 3.21849611 3.21939115 3.2193959  3.21978807 3.22002364
 3.2201043  3.22044003 3.22085064 3.22128619 3.22131338 3.22188325
 3.22223384 3.22251886 3.22271015 3.22275817 3.22301048 3.22304918
 3.22356014 3.22384381 3.22386421 3.22408982 3.22419614 3.22431522
 3.22448467 3.22457857 3.22458161 3.22473471 3.22495763 3.2252799
 3.22537582 3.22559771 3.22563812 3.22594012 3.22605002 3.22679652
 3.22685134 3.22686943 3.22701158 3.22712568 3.22729485 3.22805978
 3.22815169 3.22841804 3.22871637 3.22895696 3.2291431  3.23003215
 3.23058834 3.23079836 3.23117351 3.23147541 3.23147741 3.23176153
 3.2318169  3.23193794 3.23198651 3.23202512 3.23221541 3.23259279
 3.23322801 3.23337113 3.2334176  3.23481536 3.2350463  3.23541874
 3.23571732 3.23595674 3.23609912 3.23625845 3.23629703 3.23644917
 3.23737221 3.23773037 3.2377726  3.23780975 3.23807842 3.2380868
 3.23864165 3.23933543 3.23934081 3.2405419  3.24089268 3.24100161
 3.24346663 3.24371099 3.24377598 3.24498597 3.24518709 3.245652
 3.24582687 3.24643243 3.24661792 3.24724167 3.247881   3.24997129
 3.2503758  3.25196166 3.25202839 3.25217232 3.2537212  3.25446435
 3.25474256 3.25673168 3.25691801 3.25774798 3.25927197 3.25934339
 3.26221328 3.26349134 3.26371006 3.26454292 3.26518558 3.26720079
 3.26820954 3.26828374 3.27092509 3.27119435 3.27208235 3.27285322
 3.27297745 3.27397159 3.27401688 3.27432984 3.27519247 3.27521215
 3.27555784 3.27854321 3.27882677 3.28066672 3.28130537 3.28191061
 3.28324409 3.28370182 3.28401226 3.28401376 3.28726111 3.2875902
 3.28940225 3.29242247 3.29352903 3.29449843 3.29567401 3.29600186
 3.29758691 3.29785844 3.29801469 3.29802797 3.29864037 3.30053675
 3.30068145 3.30101632 3.30192404 3.30473468 3.30540937 3.30598328
 3.30600997 3.30626359 3.30635606 3.3121967  3.31478211 3.31643481
 3.31710965 3.31770337 3.31812686 3.31881034 3.3203068  3.32541966
 3.32704712 3.32712331 3.33112135 3.33178652 3.33289929 3.33391579
 3.33667734 3.3378455  3.34263544 3.34282859 3.34307696 3.34423961
 3.34680186 3.34915635 3.34969135 3.35222983 3.35307381 3.35312653
 3.35460602 3.35737202 3.35823026 3.3591189  3.36075682 3.3637128
 3.36409225 3.36532125 3.36566155 3.36601705 3.36645443 3.36759389
 3.37140382 3.37164596 3.37167008 3.37331439 3.37667481 3.3785396
 3.38018572 3.38111683 3.38279821 3.38297939 3.38401405 3.38503033
 3.38665992 3.38679697 3.38742865 3.38863778 3.38904318 3.39225629
 3.39410542 3.39565819 3.39700243 3.39717681 3.39814015 3.39986968
 3.4024451  3.40305007 3.40356045 3.40440155 3.40526579 3.40600243
 3.40635076 3.40752237 3.40885267 3.41078767 3.41137103 3.41177706
 3.41259666 3.41351601 3.41400962 3.41564311 3.41764092 3.41925439
 3.42181399 3.42245413 3.4226656  3.42361797 3.42456351 3.4249153
 3.42542954 3.42555472 3.42606252 3.42690373 3.4275213  3.42801907
 3.4312365  3.4334132  3.43428418 3.44008741 3.44752029 3.44784406
 3.45292928 3.46845323 3.4862506  3.49640606 3.5167453  3.52433067
 3.53297491 3.53900404 3.54233525 3.56394824 3.61113005 3.63833054
 3.66426076 3.66684162 3.67335853 3.67673874 3.71033343 3.73775023
 3.80565765 3.8415287  3.8435811  3.86877462 3.8741729  3.87501798
 3.87946389 3.88375859 3.88416017 3.9035803  3.90655942 3.90691173
 3.91893196 3.93287628 3.9741754  3.98925919 3.98961741 4.05605792
 4.10387224 4.13061264 4.20953656 4.31341874 4.33062771 4.37594805
 4.49973484 4.50480968 4.70021298 4.76601989 4.78993483 4.7968592
 4.80057073 4.8054372  4.81220361 4.81319739 4.81450863 4.81861956
 4.82032874 4.82147199 4.82760342 4.83079956 4.8316674  4.83319966
 4.83407761 4.83746894 4.83803355 4.83852568 4.83910853 4.83923943
 4.83935193 4.84079822 4.84414425 4.84471617 4.85007286 4.86195682
 4.87387856 4.89311441 4.91543838 4.93401673 4.94086419 4.94885893
 4.95841017]

  warnings.warn(

2022-12-16 10:36:27,855:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.88253109 1.92605627 1.92795054 1.9886782  1.99433162 2.03931726
 2.64662359 2.73467921 2.80970217 2.82457461 2.85618309 2.85644246
 2.86187658 2.87215304 2.87934099 2.88007329 2.88221848 2.88455439
 2.89041583 2.89252698 2.89395214 2.90146083 2.90628634 2.91298758
 2.91379113 2.91695337 2.92247684 2.92815684 2.93038457 2.93280228
 2.93307601 2.93343337 2.94268772 2.94300782 2.945578   2.94675769
 2.94749474 2.95361778 2.95394572 2.95538801 2.95630638 2.95669565
 2.96054463 2.96321439 2.96340954 2.96612024 2.9664286  2.96708653
 2.968377   2.97498964 2.97513949 2.97779376 2.98015829 2.98091424
 2.98098248 2.98148851 2.98291985 2.98479537 2.98484708 2.9850938
 2.98596581 2.98625229 2.98662629 2.98814515 2.98859101 2.99262522
 2.99298091 2.99493689 2.99541791 2.99969963 3.00034369 3.000747
 3.0008608  3.00292954 3.00359313 3.00384943 3.0041957  3.00502741
 3.00668781 3.00884762 3.00892157 3.01037924 3.01145343 3.01261717
 3.01301221 3.01425979 3.0148889  3.0161299  3.01617212 3.01650351
 3.01836749 3.01988864 3.0202367  3.02047607 3.02145089 3.02271516
 3.02422921 3.0250702  3.02729263 3.02818159 3.03045292 3.03205379
 3.03533492 3.03708326 3.03708658 3.03763872 3.03863629 3.03895502
 3.03931175 3.03986661 3.04005951 3.04032454 3.04070879 3.04253141
 3.04271766 3.04363706 3.04544897 3.04587724 3.05046413 3.05163311
 3.05174826 3.05180446 3.05223985 3.05305985 3.05552536 3.05934645
 3.05938742 3.06031395 3.06037779 3.06182068 3.06549651 3.06664139
 3.06835702 3.0697839  3.06992573 3.07037566 3.07213153 3.07323522
 3.07374407 3.07856964 3.07894226 3.08202864 3.08230082 3.08338726
 3.08406699 3.08469229 3.08483093 3.08588864 3.08625409 3.08710332
 3.08724814 3.08751221 3.08823177 3.08882668 3.08902612 3.09007181
 3.09187517 3.0919294  3.093108   3.09442701 3.09464639 3.09472146
 3.09538742 3.09630406 3.0973436  3.09758948 3.09830016 3.10030518
 3.10059312 3.1006373  3.10109468 3.10258055 3.1028135  3.1035381
 3.10486612 3.1055153  3.10566179 3.10658602 3.10724067 3.1085397
 3.10907205 3.10946185 3.10978205 3.10988552 3.11001148 3.110385
 3.11184667 3.1120538  3.11240077 3.11268132 3.11295617 3.11443483
 3.11468419 3.11625331 3.11762332 3.11801542 3.11828471 3.11837224
 3.11848863 3.11906682 3.11923425 3.11949922 3.11994368 3.12027764
 3.12031092 3.1210339  3.12144738 3.12184098 3.12390802 3.12484613
 3.12494293 3.12497536 3.12562635 3.12572732 3.12580901 3.12601356
 3.12602447 3.12618065 3.12683679 3.12706357 3.12773959 3.1277571
 3.12830295 3.12921671 3.12929243 3.12930039 3.1296791  3.12984696
 3.12992425 3.12993628 3.13181953 3.13271494 3.13336016 3.13353659
 3.13375447 3.13389474 3.1339389  3.13409229 3.13410346 3.13411086
 3.13469464 3.13473078 3.13517002 3.13595547 3.1370428  3.13725158
 3.13738956 3.13834806 3.13866486 3.13914786 3.14004296 3.14014393
 3.14046855 3.14073417 3.14093963 3.14202703 3.142327   3.14293312
 3.14293919 3.14339784 3.14477377 3.14496467 3.14584086 3.14681342
 3.14715324 3.14719343 3.14750807 3.14828207 3.14967751 3.15122935
 3.15186473 3.15217705 3.15292914 3.15346066 3.15381777 3.15427855
 3.15431684 3.15468077 3.15502584 3.15526359 3.15588658 3.15623689
 3.15694079 3.15727259 3.15727743 3.15736829 3.15755359 3.1576477
 3.15789715 3.15854755 3.15862689 3.15877355 3.15921809 3.15936189
 3.15961345 3.15980817 3.15998274 3.16040827 3.16060363 3.1609265
 3.16096592 3.16120995 3.16154343 3.16163326 3.16177308 3.16244285
 3.16268694 3.16299524 3.16307625 3.16311403 3.16314688 3.16331795
 3.16335509 3.1633675  3.16340309 3.16405624 3.16409383 3.16421415
 3.16434384 3.16435854 3.16456406 3.16477263 3.1653396  3.16564485
 3.16575723 3.16579036 3.16624666 3.166505   3.1665435  3.16667716
 3.1666857  3.16682093 3.16719098 3.16797628 3.16907311 3.16910312
 3.16911672 3.16949172 3.169561   3.17045849 3.17068171 3.17083228
 3.17113789 3.17129565 3.17151439 3.17170558 3.17230583 3.17283237
 3.17311252 3.17385271 3.17433634 3.1745276  3.17454111 3.17473824
 3.17489062 3.17494216 3.17505563 3.17530194 3.17563744 3.1764731
 3.17674185 3.17678236 3.17714973 3.17783663 3.17807589 3.1784848
 3.17851713 3.17859869 3.17872283 3.17879467 3.1788846  3.17898307
 3.17899224 3.17910377 3.17922792 3.17936834 3.17945887 3.17956165
 3.17979844 3.17996395 3.18074128 3.18116685 3.18136989 3.18141101
 3.18149793 3.18164604 3.18174299 3.18175839 3.18198527 3.18215663
 3.18220176 3.18222236 3.18227302 3.18247029 3.1827309  3.18283324
 3.18302967 3.18328958 3.18370274 3.18374022 3.18386763 3.18419113
 3.18432186 3.18433411 3.18475241 3.18495224 3.18520954 3.18536227
 3.185566   3.18582662 3.18595837 3.1865422  3.1867842  3.18693828
 3.18716295 3.1871778  3.18718836 3.18726527 3.18738505 3.18739075
 3.18755467 3.18769378 3.18885643 3.1890463  3.18932832 3.1897046
 3.18980231 3.19010779 3.19033343 3.19047509 3.19076336 3.19127567
 3.19162373 3.192515   3.19290557 3.19320393 3.193499   3.19398762
 3.19404969 3.19410151 3.19508186 3.19591438 3.19600248 3.19603158
 3.19613234 3.19633889 3.19656535 3.19696561 3.19718452 3.19731139
 3.19771123 3.19789973 3.19813671 3.19851286 3.19871053 3.19884147
 3.19940271 3.19962628 3.19970464 3.19985306 3.20009704 3.20067611
 3.20071894 3.20101847 3.20105584 3.20115012 3.20125384 3.20128823
 3.20146087 3.2018281  3.20202836 3.20243236 3.20254148 3.20296655
 3.20346878 3.20347013 3.20355447 3.20356509 3.20409735 3.20413948
 3.20422327 3.2044499  3.20450287 3.20473779 3.20480673 3.20522105
 3.20589266 3.20608166 3.20640451 3.20648869 3.20665    3.20672873
 3.20674011 3.20697127 3.20709645 3.20725472 3.20786442 3.20891395
 3.20905348 3.20949319 3.20979073 3.20989124 3.21001628 3.21002185
 3.21060859 3.21072346 3.2109174  3.21094114 3.21327361 3.2135196
 3.21362047 3.21423351 3.21457028 3.21459776 3.21470014 3.21480726
 3.21489912 3.21493515 3.21506809 3.21537101 3.21545677 3.21552596
 3.21574389 3.21603994 3.21615203 3.21624314 3.21629734 3.216473
 3.21666057 3.21671989 3.21689692 3.217482   3.21783424 3.21790842
 3.21842039 3.21892901 3.21926871 3.21989609 3.22033202 3.2205695
 3.22109749 3.22204501 3.22209786 3.22216716 3.22235096 3.2223635
 3.22256713 3.22259042 3.22268546 3.2227098  3.22290063 3.22317624
 3.22371533 3.22443866 3.2245585  3.22477839 3.2249286  3.22531354
 3.2257408  3.22738975 3.2283595  3.229217   3.22922889 3.2298372
 3.2299047  3.23066648 3.23105842 3.23206636 3.23232647 3.23263995
 3.23275211 3.23288967 3.23305722 3.23443181 3.23517824 3.23592733
 3.23606737 3.23623179 3.23631434 3.23688417 3.23752785 3.23771698
 3.23802079 3.23814056 3.24133392 3.24152976 3.24154393 3.24211773
 3.24314155 3.24362529 3.24409255 3.24423809 3.24500987 3.24525739
 3.24586497 3.24690093 3.24756131 3.24801919 3.24949731 3.2501094
 3.25011896 3.25110528 3.25257185 3.25262244 3.25335715 3.25378033
 3.25388731 3.25448153 3.25464617 3.25471657 3.25579474 3.25583577
 3.25682394 3.25868792 3.25881257 3.2594361  3.26034469 3.26047567
 3.26089115 3.2609341  3.26167747 3.26178512 3.26219584 3.26221607
 3.26333895 3.26335938 3.26572032 3.26655271 3.26719198 3.26760694
 3.26776336 3.26782571 3.26808993 3.2711925  3.27125012 3.27135578
 3.27155217 3.27165625 3.27265392 3.27339864 3.2747642  3.27585792
 3.2765329  3.27670334 3.27675167 3.27822117 3.28024697 3.28067234
 3.28087973 3.28113681 3.28182375 3.28232683 3.28277129 3.28460116
 3.28491637 3.28550589 3.28638541 3.28671652 3.28675912 3.28684654
 3.28685363 3.28718396 3.28888001 3.28993156 3.29090739 3.29107639
 3.29196718 3.29200786 3.2933875  3.293445   3.29466325 3.29468755
 3.2948849  3.29573549 3.29602386 3.29802466 3.2985014  3.29877599
 3.29978655 3.30015779 3.30347918 3.30353362 3.30444853 3.30640522
 3.30992044 3.31031036 3.31118091 3.31228819 3.3156399  3.31686508
 3.31783687 3.31932237 3.32238354 3.32321195 3.32384648 3.32442889
 3.32584679 3.32595729 3.32652391 3.32678059 3.3271202  3.32897111
 3.33164002 3.33392568 3.34082027 3.34099011 3.3440845  3.3443969
 3.35325448 3.35460531 3.35501654 3.35664933 3.35729879 3.35871912
 3.35892903 3.35903517 3.36041985 3.36084379 3.36258907 3.36308909
 3.3642541  3.36469653 3.3672031  3.36947425 3.36947651 3.37050144
 3.37172885 3.37571918 3.37630134 3.37794844 3.37892503 3.37987904
 3.38092383 3.38175347 3.38209197 3.38220675 3.3824913  3.38295015
 3.38335549 3.38412262 3.38570274 3.38619985 3.38641303 3.3864278
 3.38702945 3.38831534 3.38919408 3.38968277 3.39074134 3.39146569
 3.39617586 3.3964287  3.39749331 3.39973498 3.40014991 3.40223202
 3.40248807 3.40401628 3.40599935 3.41030221 3.41219795 3.41595875
 3.41800475 3.41942477 3.41989029 3.42177181 3.42212349 3.42676128
 3.42880066 3.4288857  3.43121249 3.43125629 3.43136797 3.43149308
 3.43170295 3.4342468  3.43583783 3.43969414 3.44041883 3.46209623
 3.47048059 3.47399426 3.47997097 3.48131915 3.50120199 3.51106158
 3.52088189 3.53808984 3.53892732 3.57611788 3.57863831 3.58353917
 3.59716101 3.61646699 3.62124632 3.63891587 3.64468943 3.64875158
 3.71121756 3.75883255 3.76073041 3.76125584 3.78106113 3.79154193
 3.79823279 3.80279119 3.8064079  3.81360102 3.81440689 3.82194803
 3.82565435 3.82956024 3.83163987 3.8365018  3.84681394 3.87428205
 3.88922438 3.93478314 3.98181472 4.01870283 4.10844516 4.11322597
 4.21660965 4.34067556 4.37887942 4.7684047  4.76940015 4.77464083
 4.78086556 4.78989241 4.79615525 4.80320306 4.80387887 4.80628763
 4.8196013  4.82075827 4.82669256 4.82781429 4.82887429 4.83377816
 4.83423739 4.8360873  4.83934702 4.85475171 4.85803003 4.87200195
 4.87409477 4.87774342 4.89048519 4.89265858 4.89862809 4.89922107
 4.91167775 4.91397481 4.91424053 4.92487097 4.99492635 5.00544641]

  warnings.warn(

2022-12-16 10:36:27,962:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.89778931 1.91892523 1.95027771 1.98486592 1.99198596 2.0670392
 2.20307775 2.58560255 2.72527104 2.8530951  2.85381801 2.86057126
 2.87221995 2.88560808 2.89080107 2.90070323 2.90555486 2.9069963
 2.90708447 2.9129657  2.91437174 2.91845965 2.92180793 2.92488472
 2.92577833 2.92652283 2.93207407 2.93425112 2.93546807 2.93985945
 2.94158553 2.94210685 2.94264943 2.94823822 2.94868287 2.94876538
 2.94888901 2.95019582 2.95248311 2.9557021  2.95912438 2.95957871
 2.96128849 2.96265704 2.9629429  2.96297893 2.96318493 2.96377692
 2.96434771 2.96488075 2.96494162 2.9650158  2.96526723 2.96564742
 2.96572368 2.96654554 2.96674871 2.96698404 2.96811762 2.96812183
 2.96876272 2.96894583 2.96988388 2.9702103  2.97050994 2.97051952
 2.97134284 2.9739641  2.97452104 2.97668344 2.97900128 2.98075847
 2.98130737 2.98167529 2.98191674 2.98265021 2.98400508 2.98426767
 2.99378451 2.995751   2.99621992 2.99660996 2.99770158 2.99842938
 2.99969805 2.9997443  3.00166186 3.00373343 3.00469172 3.00663142
 3.00678571 3.00721346 3.00959268 3.01013693 3.01044275 3.01404875
 3.01583622 3.01610468 3.01610973 3.01734363 3.01783141 3.01884199
 3.02063153 3.0219002  3.02420291 3.02724718 3.03019221 3.03077625
 3.03224871 3.03336098 3.03769703 3.03784863 3.04310438 3.04502869
 3.04540405 3.0459877  3.0466137  3.04784762 3.04975599 3.05088109
 3.05171477 3.05258041 3.0549658  3.05744649 3.05796219 3.0586888
 3.06182873 3.06217672 3.06231122 3.06245486 3.06312795 3.0638948
 3.06403478 3.06540495 3.06709521 3.06720004 3.06819152 3.06881033
 3.07091683 3.0711569  3.07122462 3.07284364 3.07306213 3.07358082
 3.07363371 3.08064581 3.08262234 3.08290852 3.08473253 3.0855057
 3.08645797 3.08659038 3.08690446 3.08691217 3.08765533 3.08790879
 3.08797046 3.08928228 3.09036209 3.09063321 3.09093461 3.09131413
 3.09225251 3.09277363 3.09294774 3.0929641  3.09324517 3.094509
 3.09590949 3.09641779 3.09700417 3.09711683 3.09741296 3.09813555
 3.09903127 3.0990511  3.0992347  3.09965858 3.09987656 3.10076709
 3.10102596 3.10115565 3.10186512 3.10233521 3.10305672 3.10460563
 3.10721367 3.10733096 3.10741424 3.10750969 3.10773894 3.10804834
 3.10830776 3.10886145 3.10946968 3.1099118  3.11020264 3.11022093
 3.11117016 3.11170763 3.11241193 3.11247169 3.11271699 3.11308793
 3.11350197 3.11386657 3.11386858 3.11507461 3.11728118 3.11820594
 3.11870008 3.11941635 3.11970082 3.12029385 3.12035631 3.12146051
 3.12157564 3.12188945 3.12202232 3.12287281 3.1233514  3.1237408
 3.12474729 3.12508185 3.12690679 3.12774667 3.12779273 3.12898415
 3.12944241 3.12975134 3.13021652 3.13044408 3.13060085 3.1307241
 3.13074492 3.13084438 3.13106415 3.13120711 3.13179835 3.1329112
 3.13295834 3.13376606 3.13488707 3.13493806 3.13501384 3.13519899
 3.13520897 3.13532326 3.13555081 3.13584536 3.13691267 3.13751456
 3.13781894 3.13800774 3.13811348 3.13847577 3.138608   3.13891098
 3.13921649 3.13933075 3.13968436 3.13971908 3.14008889 3.14039108
 3.14072062 3.14091057 3.14118568 3.14120364 3.14195455 3.14217
 3.1421888  3.14222461 3.14239528 3.14241857 3.14247891 3.14366102
 3.14385851 3.14423782 3.14430255 3.1444485  3.14477112 3.14549799
 3.14583696 3.14605933 3.14654254 3.1467365  3.14697517 3.14700107
 3.14726095 3.14744942 3.1482227  3.14835897 3.14855893 3.14880527
 3.14892469 3.14950786 3.14964218 3.14991905 3.15019872 3.1502288
 3.15035529 3.15063675 3.1506739  3.15080144 3.15095805 3.15100059
 3.15101208 3.15116183 3.15133635 3.15138422 3.15148106 3.15173294
 3.15177254 3.15181253 3.15190255 3.15204785 3.15222635 3.1525517
 3.15281157 3.15309272 3.15325196 3.15330333 3.15480692 3.15550288
 3.15559176 3.15564782 3.15570574 3.1560214  3.15605199 3.15634909
 3.15638666 3.15651713 3.15668884 3.15676043 3.15679789 3.15680929
 3.15685805 3.15690635 3.15710061 3.15712233 3.1572822  3.15743724
 3.1574745  3.15807699 3.15817086 3.1581959  3.15899216 3.1591668
 3.15932451 3.15974899 3.15993581 3.16020104 3.16026929 3.1603471
 3.16051879 3.16079212 3.16106128 3.16109172 3.16111595 3.16120483
 3.16132995 3.16167519 3.1620565  3.16231919 3.162859   3.16317509
 3.16346978 3.16383038 3.16385584 3.16433846 3.16449346 3.16456316
 3.16459164 3.16464396 3.16518432 3.16598234 3.16618265 3.16632422
 3.16642407 3.16690693 3.16707346 3.16729672 3.16787926 3.16797256
 3.16857701 3.16879566 3.16897505 3.16901997 3.16913651 3.16927582
 3.16989639 3.1702025  3.17029336 3.17052453 3.17088711 3.17091658
 3.17113782 3.17120564 3.17140314 3.17143563 3.17166633 3.17188402
 3.17226588 3.1723099  3.17249643 3.17273682 3.17275102 3.17286674
 3.17287718 3.17306147 3.17339657 3.17357661 3.17374075 3.1739638
 3.17399757 3.17407455 3.17442319 3.17494361 3.17505694 3.17513266
 3.17515237 3.17527313 3.17562516 3.17570222 3.1764384  3.17671659
 3.17680195 3.17822864 3.17846621 3.17850619 3.17890094 3.1791492
 3.17991767 3.1800028  3.18096612 3.18131181 3.18176775 3.18247246
 3.18261313 3.18264239 3.18302388 3.18315649 3.18332842 3.18369195
 3.18382382 3.18408614 3.18422909 3.18554008 3.18564753 3.186235
 3.18642096 3.18680084 3.18740687 3.18820563 3.18856952 3.18861371
 3.1887392  3.18874066 3.1887628  3.18879667 3.18886594 3.18898088
 3.18934918 3.19019293 3.19019869 3.19041356 3.19136037 3.1914539
 3.19147113 3.19171638 3.1921467  3.19278666 3.1928897  3.19343063
 3.19372537 3.19386293 3.19394753 3.19416372 3.19498169 3.19504053
 3.19544713 3.19615134 3.19630048 3.19630176 3.19635906 3.19654097
 3.19658655 3.19666552 3.19672057 3.19702751 3.19731239 3.19739587
 3.19741151 3.1976398  3.19834547 3.19861934 3.19881044 3.19912305
 3.19927163 3.19958281 3.19969009 3.20070575 3.20127879 3.20133659
 3.20134391 3.20194225 3.20210962 3.20240342 3.20264208 3.20315898
 3.20321664 3.20372577 3.20435453 3.20438331 3.204597   3.20475643
 3.20496862 3.20541459 3.20544672 3.20562784 3.20593387 3.20596734
 3.20597376 3.20633433 3.20696412 3.20708168 3.20713417 3.20714902
 3.20724202 3.20754889 3.20770646 3.20835805 3.20873697 3.20878264
 3.20885352 3.20897312 3.2090488  3.20925131 3.21007368 3.21022657
 3.21042274 3.21052212 3.21123238 3.21142763 3.21194422 3.21217167
 3.21233581 3.21245077 3.21272142 3.21296086 3.21322363 3.21329644
 3.21346914 3.21352602 3.21371335 3.21418687 3.21421074 3.21454417
 3.21506945 3.21548364 3.21572777 3.21593554 3.21637371 3.21654181
 3.21658721 3.21672741 3.21674988 3.21725982 3.21829663 3.21860658
 3.21955714 3.22010758 3.22054504 3.22248057 3.22272276 3.22279289
 3.22287718 3.22306993 3.22325398 3.22347128 3.22389647 3.22395427
 3.22456192 3.22508919 3.22512053 3.22635022 3.22698592 3.22802054
 3.22818688 3.22958378 3.22987753 3.23006994 3.23030442 3.23039126
 3.23176343 3.23257717 3.23352708 3.23368192 3.23396805 3.23421638
 3.23477437 3.23479941 3.23499846 3.23751864 3.2376559  3.23809546
 3.238271   3.23894886 3.24213477 3.24341221 3.24480013 3.24506736
 3.24519316 3.24534174 3.24597029 3.24602671 3.24651588 3.2466483
 3.24774647 3.24789177 3.24869339 3.24873086 3.24879364 3.24884626
 3.24934656 3.24967209 3.25143916 3.25327801 3.25363882 3.25467376
 3.25516136 3.25561876 3.25826024 3.25935298 3.25935441 3.26104469
 3.26205049 3.26211505 3.26650194 3.26990239 3.26999739 3.27009321
 3.27063362 3.27064466 3.2706502  3.27485307 3.27506115 3.2751804
 3.27657555 3.27718107 3.2778924  3.2782828  3.28097566 3.28129873
 3.28132029 3.28171614 3.28201382 3.28220262 3.28351795 3.28414577
 3.28658476 3.28681227 3.28743455 3.28846162 3.28944644 3.28960532
 3.2907148  3.29191092 3.29339456 3.29379851 3.29597637 3.29720611
 3.29808188 3.30031965 3.30220366 3.30554641 3.30594203 3.30683352
 3.30735073 3.30779703 3.30781614 3.30828407 3.31187045 3.31187596
 3.31229329 3.31248593 3.31400293 3.31401962 3.31506484 3.31682564
 3.317108   3.31800299 3.31817199 3.31835518 3.3202204  3.32179083
 3.32183205 3.32225986 3.32320852 3.32357422 3.32633198 3.3265111
 3.32737115 3.32841336 3.33006746 3.33095442 3.33433295 3.33506771
 3.33676668 3.3399717  3.34008148 3.34183925 3.34290239 3.34559139
 3.34631443 3.34644067 3.34652672 3.34863909 3.34939559 3.34965741
 3.350553   3.35062084 3.35078702 3.35165084 3.35177493 3.35320703
 3.35573792 3.355876   3.35600097 3.35791945 3.35901667 3.3593711
 3.3600611  3.36094773 3.36181656 3.36346346 3.36621492 3.36649836
 3.36690293 3.36712517 3.36749274 3.36778216 3.36782165 3.36836943
 3.36976937 3.36983119 3.37068678 3.37165041 3.37229731 3.37389034
 3.37741765 3.37830825 3.37838242 3.38065708 3.3811929  3.38286873
 3.38327537 3.3851947  3.3852372  3.3854951  3.38729417 3.3888908
 3.38953921 3.3905887  3.39152621 3.39677824 3.39955182 3.40055074
 3.40173935 3.40491815 3.40520419 3.40562395 3.40785518 3.40923771
 3.41149053 3.41217811 3.41435782 3.41436183 3.4180603  3.4231471
 3.42511112 3.42932673 3.4310018  3.43949096 3.43964018 3.44270965
 3.45097594 3.45101019 3.46113165 3.46607685 3.47412794 3.47774218
 3.49454236 3.49557251 3.49921514 3.50148608 3.50376274 3.50581063
 3.50714807 3.51917405 3.52582288 3.52735492 3.52795094 3.53883523
 3.63248934 3.64762335 3.76370069 3.78843252 3.79494701 3.80750436
 3.80969975 3.82744728 3.83914908 3.83926764 3.84670777 3.85286511
 3.86015084 3.86249933 3.86792939 3.89852098 3.91980661 3.9278967
 4.34520807 4.40544857 4.46827755 4.54226533 4.70776782 4.75100153
 4.76526914 4.81337985 4.81345216 4.81401156 4.81402184 4.81453379
 4.81543264 4.81930655 4.81934298 4.81976957 4.82485893 4.82638798
 4.82915517 4.83275898 4.83445513 4.84298377 4.84892965 4.85122245
 4.85323066 4.87053369 4.87940925 4.91661679 4.92822554 4.93225239
 4.94794305 4.9506194  4.97656626]

  warnings.warn(

2022-12-16 10:36:29,179:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.91730759 2.48133698 2.85098738 2.85311168 2.85363722 2.85370106
 2.88798691 2.9057947  2.91433556 2.92003991 2.92836558 2.93218619
 2.93406404 2.93831475 2.93960618 2.94166734 2.94328954 2.94891874
 2.94977788 2.95009306 2.95227003 2.95247112 2.95285877 2.95297302
 2.95410316 2.95486043 2.95495924 2.95572014 2.95606319 2.95630197
 2.95650427 2.95861417 2.96136624 2.96165933 2.963575   2.96566636
 2.96567798 2.96766374 2.96940483 2.96951979 2.96959575 2.97026382
 2.97362111 2.97578082 2.97765863 2.98352062 2.98601147 2.98734017
 2.98818234 2.98855866 2.99022294 2.99081681 2.99162139 2.99300358
 2.9965203  2.99673294 2.99731279 2.99995991 3.00107594 3.00151336
 3.00189538 3.00210014 3.00300404 3.00682262 3.00758981 3.00822083
 3.0082611  3.00969971 3.01185492 3.01410394 3.01783226 3.0180351
 3.02204403 3.02290001 3.0241302  3.02522953 3.02547094 3.0256193
 3.03071845 3.03073041 3.03227849 3.03627741 3.03629966 3.03699008
 3.04071497 3.04168069 3.04299359 3.04419487 3.0483098  3.04885026
 3.05360012 3.05380104 3.05554929 3.05627385 3.05704845 3.05827328
 3.06601652 3.06636489 3.0671196  3.06873917 3.07173607 3.07206415
 3.07268048 3.07601627 3.08090429 3.08250191 3.08270094 3.08522645
 3.08712911 3.08930814 3.08964977 3.09063777 3.09200659 3.09205375
 3.09230898 3.0923346  3.09342487 3.09365589 3.09416432 3.09885861
 3.09901641 3.10095834 3.10162331 3.10600181 3.10618824 3.10632194
 3.10700686 3.10742714 3.10791454 3.10855629 3.10914969 3.1094379
 3.11052917 3.1115061  3.11214041 3.1123718  3.11329706 3.11344316
 3.11397783 3.11431474 3.11489778 3.11551703 3.11572303 3.11580203
 3.11625097 3.11649827 3.11726049 3.11848009 3.11922567 3.12038061
 3.12074309 3.12081768 3.12110854 3.12194725 3.12311242 3.12341296
 3.12372117 3.12463572 3.12580418 3.12621086 3.12688755 3.1279274
 3.12836444 3.12846622 3.12946207 3.12952349 3.12977822 3.12980076
 3.13000537 3.13026673 3.13033045 3.13163582 3.13289255 3.1331951
 3.13375618 3.13386179 3.13403793 3.13404222 3.13405435 3.13451003
 3.13531711 3.1354151  3.1354771  3.13555171 3.13556932 3.13557464
 3.13601721 3.13757898 3.13768816 3.13797599 3.1380957  3.13861019
 3.13878206 3.13883172 3.13896392 3.14014828 3.14129797 3.14138743
 3.14140488 3.14152359 3.14180707 3.14181032 3.14227474 3.14243273
 3.14253226 3.14256989 3.14262513 3.14274834 3.14412254 3.14422405
 3.14435804 3.14445856 3.14463567 3.14466962 3.14499115 3.14504821
 3.1455298  3.14613355 3.14664875 3.14672647 3.14705337 3.147208
 3.14727543 3.14747502 3.14777292 3.14809356 3.14814893 3.14821785
 3.14870432 3.14894442 3.14901159 3.14930824 3.14945493 3.14957722
 3.1496239  3.14985228 3.15000366 3.15011681 3.15017049 3.15046362
 3.15049612 3.1511957  3.15129167 3.15161277 3.15181095 3.15243605
 3.15250479 3.15263098 3.15274928 3.15311603 3.15325053 3.15353363
 3.15366902 3.15414583 3.15426581 3.15472035 3.15502984 3.15525863
 3.15563051 3.15563375 3.15574313 3.15592669 3.1559573  3.15600342
 3.1568625  3.15735189 3.15759882 3.15806376 3.1582693  3.15857383
 3.15877874 3.15895481 3.15917549 3.16043809 3.16058388 3.16084324
 3.16102956 3.1616279  3.16180211 3.1620319  3.16226877 3.16231914
 3.16249006 3.16264946 3.16272525 3.16302915 3.16314531 3.16316426
 3.16334171 3.16358022 3.16382063 3.16384066 3.16408    3.16441021
 3.16461703 3.1646282  3.16465263 3.16491137 3.16506947 3.16519448
 3.16571395 3.16574326 3.16582246 3.16584881 3.16618023 3.16714397
 3.16716549 3.16722821 3.16759532 3.16785593 3.16797795 3.168235
 3.16827458 3.16845698 3.16871836 3.16876706 3.16909226 3.16948802
 3.17015513 3.17030882 3.17040762 3.17054966 3.17112991 3.17127836
 3.17147553 3.17170419 3.1722599  3.17304231 3.17332983 3.17367334
 3.17393496 3.17438006 3.17462928 3.17467221 3.1747399  3.17520117
 3.17560851 3.17582742 3.175983   3.17599555 3.17617665 3.17664664
 3.17702123 3.17740977 3.17768595 3.17778957 3.17806307 3.17835624
 3.17859734 3.17867204 3.17887198 3.17901699 3.17904214 3.17907825
 3.17927207 3.1796592  3.18006755 3.18007526 3.18020413 3.18021644
 3.18041843 3.18055659 3.18066122 3.18079676 3.18085804 3.18092068
 3.18117793 3.1812744  3.1814071  3.18142516 3.18159594 3.18177751
 3.18184159 3.18252789 3.18291025 3.18346038 3.18462382 3.18465145
 3.18467103 3.18516336 3.18527116 3.18528384 3.18545287 3.18583229
 3.18613331 3.18630509 3.18679705 3.18763117 3.18774879 3.18808375
 3.18837382 3.1889961  3.18904865 3.18920984 3.18921086 3.18925665
 3.18952834 3.18980131 3.1898562  3.19001073 3.19007026 3.19047202
 3.19056128 3.19065953 3.19066915 3.19072758 3.19089334 3.19109704
 3.19187761 3.19191095 3.19212285 3.19221076 3.19234449 3.19249325
 3.19250274 3.1925704  3.19282379 3.19295118 3.19303254 3.19388565
 3.19398748 3.19403694 3.19407133 3.19412642 3.19451445 3.19452701
 3.19454217 3.19462909 3.19466003 3.19484491 3.1950124  3.19501253
 3.19506288 3.19520574 3.19532047 3.19534954 3.19543035 3.19564474
 3.19573477 3.1957701  3.19609873 3.19610269 3.19615265 3.19625572
 3.19694997 3.19698171 3.19724435 3.19752128 3.19754576 3.19760561
 3.19783143 3.1979889  3.19812014 3.19862512 3.19876719 3.19889306
 3.1995247  3.19959863 3.20018678 3.20029476 3.20039152 3.20051878
 3.20122343 3.20127912 3.20137804 3.20146494 3.20146784 3.20190961
 3.2024901  3.20253062 3.20255333 3.20275524 3.20307863 3.20331359
 3.20350675 3.20361583 3.20376271 3.20378426 3.20398062 3.20399578
 3.20442967 3.20452583 3.2045315  3.20538535 3.20548764 3.2057719
 3.20623708 3.20630551 3.20663566 3.206702   3.20703242 3.20704847
 3.2071248  3.20729446 3.20729536 3.20737248 3.20749753 3.20752672
 3.20787798 3.20795825 3.20802801 3.20821882 3.20835355 3.20907732
 3.20916676 3.20919783 3.20927605 3.20963438 3.20968769 3.21023701
 3.2106886  3.21081882 3.210987   3.21128422 3.21172375 3.21268477
 3.21274447 3.21339975 3.21362449 3.21387825 3.21434989 3.21450031
 3.21513251 3.21553825 3.21565558 3.21590158 3.21600728 3.21612836
 3.21615845 3.21636768 3.21674507 3.21675363 3.21721245 3.21721685
 3.21755037 3.21789616 3.21794713 3.21820496 3.21850133 3.21875102
 3.21897124 3.21921568 3.21955416 3.22004011 3.22015397 3.22019241
 3.22020752 3.22070261 3.22150046 3.22225233 3.22225623 3.22241823
 3.22247499 3.22268365 3.22330388 3.22331893 3.22336573 3.22395736
 3.22423997 3.22479779 3.225039   3.22527978 3.2254375  3.22595017
 3.22685137 3.22754706 3.22819316 3.22865105 3.2297245  3.22987721
 3.23011525 3.23037472 3.2303965  3.23041386 3.23178296 3.23217685
 3.23355982 3.23364566 3.23453221 3.23573406 3.23640683 3.23659072
 3.23659394 3.23665984 3.23760209 3.23783228 3.23820781 3.23880401
 3.23935254 3.23954705 3.23957055 3.2399887  3.24001478 3.24114328
 3.24225909 3.24330844 3.24379211 3.24382469 3.24504601 3.24608456
 3.24672139 3.24676198 3.24696183 3.24701583 3.24729986 3.247974
 3.24829278 3.24952102 3.24964359 3.2516076  3.25172901 3.25189712
 3.25219092 3.25258514 3.25285164 3.25334515 3.25369469 3.25441849
 3.25470251 3.25498896 3.2552524  3.25530224 3.25555952 3.25668432
 3.2567857  3.25725592 3.25758785 3.25806506 3.25829022 3.25871796
 3.25942661 3.2597534  3.26038463 3.26067996 3.26083822 3.26182862
 3.26305309 3.26424788 3.26447316 3.26529099 3.26578749 3.26756592
 3.26832462 3.26935178 3.26944686 3.27095962 3.27101299 3.27116969
 3.27164628 3.2718713  3.27264951 3.27310505 3.27326916 3.2734291
 3.27468421 3.27491707 3.2751584  3.27611427 3.27839331 3.27994494
 3.28158557 3.28159306 3.28211588 3.28317491 3.28453588 3.28662582
 3.28697193 3.28719075 3.28789582 3.28854489 3.28908892 3.28960745
 3.29214665 3.29398125 3.29400841 3.29533778 3.29552037 3.29626513
 3.29924542 3.30334561 3.30397831 3.30411541 3.30573307 3.30580875
 3.30624995 3.30634792 3.30656049 3.30779451 3.30845784 3.3089523
 3.30938198 3.3117305  3.3121011  3.31233886 3.31307586 3.31311645
 3.31588439 3.31956515 3.32058391 3.32144523 3.32437462 3.32619255
 3.32663985 3.32771063 3.32793319 3.32997786 3.33049677 3.33225386
 3.33354352 3.33356194 3.33376203 3.33654387 3.33781175 3.33803085
 3.33875168 3.33942908 3.33962469 3.33981237 3.3412158  3.34193921
 3.34242254 3.3429276  3.34335959 3.34613599 3.34703365 3.34877706
 3.34915535 3.35346619 3.35476509 3.35533912 3.35614689 3.3561682
 3.358657   3.35980521 3.36175335 3.36199314 3.36231709 3.36279242
 3.3628095  3.36462633 3.36487964 3.36540886 3.36584647 3.3687071
 3.36895022 3.37064124 3.37127552 3.37138586 3.37268135 3.37559972
 3.37627181 3.37862716 3.37886794 3.37889258 3.37912125 3.38004354
 3.38114994 3.38115354 3.38122329 3.38282739 3.38382797 3.38424779
 3.38807998 3.38881492 3.3904239  3.39053281 3.39077884 3.39179726
 3.39295558 3.39317155 3.3958393  3.3980632  3.40019528 3.40061555
 3.40206348 3.40322712 3.40323365 3.40354928 3.40373021 3.40710035
 3.40847717 3.41015775 3.41175435 3.41411001 3.41495297 3.4288146
 3.43038731 3.43676528 3.46495656 3.47170232 3.4870671  3.49122635
 3.50808106 3.53088044 3.5639493  3.56411475 3.57474987 3.58940183
 3.5927387  3.59566536 3.59593078 3.6130425  3.62468276 3.64976172
 3.65570132 3.74578578 3.7459236  3.75893109 3.76319494 3.76919798
 3.7748822  3.78227865 3.78938893 3.79484671 3.81766891 4.17775273
 4.21982199 4.24264932 4.32256607 4.3566566  4.38952728 4.69608791
 4.70138728 4.70884512 4.71391374 4.75446355 4.75795475 4.77357279
 4.77498528 4.77669403 4.7845254  4.78623578 4.79362557 4.79732899
 4.79764736 4.79931059 4.8021177  4.80231661 4.80267166 4.80608025
 4.80727961 4.8157197  4.81770946 4.81812892 4.81939171 4.82211786
 4.8231859  4.82683459 4.82721452 4.82786229 4.83382077 4.84483277
 4.89255898 4.92293766 4.9576577  4.997099  ]

  warnings.warn(

2022-12-16 10:36:29,183:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.57374427 1.57512368 1.85726675 1.89359301 1.91757446 1.91775961
 1.93255168 1.95052496 1.95536736 1.9702535  1.97527244 1.98879804
 2.03468913 2.1604539  2.59695367 2.74274711 2.75665157 2.80550486
 2.81230433 2.81361272 2.82653366 2.83880108 2.84675252 2.84831988
 2.86952576 2.87856388 2.8792934  2.88635223 2.90670762 2.91115727
 2.91190066 2.91507362 2.91738759 2.91888366 2.93315352 2.93681722
 2.93687611 2.94045939 2.94288601 2.94777898 2.94795312 2.94827972
 2.94859889 2.94919771 2.95189478 2.95197868 2.95210903 2.95285616
 2.95450881 2.95533377 2.95656239 2.95670494 2.95977785 2.96344235
 2.96420189 2.96580321 2.96935927 2.97009758 2.97221939 2.97337912
 2.9738766  2.97537078 2.97575688 2.9758497  2.97622434 2.97640625
 2.97731749 2.97743657 2.97746628 2.97760828 2.97996114 2.97996563
 2.98038216 2.98046493 2.98116573 2.98139077 2.98146345 2.98216492
 2.98225476 2.98225634 2.98238967 2.98277858 2.98320497 2.98364754
 2.9840135  2.9843282  2.98492547 2.98506181 2.98515629 2.98688799
 2.9878508  2.98895819 2.99047495 2.99206645 2.99357023 2.99396045
 2.99461252 2.99595076 2.99680301 2.99770159 2.99869933 2.99898496
 2.99996029 3.00136059 3.00171635 3.00248666 3.00544008 3.00555388
 3.0056834  3.00581586 3.0062036  3.00649044 3.00692098 3.00766381
 3.01058837 3.01132646 3.01232196 3.01539247 3.01635777 3.01649324
 3.01686303 3.01687408 3.01751924 3.01938327 3.02012306 3.02201892
 3.02355069 3.02364443 3.02643465 3.02678359 3.02881968 3.03010151
 3.03263832 3.03353149 3.03611978 3.03655736 3.04178223 3.04253401
 3.04415837 3.04490372 3.04598778 3.04674502 3.04856625 3.05078391
 3.05091261 3.05809943 3.06010681 3.06100871 3.06318168 3.0640197
 3.06562869 3.06649663 3.06695645 3.06901641 3.07071183 3.07332943
 3.07379493 3.07683689 3.07777098 3.07883917 3.07900817 3.07916851
 3.07942461 3.08041514 3.08146814 3.08161739 3.08254514 3.08261396
 3.08531339 3.08874796 3.08906803 3.09312003 3.09376143 3.0938828
 3.09408505 3.09516462 3.09689594 3.0978006  3.10214337 3.10377396
 3.10391403 3.10440565 3.10471402 3.1047752  3.10479295 3.1054215
 3.10692666 3.10717988 3.10773508 3.10852548 3.11025123 3.11028431
 3.11056626 3.11079421 3.11085941 3.11147768 3.11157426 3.11208743
 3.11259876 3.11331171 3.11333452 3.11334539 3.11371354 3.1139927
 3.11483184 3.11498375 3.11519666 3.11662763 3.11676122 3.11918287
 3.12020723 3.12023766 3.1203738  3.1212759  3.121333   3.12201794
 3.12244887 3.12305788 3.12404989 3.12411356 3.12467698 3.12570525
 3.12633155 3.1267296  3.12810963 3.12831449 3.12836675 3.12889037
 3.12962098 3.13118744 3.13130011 3.13257344 3.13303313 3.1334403
 3.13386663 3.13404691 3.13441466 3.13546865 3.13560814 3.13631608
 3.13714194 3.13728961 3.1372942  3.13738634 3.13750678 3.13785675
 3.13862886 3.13867661 3.13904404 3.13909839 3.13969076 3.13980725
 3.14025688 3.14035562 3.14039985 3.14082353 3.14082848 3.14130636
 3.14162526 3.14173474 3.14200023 3.14208703 3.14260464 3.14280565
 3.14401232 3.14405359 3.14522055 3.14527022 3.14577571 3.14653254
 3.14691901 3.14761828 3.14816504 3.14825201 3.14873949 3.14998702
 3.15011069 3.15062639 3.15063454 3.15074376 3.15080338 3.15113868
 3.15129071 3.1514824  3.15149367 3.15176221 3.15225999 3.15229015
 3.15235489 3.15239461 3.15266796 3.15279673 3.15283116 3.15303197
 3.1531611  3.15328419 3.15340345 3.1534355  3.15354497 3.15354878
 3.15356068 3.1540743  3.15411504 3.15421737 3.15445083 3.1545167
 3.15453304 3.15475948 3.15478346 3.15592157 3.15609244 3.15655085
 3.15677926 3.15720305 3.15732766 3.1573414  3.15768163 3.15790026
 3.15791061 3.15798366 3.15856203 3.15865345 3.15928998 3.15978479
 3.1603684  3.16116516 3.16177187 3.1621501  3.16266374 3.163281
 3.16349583 3.16479478 3.16517284 3.16611306 3.16699204 3.1670228
 3.16707261 3.16875101 3.16933307 3.17050537 3.17079186 3.17132002
 3.17162039 3.17196819 3.17213814 3.17213918 3.17218824 3.17239146
 3.17289164 3.17360107 3.17398398 3.17449414 3.1750025  3.17514325
 3.17517898 3.17519002 3.17595071 3.17599242 3.17626543 3.17638787
 3.1765721  3.17662918 3.17710674 3.1774429  3.1775156  3.17753056
 3.17754159 3.17764099 3.17784186 3.17799512 3.17816547 3.17824512
 3.17862633 3.17869595 3.17870916 3.17888539 3.17907167 3.17913324
 3.17934191 3.17937244 3.17940144 3.1797225  3.17979097 3.18000334
 3.18042581 3.18076515 3.18082068 3.18111998 3.18130685 3.18140493
 3.18153537 3.18200506 3.18227738 3.18236945 3.182377   3.18247534
 3.18262114 3.18278507 3.18291769 3.18337003 3.18349608 3.18351411
 3.18361757 3.1838168  3.18392565 3.18398229 3.18400069 3.18402401
 3.18407098 3.18437998 3.18438432 3.18492464 3.1851095  3.185339
 3.18546447 3.18578243 3.1864501  3.18651126 3.18655311 3.18758248
 3.18765324 3.18773039 3.18826047 3.18851784 3.18924903 3.18926678
 3.18953146 3.18976854 3.19102449 3.19127462 3.19161553 3.1919778
 3.19208474 3.19268461 3.1927431  3.19304087 3.19320663 3.19342018
 3.19350406 3.19375324 3.19385368 3.19432945 3.19438611 3.19442685
 3.19442871 3.19475639 3.19508792 3.19533687 3.19553537 3.19656563
 3.1969807  3.19729289 3.19752902 3.19768644 3.19781066 3.1978936
 3.19847271 3.19918853 3.19920321 3.1994632  3.19952129 3.20002661
 3.20016723 3.20086522 3.20097939 3.20099742 3.20187733 3.20266637
 3.2026771  3.20277672 3.20289135 3.20292208 3.20303424 3.203089
 3.20312157 3.20316093 3.2035418  3.20356982 3.2035785  3.20461435
 3.20474819 3.20503412 3.20517476 3.20540344 3.20546172 3.20556477
 3.20579291 3.20582846 3.20589649 3.20601409 3.20616242 3.20626437
 3.206352   3.20672447 3.20690586 3.20719318 3.20722638 3.20726437
 3.20729233 3.20750622 3.2077004  3.20843699 3.20916651 3.20929145
 3.20930799 3.20960908 3.20985867 3.2104574  3.21097652 3.21110111
 3.21116323 3.21153819 3.2121564  3.21230906 3.21243011 3.21245882
 3.21336153 3.21340873 3.21346779 3.2142418  3.21513926 3.2152582
 3.21575914 3.21634809 3.21656274 3.21662887 3.21667992 3.21676292
 3.21697558 3.21831211 3.21844361 3.2191756  3.21953909 3.22000531
 3.22014886 3.22034352 3.2206599  3.22083819 3.22111726 3.22242187
 3.22243128 3.22267411 3.22282275 3.22300672 3.22311352 3.22392204
 3.2239396  3.2242125  3.22433158 3.22456094 3.22467352 3.22570183
 3.2257359  3.22600522 3.22602075 3.22650456 3.2267201  3.22691646
 3.22718679 3.2273254  3.22771868 3.22779802 3.2282302  3.22829224
 3.22853844 3.22874718 3.22919104 3.22935786 3.22971036 3.23057198
 3.23085734 3.23132898 3.23199437 3.23277718 3.23310306 3.23368939
 3.23433705 3.2352083  3.23624867 3.23676034 3.23733837 3.23802233
 3.23816809 3.23822952 3.23861245 3.24004339 3.2428699  3.24360844
 3.24446669 3.24461246 3.24485885 3.24736579 3.24890016 3.24905634
 3.24960289 3.25037314 3.25042565 3.25060777 3.25095627 3.25120437
 3.25315815 3.25417835 3.25423049 3.25487705 3.25576699 3.25594253
 3.25619603 3.25620152 3.25684905 3.25778454 3.25801153 3.25857441
 3.25949842 3.26377904 3.26384374 3.26452188 3.26499072 3.26532049
 3.26558259 3.26669919 3.26811574 3.26826995 3.26827132 3.26862074
 3.26955017 3.2702727  3.2728985  3.27334767 3.27390176 3.27470893
 3.27483839 3.27495694 3.27730762 3.27813851 3.28002237 3.2802973
 3.28381185 3.28495366 3.28516055 3.28779966 3.28866005 3.28897415
 3.28917034 3.29012768 3.29143329 3.29281972 3.2937056  3.29423782
 3.29432318 3.29479865 3.29575004 3.29783084 3.29901415 3.30186475
 3.30227155 3.30327101 3.30395927 3.30473955 3.30652956 3.3072491
 3.30741401 3.30777173 3.30870411 3.30870822 3.31198672 3.31243168
 3.31431876 3.31579605 3.31633737 3.31652885 3.3168148  3.31837214
 3.31848839 3.31850319 3.31949639 3.32036922 3.32045592 3.32146399
 3.32211171 3.32266198 3.32277062 3.32322834 3.32545102 3.32566986
 3.32864728 3.329192   3.32932884 3.32990141 3.33171923 3.3325738
 3.33372037 3.33446155 3.33480866 3.33494634 3.33589867 3.33661944
 3.33705729 3.33760381 3.33790207 3.33801478 3.3383152  3.33939229
 3.33990504 3.34123546 3.34225611 3.34264326 3.34265753 3.34374372
 3.34413285 3.3445167  3.34585859 3.34702799 3.34758457 3.34888966
 3.35006242 3.35226443 3.35354339 3.35402551 3.35675017 3.35723451
 3.35787159 3.35849365 3.36109031 3.36138572 3.36481127 3.36499203
 3.36892085 3.36999804 3.37021239 3.37049999 3.37067581 3.37068147
 3.37082592 3.37293958 3.37589339 3.37626183 3.37715777 3.37757881
 3.37762785 3.38099305 3.38152189 3.38223915 3.38264406 3.38572105
 3.38769247 3.38787789 3.38959992 3.39045222 3.39063786 3.39239327
 3.39282063 3.3935691  3.39400294 3.39454044 3.39460874 3.39568659
 3.39714438 3.40058669 3.40072067 3.40112249 3.40150994 3.40161671
 3.40540897 3.4061692  3.40699697 3.40916872 3.40948231 3.40949477
 3.41191992 3.41296743 3.41945961 3.42175415 3.425985   3.4341234
 3.44006779 3.44091823 3.44397999 3.44557978 3.44662361 3.44833026
 3.45924108 3.48501446 3.50054881 3.50681865 3.51408263 3.51582976
 3.51638002 3.51900656 3.51960465 3.52135989 3.52410159 3.52484622
 3.52961678 3.53072844 3.54143559 3.5578468  3.56900927 3.57360846
 3.60217205 3.62814653 3.64056631 3.65364342 3.6724451  3.67346695
 3.70089075 3.78677477 3.78772534 3.84215291 3.84434162 3.84735477
 3.86190219 3.86582222 3.87250627 3.90630704 3.93980009 3.96368964
 4.06325057 4.09889521 4.10550323 4.13640841 4.33601698 4.36400108
 4.72608627 4.75214135 4.77814631 4.78060082 4.78244605 4.80391726
 4.80670491 4.81109483 4.81119792 4.81460558 4.8148765  4.81601855
 4.82112721 4.82762157 4.8283723  4.82990362 4.8308859  4.83334829
 4.83395868 4.8383554  4.84031118 4.84157558 4.85148122 4.86420915
 4.86641934 4.89534139 4.9026702  4.91812744 4.93901606 4.95705604
 4.97601174 5.01814094 5.01843776 5.09425777]

  warnings.warn(

2022-12-16 10:36:29,186:INFO:Calculating mean and std
2022-12-16 10:36:29,187:INFO:Creating metrics dataframe
2022-12-16 10:36:29,193:INFO:Uploading results into container
2022-12-16 10:36:29,195:INFO:Uploading model into container now
2022-12-16 10:36:29,195:INFO:master_model_container: 5
2022-12-16 10:36:29,196:INFO:display_container: 2
2022-12-16 10:36:29,196:INFO:Ridge(random_state=5099)
2022-12-16 10:36:29,196:INFO:create_model() successfully completed......................................
2022-12-16 10:36:29,398:WARNING:create_model() for Ridge(random_state=5099) raised an exception or returned all 0.0, trying without fit_kwargs:
2022-12-16 10:36:29,399:WARNING:Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 795, in compare_models
    assert (
AssertionError

2022-12-16 10:36:29,399:INFO:Initializing create_model()
2022-12-16 10:36:29,399:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002281239F8E0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022810EC8B20>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:36:29,399:INFO:Checking exceptions
2022-12-16 10:36:29,403:INFO:Importing libraries
2022-12-16 10:36:29,404:INFO:Copying training dataset
2022-12-16 10:36:29,409:INFO:Defining folds
2022-12-16 10:36:29,409:INFO:Declaring metric variables
2022-12-16 10:36:29,409:INFO:Importing untrained model
2022-12-16 10:36:29,409:INFO:Ridge Regression Imported successfully
2022-12-16 10:36:29,409:INFO:Starting cross validation
2022-12-16 10:36:29,411:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:36:31,684:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.56605908 1.57737565 1.59883032 1.75943017 1.8063374  1.84765592
 1.85005792 1.85082106 1.86331607 1.89127688 1.90932599 2.08211888
 2.41751095 2.69584087 2.8284921  2.8861273  2.89717356 2.90744379
 2.90992812 2.91050154 2.91705013 2.9181032  2.9245597  2.92499431
 2.92745609 2.93094639 2.93342509 2.93488398 2.93742051 2.94172212
 2.94357612 2.94770806 2.95001518 2.95140092 2.95328437 2.95382991
 2.96011779 2.96649014 2.96676042 2.9684109  2.97145046 2.97305251
 2.97562988 2.97578928 2.97840484 2.97989054 2.98158186 2.98264734
 2.98429401 2.98617993 2.98831005 2.9889229  2.98901329 2.99089726
 2.99114584 2.99213394 2.99221493 2.99251673 2.99394042 2.9962546
 2.99630551 2.99658283 2.99701845 2.99826784 2.99923067 2.99973141
 3.00039889 3.00048364 3.00098732 3.00112494 3.00147061 3.00149823
 3.0019802  3.00217877 3.0032408  3.00353107 3.00433942 3.0052922
 3.00585634 3.00745749 3.00846167 3.00950452 3.01056232 3.01212457
 3.01249584 3.01433019 3.01502123 3.01508083 3.0158471  3.02122949
 3.02255933 3.02352898 3.02493886 3.02503316 3.02512255 3.02548825
 3.02626045 3.0264441  3.02668158 3.02792915 3.02834211 3.03023879
 3.0304109  3.03095862 3.03273002 3.03412939 3.0341471  3.03570638
 3.03693597 3.03777752 3.03836166 3.03857088 3.03916989 3.03919223
 3.03926452 3.04085505 3.0414744  3.04200389 3.04236632 3.04492465
 3.04747343 3.04798198 3.04925559 3.04943072 3.04949813 3.04986586
 3.05005504 3.05046077 3.05116642 3.05249538 3.05282147 3.05323116
 3.05452704 3.05682982 3.05758118 3.05827132 3.0603653  3.06095983
 3.06184134 3.06251223 3.06261178 3.06379236 3.06408039 3.06607795
 3.06728895 3.06838209 3.06969718 3.07238999 3.07362853 3.07652208
 3.0767812  3.07731932 3.07841048 3.08094942 3.08113189 3.08116435
 3.08383158 3.08388753 3.08472632 3.08539748 3.08903699 3.08927715
 3.08979666 3.09072015 3.09174614 3.09211512 3.0926071  3.0937058
 3.09379395 3.09446811 3.09549363 3.09706568 3.09772528 3.09795181
 3.09814026 3.09891332 3.09907341 3.10089959 3.10112867 3.10237449
 3.10290922 3.1036292  3.10391845 3.10418379 3.10479179 3.10490268
 3.10498499 3.10549855 3.10603143 3.1061575  3.10696143 3.10890457
 3.10896916 3.10927182 3.10931903 3.10940254 3.10954788 3.11055465
 3.11117655 3.11148945 3.1118104  3.11203978 3.11216439 3.11268802
 3.11286763 3.11307249 3.11450515 3.11467767 3.11490048 3.11498423
 3.1153216  3.11600638 3.11632852 3.11635615 3.11791556 3.11874391
 3.11947005 3.12275573 3.122787   3.12312922 3.12451259 3.1245496
 3.12551295 3.12570329 3.12618855 3.12755929 3.12760223 3.12776563
 3.12807066 3.1290332  3.12985504 3.13051281 3.13076748 3.13129368
 3.13165627 3.1316856  3.13182453 3.13186243 3.13224291 3.13281703
 3.1331982  3.13325752 3.13352504 3.13524728 3.13594012 3.13656868
 3.1375272  3.13763645 3.13922675 3.13987155 3.14021539 3.14100298
 3.14127078 3.14178819 3.14234813 3.14273531 3.14346394 3.14392082
 3.14449207 3.1445792  3.14482779 3.14485062 3.14486848 3.14526596
 3.14607818 3.14616808 3.14652583 3.14678518 3.1469152  3.14731024
 3.14791425 3.14877333 3.14899068 3.14949172 3.15104939 3.1511197
 3.15142636 3.15143913 3.1517081  3.15187867 3.15194957 3.15254088
 3.15308394 3.15327165 3.15333672 3.15380136 3.1544974  3.15469511
 3.1547983  3.15488786 3.15596678 3.15663795 3.15678721 3.15707815
 3.15768632 3.15770598 3.15852731 3.15902766 3.15934174 3.15967866
 3.15996968 3.16008903 3.16022447 3.16044106 3.16065629 3.16113741
 3.16176357 3.16202809 3.16208938 3.16213634 3.1623819  3.16256143
 3.16354449 3.16394406 3.16397271 3.16397997 3.16406728 3.1641042
 3.16460599 3.16513543 3.165154   3.16533934 3.16625468 3.16652826
 3.1671519  3.16726859 3.16738071 3.16739736 3.16795653 3.16800249
 3.16805908 3.16816142 3.16820913 3.16823484 3.16883288 3.16891138
 3.1690216  3.16961368 3.16967365 3.16971795 3.16983081 3.16997357
 3.17003091 3.17006997 3.17031474 3.17039353 3.17080882 3.17085656
 3.17138641 3.17162618 3.17178612 3.17194493 3.17199989 3.17206438
 3.17208247 3.17260434 3.17266585 3.17275528 3.17338613 3.17374619
 3.17400128 3.17440153 3.17473076 3.17554879 3.17570539 3.17618847
 3.17620288 3.17636847 3.17678428 3.1771977  3.17727626 3.17729473
 3.17746899 3.17765362 3.17767296 3.17771414 3.17850976 3.1785542
 3.1793519  3.17936572 3.17951543 3.17955407 3.17972166 3.17996443
 3.18002306 3.1802294  3.1805539  3.18062159 3.18080828 3.18100159
 3.18135466 3.18169817 3.18225349 3.18319797 3.1832535  3.18355645
 3.18371286 3.18417133 3.18527842 3.18529656 3.18559235 3.18566917
 3.18569776 3.18578787 3.18586814 3.18624722 3.18676556 3.18733849
 3.18758713 3.1883932  3.18839943 3.18856937 3.18892661 3.1892574
 3.18957778 3.18972235 3.18975435 3.1904748  3.19062491 3.19066658
 3.19128411 3.19140594 3.19248077 3.19261305 3.19284226 3.19307444
 3.19370612 3.19496778 3.19515617 3.19525951 3.19583261 3.1960002
 3.19616302 3.19727384 3.19830288 3.19843568 3.1990865  3.1993474
 3.19955672 3.19985092 3.20017715 3.20046919 3.20048763 3.20051966
 3.20053618 3.20065858 3.20093286 3.20093385 3.20148284 3.20159551
 3.20181731 3.20205762 3.20274684 3.20296888 3.20301143 3.20304513
 3.20310743 3.20434808 3.20464712 3.20465555 3.20467841 3.20494806
 3.20501621 3.20550082 3.20551603 3.20559052 3.20586727 3.20593432
 3.20606504 3.20617173 3.20661002 3.20700205 3.20721269 3.20785845
 3.20800107 3.20856949 3.20910138 3.20918259 3.20920221 3.20929281
 3.20943727 3.21023201 3.21037631 3.21066641 3.21072826 3.2108298
 3.21083513 3.2110497  3.21208517 3.21210628 3.21225315 3.21271963
 3.21314618 3.21344842 3.21347344 3.21350291 3.21358943 3.21557515
 3.21562335 3.21572589 3.21603674 3.2160495  3.21618282 3.21798505
 3.21798707 3.21803744 3.2183731  3.21838512 3.2184086  3.21976465
 3.21982574 3.21996904 3.22082391 3.22082391 3.22093781 3.22216005
 3.22232654 3.22234215 3.22249197 3.22275119 3.22312379 3.22325242
 3.22336093 3.22342236 3.22355286 3.22363934 3.22384678 3.22414064
 3.22457408 3.22481343 3.22493516 3.22503388 3.22504588 3.22562874
 3.22604965 3.22618199 3.22633265 3.22715647 3.22738692 3.22774415
 3.22787678 3.22792356 3.22876211 3.22897395 3.22929448 3.22935114
 3.22975664 3.23031067 3.23035815 3.23079485 3.23119781 3.23135204
 3.23140126 3.23161254 3.23181071 3.23184368 3.2319188  3.23208194
 3.23222329 3.23237673 3.23324896 3.23340361 3.23349409 3.23350593
 3.23411227 3.23424884 3.23486692 3.23505942 3.23553776 3.23638075
 3.23701674 3.23712308 3.2374294  3.23757744 3.23807369 3.23810542
 3.23823668 3.23825655 3.23876041 3.23910115 3.23938475 3.2401055
 3.24016202 3.24019399 3.24068802 3.24083152 3.24105764 3.24106121
 3.24192555 3.24269529 3.24360377 3.24361947 3.24376902 3.24466826
 3.24468125 3.24491842 3.24612779 3.24620984 3.24653045 3.24657096
 3.24682835 3.24690027 3.24694607 3.24736573 3.24747267 3.24769213
 3.24797772 3.2487641  3.24997732 3.25022128 3.25112019 3.25120192
 3.25175305 3.25230371 3.25235749 3.25262501 3.25296788 3.25314541
 3.25332252 3.25399848 3.25425701 3.25713806 3.25727907 3.25790071
 3.25936081 3.25999132 3.26083851 3.26108661 3.26179282 3.26212649
 3.26233516 3.26277593 3.26283989 3.26421656 3.26422801 3.26451371
 3.26550943 3.26557459 3.26604326 3.26679851 3.26818041 3.26826001
 3.27102247 3.27136334 3.27211269 3.2721949  3.27334774 3.27378406
 3.27401804 3.27408105 3.274625   3.27546735 3.27563141 3.27617507
 3.27646547 3.27689454 3.27808273 3.27844815 3.2792899  3.27972902
 3.27990518 3.28028191 3.28031319 3.2804781  3.28094795 3.28148092
 3.28670262 3.28697296 3.28742019 3.28803371 3.28954518 3.29041724
 3.29060025 3.29100923 3.29102871 3.29174221 3.29371233 3.29570566
 3.29636346 3.29680409 3.29688723 3.29802992 3.29842604 3.29962479
 3.30341326 3.30555904 3.30606433 3.30688417 3.3076128  3.30790715
 3.30868495 3.31280189 3.31380625 3.31447571 3.3145603  3.31506468
 3.31522865 3.31677211 3.31761319 3.31903948 3.320448   3.32278086
 3.32298665 3.3261988  3.32642843 3.32683476 3.32697183 3.3331046
 3.33330879 3.33418524 3.3350675  3.33592648 3.3393752  3.33963355
 3.34062372 3.34184447 3.34268404 3.34276591 3.34500651 3.34580759
 3.34604276 3.34793437 3.34827704 3.34846901 3.34847322 3.34917583
 3.34942035 3.34979528 3.34996764 3.35002867 3.35076126 3.35125552
 3.35313913 3.35333007 3.3535855  3.35362232 3.35487833 3.35502014
 3.35837409 3.35924906 3.35954877 3.36007373 3.36202251 3.36260042
 3.36364555 3.36402584 3.36500592 3.36617719 3.36686511 3.36773735
 3.36928247 3.37044993 3.37094564 3.37160171 3.37197695 3.37347687
 3.37521315 3.37594114 3.37843607 3.37866549 3.3796871  3.38001101
 3.38044069 3.38381512 3.38430631 3.38568011 3.38630121 3.38674699
 3.38675428 3.38942413 3.38945986 3.39185641 3.3938263  3.39595038
 3.39616782 3.39747098 3.39865518 3.39870142 3.40016779 3.40155667
 3.40167243 3.40351137 3.41117141 3.41208011 3.41299366 3.41395556
 3.4166188  3.41840924 3.41976457 3.42112587 3.42522521 3.42565685
 3.42650393 3.42900648 3.43645312 3.45087728 3.45419384 3.45639271
 3.45860748 3.46648951 3.47146207 3.47752401 3.481481   3.50112942
 3.50275528 3.53249098 3.53861852 3.57036461 3.57392571 3.64240128
 3.64967921 3.72522628 3.77760254 3.78530809 3.78779546 3.79631138
 3.80443716 3.81858042 3.84327649 3.85809714 3.9207915  3.95756822
 4.16089864 4.17298151 4.17714505 4.5285242  4.61142691 4.77329157
 4.78863703 4.80298288 4.80382171 4.80421265 4.81047667 4.82171761
 4.82860923 4.8354694  4.8364791  4.84885305 4.84990138 4.85340349
 4.85443827 4.85497793 4.85531144 4.85752474 4.85965502 4.8638313
 4.87481214 4.87757297 4.88217918 4.89272965 4.92798206 4.93196625
 4.94741297 4.9487199  4.95762671 4.98184733 4.98212751 5.11426524]

  warnings.warn(

2022-12-16 10:36:31,812:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.68808594 1.86916625 1.9220191  1.93792895 1.94600065 1.97140397
 2.15499595 2.17301879 2.82413941 2.83015103 2.8462422  2.8629496
 2.91365589 2.91429042 2.91644713 2.92178867 2.92293848 2.92312732
 2.95100367 2.95642209 2.95912424 2.96118898 2.96244148 2.96295403
 2.97277189 2.97429214 2.97484283 2.97698869 2.97950917 2.9818062
 2.98197817 2.98269914 2.9830093  2.9879066  2.98841085 2.99012439
 2.99200082 2.99480941 2.99596865 2.99631659 2.99673572 2.99863148
 2.99920626 3.00064916 3.00271869 3.00282667 3.00363187 3.00553735
 3.00829818 3.00903998 3.0098128  3.0120565  3.0145687  3.01518986
 3.01548443 3.0172693  3.01738982 3.01745032 3.01827245 3.01840113
 3.01952727 3.01957778 3.01975072 3.01982321 3.02021082 3.02072457
 3.02138962 3.0217945  3.02211126 3.02289044 3.02418931 3.02629608
 3.02640333 3.02860673 3.0293411  3.02942816 3.02951513 3.0308759
 3.03129522 3.03258159 3.03473237 3.03754623 3.03828726 3.03869091
 3.03883281 3.03891225 3.03981875 3.03998429 3.04050938 3.04098858
 3.04182055 3.04196614 3.04213321 3.04219083 3.04240928 3.04321197
 3.04328175 3.04434413 3.0470241  3.04958791 3.04980556 3.05155608
 3.05264915 3.05348968 3.05350081 3.05357245 3.05410225 3.05578492
 3.05806766 3.05824626 3.05834197 3.05980153 3.05987485 3.06163068
 3.06163661 3.06210773 3.0628213  3.06288613 3.06341494 3.06356614
 3.06361254 3.06390878 3.06617727 3.06796637 3.06827881 3.06884148
 3.06913092 3.06917214 3.06927423 3.06947348 3.06960823 3.0709443
 3.07163443 3.07416343 3.0754534  3.07584578 3.0760512  3.07666444
 3.07671599 3.07769929 3.07840096 3.07846681 3.07897161 3.07961988
 3.07963996 3.07984803 3.08076198 3.08164773 3.08319222 3.08451168
 3.0856666  3.08568761 3.09069128 3.09091469 3.09460969 3.09531089
 3.09643757 3.09784707 3.0978841  3.09815717 3.09959922 3.0999139
 3.10086354 3.10104671 3.10151046 3.10327711 3.10365622 3.10560807
 3.10646239 3.1074129  3.1092626  3.11047275 3.11107826 3.11143591
 3.11182505 3.11458528 3.11580838 3.11622117 3.11649104 3.11653656
 3.11749503 3.11804863 3.11839351 3.11851801 3.11976054 3.12018229
 3.12101212 3.121332   3.12192343 3.12236032 3.12300518 3.1252082
 3.12528955 3.12592884 3.12618866 3.12676686 3.12692379 3.12714674
 3.12780152 3.12802674 3.1282353  3.12869205 3.12935687 3.12974962
 3.13128973 3.13188261 3.13244712 3.13245594 3.13286995 3.13387379
 3.13402772 3.13443689 3.13473614 3.13489661 3.13497541 3.13517382
 3.13588785 3.13592653 3.13703754 3.13810528 3.13837282 3.13859638
 3.13860546 3.1386088  3.13875133 3.13936384 3.13938968 3.13960801
 3.14029101 3.1406029  3.14138784 3.14154034 3.14159208 3.14194371
 3.14307246 3.14323775 3.14338428 3.14344539 3.14422417 3.14426015
 3.14432877 3.14559138 3.14705796 3.14720385 3.14735394 3.14747818
 3.14768736 3.147742   3.14834122 3.1487321  3.14880725 3.14900825
 3.1490489  3.14908546 3.14946276 3.1499683  3.15032404 3.1516451
 3.15181701 3.15183874 3.15189019 3.152122   3.15217015 3.1523551
 3.15235651 3.15245978 3.15274216 3.15285978 3.15353325 3.15390759
 3.15396781 3.15428555 3.15536764 3.15549803 3.15575467 3.15575827
 3.1564222  3.15645687 3.15655049 3.15682753 3.15691909 3.15708771
 3.15709572 3.15803863 3.15847009 3.15941532 3.15952449 3.15954439
 3.15963057 3.15984791 3.15990567 3.16021481 3.16031921 3.16060286
 3.16067442 3.16082281 3.16142198 3.16176068 3.1618921  3.16226772
 3.16238757 3.16268173 3.16283712 3.1629195  3.16343418 3.16360556
 3.16371966 3.16402244 3.16518446 3.16522986 3.1655712  3.16594724
 3.16616274 3.16637096 3.16661402 3.16687023 3.16715153 3.16724746
 3.16726115 3.16768492 3.16770809 3.16780206 3.1678497  3.1681991
 3.16839589 3.16849569 3.1686772  3.16880682 3.16902202 3.1695655
 3.16990782 3.16991081 3.17030574 3.17042603 3.17064617 3.17095958
 3.17099396 3.17100094 3.17162837 3.17164874 3.17218144 3.17231109
 3.17233343 3.17247347 3.17271827 3.17274589 3.17297897 3.17329741
 3.17338877 3.17373366 3.17395969 3.17397905 3.17401065 3.17429232
 3.17515105 3.1752475  3.17579523 3.17581883 3.17602278 3.17617946
 3.17621482 3.17680291 3.17684205 3.17711571 3.17726079 3.17733353
 3.17735891 3.17849574 3.17957111 3.17972752 3.17979124 3.17981421
 3.17981438 3.17983158 3.18002142 3.18002695 3.18004542 3.18117363
 3.18133747 3.18139526 3.18174252 3.18184007 3.18187428 3.1821765
 3.18273405 3.1827643  3.18319429 3.18356333 3.1837503  3.18430912
 3.18473995 3.18508708 3.18552873 3.18584488 3.18592711 3.18597836
 3.18606527 3.18618706 3.18656331 3.18662641 3.18672296 3.18673653
 3.18691576 3.1869655  3.18711497 3.18730312 3.18742187 3.18751607
 3.18757236 3.18796608 3.18804369 3.18820442 3.18838638 3.18866768
 3.18888328 3.18894304 3.18907567 3.18917697 3.18928635 3.1894265
 3.18956483 3.18998505 3.19011079 3.19025189 3.19052252 3.19083509
 3.1908633  3.19127145 3.1916451  3.19166641 3.19207996 3.192517
 3.19291548 3.19292165 3.19297089 3.19316898 3.19330414 3.19392607
 3.19466429 3.19479918 3.19512363 3.19619166 3.19640891 3.19654095
 3.19656122 3.19693482 3.1969972  3.19729936 3.19731434 3.19750861
 3.19767529 3.1977146  3.19780927 3.19809623 3.19843913 3.19867048
 3.19869523 3.19876221 3.19878711 3.19884692 3.19908268 3.1993124
 3.19943133 3.19949636 3.1997167  3.20003484 3.20005226 3.20008119
 3.20012657 3.20023401 3.20098272 3.20100752 3.2010464  3.20118092
 3.20126777 3.20143592 3.20150237 3.20157303 3.20219242 3.20223333
 3.20260742 3.20266326 3.20273004 3.20298997 3.20335663 3.20348069
 3.2039089  3.20393765 3.20398431 3.2041797  3.2043007  3.20489002
 3.20516133 3.2057612  3.20620792 3.20672225 3.20676893 3.20688002
 3.2075366  3.20778133 3.20802986 3.20819082 3.20891118 3.20930604
 3.20938432 3.20941945 3.20946698 3.20971212 3.21075879 3.2110556
 3.21110468 3.21127362 3.21155503 3.21164543 3.21207277 3.212123
 3.21217108 3.21243991 3.21246666 3.21295549 3.21336465 3.21399798
 3.21429481 3.21436472 3.2144844  3.21474747 3.21494267 3.21499604
 3.21544032 3.21576244 3.21583622 3.21585229 3.21590566 3.21624558
 3.21633448 3.21646548 3.21657312 3.21665449 3.21665842 3.21680018
 3.21706772 3.21727665 3.21742727 3.21889086 3.21911014 3.21970049
 3.21976821 3.21991844 3.21994207 3.22000091 3.22005425 3.2201854
 3.22026812 3.22036025 3.22061434 3.22102947 3.22162755 3.22239289
 3.22290085 3.2231841  3.2235912  3.22362117 3.22400399 3.22413282
 3.22473043 3.22572305 3.22709355 3.22785229 3.22806414 3.22879745
 3.231439   3.23163341 3.23192566 3.23229746 3.2324068  3.2326405
 3.23264354 3.23284545 3.23297434 3.23336603 3.23340112 3.23410537
 3.23482087 3.2351571  3.23523918 3.23628677 3.2367673  3.23714997
 3.23720813 3.23805515 3.23829804 3.23850608 3.24036644 3.24042503
 3.24071655 3.24084571 3.24319245 3.24331002 3.24349863 3.24378683
 3.24564867 3.24706875 3.24747264 3.24780219 3.24822463 3.24854047
 3.24997847 3.25033021 3.25085281 3.25164887 3.25170758 3.25237044
 3.25351707 3.25425073 3.25686851 3.2569936  3.2584809  3.25850064
 3.25852935 3.25974098 3.26005189 3.26203113 3.2625562  3.26377627
 3.26378493 3.26390194 3.26403456 3.26626606 3.26644749 3.26769919
 3.26926551 3.26993205 3.27017823 3.27048381 3.27207648 3.27382917
 3.27468897 3.27660803 3.27916452 3.27970774 3.2800642  3.28037549
 3.28098285 3.28201879 3.28681321 3.28871989 3.29091023 3.29218634
 3.29383909 3.29419352 3.29492869 3.29860933 3.29938558 3.3002613
 3.30080073 3.30252124 3.30273683 3.30499665 3.3076453  3.30787124
 3.3104947  3.31168795 3.31302229 3.31365978 3.31439996 3.31855258
 3.31857098 3.31930103 3.32164212 3.32184266 3.32238505 3.32241932
 3.32309532 3.32347323 3.32395271 3.32492346 3.32701594 3.32857163
 3.32989042 3.33126228 3.33133761 3.33198133 3.33297084 3.33317058
 3.3348328  3.33570555 3.33584909 3.33748317 3.33768607 3.33771773
 3.33819128 3.33863452 3.33891277 3.33992464 3.34001904 3.34011853
 3.34068666 3.34322261 3.34418447 3.3445701  3.34475433 3.34514746
 3.34639291 3.34720927 3.34727014 3.34997954 3.35113712 3.35196135
 3.35624069 3.35738781 3.35997354 3.36012644 3.36040529 3.36095212
 3.36126999 3.36324174 3.36408767 3.36493935 3.36518808 3.36784217
 3.36819692 3.36828938 3.37093642 3.37172255 3.37280987 3.37334881
 3.37453349 3.37484437 3.37503728 3.37506945 3.37560274 3.37701713
 3.37928394 3.37942945 3.37979606 3.37997319 3.38013289 3.38054138
 3.38200657 3.38267249 3.38335732 3.38495197 3.38847803 3.38921307
 3.39007726 3.39010176 3.39187074 3.39531137 3.39649454 3.39769795
 3.40125731 3.4024823  3.40256417 3.40468759 3.40501925 3.40521241
 3.40524322 3.40597618 3.40687986 3.40726171 3.40969037 3.41006148
 3.41155357 3.41747114 3.42127576 3.42128412 3.42207936 3.42258033
 3.42477347 3.43112164 3.44933713 3.45109114 3.45140917 3.45397212
 3.4614734  3.48403365 3.48805963 3.4895644  3.50721481 3.51766282
 3.54215376 3.55833463 3.56026785 3.60954357 3.62448267 3.64537437
 3.66292079 3.67121977 3.67674241 3.68804786 3.70091183 3.70408405
 3.71208226 3.73859734 3.75169399 3.77102185 3.79000996 3.79196673
 3.79792633 3.80389251 3.8058431  3.81638887 3.8186024  3.82916216
 3.83390314 3.84061309 3.84474397 3.85260458 3.85755167 3.8659055
 3.88968185 3.93769584 4.12994757 4.1403437  4.15700628 4.18392196
 4.32886173 4.52415219 4.62827597 4.70192606 4.7336355  4.75704531
 4.7721464  4.77378033 4.78133378 4.78258348 4.7848125  4.78941466
 4.79230952 4.79325948 4.79880363 4.80936048 4.81279686 4.81370583
 4.81464225 4.81531336 4.82310266 4.82441672 4.83243766 4.83484434
 4.83638426 4.83892394 4.84997254 4.85720332 4.85835769 4.85920071
 4.86154994 4.8664405  4.86822092 4.87380285 4.90970739 4.91806118
 4.91841685 4.93209775 4.93315423 5.03818009 5.20294305]

  warnings.warn(

2022-12-16 10:36:31,900:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.76226365 1.92588159 1.94390458 1.95009569 1.96349732 2.00983397
 2.0219521  2.03327507 2.05390017 2.08478706 2.20259741 2.79750467
 2.80515001 2.80747118 2.8192948  2.82824551 2.83496841 2.84779728
 2.86199491 2.87419848 2.88580941 2.93407502 2.93592695 2.94790705
 2.95128751 2.95372943 2.96066575 2.96436228 2.96636577 2.96716133
 2.97145476 2.97290075 2.97636651 2.97807212 2.97978342 2.98689604
 2.98894737 2.99005781 2.99113443 2.99188558 2.99432096 2.99463744
 2.99559917 2.99622445 2.99718445 2.99719016 2.99728607 2.99780015
 2.99836005 3.0013642  3.00159655 3.00519721 3.00566669 3.0063291
 3.00740553 3.0075877  3.00915215 3.01080727 3.01164567 3.01209584
 3.01220184 3.0130314  3.01640927 3.01852444 3.0196243  3.02150918
 3.02246346 3.0229232  3.02411913 3.02590007 3.02797951 3.02889866
 3.02893504 3.02919113 3.03072473 3.03262243 3.03372184 3.03399922
 3.03437997 3.03464875 3.03496467 3.03576687 3.03707095 3.03741386
 3.0397609  3.04074606 3.04212095 3.04297831 3.04298577 3.04364726
 3.04528366 3.04650271 3.04750004 3.04761482 3.05093433 3.05348485
 3.05519465 3.05762251 3.05867431 3.05905165 3.05925939 3.05971061
 3.0626567  3.06351545 3.06515782 3.06642657 3.06712801 3.07142045
 3.07583733 3.07643323 3.07859178 3.07919836 3.07952286 3.0810509
 3.08273344 3.08275962 3.08299667 3.0833254  3.08705336 3.08924398
 3.08985391 3.09084841 3.09376013 3.09464406 3.09510133 3.0981907
 3.10028769 3.10126939 3.1016832  3.10175668 3.10345575 3.10411435
 3.10426413 3.10438269 3.10486146 3.10516694 3.10563151 3.10671892
 3.10692345 3.10813505 3.10892758 3.10895943 3.10960301 3.11045078
 3.11067355 3.11101751 3.11141904 3.11232446 3.11272227 3.11348793
 3.11614378 3.11624367 3.11640085 3.11677482 3.11714065 3.11716874
 3.11753565 3.11875001 3.1198141  3.1205631  3.12144751 3.12149167
 3.12209156 3.12231593 3.12280861 3.12288754 3.12346634 3.12348719
 3.1240565  3.12438927 3.12468279 3.12471362 3.12536104 3.1261589
 3.12651806 3.12716871 3.12780021 3.12841942 3.12893622 3.12930809
 3.12936111 3.12937903 3.12938653 3.12984505 3.13023199 3.13053467
 3.13124411 3.13139289 3.13196274 3.13259017 3.13328415 3.13373692
 3.13376501 3.13409403 3.13418982 3.13436447 3.13470762 3.13504217
 3.13567998 3.13576067 3.13585934 3.13609227 3.13658706 3.13694716
 3.13748268 3.13769838 3.13813171 3.13823907 3.13845557 3.13851341
 3.13872941 3.13924367 3.13933418 3.13949558 3.13951635 3.13955691
 3.14066047 3.1409117  3.14135901 3.14194647 3.1422717  3.14242471
 3.14253535 3.14307301 3.14333427 3.14383291 3.14394612 3.14412774
 3.14418981 3.14445065 3.14449468 3.14491262 3.14500786 3.14565534
 3.14573481 3.14573929 3.14582296 3.14586963 3.14587976 3.14672013
 3.14706679 3.14731857 3.14732234 3.1476467  3.14786857 3.14791375
 3.14800717 3.14832311 3.14835288 3.14836497 3.14888922 3.14944166
 3.15032654 3.15109992 3.15123455 3.15174277 3.15175187 3.15224112
 3.15241373 3.15303427 3.15311245 3.15320546 3.15324899 3.15366254
 3.15394433 3.1540657  3.15414587 3.15422224 3.15458109 3.15483799
 3.15487937 3.15562022 3.15563112 3.15580048 3.15596172 3.15612543
 3.15681689 3.15686622 3.15777952 3.15826492 3.15889792 3.15893047
 3.15905211 3.15911455 3.15966866 3.15969335 3.16020042 3.16026629
 3.16041513 3.16100757 3.16144982 3.16202315 3.16202598 3.162183
 3.16242538 3.16254426 3.16261681 3.16271183 3.16297343 3.16301749
 3.16302569 3.16344258 3.16358099 3.16395104 3.16458763 3.16483502
 3.16505795 3.16513792 3.16515372 3.16528456 3.16588768 3.16642221
 3.16650725 3.16662522 3.16709564 3.16733047 3.16744811 3.16760291
 3.16768025 3.16769937 3.16771229 3.16800741 3.16823004 3.16891894
 3.16902216 3.16914792 3.16923548 3.1696612  3.17014043 3.17024356
 3.17053344 3.17132265 3.17165104 3.17182718 3.17186002 3.17207457
 3.17276233 3.17314856 3.17340516 3.17351554 3.17370508 3.17468616
 3.17484549 3.1749264  3.17564324 3.17575335 3.17628136 3.17649085
 3.17654417 3.17685989 3.17715216 3.17715275 3.17765793 3.17779314
 3.17812106 3.17884974 3.17928427 3.17936744 3.17952332 3.17962898
 3.17975236 3.1805384  3.18083138 3.18093352 3.1811774  3.18127831
 3.18145305 3.18203572 3.18228375 3.18247375 3.18269109 3.18276274
 3.18285466 3.18304194 3.18326761 3.1832766  3.18357008 3.18413126
 3.18453143 3.18505768 3.18507135 3.18540116 3.18586485 3.18607477
 3.18618587 3.18633042 3.18633054 3.1864718  3.18674726 3.18682091
 3.18791916 3.18800936 3.18842896 3.1886767  3.18889059 3.18897188
 3.18912883 3.18943293 3.18965173 3.18997276 3.19039217 3.19070612
 3.19108832 3.19143168 3.19150203 3.19164157 3.19181526 3.19203495
 3.19274283 3.19301135 3.19334456 3.19345405 3.19364977 3.19364988
 3.19399888 3.19536078 3.19577122 3.19599896 3.19659288 3.19707177
 3.19721196 3.19811894 3.19853564 3.19902429 3.19909605 3.19922065
 3.19933085 3.19973063 3.1998296  3.20052567 3.2011257  3.20114713
 3.20117497 3.20135057 3.2018494  3.20191446 3.20280997 3.20296434
 3.20299159 3.20330723 3.20405313 3.20449935 3.20501327 3.2050769
 3.20521605 3.20538154 3.20544813 3.20548346 3.2056984  3.20620227
 3.20621043 3.2065604  3.20664071 3.20669427 3.20705988 3.20715789
 3.20743797 3.20788687 3.20825967 3.20844752 3.20877841 3.20943108
 3.20962066 3.20988613 3.21044773 3.21054073 3.21058875 3.2108169
 3.21101295 3.2114482  3.21166682 3.21213279 3.21262611 3.21382325
 3.21394813 3.21422777 3.21435706 3.21445762 3.2144769  3.21461595
 3.21477843 3.21488864 3.21503676 3.21534107 3.21549397 3.21595465
 3.21600263 3.2161258  3.21620495 3.21651908 3.21685403 3.217462
 3.21822376 3.21843185 3.2184964  3.21911981 3.21977658 3.22048624
 3.22086486 3.22113894 3.22146962 3.22152125 3.2216356  3.22239853
 3.22287068 3.22423651 3.22426143 3.2246178  3.22558862 3.22567437
 3.22571088 3.22583548 3.22643259 3.22709561 3.22804458 3.2285058
 3.22895221 3.22946539 3.22985305 3.23007016 3.23035547 3.23049723
 3.23094366 3.23096088 3.23108023 3.23109381 3.23138636 3.23161302
 3.2332458  3.23459322 3.23502322 3.23528863 3.23533569 3.23564358
 3.23570473 3.23573755 3.23596597 3.23682439 3.23691439 3.23699692
 3.23703102 3.23826189 3.23831922 3.23844935 3.2386297  3.23873224
 3.23953914 3.23985969 3.24037216 3.2404846  3.24117908 3.24159884
 3.24207785 3.2424296  3.24273477 3.24284083 3.24389107 3.24400131
 3.24404177 3.24412455 3.2441701  3.2443596  3.24524342 3.24625467
 3.24628115 3.24649853 3.24726086 3.24824484 3.24866704 3.2487549
 3.24967634 3.25013807 3.25046151 3.25153942 3.25208785 3.25214399
 3.25239987 3.25266317 3.25303323 3.25417062 3.25423074 3.25512923
 3.25566318 3.25571387 3.25594932 3.25612105 3.25638735 3.25646961
 3.25694804 3.25711012 3.25821115 3.25865738 3.25940323 3.259854
 3.26007742 3.26008374 3.26194363 3.26229274 3.26252641 3.26285189
 3.2629757  3.26390185 3.26467789 3.26541045 3.26676239 3.26751171
 3.2697952  3.27025926 3.27099693 3.27104721 3.27121065 3.2715352
 3.27185343 3.27402401 3.27506958 3.27529463 3.27619643 3.27655823
 3.2769731  3.27710118 3.27734127 3.27794643 3.27931855 3.27989231
 3.28177721 3.28183549 3.28218269 3.28232404 3.2827389  3.28334188
 3.28355916 3.2836627  3.28387344 3.28459897 3.28546855 3.28668534
 3.28735003 3.28784615 3.28842154 3.28918812 3.2892171  3.29034632
 3.29055199 3.29066423 3.2909663  3.29128389 3.29150128 3.29188034
 3.29478391 3.29591592 3.296207   3.29771851 3.2984633  3.29939413
 3.29987221 3.30006674 3.30112441 3.30223242 3.30267576 3.30347087
 3.30387122 3.30548295 3.30600917 3.30775715 3.30958911 3.30988308
 3.31039061 3.31121598 3.31262153 3.31480367 3.31497419 3.31546339
 3.3161107  3.32036024 3.32085694 3.32094    3.32111922 3.32127791
 3.32180633 3.32181934 3.3231785  3.32329624 3.3272499  3.32735395
 3.32927816 3.33039953 3.3307438  3.33148639 3.3331391  3.33317855
 3.33367654 3.33433584 3.33686836 3.33831943 3.34124916 3.34303746
 3.34607193 3.3464385  3.34694788 3.34726859 3.35033643 3.35223186
 3.3526809  3.35269477 3.35306865 3.35388735 3.35620575 3.35655212
 3.35665561 3.35709774 3.35966477 3.36033763 3.36077388 3.36476954
 3.36509325 3.36684352 3.36768872 3.36842546 3.36939854 3.37026579
 3.37242895 3.37365158 3.37415794 3.37446793 3.37478114 3.37546562
 3.37608571 3.37663748 3.37672755 3.3787849  3.37951291 3.38192733
 3.38367813 3.38379103 3.38399291 3.38414158 3.3845546  3.38607894
 3.38718851 3.38758205 3.38777346 3.38783915 3.38879298 3.38880849
 3.38928715 3.39042489 3.39341841 3.39801782 3.39814798 3.40063032
 3.40088597 3.40095719 3.40238532 3.40323745 3.40576768 3.40707256
 3.41414497 3.41742616 3.42442652 3.42619801 3.42863291 3.42905027
 3.43357037 3.4365241  3.43805729 3.44935673 3.45162708 3.45590338
 3.45912136 3.47524506 3.47813861 3.48164842 3.48200507 3.48809801
 3.48881986 3.48963682 3.49100977 3.4955207  3.50338316 3.50569609
 3.5097049  3.51555308 3.51890173 3.52526249 3.52542598 3.54077999
 3.61370598 3.64595903 3.66249594 3.66766451 3.69334987 3.71961043
 3.72149789 3.76906123 3.80014318 3.80357571 3.83070097 3.83113165
 3.83663741 3.86133097 3.86177642 3.86223471 3.86464152 3.92075781
 3.94555275 3.94601775 3.95011757 3.96366373 3.96395275 4.11818528
 4.12079207 4.16177885 4.32892801 4.44810251 4.74432951 4.76354829
 4.76504845 4.77199385 4.77384085 4.77600629 4.78273537 4.79119429
 4.79764477 4.80087405 4.80124338 4.80176763 4.80212097 4.80312741
 4.80860154 4.81649865 4.81755977 4.81780812 4.81830185 4.81906676
 4.81910406 4.82335365 4.82440486 4.83088742 4.83158348 4.83312978
 4.8348839  4.83806621 4.84618509 4.84981924 4.85836699 4.86173895
 4.86323446 4.87568441 4.88734401 4.89322871 4.92835632 4.93298868
 4.95508111]

  warnings.warn(

2022-12-16 10:36:31,901:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.65469548 1.92672316 1.93709954 1.95953165 1.96030034 1.96179116
 1.98770457 1.98838418 2.00290839 2.01558313 2.14102525 2.17744726
 2.85190621 2.8694473  2.87182911 2.87287236 2.88036172 2.89599968
 2.89721357 2.89730817 2.8984551  2.89966213 2.90233622 2.90402516
 2.90549354 2.90593196 2.90603592 2.90741185 2.90816175 2.90980028
 2.91016106 2.91531371 2.91606933 2.91939623 2.92036599 2.9209326
 2.92451498 2.92534236 2.92737685 2.92810083 2.93012335 2.93283742
 2.94115605 2.94225965 2.9423291  2.94386674 2.94854729 2.94891473
 2.95205044 2.95238053 2.95473825 2.95522753 2.95524313 2.95543428
 2.9581449  2.95864832 2.95910803 2.95943039 2.95973028 2.96054005
 2.96070324 2.96149853 2.96311968 2.96511541 2.96548633 2.96680748
 2.96783713 2.96823153 2.97004969 2.97176306 2.97220564 2.97220975
 2.9734435  2.97349571 2.97715713 2.9778144  2.9786426  2.97883298
 2.97970879 2.98391398 2.98751254 2.98810344 2.98833048 2.98881194
 2.98938591 2.99132583 2.99538066 2.99585921 3.00138567 3.00359527
 3.00507093 3.0053093  3.0057306  3.007601   3.00795141 3.01039713
 3.01249833 3.01251969 3.01275643 3.01284065 3.01320828 3.01527472
 3.01567819 3.01889758 3.01927656 3.02405117 3.02681731 3.02870504
 3.02925428 3.03256599 3.03632185 3.03693937 3.03986225 3.05060069
 3.05213985 3.05471328 3.06055505 3.06150273 3.06653726 3.06706954
 3.07343821 3.07369556 3.07463992 3.07615244 3.07866541 3.08286221
 3.08659126 3.08702587 3.08720422 3.09089398 3.0918701  3.09668698
 3.09687212 3.09828806 3.0984853  3.10021275 3.10028686 3.10056677
 3.1009548  3.10198476 3.10218624 3.10287029 3.10448438 3.10607966
 3.10980913 3.11025461 3.11192109 3.11214974 3.11369637 3.11390569
 3.1142926  3.1144256  3.11485685 3.11700168 3.11765904 3.11840656
 3.11891324 3.11961586 3.11981303 3.12027129 3.12035034 3.12045661
 3.12200309 3.12200874 3.12244354 3.12314945 3.12380485 3.12400906
 3.12418695 3.12450823 3.12586999 3.12654131 3.12656965 3.12701213
 3.12732348 3.12777158 3.12854358 3.13005744 3.13026134 3.13228827
 3.13238146 3.13292934 3.13307693 3.13319038 3.13347945 3.13385997
 3.13392209 3.13499172 3.13589979 3.13619343 3.13676373 3.13686788
 3.13749191 3.13791246 3.13817564 3.13900353 3.13917833 3.13975441
 3.14042004 3.14085234 3.14176697 3.14181243 3.14206638 3.14235154
 3.14294835 3.14338638 3.14362375 3.14442686 3.14488955 3.14544257
 3.1456436  3.14579655 3.14605076 3.14618287 3.14655097 3.14671974
 3.14675385 3.14676573 3.14706064 3.14834689 3.14893561 3.149313
 3.14972405 3.1499152  3.15022852 3.15032411 3.1506426  3.15129678
 3.15137846 3.15164371 3.15219113 3.15223338 3.15235868 3.15238897
 3.15244169 3.15297683 3.15304508 3.15325573 3.15352894 3.15389179
 3.1542051  3.15506792 3.15511893 3.15540061 3.15561753 3.15617182
 3.15720976 3.15730035 3.15802346 3.15815903 3.1581734  3.15928861
 3.15939472 3.15955857 3.15966294 3.15968106 3.15969234 3.15972983
 3.15975113 3.15996816 3.16024489 3.16074484 3.16104753 3.16153705
 3.1619255  3.16204963 3.16275289 3.16295383 3.16300086 3.16304175
 3.16306058 3.16316781 3.16319444 3.16327351 3.16329005 3.16366676
 3.1639278  3.16402574 3.16507452 3.16509366 3.16521197 3.16541875
 3.1659639  3.16602319 3.16610381 3.16616776 3.16693478 3.16752414
 3.16758627 3.16759825 3.16806614 3.16809796 3.1683965  3.16858123
 3.16876498 3.16912074 3.16919214 3.16931919 3.16937146 3.16960234
 3.17035453 3.17065457 3.17076855 3.17096805 3.17169635 3.17172455
 3.1717891  3.1723653  3.17262737 3.17262934 3.17281394 3.17283322
 3.17302869 3.17307016 3.17357152 3.17377029 3.17416633 3.1744316
 3.17486546 3.17502327 3.1752515  3.17588485 3.17591565 3.17614829
 3.17617848 3.17661253 3.17680243 3.17694148 3.17715231 3.17763347
 3.1776646  3.17790522 3.17821531 3.17840847 3.17859161 3.17868085
 3.17870983 3.17930871 3.17975774 3.17986472 3.18004437 3.18043177
 3.18050588 3.18063411 3.18064387 3.1807052  3.18084624 3.18096416
 3.18118128 3.1814069  3.18145117 3.18164582 3.18171542 3.18240726
 3.18246213 3.18246338 3.18272272 3.18272679 3.18278035 3.18287845
 3.18290535 3.18299332 3.18307125 3.18313256 3.18324522 3.18341161
 3.1834737  3.18391079 3.18406608 3.18409114 3.1841507  3.18429129
 3.1845615  3.18478179 3.1847911  3.18479423 3.18492662 3.18496765
 3.1850111  3.18531587 3.18657497 3.18662928 3.18731686 3.18738949
 3.18761726 3.18824083 3.18829557 3.18884596 3.18914926 3.18925217
 3.1892625  3.18932628 3.18949632 3.18950469 3.18967121 3.18982669
 3.18996964 3.19040348 3.19083339 3.19102925 3.19114866 3.19123205
 3.19173408 3.19181455 3.19204932 3.19220378 3.19236778 3.1925238
 3.19296395 3.19307196 3.19312129 3.19329867 3.19342449 3.19348146
 3.19350242 3.19360102 3.19361107 3.19378177 3.19393235 3.19432014
 3.19460218 3.19462486 3.19465909 3.19473903 3.19480466 3.19482204
 3.19533649 3.19546492 3.19559698 3.19569395 3.19579488 3.19621304
 3.19659749 3.19670333 3.19712319 3.19787858 3.19791555 3.19795794
 3.19802474 3.19811472 3.19860317 3.19882318 3.19884021 3.19901868
 3.19917819 3.19962037 3.19972295 3.19981939 3.20050208 3.20059371
 3.20062911 3.20112645 3.20114534 3.2012763  3.20214584 3.20222192
 3.20241569 3.2030581  3.20318502 3.20341806 3.20351371 3.20380724
 3.20401581 3.20433251 3.20434165 3.20454015 3.20470379 3.20498791
 3.20504464 3.20507457 3.20525696 3.20546085 3.20551747 3.20579476
 3.20580128 3.20583752 3.20600814 3.20745387 3.20762937 3.20841853
 3.20844018 3.2086845  3.20898077 3.20955758 3.20964681 3.20978123
 3.20981727 3.20992986 3.20994701 3.21013921 3.21044118 3.21060733
 3.21061512 3.21065901 3.21069045 3.21120082 3.21125953 3.21162474
 3.21194894 3.21210545 3.21216842 3.21269817 3.21273049 3.21334854
 3.21368405 3.21432782 3.21471317 3.21472622 3.21479897 3.21490186
 3.21548549 3.21582675 3.21592936 3.2160706  3.21612044 3.21638418
 3.21650597 3.21662157 3.21669967 3.21681585 3.21686796 3.21688796
 3.21787632 3.21849611 3.21939115 3.2193959  3.21978807 3.22002364
 3.2201043  3.22044003 3.22085064 3.22128619 3.22131338 3.22188325
 3.22223384 3.22251886 3.22271015 3.22275817 3.22301048 3.22304918
 3.22356014 3.22384381 3.22386421 3.22408982 3.22419614 3.22431522
 3.22448467 3.22457857 3.22458161 3.22473471 3.22495763 3.2252799
 3.22537582 3.22559771 3.22563812 3.22594012 3.22605002 3.22679652
 3.22685134 3.22686943 3.22701158 3.22712568 3.22729485 3.22805978
 3.22815169 3.22841804 3.22871637 3.22895696 3.2291431  3.23003215
 3.23058834 3.23079836 3.23117351 3.23147541 3.23147741 3.23176153
 3.2318169  3.23193794 3.23198651 3.23202512 3.23221541 3.23259279
 3.23322801 3.23337113 3.2334176  3.23481536 3.2350463  3.23541874
 3.23571732 3.23595674 3.23609912 3.23625845 3.23629703 3.23644917
 3.23737221 3.23773037 3.2377726  3.23780975 3.23807842 3.2380868
 3.23864165 3.23933543 3.23934081 3.2405419  3.24089268 3.24100161
 3.24346663 3.24371099 3.24377598 3.24498597 3.24518709 3.245652
 3.24582687 3.24643243 3.24661792 3.24724167 3.247881   3.24997129
 3.2503758  3.25196166 3.25202839 3.25217232 3.2537212  3.25446435
 3.25474256 3.25673168 3.25691801 3.25774798 3.25927197 3.25934339
 3.26221328 3.26349134 3.26371006 3.26454292 3.26518558 3.26720079
 3.26820954 3.26828374 3.27092509 3.27119435 3.27208235 3.27285322
 3.27297745 3.27397159 3.27401688 3.27432984 3.27519247 3.27521215
 3.27555784 3.27854321 3.27882677 3.28066672 3.28130537 3.28191061
 3.28324409 3.28370182 3.28401226 3.28401376 3.28726111 3.2875902
 3.28940225 3.29242247 3.29352903 3.29449843 3.29567401 3.29600186
 3.29758691 3.29785844 3.29801469 3.29802797 3.29864037 3.30053675
 3.30068145 3.30101632 3.30192404 3.30473468 3.30540937 3.30598328
 3.30600997 3.30626359 3.30635606 3.3121967  3.31478211 3.31643481
 3.31710965 3.31770337 3.31812686 3.31881034 3.3203068  3.32541966
 3.32704712 3.32712331 3.33112135 3.33178652 3.33289929 3.33391579
 3.33667734 3.3378455  3.34263544 3.34282859 3.34307696 3.34423961
 3.34680186 3.34915635 3.34969135 3.35222983 3.35307381 3.35312653
 3.35460602 3.35737202 3.35823026 3.3591189  3.36075682 3.3637128
 3.36409225 3.36532125 3.36566155 3.36601705 3.36645443 3.36759389
 3.37140382 3.37164596 3.37167008 3.37331439 3.37667481 3.3785396
 3.38018572 3.38111683 3.38279821 3.38297939 3.38401405 3.38503033
 3.38665992 3.38679697 3.38742865 3.38863778 3.38904318 3.39225629
 3.39410542 3.39565819 3.39700243 3.39717681 3.39814015 3.39986968
 3.4024451  3.40305007 3.40356045 3.40440155 3.40526579 3.40600243
 3.40635076 3.40752237 3.40885267 3.41078767 3.41137103 3.41177706
 3.41259666 3.41351601 3.41400962 3.41564311 3.41764092 3.41925439
 3.42181399 3.42245413 3.4226656  3.42361797 3.42456351 3.4249153
 3.42542954 3.42555472 3.42606252 3.42690373 3.4275213  3.42801907
 3.4312365  3.4334132  3.43428418 3.44008741 3.44752029 3.44784406
 3.45292928 3.46845323 3.4862506  3.49640606 3.5167453  3.52433067
 3.53297491 3.53900404 3.54233525 3.56394824 3.61113005 3.63833054
 3.66426076 3.66684162 3.67335853 3.67673874 3.71033343 3.73775023
 3.80565765 3.8415287  3.8435811  3.86877462 3.8741729  3.87501798
 3.87946389 3.88375859 3.88416017 3.9035803  3.90655942 3.90691173
 3.91893196 3.93287628 3.9741754  3.98925919 3.98961741 4.05605792
 4.10387224 4.13061264 4.20953656 4.31341874 4.33062771 4.37594805
 4.49973484 4.50480968 4.70021298 4.76601989 4.78993483 4.7968592
 4.80057073 4.8054372  4.81220361 4.81319739 4.81450863 4.81861956
 4.82032874 4.82147199 4.82760342 4.83079956 4.8316674  4.83319966
 4.83407761 4.83746894 4.83803355 4.83852568 4.83910853 4.83923943
 4.83935193 4.84079822 4.84414425 4.84471617 4.85007286 4.86195682
 4.87387856 4.89311441 4.91543838 4.93401673 4.94086419 4.94885893
 4.95841017]

  warnings.warn(

2022-12-16 10:36:32,089:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.60813772 1.86538539 1.87785333 1.93538255 2.04817109 2.18533858
 2.680479   2.83195425 2.83533904 2.86823343 2.89089396 2.91049326
 2.91797443 2.92452238 2.9248451  2.92615452 2.92652845 2.92984347
 2.93002569 2.93071676 2.93164748 2.93169979 2.93692293 2.94397019
 2.94553792 2.95002326 2.95181763 2.95578444 2.95707794 2.95799084
 2.95934378 2.96094584 2.96214188 2.96624817 2.96688083 2.96800521
 2.96805187 2.96965818 2.97064273 2.97439461 2.97572853 2.97599039
 2.97620114 2.97638947 2.97758965 2.97764728 2.98256439 2.98409097
 2.98655283 2.9886152  2.98981124 2.99258597 2.992741   2.99345016
 2.99369136 2.9953961  2.99760665 2.99830264 2.99950664 3.00134649
 3.00192585 3.0019456  3.00214901 3.00579019 3.00686478 3.00897467
 3.00931017 3.01080991 3.01134679 3.01169228 3.01206771 3.01207268
 3.01216561 3.01696238 3.01954436 3.01960978 3.0215378  3.0231229
 3.02438598 3.02445574 3.02537228 3.02650646 3.02670352 3.02736089
 3.02746928 3.02988561 3.03513703 3.03637612 3.03738523 3.03867448
 3.04233642 3.04327892 3.04356442 3.04668371 3.04813578 3.05075125
 3.0512259  3.05173474 3.0536179  3.05436631 3.05484889 3.05534011
 3.05567661 3.05651817 3.05663339 3.05786453 3.06108618 3.0621416
 3.0627262  3.06288002 3.06354569 3.06673335 3.06770109 3.06813637
 3.06851265 3.0685841  3.07025396 3.07102325 3.0726223  3.07387808
 3.0738845  3.07449387 3.07533183 3.07736843 3.07957004 3.08118437
 3.08122921 3.08176341 3.08204727 3.08254282 3.08460924 3.0848181
 3.08664127 3.08783237 3.08849934 3.08902067 3.08951457 3.09099037
 3.09198216 3.09206947 3.09353886 3.09406944 3.09454558 3.09598482
 3.09669835 3.09761373 3.09944643 3.09951153 3.0997301  3.10019393
 3.10389341 3.10421364 3.10563132 3.10624959 3.10628981 3.10688604
 3.10798573 3.10906165 3.11063625 3.11069259 3.11070117 3.1108972
 3.11129937 3.11132426 3.11179524 3.11181876 3.11225475 3.11278618
 3.11332568 3.11333115 3.11371276 3.11385206 3.11405169 3.11503317
 3.11584652 3.11603121 3.11793295 3.11799326 3.11805192 3.11837613
 3.11845736 3.11867118 3.11867152 3.11981785 3.12050145 3.12052876
 3.12112872 3.12114896 3.12179741 3.12417755 3.12431639 3.1246106
 3.12461094 3.12471982 3.12548561 3.12598756 3.12823056 3.12834134
 3.12844562 3.12852561 3.1285978  3.12985553 3.12992809 3.12993961
 3.12994069 3.13000657 3.13020169 3.13038964 3.13042638 3.13049475
 3.13059501 3.13140596 3.13190884 3.13203303 3.13213411 3.13217275
 3.13246051 3.13376615 3.13377394 3.13452073 3.1347208  3.13513135
 3.13532117 3.13536144 3.1364218  3.13708359 3.137395   3.13851405
 3.13854753 3.13901137 3.13938753 3.13978237 3.14143747 3.14156943
 3.14176693 3.14187604 3.14200609 3.14259185 3.14268521 3.14272275
 3.1429676  3.14350087 3.14368253 3.14434655 3.14439378 3.14541303
 3.14698868 3.14724519 3.14731257 3.14759238 3.1476817  3.14792974
 3.14808945 3.14820639 3.14843894 3.14845963 3.14897119 3.14897439
 3.14920686 3.14934796 3.14938974 3.15032091 3.15063128 3.15112451
 3.15121265 3.15172124 3.15191884 3.15245921 3.1526306  3.15264145
 3.15301807 3.15370648 3.15376185 3.15409557 3.15437944 3.15466653
 3.15468521 3.1548288  3.15483227 3.15545809 3.15565201 3.15570061
 3.15626496 3.15678041 3.15712244 3.15729551 3.15763834 3.15798732
 3.15802523 3.15832968 3.15837083 3.15857292 3.15859713 3.15887088
 3.15916044 3.15939821 3.15962937 3.15966443 3.15998969 3.16020564
 3.16024591 3.16071631 3.16094042 3.16116307 3.16133376 3.16253672
 3.16319861 3.16338805 3.1635211  3.16369067 3.16393179 3.16412682
 3.16418294 3.164605   3.16471388 3.16488478 3.16511669 3.16522157
 3.16694819 3.16711067 3.1677075  3.16803422 3.16812123 3.16837041
 3.16843736 3.16861856 3.16885043 3.16887429 3.16922952 3.1693673
 3.17035349 3.17047581 3.1706796  3.17115747 3.17196812 3.17238611
 3.17256708 3.17305905 3.17324164 3.17414265 3.17415564 3.17433208
 3.17436393 3.17451513 3.17462401 3.17481699 3.1756036  3.17657518
 3.1768293  3.17698481 3.17759023 3.17806084 3.17840124 3.17857618
 3.17912075 3.17934663 3.1795167  3.17996866 3.18004515 3.18044621
 3.18062589 3.18267964 3.18331696 3.18413132 3.18433051 3.18474446
 3.18521804 3.1864514  3.18660673 3.18663399 3.18674287 3.18690024
 3.18697126 3.18716177 3.18727286 3.18749323 3.18758719 3.18759167
 3.1882668  3.18835534 3.18887711 3.18907115 3.18919157 3.18929692
 3.18989397 3.19015391 3.190187   3.19028835 3.19047208 3.19048758
 3.19072048 3.19076998 3.190817   3.19082895 3.19088723 3.19094397
 3.19117737 3.19178771 3.19182656 3.19207279 3.1926206  3.19274485
 3.19285373 3.19311603 3.19322826 3.19326337 3.19339341 3.19379605
 3.19379639 3.19391697 3.19424763 3.1942954  3.19450199 3.19455555
 3.19497669 3.1951269  3.19513901 3.19557408 3.19578443 3.19702198
 3.19716114 3.1976009  3.19809372 3.19839435 3.19877219 3.1991067
 3.19922688 3.19948898 3.19960425 3.19968805 3.19991154 3.19999183
 3.20017146 3.20018501 3.20050173 3.20051682 3.20066438 3.20073641
 3.20082491 3.20120065 3.20155223 3.20186861 3.20214715 3.20327418
 3.20343198 3.20355387 3.20363345 3.20406836 3.20412088 3.20570585
 3.20604868 3.20624226 3.20631677 3.20662061 3.20662709 3.20671887
 3.20680457 3.20686072 3.20721101 3.20734867 3.20740607 3.20756719
 3.20766577 3.2079957  3.20814157 3.20879069 3.20910746 3.20932598
 3.20965788 3.20991274 3.20997487 3.21023432 3.21029558 3.21063389
 3.21088626 3.21096086 3.21196549 3.21198661 3.21237759 3.21254857
 3.21283589 3.21288133 3.21293411 3.21298734 3.21308259 3.21331446
 3.21359636 3.21379872 3.21388002 3.21408955 3.21412439 3.21427312
 3.21460302 3.21501122 3.21531517 3.21533637 3.21536461 3.21547349
 3.21563429 3.21567938 3.21586658 3.21595371 3.21606482 3.21614797
 3.21634518 3.21660098 3.21684701 3.21773018 3.21816645 3.2181994
 3.21824638 3.21829387 3.21877823 3.21904497 3.21917754 3.21935468
 3.21944137 3.21987942 3.21991676 3.22033598 3.22043542 3.22048649
 3.22077859 3.22083835 3.22085821 3.22113238 3.22145495 3.22154777
 3.2217113  3.22202265 3.22215007 3.22218269 3.22234548 3.2227909
 3.2227918  3.22410378 3.22500688 3.22501494 3.2250542  3.22555889
 3.2259455  3.22599062 3.22604213 3.22684436 3.22688929 3.22785116
 3.22865701 3.22869355 3.22931395 3.22973535 3.22988678 3.23026029
 3.2308316  3.23134137 3.23155221 3.23205321 3.23248934 3.23268486
 3.23275363 3.23276786 3.23353078 3.23356344 3.2337507  3.23430384
 3.23636662 3.23646443 3.23660869 3.2381137  3.2390548  3.23918722
 3.24027411 3.24105545 3.24134056 3.24265048 3.24266978 3.24341084
 3.24398111 3.2442872  3.2450526  3.24516385 3.24520606 3.2461347
 3.24704623 3.24814693 3.24821444 3.24824335 3.24834593 3.24907952
 3.24922914 3.24981586 3.25009024 3.25081449 3.25151033 3.25154092
 3.25223072 3.25244025 3.25254933 3.25321744 3.25322164 3.25335499
 3.25362017 3.25383814 3.25461975 3.25547703 3.25703901 3.25823249
 3.2596201  3.26052074 3.26090122 3.26105523 3.26138309 3.26155499
 3.26195869 3.26207242 3.2631474  3.26393054 3.26524215 3.26652991
 3.26744645 3.26770857 3.26796741 3.26868343 3.27054563 3.270895
 3.27121927 3.27136785 3.27236963 3.27302049 3.27306244 3.27356473
 3.27371324 3.27408948 3.2774527  3.2783047  3.2792718  3.28027449
 3.28068061 3.28194008 3.2824201  3.2827128  3.28323928 3.28370931
 3.28375668 3.28389016 3.28424956 3.28481721 3.28621403 3.28794785
 3.28875249 3.28876726 3.29061316 3.29078537 3.29130746 3.29214436
 3.29340203 3.29348468 3.29738588 3.29756658 3.29853177 3.29858906
 3.3018098  3.30285103 3.30290366 3.30304207 3.30318727 3.30418352
 3.30472163 3.30478648 3.30602973 3.30734687 3.30911624 3.30918939
 3.30966377 3.31012559 3.31586096 3.31624839 3.31740841 3.31813155
 3.3183963  3.31896008 3.31970949 3.31999102 3.32012007 3.32042691
 3.32507178 3.32742383 3.32771159 3.32862403 3.32988135 3.33011689
 3.33081181 3.33414138 3.33467857 3.33528606 3.33576804 3.33759191
 3.33984579 3.34119027 3.34387749 3.34420755 3.34438279 3.34591205
 3.34678052 3.34798374 3.34826096 3.34881419 3.34916039 3.34976849
 3.35060543 3.35333659 3.35344058 3.35351534 3.35830173 3.35879708
 3.35990446 3.36042744 3.36097521 3.3629573  3.36483004 3.36546847
 3.36722839 3.37432677 3.37663772 3.37733804 3.37737346 3.37773454
 3.3789795  3.38002067 3.38082588 3.38100605 3.38175541 3.38207186
 3.38259136 3.38496353 3.3864007  3.38691184 3.3887543  3.38879993
 3.38932636 3.38999541 3.39080393 3.39222471 3.39339388 3.39435104
 3.39478811 3.39511216 3.39746536 3.39752184 3.39939169 3.39970831
 3.40312663 3.40411827 3.40687988 3.40704513 3.40936715 3.40980878
 3.4099524  3.41057628 3.41206179 3.41486545 3.41607902 3.41759729
 3.42037616 3.42594792 3.43081064 3.43310856 3.43612756 3.43993376
 3.44466873 3.44507463 3.44970601 3.45067287 3.45461621 3.45560531
 3.46131604 3.46187109 3.46576013 3.46587446 3.46873798 3.46912985
 3.47991268 3.4819048  3.49457318 3.50368697 3.51342385 3.52992556
 3.53883771 3.54354945 3.54377251 3.54729788 3.56153185 3.56523467
 3.58004893 3.58627958 3.59586904 3.62076385 3.62591834 3.63932179
 3.647883   3.65698236 3.6887289  3.70330668 3.77811705 3.77954906
 3.79146957 3.79803623 3.8198288  3.82678576 3.84478135 3.84500654
 3.84932904 3.85103713 3.86139238 3.90487268 3.98115604 4.05235693
 4.06516769 4.13570447 4.14088939 4.14156772 4.14910417 4.2008167
 4.20874327 4.38352619 4.38691316 4.44293838 4.60328841 4.69557484
 4.72659408 4.75662129 4.76202529 4.77059558 4.79596711 4.79630118
 4.79853465 4.80365061 4.80562789 4.80592824 4.81266557 4.81615911
 4.81960944 4.82678461 4.82989776 4.83832166 4.85222212 4.85241449
 4.86183717 4.87329702 4.87546484 4.88063497 4.88134948 4.88465403
 4.90306089 4.90562134 4.91262746 4.91679623 4.95432286 4.96846487]

  warnings.warn(

2022-12-16 10:36:32,138:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.57267138 1.76276319 1.80507684 1.82442971 1.95324058 2.05321142
 2.44394199 2.44769165 2.85281155 2.87211543 2.90114154 2.91205009
 2.92735788 2.93208509 2.93507603 2.95238774 2.9533108  2.95405612
 2.95733193 2.96014151 2.96180219 2.96213402 2.96236712 2.96283924
 2.96372461 2.96497349 2.9675779  2.96881243 2.9711538  2.97165666
 2.97195541 2.97298252 2.97647512 2.97808982 2.97849002 2.97924499
 2.9805493  2.98130118 2.98193386 2.98203166 2.98248973 2.98253665
 2.98500995 2.9851651  2.98574107 2.98675728 2.98869978 2.98972199
 2.98975812 2.99049403 2.99197367 2.99379357 2.99414332 2.99806158
 3.00025297 3.00119969 3.00127794 3.00137667 3.00368454 3.00437044
 3.00512454 3.00512962 3.00563682 3.00565222 3.00727696 3.00758254
 3.00858732 3.00938953 3.00969735 3.0099527  3.01007771 3.01116086
 3.01267142 3.0142492  3.01514175 3.01546833 3.01704481 3.01819744
 3.01843024 3.01864373 3.01979148 3.01991714 3.02026571 3.02301333
 3.02337147 3.02581054 3.02964119 3.03044228 3.0305686  3.03072701
 3.03081178 3.03137315 3.03158445 3.03166547 3.03436765 3.03706904
 3.03731741 3.03855081 3.04017197 3.04263934 3.04843673 3.04927701
 3.04967587 3.0510663  3.05263933 3.05673425 3.05860936 3.06198174
 3.06319247 3.06585515 3.0660288  3.06687836 3.06699363 3.06719609
 3.07098682 3.07208056 3.08123997 3.08136705 3.08329381 3.08407542
 3.08429074 3.08451304 3.08573575 3.08575216 3.08577819 3.08619207
 3.08779396 3.08838017 3.08924278 3.09137476 3.09214688 3.09238755
 3.09348808 3.09361046 3.09559828 3.09618125 3.09825084 3.10071174
 3.10074076 3.10184255 3.10295719 3.10672032 3.1073097  3.10852805
 3.10910151 3.10915133 3.1102295  3.11157081 3.11207637 3.11227179
 3.11297739 3.11430503 3.1147409  3.11488578 3.115519   3.11603972
 3.11619934 3.11705171 3.11792183 3.11847686 3.11912337 3.11960483
 3.11967316 3.11967814 3.11975109 3.11982933 3.12017742 3.12021011
 3.12086358 3.12122602 3.12157919 3.12234803 3.12245594 3.12280163
 3.12314145 3.1233291  3.12334721 3.12371809 3.12388314 3.1244202
 3.12485825 3.12607685 3.12638025 3.1274468  3.12745355 3.12762685
 3.12784383 3.12800142 3.12803931 3.1285056  3.12851615 3.12868897
 3.1289348  3.12999682 3.13047904 3.13078397 3.13101781 3.13187579
 3.13203013 3.13204618 3.13227256 3.13284112 3.13333982 3.13344524
 3.13351469 3.13372523 3.1337497  3.13413341 3.13419616 3.13519584
 3.13547322 3.13571717 3.13628705 3.13630603 3.13637535 3.13683283
 3.13696651 3.13742057 3.13794328 3.13829975 3.13977698 3.13978685
 3.14099212 3.14110205 3.14142799 3.14178287 3.14229501 3.14254086
 3.14262992 3.14267584 3.14268254 3.1428789  3.14293782 3.14355366
 3.14366995 3.14382635 3.14385452 3.14389827 3.14439947 3.14479107
 3.1448934  3.14515486 3.14530249 3.14551038 3.14564214 3.14574569
 3.14589699 3.14601824 3.14616581 3.14620847 3.14639959 3.14657197
 3.14668991 3.14676788 3.14683545 3.14719981 3.14728499 3.14732401
 3.14745532 3.14779354 3.1479597  3.1483604  3.14862283 3.14864988
 3.14889385 3.14897879 3.14898155 3.14900625 3.14939772 3.14998653
 3.15035224 3.15049606 3.15049848 3.15075381 3.15088073 3.15091972
 3.15102579 3.15109921 3.15142549 3.15207874 3.15214791 3.15316681
 3.15349541 3.15419686 3.15454632 3.15545236 3.15577747 3.15606093
 3.1561428  3.15624714 3.15638012 3.15640903 3.15662757 3.15667003
 3.15676194 3.15681253 3.15718936 3.15741238 3.15747282 3.15784847
 3.15792166 3.15819889 3.15895266 3.15897727 3.15918191 3.15943448
 3.15959299 3.15964183 3.16071132 3.16097518 3.16119384 3.16236211
 3.16250188 3.16268262 3.1633541  3.16340815 3.16341648 3.16355948
 3.16369568 3.16410392 3.16438045 3.16527192 3.16534457 3.16543718
 3.16561643 3.16583159 3.16618576 3.1662447  3.16629763 3.16671981
 3.16680072 3.16700425 3.16769281 3.16782596 3.16790245 3.16790737
 3.16815907 3.16816966 3.16901547 3.16905372 3.16930785 3.1696214
 3.16981147 3.1700202  3.17059828 3.1706773  3.17082038 3.17092165
 3.17129382 3.17149597 3.17156578 3.17160752 3.17165025 3.17185149
 3.17203655 3.17216394 3.17218929 3.17228802 3.1723464  3.17258703
 3.17265027 3.17268409 3.17286638 3.17287761 3.17289191 3.17294847
 3.17309949 3.17341363 3.17352186 3.17357976 3.17371972 3.17373419
 3.1738216  3.17399478 3.17400596 3.1745108  3.17473025 3.17481638
 3.17484942 3.17502044 3.17502653 3.17523634 3.17528364 3.17534825
 3.17536438 3.17554174 3.17573802 3.17588036 3.17599552 3.17602845
 3.17638719 3.17669935 3.176708   3.17677191 3.17710381 3.1772099
 3.1772634  3.1774532  3.17762557 3.1777671  3.17785328 3.17788503
 3.17803334 3.17810101 3.1783634  3.17842274 3.17851275 3.17856982
 3.17859735 3.17939938 3.17941925 3.1795298  3.17982282 3.17998452
 3.18033916 3.18046041 3.18046421 3.18060758 3.18073435 3.18079145
 3.18079738 3.18084517 3.18108528 3.18111663 3.1811598  3.18145187
 3.18178407 3.18207197 3.18238495 3.18247351 3.18311926 3.18363986
 3.18375191 3.18400082 3.18448624 3.1845713  3.1858404  3.18585839
 3.18626507 3.18637268 3.18648484 3.18680415 3.18690231 3.18697341
 3.18698368 3.18702751 3.18714989 3.18721962 3.18725908 3.18745835
 3.18750617 3.18757144 3.18762752 3.18765995 3.18800693 3.18815164
 3.18816327 3.1882005  3.18821764 3.18853507 3.18857158 3.18906753
 3.1892266  3.18931231 3.18951047 3.18975671 3.19001968 3.19003377
 3.19023486 3.19132319 3.1915056  3.19178348 3.19182305 3.19189179
 3.19190698 3.19241374 3.19266597 3.19334074 3.19382872 3.19396262
 3.19411656 3.19433928 3.1947891  3.19495762 3.19501235 3.19539778
 3.19539859 3.19564752 3.19589537 3.19597389 3.19638296 3.19666527
 3.19697469 3.1970301  3.19732734 3.19734727 3.19734964 3.19748042
 3.19872218 3.19872712 3.19897186 3.19957744 3.19991551 3.1999271
 3.20012161 3.20017206 3.20052669 3.20059107 3.2007318  3.20099575
 3.20123064 3.20131927 3.20134855 3.20183435 3.20191634 3.20316616
 3.20362125 3.20403635 3.20410593 3.20416532 3.20432775 3.20471261
 3.20514145 3.20525859 3.20526999 3.20539409 3.20578084 3.20601203
 3.20624524 3.20671631 3.20696583 3.2071576  3.20722949 3.20794267
 3.20801727 3.20858763 3.20870775 3.20891033 3.20912372 3.20920427
 3.20947035 3.20965916 3.21090648 3.21162244 3.2127463  3.21412252
 3.21444447 3.21454883 3.21465746 3.21479968 3.21520365 3.21520805
 3.21524296 3.21628762 3.21635935 3.21657644 3.21746056 3.21764289
 3.2181883  3.21848109 3.21850049 3.21861186 3.2186924  3.21888432
 3.21933283 3.22001643 3.22018195 3.22088349 3.22126483 3.22236481
 3.22248463 3.22407327 3.22440892 3.22525308 3.22577784 3.22610323
 3.22621436 3.22635716 3.22679315 3.22745339 3.22764082 3.22830161
 3.22846424 3.22879545 3.22916123 3.22935755 3.23024331 3.23036787
 3.23074685 3.23136648 3.23150843 3.23220127 3.23256236 3.23275987
 3.23349998 3.2337747  3.23399654 3.23584004 3.23628384 3.23644613
 3.2370989  3.24019328 3.24043449 3.24155322 3.24370901 3.24482267
 3.24554121 3.24610651 3.24629873 3.24849356 3.24913651 3.24930265
 3.24975812 3.24976644 3.24984731 3.25033959 3.25077034 3.25327516
 3.25370054 3.25419159 3.25441911 3.25505743 3.2565606  3.25702868
 3.25925    3.25925689 3.2599881  3.26017918 3.26056197 3.26089213
 3.26093457 3.26129837 3.26137982 3.26173686 3.26289354 3.26316231
 3.26348081 3.2639071  3.26433659 3.26441999 3.26466628 3.26485076
 3.2672839  3.26752735 3.26770265 3.26833725 3.2698827  3.27127888
 3.27174741 3.27206415 3.27279939 3.27644326 3.27672288 3.27687147
 3.27697602 3.27734796 3.27790912 3.27836426 3.27887103 3.27915928
 3.27927055 3.27929845 3.27932192 3.27933206 3.28002964 3.28005699
 3.28066287 3.28117752 3.2819608  3.28212459 3.28369725 3.28409692
 3.28478489 3.28553479 3.28571112 3.28632369 3.28683426 3.28766398
 3.28863612 3.29087134 3.29200271 3.29233271 3.29449534 3.29506036
 3.29540626 3.29591848 3.29623078 3.29649078 3.29783569 3.29843591
 3.29851931 3.29911379 3.30009569 3.30047026 3.30243772 3.30310479
 3.30359934 3.30424303 3.30442166 3.30497884 3.30612503 3.31013094
 3.31099937 3.31260144 3.31469476 3.31491827 3.3200498  3.32103056
 3.32210868 3.32328088 3.32366862 3.32372318 3.32627386 3.32980205
 3.33185746 3.33238234 3.3325788  3.33442452 3.3361399  3.33850172
 3.3396512  3.34143913 3.3457625  3.34850976 3.348626   3.35351658
 3.35391694 3.35559738 3.35585685 3.35794743 3.35818477 3.3612568
 3.36262457 3.3629736  3.3636592  3.3641718  3.36598468 3.36645462
 3.36731398 3.36967866 3.37178712 3.37281326 3.37363013 3.37542964
 3.37723105 3.37754033 3.37856802 3.37898559 3.37961201 3.38346677
 3.38430592 3.38443965 3.38462842 3.3881719  3.3893555  3.39069334
 3.3938958  3.39490716 3.40725259 3.40826885 3.40827477 3.4116857
 3.42247813 3.42861666 3.43085665 3.43092351 3.44236519 3.44518464
 3.45419134 3.45456343 3.45672674 3.464413   3.46723307 3.4681179
 3.47564969 3.47758935 3.47872038 3.49454709 3.53817799 3.60951941
 3.61895422 3.62958027 3.63956014 3.65739921 3.66133016 3.66219532
 3.681949   3.69353831 3.75498102 3.77107838 3.77285621 3.7959146
 3.79790731 3.8023934  3.80344876 3.81344221 3.82111472 3.8230768
 3.82925871 3.82981355 3.8309971  3.83718223 3.84009801 3.84192371
 3.84352475 3.84538142 3.92672285 3.93045792 3.94038416 3.98820091
 4.14083166 4.14392331 4.16522894 4.23265708 4.38932965 4.73025156
 4.74338204 4.74750025 4.77786689 4.78505196 4.79871783 4.80282251
 4.80723795 4.80731591 4.81021832 4.81265441 4.81652717 4.81874932
 4.81926418 4.82115125 4.82129726 4.82181098 4.82233099 4.82394691
 4.82773661 4.82794796 4.8288748  4.82981845 4.83877053 4.83976398
 4.84203349 4.84689678 4.85166143 4.85455423 4.85785137 4.86060837
 4.8649157  4.86571678 4.86736844 4.88047277 4.91350207 4.91995793
 4.92094285 4.92961725]

  warnings.warn(

2022-12-16 10:36:32,254:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.89778931 1.91892523 1.95027771 1.98486592 1.99198596 2.0670392
 2.20307775 2.58560255 2.72527104 2.8530951  2.85381801 2.86057126
 2.87221995 2.88560808 2.89080107 2.90070323 2.90555486 2.9069963
 2.90708447 2.9129657  2.91437174 2.91845965 2.92180793 2.92488472
 2.92577833 2.92652283 2.93207407 2.93425112 2.93546807 2.93985945
 2.94158553 2.94210685 2.94264943 2.94823822 2.94868287 2.94876538
 2.94888901 2.95019582 2.95248311 2.9557021  2.95912438 2.95957871
 2.96128849 2.96265704 2.9629429  2.96297893 2.96318493 2.96377692
 2.96434771 2.96488075 2.96494162 2.9650158  2.96526723 2.96564742
 2.96572368 2.96654554 2.96674871 2.96698404 2.96811762 2.96812183
 2.96876272 2.96894583 2.96988388 2.9702103  2.97050994 2.97051952
 2.97134284 2.9739641  2.97452104 2.97668344 2.97900128 2.98075847
 2.98130737 2.98167529 2.98191674 2.98265021 2.98400508 2.98426767
 2.99378451 2.995751   2.99621992 2.99660996 2.99770158 2.99842938
 2.99969805 2.9997443  3.00166186 3.00373343 3.00469172 3.00663142
 3.00678571 3.00721346 3.00959268 3.01013693 3.01044275 3.01404875
 3.01583622 3.01610468 3.01610973 3.01734363 3.01783141 3.01884199
 3.02063153 3.0219002  3.02420291 3.02724718 3.03019221 3.03077625
 3.03224871 3.03336098 3.03769703 3.03784863 3.04310438 3.04502869
 3.04540405 3.0459877  3.0466137  3.04784762 3.04975599 3.05088109
 3.05171477 3.05258041 3.0549658  3.05744649 3.05796219 3.0586888
 3.06182873 3.06217672 3.06231122 3.06245486 3.06312795 3.0638948
 3.06403478 3.06540495 3.06709521 3.06720004 3.06819152 3.06881033
 3.07091683 3.0711569  3.07122462 3.07284364 3.07306213 3.07358082
 3.07363371 3.08064581 3.08262234 3.08290852 3.08473253 3.0855057
 3.08645797 3.08659038 3.08690446 3.08691217 3.08765533 3.08790879
 3.08797046 3.08928228 3.09036209 3.09063321 3.09093461 3.09131413
 3.09225251 3.09277363 3.09294774 3.0929641  3.09324517 3.094509
 3.09590949 3.09641779 3.09700417 3.09711683 3.09741296 3.09813555
 3.09903127 3.0990511  3.0992347  3.09965858 3.09987656 3.10076709
 3.10102596 3.10115565 3.10186512 3.10233521 3.10305672 3.10460563
 3.10721367 3.10733096 3.10741424 3.10750969 3.10773894 3.10804834
 3.10830776 3.10886145 3.10946968 3.1099118  3.11020264 3.11022093
 3.11117016 3.11170763 3.11241193 3.11247169 3.11271699 3.11308793
 3.11350197 3.11386657 3.11386858 3.11507461 3.11728118 3.11820594
 3.11870008 3.11941635 3.11970082 3.12029385 3.12035631 3.12146051
 3.12157564 3.12188945 3.12202232 3.12287281 3.1233514  3.1237408
 3.12474729 3.12508185 3.12690679 3.12774667 3.12779273 3.12898415
 3.12944241 3.12975134 3.13021652 3.13044408 3.13060085 3.1307241
 3.13074492 3.13084438 3.13106415 3.13120711 3.13179835 3.1329112
 3.13295834 3.13376606 3.13488707 3.13493806 3.13501384 3.13519899
 3.13520897 3.13532326 3.13555081 3.13584536 3.13691267 3.13751456
 3.13781894 3.13800774 3.13811348 3.13847577 3.138608   3.13891098
 3.13921649 3.13933075 3.13968436 3.13971908 3.14008889 3.14039108
 3.14072062 3.14091057 3.14118568 3.14120364 3.14195455 3.14217
 3.1421888  3.14222461 3.14239528 3.14241857 3.14247891 3.14366102
 3.14385851 3.14423782 3.14430255 3.1444485  3.14477112 3.14549799
 3.14583696 3.14605933 3.14654254 3.1467365  3.14697517 3.14700107
 3.14726095 3.14744942 3.1482227  3.14835897 3.14855893 3.14880527
 3.14892469 3.14950786 3.14964218 3.14991905 3.15019872 3.1502288
 3.15035529 3.15063675 3.1506739  3.15080144 3.15095805 3.15100059
 3.15101208 3.15116183 3.15133635 3.15138422 3.15148106 3.15173294
 3.15177254 3.15181253 3.15190255 3.15204785 3.15222635 3.1525517
 3.15281157 3.15309272 3.15325196 3.15330333 3.15480692 3.15550288
 3.15559176 3.15564782 3.15570574 3.1560214  3.15605199 3.15634909
 3.15638666 3.15651713 3.15668884 3.15676043 3.15679789 3.15680929
 3.15685805 3.15690635 3.15710061 3.15712233 3.1572822  3.15743724
 3.1574745  3.15807699 3.15817086 3.1581959  3.15899216 3.1591668
 3.15932451 3.15974899 3.15993581 3.16020104 3.16026929 3.1603471
 3.16051879 3.16079212 3.16106128 3.16109172 3.16111595 3.16120483
 3.16132995 3.16167519 3.1620565  3.16231919 3.162859   3.16317509
 3.16346978 3.16383038 3.16385584 3.16433846 3.16449346 3.16456316
 3.16459164 3.16464396 3.16518432 3.16598234 3.16618265 3.16632422
 3.16642407 3.16690693 3.16707346 3.16729672 3.16787926 3.16797256
 3.16857701 3.16879566 3.16897505 3.16901997 3.16913651 3.16927582
 3.16989639 3.1702025  3.17029336 3.17052453 3.17088711 3.17091658
 3.17113782 3.17120564 3.17140314 3.17143563 3.17166633 3.17188402
 3.17226588 3.1723099  3.17249643 3.17273682 3.17275102 3.17286674
 3.17287718 3.17306147 3.17339657 3.17357661 3.17374075 3.1739638
 3.17399757 3.17407455 3.17442319 3.17494361 3.17505694 3.17513266
 3.17515237 3.17527313 3.17562516 3.17570222 3.1764384  3.17671659
 3.17680195 3.17822864 3.17846621 3.17850619 3.17890094 3.1791492
 3.17991767 3.1800028  3.18096612 3.18131181 3.18176775 3.18247246
 3.18261313 3.18264239 3.18302388 3.18315649 3.18332842 3.18369195
 3.18382382 3.18408614 3.18422909 3.18554008 3.18564753 3.186235
 3.18642096 3.18680084 3.18740687 3.18820563 3.18856952 3.18861371
 3.1887392  3.18874066 3.1887628  3.18879667 3.18886594 3.18898088
 3.18934918 3.19019293 3.19019869 3.19041356 3.19136037 3.1914539
 3.19147113 3.19171638 3.1921467  3.19278666 3.1928897  3.19343063
 3.19372537 3.19386293 3.19394753 3.19416372 3.19498169 3.19504053
 3.19544713 3.19615134 3.19630048 3.19630176 3.19635906 3.19654097
 3.19658655 3.19666552 3.19672057 3.19702751 3.19731239 3.19739587
 3.19741151 3.1976398  3.19834547 3.19861934 3.19881044 3.19912305
 3.19927163 3.19958281 3.19969009 3.20070575 3.20127879 3.20133659
 3.20134391 3.20194225 3.20210962 3.20240342 3.20264208 3.20315898
 3.20321664 3.20372577 3.20435453 3.20438331 3.204597   3.20475643
 3.20496862 3.20541459 3.20544672 3.20562784 3.20593387 3.20596734
 3.20597376 3.20633433 3.20696412 3.20708168 3.20713417 3.20714902
 3.20724202 3.20754889 3.20770646 3.20835805 3.20873697 3.20878264
 3.20885352 3.20897312 3.2090488  3.20925131 3.21007368 3.21022657
 3.21042274 3.21052212 3.21123238 3.21142763 3.21194422 3.21217167
 3.21233581 3.21245077 3.21272142 3.21296086 3.21322363 3.21329644
 3.21346914 3.21352602 3.21371335 3.21418687 3.21421074 3.21454417
 3.21506945 3.21548364 3.21572777 3.21593554 3.21637371 3.21654181
 3.21658721 3.21672741 3.21674988 3.21725982 3.21829663 3.21860658
 3.21955714 3.22010758 3.22054504 3.22248057 3.22272276 3.22279289
 3.22287718 3.22306993 3.22325398 3.22347128 3.22389647 3.22395427
 3.22456192 3.22508919 3.22512053 3.22635022 3.22698592 3.22802054
 3.22818688 3.22958378 3.22987753 3.23006994 3.23030442 3.23039126
 3.23176343 3.23257717 3.23352708 3.23368192 3.23396805 3.23421638
 3.23477437 3.23479941 3.23499846 3.23751864 3.2376559  3.23809546
 3.238271   3.23894886 3.24213477 3.24341221 3.24480013 3.24506736
 3.24519316 3.24534174 3.24597029 3.24602671 3.24651588 3.2466483
 3.24774647 3.24789177 3.24869339 3.24873086 3.24879364 3.24884626
 3.24934656 3.24967209 3.25143916 3.25327801 3.25363882 3.25467376
 3.25516136 3.25561876 3.25826024 3.25935298 3.25935441 3.26104469
 3.26205049 3.26211505 3.26650194 3.26990239 3.26999739 3.27009321
 3.27063362 3.27064466 3.2706502  3.27485307 3.27506115 3.2751804
 3.27657555 3.27718107 3.2778924  3.2782828  3.28097566 3.28129873
 3.28132029 3.28171614 3.28201382 3.28220262 3.28351795 3.28414577
 3.28658476 3.28681227 3.28743455 3.28846162 3.28944644 3.28960532
 3.2907148  3.29191092 3.29339456 3.29379851 3.29597637 3.29720611
 3.29808188 3.30031965 3.30220366 3.30554641 3.30594203 3.30683352
 3.30735073 3.30779703 3.30781614 3.30828407 3.31187045 3.31187596
 3.31229329 3.31248593 3.31400293 3.31401962 3.31506484 3.31682564
 3.317108   3.31800299 3.31817199 3.31835518 3.3202204  3.32179083
 3.32183205 3.32225986 3.32320852 3.32357422 3.32633198 3.3265111
 3.32737115 3.32841336 3.33006746 3.33095442 3.33433295 3.33506771
 3.33676668 3.3399717  3.34008148 3.34183925 3.34290239 3.34559139
 3.34631443 3.34644067 3.34652672 3.34863909 3.34939559 3.34965741
 3.350553   3.35062084 3.35078702 3.35165084 3.35177493 3.35320703
 3.35573792 3.355876   3.35600097 3.35791945 3.35901667 3.3593711
 3.3600611  3.36094773 3.36181656 3.36346346 3.36621492 3.36649836
 3.36690293 3.36712517 3.36749274 3.36778216 3.36782165 3.36836943
 3.36976937 3.36983119 3.37068678 3.37165041 3.37229731 3.37389034
 3.37741765 3.37830825 3.37838242 3.38065708 3.3811929  3.38286873
 3.38327537 3.3851947  3.3852372  3.3854951  3.38729417 3.3888908
 3.38953921 3.3905887  3.39152621 3.39677824 3.39955182 3.40055074
 3.40173935 3.40491815 3.40520419 3.40562395 3.40785518 3.40923771
 3.41149053 3.41217811 3.41435782 3.41436183 3.4180603  3.4231471
 3.42511112 3.42932673 3.4310018  3.43949096 3.43964018 3.44270965
 3.45097594 3.45101019 3.46113165 3.46607685 3.47412794 3.47774218
 3.49454236 3.49557251 3.49921514 3.50148608 3.50376274 3.50581063
 3.50714807 3.51917405 3.52582288 3.52735492 3.52795094 3.53883523
 3.63248934 3.64762335 3.76370069 3.78843252 3.79494701 3.80750436
 3.80969975 3.82744728 3.83914908 3.83926764 3.84670777 3.85286511
 3.86015084 3.86249933 3.86792939 3.89852098 3.91980661 3.9278967
 4.34520807 4.40544857 4.46827755 4.54226533 4.70776782 4.75100153
 4.76526914 4.81337985 4.81345216 4.81401156 4.81402184 4.81453379
 4.81543264 4.81930655 4.81934298 4.81976957 4.82485893 4.82638798
 4.82915517 4.83275898 4.83445513 4.84298377 4.84892965 4.85122245
 4.85323066 4.87053369 4.87940925 4.91661679 4.92822554 4.93225239
 4.94794305 4.9506194  4.97656626]

  warnings.warn(

2022-12-16 10:36:32,346:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.88253109 1.92605627 1.92795054 1.9886782  1.99433162 2.03931726
 2.64662359 2.73467921 2.80970217 2.82457461 2.85618309 2.85644246
 2.86187658 2.87215304 2.87934099 2.88007329 2.88221848 2.88455439
 2.89041583 2.89252698 2.89395214 2.90146083 2.90628634 2.91298758
 2.91379113 2.91695337 2.92247684 2.92815684 2.93038457 2.93280228
 2.93307601 2.93343337 2.94268772 2.94300782 2.945578   2.94675769
 2.94749474 2.95361778 2.95394572 2.95538801 2.95630638 2.95669565
 2.96054463 2.96321439 2.96340954 2.96612024 2.9664286  2.96708653
 2.968377   2.97498964 2.97513949 2.97779376 2.98015829 2.98091424
 2.98098248 2.98148851 2.98291985 2.98479537 2.98484708 2.9850938
 2.98596581 2.98625229 2.98662629 2.98814515 2.98859101 2.99262522
 2.99298091 2.99493689 2.99541791 2.99969963 3.00034369 3.000747
 3.0008608  3.00292954 3.00359313 3.00384943 3.0041957  3.00502741
 3.00668781 3.00884762 3.00892157 3.01037924 3.01145343 3.01261717
 3.01301221 3.01425979 3.0148889  3.0161299  3.01617212 3.01650351
 3.01836749 3.01988864 3.0202367  3.02047607 3.02145089 3.02271516
 3.02422921 3.0250702  3.02729263 3.02818159 3.03045292 3.03205379
 3.03533492 3.03708326 3.03708658 3.03763872 3.03863629 3.03895502
 3.03931175 3.03986661 3.04005951 3.04032454 3.04070879 3.04253141
 3.04271766 3.04363706 3.04544897 3.04587724 3.05046413 3.05163311
 3.05174826 3.05180446 3.05223985 3.05305985 3.05552536 3.05934645
 3.05938742 3.06031395 3.06037779 3.06182068 3.06549651 3.06664139
 3.06835702 3.0697839  3.06992573 3.07037566 3.07213153 3.07323522
 3.07374407 3.07856964 3.07894226 3.08202864 3.08230082 3.08338726
 3.08406699 3.08469229 3.08483093 3.08588864 3.08625409 3.08710332
 3.08724814 3.08751221 3.08823177 3.08882668 3.08902612 3.09007181
 3.09187517 3.0919294  3.093108   3.09442701 3.09464639 3.09472146
 3.09538742 3.09630406 3.0973436  3.09758948 3.09830016 3.10030518
 3.10059312 3.1006373  3.10109468 3.10258055 3.1028135  3.1035381
 3.10486612 3.1055153  3.10566179 3.10658602 3.10724067 3.1085397
 3.10907205 3.10946185 3.10978205 3.10988552 3.11001148 3.110385
 3.11184667 3.1120538  3.11240077 3.11268132 3.11295617 3.11443483
 3.11468419 3.11625331 3.11762332 3.11801542 3.11828471 3.11837224
 3.11848863 3.11906682 3.11923425 3.11949922 3.11994368 3.12027764
 3.12031092 3.1210339  3.12144738 3.12184098 3.12390802 3.12484613
 3.12494293 3.12497536 3.12562635 3.12572732 3.12580901 3.12601356
 3.12602447 3.12618065 3.12683679 3.12706357 3.12773959 3.1277571
 3.12830295 3.12921671 3.12929243 3.12930039 3.1296791  3.12984696
 3.12992425 3.12993628 3.13181953 3.13271494 3.13336016 3.13353659
 3.13375447 3.13389474 3.1339389  3.13409229 3.13410346 3.13411086
 3.13469464 3.13473078 3.13517002 3.13595547 3.1370428  3.13725158
 3.13738956 3.13834806 3.13866486 3.13914786 3.14004296 3.14014393
 3.14046855 3.14073417 3.14093963 3.14202703 3.142327   3.14293312
 3.14293919 3.14339784 3.14477377 3.14496467 3.14584086 3.14681342
 3.14715324 3.14719343 3.14750807 3.14828207 3.14967751 3.15122935
 3.15186473 3.15217705 3.15292914 3.15346066 3.15381777 3.15427855
 3.15431684 3.15468077 3.15502584 3.15526359 3.15588658 3.15623689
 3.15694079 3.15727259 3.15727743 3.15736829 3.15755359 3.1576477
 3.15789715 3.15854755 3.15862689 3.15877355 3.15921809 3.15936189
 3.15961345 3.15980817 3.15998274 3.16040827 3.16060363 3.1609265
 3.16096592 3.16120995 3.16154343 3.16163326 3.16177308 3.16244285
 3.16268694 3.16299524 3.16307625 3.16311403 3.16314688 3.16331795
 3.16335509 3.1633675  3.16340309 3.16405624 3.16409383 3.16421415
 3.16434384 3.16435854 3.16456406 3.16477263 3.1653396  3.16564485
 3.16575723 3.16579036 3.16624666 3.166505   3.1665435  3.16667716
 3.1666857  3.16682093 3.16719098 3.16797628 3.16907311 3.16910312
 3.16911672 3.16949172 3.169561   3.17045849 3.17068171 3.17083228
 3.17113789 3.17129565 3.17151439 3.17170558 3.17230583 3.17283237
 3.17311252 3.17385271 3.17433634 3.1745276  3.17454111 3.17473824
 3.17489062 3.17494216 3.17505563 3.17530194 3.17563744 3.1764731
 3.17674185 3.17678236 3.17714973 3.17783663 3.17807589 3.1784848
 3.17851713 3.17859869 3.17872283 3.17879467 3.1788846  3.17898307
 3.17899224 3.17910377 3.17922792 3.17936834 3.17945887 3.17956165
 3.17979844 3.17996395 3.18074128 3.18116685 3.18136989 3.18141101
 3.18149793 3.18164604 3.18174299 3.18175839 3.18198527 3.18215663
 3.18220176 3.18222236 3.18227302 3.18247029 3.1827309  3.18283324
 3.18302967 3.18328958 3.18370274 3.18374022 3.18386763 3.18419113
 3.18432186 3.18433411 3.18475241 3.18495224 3.18520954 3.18536227
 3.185566   3.18582662 3.18595837 3.1865422  3.1867842  3.18693828
 3.18716295 3.1871778  3.18718836 3.18726527 3.18738505 3.18739075
 3.18755467 3.18769378 3.18885643 3.1890463  3.18932832 3.1897046
 3.18980231 3.19010779 3.19033343 3.19047509 3.19076336 3.19127567
 3.19162373 3.192515   3.19290557 3.19320393 3.193499   3.19398762
 3.19404969 3.19410151 3.19508186 3.19591438 3.19600248 3.19603158
 3.19613234 3.19633889 3.19656535 3.19696561 3.19718452 3.19731139
 3.19771123 3.19789973 3.19813671 3.19851286 3.19871053 3.19884147
 3.19940271 3.19962628 3.19970464 3.19985306 3.20009704 3.20067611
 3.20071894 3.20101847 3.20105584 3.20115012 3.20125384 3.20128823
 3.20146087 3.2018281  3.20202836 3.20243236 3.20254148 3.20296655
 3.20346878 3.20347013 3.20355447 3.20356509 3.20409735 3.20413948
 3.20422327 3.2044499  3.20450287 3.20473779 3.20480673 3.20522105
 3.20589266 3.20608166 3.20640451 3.20648869 3.20665    3.20672873
 3.20674011 3.20697127 3.20709645 3.20725472 3.20786442 3.20891395
 3.20905348 3.20949319 3.20979073 3.20989124 3.21001628 3.21002185
 3.21060859 3.21072346 3.2109174  3.21094114 3.21327361 3.2135196
 3.21362047 3.21423351 3.21457028 3.21459776 3.21470014 3.21480726
 3.21489912 3.21493515 3.21506809 3.21537101 3.21545677 3.21552596
 3.21574389 3.21603994 3.21615203 3.21624314 3.21629734 3.216473
 3.21666057 3.21671989 3.21689692 3.217482   3.21783424 3.21790842
 3.21842039 3.21892901 3.21926871 3.21989609 3.22033202 3.2205695
 3.22109749 3.22204501 3.22209786 3.22216716 3.22235096 3.2223635
 3.22256713 3.22259042 3.22268546 3.2227098  3.22290063 3.22317624
 3.22371533 3.22443866 3.2245585  3.22477839 3.2249286  3.22531354
 3.2257408  3.22738975 3.2283595  3.229217   3.22922889 3.2298372
 3.2299047  3.23066648 3.23105842 3.23206636 3.23232647 3.23263995
 3.23275211 3.23288967 3.23305722 3.23443181 3.23517824 3.23592733
 3.23606737 3.23623179 3.23631434 3.23688417 3.23752785 3.23771698
 3.23802079 3.23814056 3.24133392 3.24152976 3.24154393 3.24211773
 3.24314155 3.24362529 3.24409255 3.24423809 3.24500987 3.24525739
 3.24586497 3.24690093 3.24756131 3.24801919 3.24949731 3.2501094
 3.25011896 3.25110528 3.25257185 3.25262244 3.25335715 3.25378033
 3.25388731 3.25448153 3.25464617 3.25471657 3.25579474 3.25583577
 3.25682394 3.25868792 3.25881257 3.2594361  3.26034469 3.26047567
 3.26089115 3.2609341  3.26167747 3.26178512 3.26219584 3.26221607
 3.26333895 3.26335938 3.26572032 3.26655271 3.26719198 3.26760694
 3.26776336 3.26782571 3.26808993 3.2711925  3.27125012 3.27135578
 3.27155217 3.27165625 3.27265392 3.27339864 3.2747642  3.27585792
 3.2765329  3.27670334 3.27675167 3.27822117 3.28024697 3.28067234
 3.28087973 3.28113681 3.28182375 3.28232683 3.28277129 3.28460116
 3.28491637 3.28550589 3.28638541 3.28671652 3.28675912 3.28684654
 3.28685363 3.28718396 3.28888001 3.28993156 3.29090739 3.29107639
 3.29196718 3.29200786 3.2933875  3.293445   3.29466325 3.29468755
 3.2948849  3.29573549 3.29602386 3.29802466 3.2985014  3.29877599
 3.29978655 3.30015779 3.30347918 3.30353362 3.30444853 3.30640522
 3.30992044 3.31031036 3.31118091 3.31228819 3.3156399  3.31686508
 3.31783687 3.31932237 3.32238354 3.32321195 3.32384648 3.32442889
 3.32584679 3.32595729 3.32652391 3.32678059 3.3271202  3.32897111
 3.33164002 3.33392568 3.34082027 3.34099011 3.3440845  3.3443969
 3.35325448 3.35460531 3.35501654 3.35664933 3.35729879 3.35871912
 3.35892903 3.35903517 3.36041985 3.36084379 3.36258907 3.36308909
 3.3642541  3.36469653 3.3672031  3.36947425 3.36947651 3.37050144
 3.37172885 3.37571918 3.37630134 3.37794844 3.37892503 3.37987904
 3.38092383 3.38175347 3.38209197 3.38220675 3.3824913  3.38295015
 3.38335549 3.38412262 3.38570274 3.38619985 3.38641303 3.3864278
 3.38702945 3.38831534 3.38919408 3.38968277 3.39074134 3.39146569
 3.39617586 3.3964287  3.39749331 3.39973498 3.40014991 3.40223202
 3.40248807 3.40401628 3.40599935 3.41030221 3.41219795 3.41595875
 3.41800475 3.41942477 3.41989029 3.42177181 3.42212349 3.42676128
 3.42880066 3.4288857  3.43121249 3.43125629 3.43136797 3.43149308
 3.43170295 3.4342468  3.43583783 3.43969414 3.44041883 3.46209623
 3.47048059 3.47399426 3.47997097 3.48131915 3.50120199 3.51106158
 3.52088189 3.53808984 3.53892732 3.57611788 3.57863831 3.58353917
 3.59716101 3.61646699 3.62124632 3.63891587 3.64468943 3.64875158
 3.71121756 3.75883255 3.76073041 3.76125584 3.78106113 3.79154193
 3.79823279 3.80279119 3.8064079  3.81360102 3.81440689 3.82194803
 3.82565435 3.82956024 3.83163987 3.8365018  3.84681394 3.87428205
 3.88922438 3.93478314 3.98181472 4.01870283 4.10844516 4.11322597
 4.21660965 4.34067556 4.37887942 4.7684047  4.76940015 4.77464083
 4.78086556 4.78989241 4.79615525 4.80320306 4.80387887 4.80628763
 4.8196013  4.82075827 4.82669256 4.82781429 4.82887429 4.83377816
 4.83423739 4.8360873  4.83934702 4.85475171 4.85803003 4.87200195
 4.87409477 4.87774342 4.89048519 4.89265858 4.89862809 4.89922107
 4.91167775 4.91397481 4.91424053 4.92487097 4.99492635 5.00544641]

  warnings.warn(

2022-12-16 10:36:33,688:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.57374427 1.57512368 1.85726675 1.89359301 1.91757446 1.91775961
 1.93255168 1.95052496 1.95536736 1.9702535  1.97527244 1.98879804
 2.03468913 2.1604539  2.59695367 2.74274711 2.75665157 2.80550486
 2.81230433 2.81361272 2.82653366 2.83880108 2.84675252 2.84831988
 2.86952576 2.87856388 2.8792934  2.88635223 2.90670762 2.91115727
 2.91190066 2.91507362 2.91738759 2.91888366 2.93315352 2.93681722
 2.93687611 2.94045939 2.94288601 2.94777898 2.94795312 2.94827972
 2.94859889 2.94919771 2.95189478 2.95197868 2.95210903 2.95285616
 2.95450881 2.95533377 2.95656239 2.95670494 2.95977785 2.96344235
 2.96420189 2.96580321 2.96935927 2.97009758 2.97221939 2.97337912
 2.9738766  2.97537078 2.97575688 2.9758497  2.97622434 2.97640625
 2.97731749 2.97743657 2.97746628 2.97760828 2.97996114 2.97996563
 2.98038216 2.98046493 2.98116573 2.98139077 2.98146345 2.98216492
 2.98225476 2.98225634 2.98238967 2.98277858 2.98320497 2.98364754
 2.9840135  2.9843282  2.98492547 2.98506181 2.98515629 2.98688799
 2.9878508  2.98895819 2.99047495 2.99206645 2.99357023 2.99396045
 2.99461252 2.99595076 2.99680301 2.99770159 2.99869933 2.99898496
 2.99996029 3.00136059 3.00171635 3.00248666 3.00544008 3.00555388
 3.0056834  3.00581586 3.0062036  3.00649044 3.00692098 3.00766381
 3.01058837 3.01132646 3.01232196 3.01539247 3.01635777 3.01649324
 3.01686303 3.01687408 3.01751924 3.01938327 3.02012306 3.02201892
 3.02355069 3.02364443 3.02643465 3.02678359 3.02881968 3.03010151
 3.03263832 3.03353149 3.03611978 3.03655736 3.04178223 3.04253401
 3.04415837 3.04490372 3.04598778 3.04674502 3.04856625 3.05078391
 3.05091261 3.05809943 3.06010681 3.06100871 3.06318168 3.0640197
 3.06562869 3.06649663 3.06695645 3.06901641 3.07071183 3.07332943
 3.07379493 3.07683689 3.07777098 3.07883917 3.07900817 3.07916851
 3.07942461 3.08041514 3.08146814 3.08161739 3.08254514 3.08261396
 3.08531339 3.08874796 3.08906803 3.09312003 3.09376143 3.0938828
 3.09408505 3.09516462 3.09689594 3.0978006  3.10214337 3.10377396
 3.10391403 3.10440565 3.10471402 3.1047752  3.10479295 3.1054215
 3.10692666 3.10717988 3.10773508 3.10852548 3.11025123 3.11028431
 3.11056626 3.11079421 3.11085941 3.11147768 3.11157426 3.11208743
 3.11259876 3.11331171 3.11333452 3.11334539 3.11371354 3.1139927
 3.11483184 3.11498375 3.11519666 3.11662763 3.11676122 3.11918287
 3.12020723 3.12023766 3.1203738  3.1212759  3.121333   3.12201794
 3.12244887 3.12305788 3.12404989 3.12411356 3.12467698 3.12570525
 3.12633155 3.1267296  3.12810963 3.12831449 3.12836675 3.12889037
 3.12962098 3.13118744 3.13130011 3.13257344 3.13303313 3.1334403
 3.13386663 3.13404691 3.13441466 3.13546865 3.13560814 3.13631608
 3.13714194 3.13728961 3.1372942  3.13738634 3.13750678 3.13785675
 3.13862886 3.13867661 3.13904404 3.13909839 3.13969076 3.13980725
 3.14025688 3.14035562 3.14039985 3.14082353 3.14082848 3.14130636
 3.14162526 3.14173474 3.14200023 3.14208703 3.14260464 3.14280565
 3.14401232 3.14405359 3.14522055 3.14527022 3.14577571 3.14653254
 3.14691901 3.14761828 3.14816504 3.14825201 3.14873949 3.14998702
 3.15011069 3.15062639 3.15063454 3.15074376 3.15080338 3.15113868
 3.15129071 3.1514824  3.15149367 3.15176221 3.15225999 3.15229015
 3.15235489 3.15239461 3.15266796 3.15279673 3.15283116 3.15303197
 3.1531611  3.15328419 3.15340345 3.1534355  3.15354497 3.15354878
 3.15356068 3.1540743  3.15411504 3.15421737 3.15445083 3.1545167
 3.15453304 3.15475948 3.15478346 3.15592157 3.15609244 3.15655085
 3.15677926 3.15720305 3.15732766 3.1573414  3.15768163 3.15790026
 3.15791061 3.15798366 3.15856203 3.15865345 3.15928998 3.15978479
 3.1603684  3.16116516 3.16177187 3.1621501  3.16266374 3.163281
 3.16349583 3.16479478 3.16517284 3.16611306 3.16699204 3.1670228
 3.16707261 3.16875101 3.16933307 3.17050537 3.17079186 3.17132002
 3.17162039 3.17196819 3.17213814 3.17213918 3.17218824 3.17239146
 3.17289164 3.17360107 3.17398398 3.17449414 3.1750025  3.17514325
 3.17517898 3.17519002 3.17595071 3.17599242 3.17626543 3.17638787
 3.1765721  3.17662918 3.17710674 3.1774429  3.1775156  3.17753056
 3.17754159 3.17764099 3.17784186 3.17799512 3.17816547 3.17824512
 3.17862633 3.17869595 3.17870916 3.17888539 3.17907167 3.17913324
 3.17934191 3.17937244 3.17940144 3.1797225  3.17979097 3.18000334
 3.18042581 3.18076515 3.18082068 3.18111998 3.18130685 3.18140493
 3.18153537 3.18200506 3.18227738 3.18236945 3.182377   3.18247534
 3.18262114 3.18278507 3.18291769 3.18337003 3.18349608 3.18351411
 3.18361757 3.1838168  3.18392565 3.18398229 3.18400069 3.18402401
 3.18407098 3.18437998 3.18438432 3.18492464 3.1851095  3.185339
 3.18546447 3.18578243 3.1864501  3.18651126 3.18655311 3.18758248
 3.18765324 3.18773039 3.18826047 3.18851784 3.18924903 3.18926678
 3.18953146 3.18976854 3.19102449 3.19127462 3.19161553 3.1919778
 3.19208474 3.19268461 3.1927431  3.19304087 3.19320663 3.19342018
 3.19350406 3.19375324 3.19385368 3.19432945 3.19438611 3.19442685
 3.19442871 3.19475639 3.19508792 3.19533687 3.19553537 3.19656563
 3.1969807  3.19729289 3.19752902 3.19768644 3.19781066 3.1978936
 3.19847271 3.19918853 3.19920321 3.1994632  3.19952129 3.20002661
 3.20016723 3.20086522 3.20097939 3.20099742 3.20187733 3.20266637
 3.2026771  3.20277672 3.20289135 3.20292208 3.20303424 3.203089
 3.20312157 3.20316093 3.2035418  3.20356982 3.2035785  3.20461435
 3.20474819 3.20503412 3.20517476 3.20540344 3.20546172 3.20556477
 3.20579291 3.20582846 3.20589649 3.20601409 3.20616242 3.20626437
 3.206352   3.20672447 3.20690586 3.20719318 3.20722638 3.20726437
 3.20729233 3.20750622 3.2077004  3.20843699 3.20916651 3.20929145
 3.20930799 3.20960908 3.20985867 3.2104574  3.21097652 3.21110111
 3.21116323 3.21153819 3.2121564  3.21230906 3.21243011 3.21245882
 3.21336153 3.21340873 3.21346779 3.2142418  3.21513926 3.2152582
 3.21575914 3.21634809 3.21656274 3.21662887 3.21667992 3.21676292
 3.21697558 3.21831211 3.21844361 3.2191756  3.21953909 3.22000531
 3.22014886 3.22034352 3.2206599  3.22083819 3.22111726 3.22242187
 3.22243128 3.22267411 3.22282275 3.22300672 3.22311352 3.22392204
 3.2239396  3.2242125  3.22433158 3.22456094 3.22467352 3.22570183
 3.2257359  3.22600522 3.22602075 3.22650456 3.2267201  3.22691646
 3.22718679 3.2273254  3.22771868 3.22779802 3.2282302  3.22829224
 3.22853844 3.22874718 3.22919104 3.22935786 3.22971036 3.23057198
 3.23085734 3.23132898 3.23199437 3.23277718 3.23310306 3.23368939
 3.23433705 3.2352083  3.23624867 3.23676034 3.23733837 3.23802233
 3.23816809 3.23822952 3.23861245 3.24004339 3.2428699  3.24360844
 3.24446669 3.24461246 3.24485885 3.24736579 3.24890016 3.24905634
 3.24960289 3.25037314 3.25042565 3.25060777 3.25095627 3.25120437
 3.25315815 3.25417835 3.25423049 3.25487705 3.25576699 3.25594253
 3.25619603 3.25620152 3.25684905 3.25778454 3.25801153 3.25857441
 3.25949842 3.26377904 3.26384374 3.26452188 3.26499072 3.26532049
 3.26558259 3.26669919 3.26811574 3.26826995 3.26827132 3.26862074
 3.26955017 3.2702727  3.2728985  3.27334767 3.27390176 3.27470893
 3.27483839 3.27495694 3.27730762 3.27813851 3.28002237 3.2802973
 3.28381185 3.28495366 3.28516055 3.28779966 3.28866005 3.28897415
 3.28917034 3.29012768 3.29143329 3.29281972 3.2937056  3.29423782
 3.29432318 3.29479865 3.29575004 3.29783084 3.29901415 3.30186475
 3.30227155 3.30327101 3.30395927 3.30473955 3.30652956 3.3072491
 3.30741401 3.30777173 3.30870411 3.30870822 3.31198672 3.31243168
 3.31431876 3.31579605 3.31633737 3.31652885 3.3168148  3.31837214
 3.31848839 3.31850319 3.31949639 3.32036922 3.32045592 3.32146399
 3.32211171 3.32266198 3.32277062 3.32322834 3.32545102 3.32566986
 3.32864728 3.329192   3.32932884 3.32990141 3.33171923 3.3325738
 3.33372037 3.33446155 3.33480866 3.33494634 3.33589867 3.33661944
 3.33705729 3.33760381 3.33790207 3.33801478 3.3383152  3.33939229
 3.33990504 3.34123546 3.34225611 3.34264326 3.34265753 3.34374372
 3.34413285 3.3445167  3.34585859 3.34702799 3.34758457 3.34888966
 3.35006242 3.35226443 3.35354339 3.35402551 3.35675017 3.35723451
 3.35787159 3.35849365 3.36109031 3.36138572 3.36481127 3.36499203
 3.36892085 3.36999804 3.37021239 3.37049999 3.37067581 3.37068147
 3.37082592 3.37293958 3.37589339 3.37626183 3.37715777 3.37757881
 3.37762785 3.38099305 3.38152189 3.38223915 3.38264406 3.38572105
 3.38769247 3.38787789 3.38959992 3.39045222 3.39063786 3.39239327
 3.39282063 3.3935691  3.39400294 3.39454044 3.39460874 3.39568659
 3.39714438 3.40058669 3.40072067 3.40112249 3.40150994 3.40161671
 3.40540897 3.4061692  3.40699697 3.40916872 3.40948231 3.40949477
 3.41191992 3.41296743 3.41945961 3.42175415 3.425985   3.4341234
 3.44006779 3.44091823 3.44397999 3.44557978 3.44662361 3.44833026
 3.45924108 3.48501446 3.50054881 3.50681865 3.51408263 3.51582976
 3.51638002 3.51900656 3.51960465 3.52135989 3.52410159 3.52484622
 3.52961678 3.53072844 3.54143559 3.5578468  3.56900927 3.57360846
 3.60217205 3.62814653 3.64056631 3.65364342 3.6724451  3.67346695
 3.70089075 3.78677477 3.78772534 3.84215291 3.84434162 3.84735477
 3.86190219 3.86582222 3.87250627 3.90630704 3.93980009 3.96368964
 4.06325057 4.09889521 4.10550323 4.13640841 4.33601698 4.36400108
 4.72608627 4.75214135 4.77814631 4.78060082 4.78244605 4.80391726
 4.80670491 4.81109483 4.81119792 4.81460558 4.8148765  4.81601855
 4.82112721 4.82762157 4.8283723  4.82990362 4.8308859  4.83334829
 4.83395868 4.8383554  4.84031118 4.84157558 4.85148122 4.86420915
 4.86641934 4.89534139 4.9026702  4.91812744 4.93901606 4.95705604
 4.97601174 5.01814094 5.01843776 5.09425777]

  warnings.warn(

2022-12-16 10:36:33,698:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.91730759 2.48133698 2.85098738 2.85311168 2.85363722 2.85370106
 2.88798691 2.9057947  2.91433556 2.92003991 2.92836558 2.93218619
 2.93406404 2.93831475 2.93960618 2.94166734 2.94328954 2.94891874
 2.94977788 2.95009306 2.95227003 2.95247112 2.95285877 2.95297302
 2.95410316 2.95486043 2.95495924 2.95572014 2.95606319 2.95630197
 2.95650427 2.95861417 2.96136624 2.96165933 2.963575   2.96566636
 2.96567798 2.96766374 2.96940483 2.96951979 2.96959575 2.97026382
 2.97362111 2.97578082 2.97765863 2.98352062 2.98601147 2.98734017
 2.98818234 2.98855866 2.99022294 2.99081681 2.99162139 2.99300358
 2.9965203  2.99673294 2.99731279 2.99995991 3.00107594 3.00151336
 3.00189538 3.00210014 3.00300404 3.00682262 3.00758981 3.00822083
 3.0082611  3.00969971 3.01185492 3.01410394 3.01783226 3.0180351
 3.02204403 3.02290001 3.0241302  3.02522953 3.02547094 3.0256193
 3.03071845 3.03073041 3.03227849 3.03627741 3.03629966 3.03699008
 3.04071497 3.04168069 3.04299359 3.04419487 3.0483098  3.04885026
 3.05360012 3.05380104 3.05554929 3.05627385 3.05704845 3.05827328
 3.06601652 3.06636489 3.0671196  3.06873917 3.07173607 3.07206415
 3.07268048 3.07601627 3.08090429 3.08250191 3.08270094 3.08522645
 3.08712911 3.08930814 3.08964977 3.09063777 3.09200659 3.09205375
 3.09230898 3.0923346  3.09342487 3.09365589 3.09416432 3.09885861
 3.09901641 3.10095834 3.10162331 3.10600181 3.10618824 3.10632194
 3.10700686 3.10742714 3.10791454 3.10855629 3.10914969 3.1094379
 3.11052917 3.1115061  3.11214041 3.1123718  3.11329706 3.11344316
 3.11397783 3.11431474 3.11489778 3.11551703 3.11572303 3.11580203
 3.11625097 3.11649827 3.11726049 3.11848009 3.11922567 3.12038061
 3.12074309 3.12081768 3.12110854 3.12194725 3.12311242 3.12341296
 3.12372117 3.12463572 3.12580418 3.12621086 3.12688755 3.1279274
 3.12836444 3.12846622 3.12946207 3.12952349 3.12977822 3.12980076
 3.13000537 3.13026673 3.13033045 3.13163582 3.13289255 3.1331951
 3.13375618 3.13386179 3.13403793 3.13404222 3.13405435 3.13451003
 3.13531711 3.1354151  3.1354771  3.13555171 3.13556932 3.13557464
 3.13601721 3.13757898 3.13768816 3.13797599 3.1380957  3.13861019
 3.13878206 3.13883172 3.13896392 3.14014828 3.14129797 3.14138743
 3.14140488 3.14152359 3.14180707 3.14181032 3.14227474 3.14243273
 3.14253226 3.14256989 3.14262513 3.14274834 3.14412254 3.14422405
 3.14435804 3.14445856 3.14463567 3.14466962 3.14499115 3.14504821
 3.1455298  3.14613355 3.14664875 3.14672647 3.14705337 3.147208
 3.14727543 3.14747502 3.14777292 3.14809356 3.14814893 3.14821785
 3.14870432 3.14894442 3.14901159 3.14930824 3.14945493 3.14957722
 3.1496239  3.14985228 3.15000366 3.15011681 3.15017049 3.15046362
 3.15049612 3.1511957  3.15129167 3.15161277 3.15181095 3.15243605
 3.15250479 3.15263098 3.15274928 3.15311603 3.15325053 3.15353363
 3.15366902 3.15414583 3.15426581 3.15472035 3.15502984 3.15525863
 3.15563051 3.15563375 3.15574313 3.15592669 3.1559573  3.15600342
 3.1568625  3.15735189 3.15759882 3.15806376 3.1582693  3.15857383
 3.15877874 3.15895481 3.15917549 3.16043809 3.16058388 3.16084324
 3.16102956 3.1616279  3.16180211 3.1620319  3.16226877 3.16231914
 3.16249006 3.16264946 3.16272525 3.16302915 3.16314531 3.16316426
 3.16334171 3.16358022 3.16382063 3.16384066 3.16408    3.16441021
 3.16461703 3.1646282  3.16465263 3.16491137 3.16506947 3.16519448
 3.16571395 3.16574326 3.16582246 3.16584881 3.16618023 3.16714397
 3.16716549 3.16722821 3.16759532 3.16785593 3.16797795 3.168235
 3.16827458 3.16845698 3.16871836 3.16876706 3.16909226 3.16948802
 3.17015513 3.17030882 3.17040762 3.17054966 3.17112991 3.17127836
 3.17147553 3.17170419 3.1722599  3.17304231 3.17332983 3.17367334
 3.17393496 3.17438006 3.17462928 3.17467221 3.1747399  3.17520117
 3.17560851 3.17582742 3.175983   3.17599555 3.17617665 3.17664664
 3.17702123 3.17740977 3.17768595 3.17778957 3.17806307 3.17835624
 3.17859734 3.17867204 3.17887198 3.17901699 3.17904214 3.17907825
 3.17927207 3.1796592  3.18006755 3.18007526 3.18020413 3.18021644
 3.18041843 3.18055659 3.18066122 3.18079676 3.18085804 3.18092068
 3.18117793 3.1812744  3.1814071  3.18142516 3.18159594 3.18177751
 3.18184159 3.18252789 3.18291025 3.18346038 3.18462382 3.18465145
 3.18467103 3.18516336 3.18527116 3.18528384 3.18545287 3.18583229
 3.18613331 3.18630509 3.18679705 3.18763117 3.18774879 3.18808375
 3.18837382 3.1889961  3.18904865 3.18920984 3.18921086 3.18925665
 3.18952834 3.18980131 3.1898562  3.19001073 3.19007026 3.19047202
 3.19056128 3.19065953 3.19066915 3.19072758 3.19089334 3.19109704
 3.19187761 3.19191095 3.19212285 3.19221076 3.19234449 3.19249325
 3.19250274 3.1925704  3.19282379 3.19295118 3.19303254 3.19388565
 3.19398748 3.19403694 3.19407133 3.19412642 3.19451445 3.19452701
 3.19454217 3.19462909 3.19466003 3.19484491 3.1950124  3.19501253
 3.19506288 3.19520574 3.19532047 3.19534954 3.19543035 3.19564474
 3.19573477 3.1957701  3.19609873 3.19610269 3.19615265 3.19625572
 3.19694997 3.19698171 3.19724435 3.19752128 3.19754576 3.19760561
 3.19783143 3.1979889  3.19812014 3.19862512 3.19876719 3.19889306
 3.1995247  3.19959863 3.20018678 3.20029476 3.20039152 3.20051878
 3.20122343 3.20127912 3.20137804 3.20146494 3.20146784 3.20190961
 3.2024901  3.20253062 3.20255333 3.20275524 3.20307863 3.20331359
 3.20350675 3.20361583 3.20376271 3.20378426 3.20398062 3.20399578
 3.20442967 3.20452583 3.2045315  3.20538535 3.20548764 3.2057719
 3.20623708 3.20630551 3.20663566 3.206702   3.20703242 3.20704847
 3.2071248  3.20729446 3.20729536 3.20737248 3.20749753 3.20752672
 3.20787798 3.20795825 3.20802801 3.20821882 3.20835355 3.20907732
 3.20916676 3.20919783 3.20927605 3.20963438 3.20968769 3.21023701
 3.2106886  3.21081882 3.210987   3.21128422 3.21172375 3.21268477
 3.21274447 3.21339975 3.21362449 3.21387825 3.21434989 3.21450031
 3.21513251 3.21553825 3.21565558 3.21590158 3.21600728 3.21612836
 3.21615845 3.21636768 3.21674507 3.21675363 3.21721245 3.21721685
 3.21755037 3.21789616 3.21794713 3.21820496 3.21850133 3.21875102
 3.21897124 3.21921568 3.21955416 3.22004011 3.22015397 3.22019241
 3.22020752 3.22070261 3.22150046 3.22225233 3.22225623 3.22241823
 3.22247499 3.22268365 3.22330388 3.22331893 3.22336573 3.22395736
 3.22423997 3.22479779 3.225039   3.22527978 3.2254375  3.22595017
 3.22685137 3.22754706 3.22819316 3.22865105 3.2297245  3.22987721
 3.23011525 3.23037472 3.2303965  3.23041386 3.23178296 3.23217685
 3.23355982 3.23364566 3.23453221 3.23573406 3.23640683 3.23659072
 3.23659394 3.23665984 3.23760209 3.23783228 3.23820781 3.23880401
 3.23935254 3.23954705 3.23957055 3.2399887  3.24001478 3.24114328
 3.24225909 3.24330844 3.24379211 3.24382469 3.24504601 3.24608456
 3.24672139 3.24676198 3.24696183 3.24701583 3.24729986 3.247974
 3.24829278 3.24952102 3.24964359 3.2516076  3.25172901 3.25189712
 3.25219092 3.25258514 3.25285164 3.25334515 3.25369469 3.25441849
 3.25470251 3.25498896 3.2552524  3.25530224 3.25555952 3.25668432
 3.2567857  3.25725592 3.25758785 3.25806506 3.25829022 3.25871796
 3.25942661 3.2597534  3.26038463 3.26067996 3.26083822 3.26182862
 3.26305309 3.26424788 3.26447316 3.26529099 3.26578749 3.26756592
 3.26832462 3.26935178 3.26944686 3.27095962 3.27101299 3.27116969
 3.27164628 3.2718713  3.27264951 3.27310505 3.27326916 3.2734291
 3.27468421 3.27491707 3.2751584  3.27611427 3.27839331 3.27994494
 3.28158557 3.28159306 3.28211588 3.28317491 3.28453588 3.28662582
 3.28697193 3.28719075 3.28789582 3.28854489 3.28908892 3.28960745
 3.29214665 3.29398125 3.29400841 3.29533778 3.29552037 3.29626513
 3.29924542 3.30334561 3.30397831 3.30411541 3.30573307 3.30580875
 3.30624995 3.30634792 3.30656049 3.30779451 3.30845784 3.3089523
 3.30938198 3.3117305  3.3121011  3.31233886 3.31307586 3.31311645
 3.31588439 3.31956515 3.32058391 3.32144523 3.32437462 3.32619255
 3.32663985 3.32771063 3.32793319 3.32997786 3.33049677 3.33225386
 3.33354352 3.33356194 3.33376203 3.33654387 3.33781175 3.33803085
 3.33875168 3.33942908 3.33962469 3.33981237 3.3412158  3.34193921
 3.34242254 3.3429276  3.34335959 3.34613599 3.34703365 3.34877706
 3.34915535 3.35346619 3.35476509 3.35533912 3.35614689 3.3561682
 3.358657   3.35980521 3.36175335 3.36199314 3.36231709 3.36279242
 3.3628095  3.36462633 3.36487964 3.36540886 3.36584647 3.3687071
 3.36895022 3.37064124 3.37127552 3.37138586 3.37268135 3.37559972
 3.37627181 3.37862716 3.37886794 3.37889258 3.37912125 3.38004354
 3.38114994 3.38115354 3.38122329 3.38282739 3.38382797 3.38424779
 3.38807998 3.38881492 3.3904239  3.39053281 3.39077884 3.39179726
 3.39295558 3.39317155 3.3958393  3.3980632  3.40019528 3.40061555
 3.40206348 3.40322712 3.40323365 3.40354928 3.40373021 3.40710035
 3.40847717 3.41015775 3.41175435 3.41411001 3.41495297 3.4288146
 3.43038731 3.43676528 3.46495656 3.47170232 3.4870671  3.49122635
 3.50808106 3.53088044 3.5639493  3.56411475 3.57474987 3.58940183
 3.5927387  3.59566536 3.59593078 3.6130425  3.62468276 3.64976172
 3.65570132 3.74578578 3.7459236  3.75893109 3.76319494 3.76919798
 3.7748822  3.78227865 3.78938893 3.79484671 3.81766891 4.17775273
 4.21982199 4.24264932 4.32256607 4.3566566  4.38952728 4.69608791
 4.70138728 4.70884512 4.71391374 4.75446355 4.75795475 4.77357279
 4.77498528 4.77669403 4.7845254  4.78623578 4.79362557 4.79732899
 4.79764736 4.79931059 4.8021177  4.80231661 4.80267166 4.80608025
 4.80727961 4.8157197  4.81770946 4.81812892 4.81939171 4.82211786
 4.8231859  4.82683459 4.82721452 4.82786229 4.83382077 4.84483277
 4.89255898 4.92293766 4.9576577  4.997099  ]

  warnings.warn(

2022-12-16 10:36:33,700:INFO:Calculating mean and std
2022-12-16 10:36:33,702:INFO:Creating metrics dataframe
2022-12-16 10:36:33,712:INFO:Uploading results into container
2022-12-16 10:36:33,714:INFO:Uploading model into container now
2022-12-16 10:36:33,715:INFO:master_model_container: 6
2022-12-16 10:36:33,715:INFO:display_container: 2
2022-12-16 10:36:33,717:INFO:Ridge(random_state=5099)
2022-12-16 10:36:33,717:INFO:create_model() successfully completed......................................
2022-12-16 10:36:33,934:ERROR:create_model() for Ridge(random_state=5099) raised an exception or returned all 0.0:
2022-12-16 10:36:33,935:ERROR:Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 795, in compare_models
    assert (
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 811, in compare_models
    assert (
AssertionError

2022-12-16 10:36:33,935:INFO:Initializing Elastic Net
2022-12-16 10:36:33,935:INFO:Total runtime is 0.6112797180811564 minutes
2022-12-16 10:36:33,935:INFO:SubProcess create_model() called ==================================
2022-12-16 10:36:33,936:INFO:Initializing create_model()
2022-12-16 10:36:33,936:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002281239F8E0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022810EC8B20>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:36:33,936:INFO:Checking exceptions
2022-12-16 10:36:33,942:INFO:Importing libraries
2022-12-16 10:36:33,942:INFO:Copying training dataset
2022-12-16 10:36:33,951:INFO:Defining folds
2022-12-16 10:36:33,951:INFO:Declaring metric variables
2022-12-16 10:36:33,951:INFO:Importing untrained model
2022-12-16 10:36:33,952:INFO:Elastic Net Imported successfully
2022-12-16 10:36:33,952:INFO:Starting cross validation
2022-12-16 10:36:33,955:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:36:35,903:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.27146172]

  warnings.warn(

2022-12-16 10:36:35,952:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.26859131]

  warnings.warn(

2022-12-16 10:36:35,978:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.2657559]

  warnings.warn(

2022-12-16 10:36:36,067:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.25673412]

  warnings.warn(

2022-12-16 10:36:36,078:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.27104008]

  warnings.warn(

2022-12-16 10:36:36,082:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.26511148]

  warnings.warn(

2022-12-16 10:36:36,128:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.26446707]

  warnings.warn(

2022-12-16 10:36:36,197:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.26214718]

  warnings.warn(

2022-12-16 10:36:37,322:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.26562701]

  warnings.warn(

2022-12-16 10:36:37,332:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.26072948]

  warnings.warn(

2022-12-16 10:36:37,333:INFO:Calculating mean and std
2022-12-16 10:36:37,335:INFO:Creating metrics dataframe
2022-12-16 10:36:37,339:INFO:Uploading results into container
2022-12-16 10:36:37,339:INFO:Uploading model into container now
2022-12-16 10:36:37,340:INFO:master_model_container: 7
2022-12-16 10:36:37,340:INFO:display_container: 2
2022-12-16 10:36:37,340:INFO:ElasticNet(random_state=5099)
2022-12-16 10:36:37,341:INFO:create_model() successfully completed......................................
2022-12-16 10:36:37,481:WARNING:create_model() for ElasticNet(random_state=5099) raised an exception or returned all 0.0, trying without fit_kwargs:
2022-12-16 10:36:37,481:WARNING:Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 795, in compare_models
    assert (
AssertionError

2022-12-16 10:36:37,481:INFO:Initializing create_model()
2022-12-16 10:36:37,481:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002281239F8E0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022810EC8B20>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:36:37,482:INFO:Checking exceptions
2022-12-16 10:36:37,484:INFO:Importing libraries
2022-12-16 10:36:37,484:INFO:Copying training dataset
2022-12-16 10:36:37,488:INFO:Defining folds
2022-12-16 10:36:37,488:INFO:Declaring metric variables
2022-12-16 10:36:37,489:INFO:Importing untrained model
2022-12-16 10:36:37,489:INFO:Elastic Net Imported successfully
2022-12-16 10:36:37,489:INFO:Starting cross validation
2022-12-16 10:36:37,491:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:36:39,478:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.27146172]

  warnings.warn(

2022-12-16 10:36:39,553:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.2657559]

  warnings.warn(

2022-12-16 10:36:39,610:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.27104008]

  warnings.warn(

2022-12-16 10:36:39,642:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.26859131]

  warnings.warn(

2022-12-16 10:36:39,728:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.25673412]

  warnings.warn(

2022-12-16 10:36:39,751:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.26511148]

  warnings.warn(

2022-12-16 10:36:39,765:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.26446707]

  warnings.warn(

2022-12-16 10:36:39,797:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.26214718]

  warnings.warn(

2022-12-16 10:36:40,548:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.26072948]

  warnings.warn(

2022-12-16 10:36:40,567:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.26562701]

  warnings.warn(

2022-12-16 10:36:40,568:INFO:Calculating mean and std
2022-12-16 10:36:40,569:INFO:Creating metrics dataframe
2022-12-16 10:36:40,577:INFO:Uploading results into container
2022-12-16 10:36:40,578:INFO:Uploading model into container now
2022-12-16 10:36:40,578:INFO:master_model_container: 8
2022-12-16 10:36:40,578:INFO:display_container: 2
2022-12-16 10:36:40,579:INFO:ElasticNet(random_state=5099)
2022-12-16 10:36:40,579:INFO:create_model() successfully completed......................................
2022-12-16 10:36:40,729:ERROR:create_model() for ElasticNet(random_state=5099) raised an exception or returned all 0.0:
2022-12-16 10:36:40,729:ERROR:Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 795, in compare_models
    assert (
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 811, in compare_models
    assert (
AssertionError

2022-12-16 10:36:40,729:INFO:Initializing Least Angle Regression
2022-12-16 10:36:40,729:INFO:Total runtime is 0.7245114207267762 minutes
2022-12-16 10:36:40,729:INFO:SubProcess create_model() called ==================================
2022-12-16 10:36:40,730:INFO:Initializing create_model()
2022-12-16 10:36:40,730:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002281239F8E0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022810EC8B20>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:36:40,730:INFO:Checking exceptions
2022-12-16 10:36:40,734:INFO:Importing libraries
2022-12-16 10:36:40,734:INFO:Copying training dataset
2022-12-16 10:36:40,740:INFO:Defining folds
2022-12-16 10:36:40,740:INFO:Declaring metric variables
2022-12-16 10:36:40,740:INFO:Importing untrained model
2022-12-16 10:36:40,741:INFO:Least Angle Regression Imported successfully
2022-12-16 10:36:40,741:INFO:Starting cross validation
2022-12-16 10:36:40,742:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:36:42,320:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:36:42,403:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:36:42,479:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:36:42,522:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:36:42,524:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:36:42,575:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:36:42,663:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:36:42,671:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:36:42,690:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.552531   1.56467038 1.59033579 1.73910471 1.78661731 1.8341153
 1.835671   1.83732994 1.84980316 1.877411   1.9044356  2.06936281
 2.40069236 2.67731307 2.82516621 2.88535327 2.88872943 2.89317987
 2.90474467 2.90551601 2.9056882  2.91196396 2.91246877 2.91508491
 2.91603287 2.91862225 2.92229327 2.93076166 2.93500176 2.93635454
 2.93929335 2.94768077 2.9514766  2.95172319 2.95374071 2.95469232
 2.95725359 2.96386456 2.96466542 2.96842579 2.97069105 2.97156934
 2.97256881 2.97488625 2.97579023 2.97596245 2.97603506 2.97655031
 2.97936121 2.97991995 2.98142739 2.982066   2.9839014  2.98521988
 2.98630791 2.98807401 2.98815904 2.98877966 2.98928759 2.98945592
 2.99174499 2.99415341 2.99605068 2.99608737 2.9967802  2.9992121
 2.99929628 2.99998368 3.00008934 3.00152775 3.00162066 3.00272804
 3.00307775 3.00406496 3.00451295 3.00504455 3.00704805 3.00812309
 3.00858496 3.00960643 3.01123367 3.01154354 3.0123489  3.01517616
 3.0160732  3.01745928 3.01746127 3.01803186 3.01899818 3.01913571
 3.01983643 3.01986657 3.02296476 3.02309714 3.02538805 3.02633821
 3.02705241 3.02772335 3.02807756 3.02957367 3.02960894 3.0314714
 3.03175387 3.03232996 3.03351356 3.03496627 3.03519163 3.03637164
 3.03778457 3.037933   3.03971312 3.04022658 3.04031028 3.04150676
 3.04187782 3.0421388  3.04236693 3.04274962 3.04301673 3.04449009
 3.04458606 3.04487041 3.04572234 3.04649398 3.04654759 3.04923857
 3.04935941 3.04947848 3.05067867 3.05205469 3.05447946 3.05499235
 3.05499891 3.05502462 3.05633472 3.05696223 3.05702209 3.05824595
 3.0588903  3.05939414 3.06058758 3.06077244 3.06235282 3.06628472
 3.06652632 3.06754955 3.07098689 3.07136777 3.07185131 3.07240795
 3.07296006 3.07421617 3.07778068 3.07801945 3.07821745 3.07839732
 3.07957509 3.08005171 3.08065968 3.08096584 3.08180356 3.08291497
 3.08384577 3.08432776 3.08454955 3.08532632 3.08546301 3.08575408
 3.08674452 3.08706711 3.08724238 3.08795611 3.08892271 3.09016118
 3.0902469  3.09144888 3.09175227 3.09185525 3.09193155 3.0920396
 3.09422731 3.09514913 3.09547133 3.09547823 3.09644964 3.09680011
 3.09694934 3.09734847 3.09866506 3.09867086 3.09921197 3.09951996
 3.10007184 3.10010321 3.10019814 3.10081295 3.10143657 3.10145309
 3.10158058 3.10163181 3.10184062 3.1019589  3.10326861 3.1033698
 3.10446663 3.10447251 3.1058165  3.10615112 3.11006511 3.11027156
 3.11322366 3.11407513 3.11435573 3.1153886  3.1155107  3.11588482
 3.11607185 3.11687615 3.11717857 3.11764037 3.11777426 3.11868773
 3.11996934 3.11997462 3.12029929 3.12038797 3.1207233  3.12116569
 3.12185808 3.12214892 3.12267329 3.1237192  3.12645567 3.1269826
 3.12759412 3.12791639 3.12854681 3.12967773 3.12983204 3.13010851
 3.13012194 3.13205684 3.13261283 3.13281598 3.13294603 3.13508461
 3.135232   3.13571824 3.13639317 3.13662367 3.13716144 3.13748851
 3.13758106 3.1383226  3.13894781 3.13897886 3.13967538 3.14009336
 3.14018143 3.14111428 3.14119563 3.14149573 3.14164148 3.14222561
 3.14226273 3.14229538 3.14250334 3.14290974 3.14355908 3.14362345
 3.14443168 3.14461377 3.14462715 3.14572191 3.14589246 3.14668768
 3.14774588 3.14789672 3.14822394 3.14828344 3.14876358 3.14887429
 3.14905446 3.14955442 3.14982484 3.1511433  3.15133826 3.15181432
 3.15197014 3.15232465 3.15282406 3.15334079 3.1538929  3.15394633
 3.15472877 3.15505849 3.15512569 3.15528528 3.1553233  3.15609571
 3.15657177 3.15752641 3.15802232 3.15847807 3.158692   3.15937954
 3.15943235 3.15950092 3.15977422 3.15996265 3.16102714 3.16126309
 3.16132254 3.1615562  3.16168338 3.16179043 3.16223419 3.16225495
 3.1636274  3.16378292 3.16444982 3.16446392 3.16503723 3.16510023
 3.16539957 3.16558278 3.16570903 3.16587098 3.16637994 3.16677069
 3.16704962 3.16706596 3.16717737 3.16718558 3.16754553 3.16764923
 3.16778814 3.1687824  3.16913135 3.16961092 3.1702292  3.17050989
 3.17081486 3.17118938 3.1712503  3.17129187 3.1714136  3.17170256
 3.17208145 3.17236595 3.17278869 3.17300353 3.17338658 3.17355835
 3.17367149 3.17420177 3.17422461 3.17467737 3.17487778 3.17543307
 3.17544678 3.17564445 3.17603623 3.17607592 3.17622675 3.17650178
 3.17687291 3.17694152 3.17715499 3.17786865 3.17794942 3.17807842
 3.17835323 3.17859531 3.1786548  3.17865605 3.17871551 3.17879015
 3.17985612 3.18024162 3.1804416  3.18067117 3.18074385 3.18075031
 3.18100594 3.18151623 3.18164779 3.18195822 3.18205908 3.18215817
 3.18278422 3.18322292 3.18333633 3.18343205 3.18345844 3.18367723
 3.18390663 3.18396154 3.18417317 3.18442317 3.18562629 3.1860676
 3.18794444 3.18804176 3.18804338 3.18838666 3.18861666 3.18886423
 3.18901224 3.18947622 3.19003367 3.19010591 3.19028256 3.19054377
 3.19070684 3.19103537 3.19121025 3.19199956 3.19216665 3.19223245
 3.19272538 3.19308832 3.19342046 3.19376759 3.19403746 3.19487328
 3.19594547 3.19670559 3.19671621 3.1969496  3.1969991  3.19759537
 3.19771268 3.19802669 3.19878923 3.19909105 3.19933931 3.19938583
 3.1997326  3.20010631 3.20050255 3.20132462 3.20144594 3.20168781
 3.20254625 3.20377293 3.20385629 3.20406614 3.20442401 3.20470947
 3.20478938 3.20483922 3.20550158 3.2056212  3.20584491 3.2059935
 3.20612593 3.20616164 3.2065794  3.20728672 3.20734884 3.20752822
 3.20756806 3.20784017 3.20830468 3.20843645 3.20849953 3.20857627
 3.20866192 3.20887752 3.20891143 3.20927857 3.2096601  3.21015225
 3.2102683  3.21082648 3.21102742 3.21157633 3.21207263 3.21275778
 3.21280286 3.21282573 3.21294108 3.21335551 3.21348493 3.2138825
 3.21410417 3.21494566 3.2150736  3.21535685 3.21586038 3.21592421
 3.21638498 3.21655466 3.21716361 3.21737551 3.21749881 3.21829981
 3.21898366 3.21925054 3.21927524 3.2194657  3.21974186 3.21999593
 3.22013455 3.22066842 3.22089814 3.22184909 3.22185979 3.22218568
 3.22222876 3.22238277 3.22243312 3.22262431 3.22285788 3.22318963
 3.22335894 3.22340113 3.22340922 3.22362756 3.22379869 3.22390552
 3.22439452 3.22520352 3.22525865 3.22534117 3.22535282 3.22589329
 3.22602443 3.22609048 3.22737218 3.22758065 3.22808982 3.22811481
 3.22842191 3.22878983 3.22927494 3.2294147  3.2302584  3.23029768
 3.23065638 3.23107988 3.23143975 3.23206116 3.23259834 3.23271743
 3.23286523 3.23413101 3.23442511 3.2344972  3.23485492 3.23564462
 3.23571832 3.23574212 3.23581724 3.23608584 3.23625224 3.23637051
 3.23692944 3.23717708 3.23733355 3.23734079 3.23750253 3.23772693
 3.23781305 3.23792018 3.23818724 3.23821204 3.23829751 3.23904333
 3.23956754 3.23981119 3.23991833 3.2399189  3.24001436 3.24041688
 3.24136498 3.242355   3.24276067 3.24277622 3.24328067 3.24375737
 3.24435104 3.24446444 3.24457    3.24459726 3.24466722 3.24476147
 3.24575536 3.24591345 3.24607781 3.24630071 3.24686172 3.24696976
 3.24717615 3.24826446 3.24828885 3.24839886 3.24883051 3.24905866
 3.24917718 3.25012206 3.25165221 3.25260518 3.2533793  3.25337972
 3.25344454 3.25423502 3.25425233 3.25495899 3.25521625 3.25583486
 3.25590843 3.25683697 3.25739888 3.25749021 3.25791625 3.25831642
 3.25910057 3.25988275 3.2599137  3.26008026 3.26078593 3.260921
 3.2611423  3.26184474 3.26209478 3.26219641 3.26253029 3.26272467
 3.26314108 3.26425658 3.26459356 3.26578238 3.26789118 3.26890481
 3.26975742 3.27050774 3.27089048 3.27113812 3.27341781 3.27364683
 3.273784   3.27418622 3.27429365 3.27510542 3.27521076 3.2758837
 3.27731726 3.27734581 3.27735071 3.27764412 3.27790329 3.27807532
 3.28028958 3.28072597 3.28103232 3.28211055 3.28295154 3.2836012
 3.28475392 3.28540831 3.2860081  3.28759221 3.28867103 3.28876243
 3.29047737 3.29105618 3.29147724 3.29185237 3.29251606 3.292595
 3.29413492 3.29417961 3.29521672 3.29528297 3.30008995 3.30044532
 3.30245187 3.3026811  3.30296491 3.30388441 3.30477295 3.30578895
 3.30877607 3.31001813 3.31357688 3.31454153 3.31507168 3.31562832
 3.31581403 3.31607909 3.31778172 3.31791571 3.31797931 3.31876908
 3.31958052 3.32049882 3.32158757 3.32196712 3.32256852 3.32262244
 3.32331144 3.32409176 3.33005486 3.33018156 3.33197593 3.33449575
 3.3374986  3.33811987 3.33900416 3.33966337 3.34301431 3.34332979
 3.34395083 3.34502956 3.34503391 3.34542743 3.34565081 3.3456956
 3.34600478 3.3467274  3.3477674  3.35010206 3.35012482 3.35023949
 3.35069108 3.35124463 3.35190973 3.35327948 3.353659   3.35431115
 3.35447389 3.35482241 3.35603416 3.35748501 3.35780344 3.35802877
 3.35918134 3.36032225 3.36147119 3.36314899 3.36371609 3.36507829
 3.36578993 3.36682306 3.36698807 3.3681368  3.3681641  3.369128
 3.36946131 3.37358916 3.37465749 3.37530187 3.37740129 3.37961784
 3.38025055 3.38059691 3.38179161 3.3823075  3.3829788  3.38311185
 3.38349744 3.38501303 3.38516035 3.38817547 3.39055591 3.39224193
 3.39269945 3.39467497 3.39552131 3.397857   3.39853264 3.3988626
 3.40084519 3.4014935  3.40384256 3.40438584 3.40515522 3.40630689
 3.41068466 3.41395482 3.4148719  3.41565192 3.4157353  3.41712734
 3.42311936 3.42627665 3.42786959 3.42982121 3.43013072 3.43828202
 3.44481755 3.44734183 3.45379501 3.45633359 3.45634083 3.46104858
 3.46114241 3.4808492  3.48159928 3.48485755 3.51475363 3.52934254
 3.53428867 3.56775972 3.56901919 3.58110635 3.63709492 3.64785349
 3.71985815 3.77322924 3.78079003 3.78342094 3.79233233 3.80572396
 3.81474951 3.84402665 3.85270571 3.91653639 3.95214365 4.16479264
 4.17582004 4.18308193 4.53046741 4.6272437  4.77339064 4.78875094
 4.79368631 4.80113838 4.80153693 4.80446065 4.81362454 4.83006692
 4.83666249 4.8427805  4.8442306  4.85590733 4.85664522 4.86054792
 4.86133654 4.86141579 4.86265048 4.8643786  4.87068137 4.88447023
 4.88590743 4.88888038 4.9070527  4.93865185 4.94225137 4.94833571
 4.95522619 4.95880867 4.98896627 4.98901946 5.12788891]

  warnings.warn(

2022-12-16 10:36:42,754:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.6765099  1.85136065 1.9066638  1.92525143 1.92948757 1.95844074
 2.14361077 2.15906158 2.82161991 2.82690176 2.84345146 2.86368035
 2.91028007 2.91157449 2.91837488 2.91949781 2.92106434 2.92613428
 2.94676707 2.95331486 2.95603747 2.95971775 2.95992548 2.96298153
 2.96969248 2.97238685 2.97269729 2.97584399 2.9777742  2.97929794
 2.98001169 2.98032548 2.98213355 2.98462971 2.98646207 2.99034361
 2.99122137 2.99242143 2.99342738 2.99350987 2.99385837 2.99447171
 2.99460077 2.99581526 2.99902613 3.00401349 3.00410654 3.00550668
 3.00702029 3.0078337  3.0085114  3.00891979 3.0121329  3.01366058
 3.01389528 3.01564379 3.01599358 3.01644216 3.01730029 3.01736691
 3.01748447 3.01788458 3.01804209 3.01959805 3.02020251 3.02090038
 3.02097337 3.02122176 3.021242   3.02201956 3.02333892 3.02505487
 3.02741564 3.02755428 3.02860459 3.02927957 3.02961375 3.03192528
 3.03208502 3.03318535 3.03429999 3.03619467 3.03801591 3.03803808
 3.03851589 3.03886967 3.03937456 3.03951522 3.04024007 3.04084636
 3.0410909  3.04110329 3.04120049 3.04206946 3.042721   3.04282143
 3.04322088 3.04322737 3.0466487  3.0488838  3.04898018 3.0495406
 3.05259221 3.05374854 3.05411928 3.05489137 3.05530822 3.05591639
 3.05743498 3.05839887 3.05846693 3.05952832 3.05974114 3.05993066
 3.06063616 3.0631928  3.06322139 3.06402531 3.06417581 3.06421345
 3.06433506 3.06484004 3.06627328 3.06649224 3.06679239 3.06683044
 3.06701073 3.06739744 3.06758341 3.06902802 3.06951836 3.07111423
 3.07134162 3.07177218 3.07216508 3.07310556 3.07326001 3.07402615
 3.07459568 3.07536625 3.07548432 3.07640245 3.07722186 3.07789905
 3.07829017 3.08172818 3.08267749 3.08320524 3.08373574 3.08406348
 3.08450174 3.08746087 3.08974341 3.09020551 3.09021825 3.09072028
 3.09175989 3.0920668  3.09482991 3.09653401 3.09679542 3.09690697
 3.0985485  3.09963766 3.10013292 3.10071848 3.10190605 3.10341587
 3.10433009 3.10563179 3.10715127 3.10795461 3.10917351 3.10977382
 3.1109533  3.1117427  3.11310332 3.11325944 3.11381767 3.11527607
 3.11574143 3.11755734 3.11762169 3.11809936 3.11856789 3.11882188
 3.11912927 3.11943237 3.11981166 3.12063718 3.12120352 3.12198978
 3.12372119 3.1247726  3.12489168 3.12527743 3.12595288 3.12620219
 3.12744796 3.12760288 3.12773309 3.12776394 3.12782192 3.12810867
 3.12958808 3.13084159 3.13086831 3.13167446 3.13180244 3.1318858
 3.13190597 3.13232864 3.13309285 3.13313985 3.13381843 3.1340929
 3.13473143 3.13489695 3.13510844 3.13565918 3.13582628 3.13610413
 3.13629231 3.13782465 3.13839885 3.13849266 3.13849295 3.13888063
 3.13907317 3.13991489 3.14013996 3.14020847 3.14075128 3.14138086
 3.14148366 3.14232627 3.14251513 3.14268425 3.14290977 3.14317727
 3.14344771 3.14377415 3.14520002 3.14534649 3.1457265  3.14635924
 3.14642539 3.14643061 3.14663865 3.14675554 3.14780251 3.14794876
 3.14812915 3.14822039 3.1489634  3.1495301  3.15031898 3.15045477
 3.15065008 3.15083784 3.15120085 3.15159347 3.15183457 3.15223923
 3.1526703  3.15290956 3.1530781  3.15341161 3.15350554 3.15351797
 3.15374659 3.15419686 3.15421596 3.15429154 3.15453982 3.15469611
 3.15481262 3.15521185 3.15562271 3.15660373 3.15783751 3.1580894
 3.15822121 3.15837221 3.15846108 3.15871153 3.15880762 3.15898393
 3.15920499 3.15964809 3.15978491 3.15991948 3.1601346  3.16018728
 3.16123125 3.16133907 3.16146275 3.16164138 3.1618605  3.16218859
 3.16273686 3.16352426 3.16396812 3.16396839 3.16400142 3.16421886
 3.16433215 3.16436909 3.16440276 3.16462141 3.1646913  3.16478889
 3.16510163 3.16531018 3.166009   3.16622329 3.16628911 3.16633266
 3.16633842 3.1664929  3.16680338 3.16711822 3.1672299  3.16739772
 3.16749631 3.16876633 3.16902741 3.16912313 3.16938005 3.16939896
 3.16967367 3.17047647 3.17060674 3.17092497 3.17105761 3.17110313
 3.17117932 3.17127684 3.17150393 3.17163877 3.17194615 3.17211312
 3.1721395  3.17220158 3.17222943 3.17236901 3.17262935 3.17277973
 3.17341973 3.17345326 3.17360255 3.17383335 3.17391797 3.17410582
 3.17423287 3.17427431 3.1748798  3.1759212  3.17598594 3.17624078
 3.17636194 3.17671498 3.17725272 3.17760145 3.17791175 3.17801594
 3.17802845 3.17852511 3.17854326 3.17864584 3.17876508 3.17960783
 3.17972641 3.18045103 3.18051045 3.18062305 3.18131036 3.18137286
 3.181439   3.18154131 3.18168529 3.18205409 3.18211872 3.1833797
 3.18350686 3.18407199 3.18430122 3.18432079 3.18434426 3.18437399
 3.18442609 3.18447967 3.18484133 3.18558065 3.18579431 3.18627161
 3.18642204 3.18643512 3.186445   3.18687531 3.18691124 3.18691234
 3.18718243 3.18724281 3.18739106 3.18771701 3.18805452 3.188118
 3.18820212 3.18832009 3.18845652 3.18861091 3.18901102 3.18902597
 3.18915288 3.18951653 3.18956124 3.18956393 3.18977986 3.18989523
 3.18995438 3.19051026 3.19072319 3.19076351 3.19097183 3.19112022
 3.19122892 3.19179718 3.19291935 3.19305692 3.19323778 3.19354355
 3.19425558 3.1942625  3.19443082 3.19453    3.19455521 3.1947208
 3.19509637 3.19543483 3.19546673 3.19559009 3.19560156 3.19596333
 3.19620784 3.19627907 3.19630779 3.19631002 3.19712825 3.19725739
 3.19728982 3.1972922  3.19785193 3.19789778 3.19843047 3.19899325
 3.19909459 3.19940833 3.19941303 3.1995596  3.19962582 3.19991675
 3.20001066 3.20015371 3.20017313 3.20017978 3.20031024 3.20034207
 3.20044059 3.20076658 3.20081091 3.2011173  3.20133704 3.2014525
 3.20171636 3.20173451 3.20185282 3.20233452 3.20235509 3.20270845
 3.20320642 3.20337807 3.20425565 3.20439271 3.20482317 3.20489174
 3.20495842 3.20531814 3.20547455 3.20553845 3.20600687 3.206023
 3.2061533  3.20712889 3.20734296 3.20783669 3.20784769 3.20803683
 3.20846425 3.20857586 3.20861102 3.20878476 3.20945892 3.20973341
 3.20978992 3.20993776 3.20999819 3.21072629 3.2107482  3.21084653
 3.2111477  3.21123483 3.21131968 3.21142142 3.21192262 3.21193946
 3.21229275 3.21252027 3.21272894 3.21280693 3.21300407 3.21387663
 3.2142138  3.21449188 3.21457087 3.21483374 3.21486608 3.21502072
 3.21503803 3.21570483 3.21572032 3.21574256 3.2158539  3.21604591
 3.21623013 3.2164667  3.21648243 3.21667786 3.21754523 3.21762385
 3.21771076 3.21778339 3.217994   3.21811449 3.21819061 3.21847068
 3.21849054 3.21873427 3.21946923 3.21972081 3.22007678 3.22054407
 3.22151211 3.22195132 3.22247767 3.22260158 3.22280747 3.22296636
 3.22342654 3.22424858 3.22451693 3.22486109 3.22492228 3.22502669
 3.22649551 3.22817195 3.2285869  3.22873298 3.22927769 3.23072979
 3.23094961 3.23181256 3.23214696 3.23317371 3.23351945 3.23404421
 3.23419534 3.23491527 3.23509488 3.23536068 3.23539615 3.23551497
 3.23601373 3.23677294 3.23751812 3.23774956 3.23791986 3.23933059
 3.23965225 3.24011603 3.2402728  3.24060367 3.24080694 3.2411548
 3.2418094  3.24282468 3.24432648 3.24614402 3.24701965 3.24852703
 3.24912042 3.24925538 3.25015366 3.25034676 3.25036958 3.25109786
 3.25113961 3.25365472 3.25372847 3.25385631 3.25392565 3.25426872
 3.25505087 3.25629566 3.25680876 3.25772648 3.25815322 3.26035008
 3.26169702 3.26262926 3.26316358 3.26355963 3.2641454  3.26512446
 3.26632852 3.26646248 3.26728311 3.26765272 3.26810139 3.26889421
 3.26946118 3.27171939 3.27225499 3.27240212 3.27245701 3.27353294
 3.27592871 3.27869283 3.27985032 3.28030538 3.28091151 3.28263761
 3.28337474 3.28464109 3.29236968 3.29253625 3.29351421 3.29712642
 3.29914172 3.2992816  3.29993478 3.30029818 3.3003907  3.30078774
 3.3024927  3.3032413  3.30394943 3.30896269 3.31140166 3.31250161
 3.31310161 3.31623726 3.31734345 3.31817877 3.31836393 3.32049551
 3.32144969 3.32332328 3.32339751 3.3237752  3.32450161 3.32472718
 3.32598727 3.32606541 3.32729517 3.32783115 3.32792575 3.32866185
 3.32922222 3.32946096 3.32993504 3.33005879 3.33411719 3.3348394
 3.33521274 3.33571248 3.33617929 3.33764993 3.33889443 3.33930339
 3.34021075 3.34031849 3.34076962 3.34126432 3.34239917 3.34282143
 3.34454721 3.34473086 3.34615523 3.34714217 3.34789527 3.34905218
 3.35041561 3.3538901  3.35433532 3.35438068 3.35471142 3.35645251
 3.35735135 3.35896729 3.35933424 3.36054838 3.36107758 3.36208102
 3.36261769 3.3639882  3.36491767 3.36572416 3.36684194 3.36711001
 3.36723444 3.36993333 3.37014933 3.37016669 3.37165223 3.37180752
 3.37294167 3.37471765 3.37491232 3.37666939 3.37686709 3.37733911
 3.37875779 3.37921734 3.38003798 3.38070725 3.38075132 3.38089856
 3.38108156 3.38276577 3.38356877 3.38494412 3.38861555 3.39060555
 3.39076404 3.39148141 3.3951359  3.39597914 3.39651213 3.40174391
 3.40205813 3.40308658 3.40370383 3.40519781 3.40633614 3.40640205
 3.40659108 3.40736094 3.4079265  3.40889264 3.40938427 3.41077615
 3.4134212  3.41879522 3.4218045  3.42274076 3.42282486 3.42410511
 3.43303741 3.43368522 3.45270464 3.45306031 3.45371381 3.45425237
 3.46220141 3.48896715 3.4935366  3.49678642 3.50498486 3.53021744
 3.54126925 3.55718554 3.56108922 3.60836496 3.62041694 3.64434231
 3.6632576  3.67004757 3.67642424 3.68752727 3.69956235 3.7068061
 3.71024757 3.73862813 3.74357767 3.76860776 3.7882591  3.78881874
 3.79437363 3.80267532 3.80395481 3.81611287 3.81708194 3.82930463
 3.83315217 3.84148055 3.84512967 3.85202791 3.85904062 3.86512186
 3.88795234 3.93663109 4.1333494  4.1446078  4.16242675 4.18977908
 4.3297335  4.52692543 4.61940842 4.70056403 4.73238859 4.76092825
 4.77093845 4.77473051 4.78162968 4.7830993  4.7842153  4.79349932
 4.7942904  4.79627011 4.80267826 4.8109834  4.81558037 4.81635678
 4.81834415 4.81882882 4.82276251 4.82838289 4.8365524  4.83858646
 4.83867768 4.84323494 4.85513793 4.86089856 4.86132887 4.86159747
 4.86796071 4.86971713 4.87348889 4.88082307 4.90636889 4.9165705
 4.92552738 4.93131816 4.93233014 5.03905364 5.21145402]

  warnings.warn(

2022-12-16 10:36:42,842:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.75236179 1.90805496 1.93131937 1.93343454 1.94766262 1.99550885
 2.00943647 2.01972218 2.04298853 2.06888875 2.18952565 2.79592469
 2.80373121 2.8080597  2.81836196 2.82550179 2.8286418  2.85008061
 2.8642022  2.8658445  2.88138763 2.92873152 2.93126729 2.94553253
 2.94881246 2.94899426 2.95440884 2.9622745  2.96356045 2.96428408
 2.97121847 2.97201274 2.97688895 2.97694153 2.9777487  2.98757256
 2.98872012 2.98990446 2.99009535 2.99019089 2.99299522 2.99330389
 2.99375189 2.99655426 2.99674731 2.99700727 2.99730368 2.99759617
 2.99856822 2.99863711 2.99991036 3.00162138 3.00506692 3.00720753
 3.00925001 3.00941223 3.00946962 3.0105     3.01063011 3.01238531
 3.01299509 3.01320012 3.01579842 3.01765147 3.01935997 3.01997685
 3.02080831 3.02292954 3.02488523 3.02509333 3.02653288 3.02681065
 3.02855021 3.03040583 3.03087554 3.03141265 3.03416437 3.03420938
 3.03584396 3.03695972 3.03714585 3.03718316 3.03769712 3.03996514
 3.04029211 3.04271124 3.04315614 3.04385305 3.04463708 3.04514686
 3.04617143 3.04860321 3.04899593 3.05012294 3.05522829 3.05584074
 3.05647125 3.05847646 3.05970489 3.05974578 3.06038332 3.06262443
 3.06336241 3.0650792  3.06608536 3.06775677 3.06944417 3.07293665
 3.07429461 3.07478022 3.07531332 3.07791714 3.08058982 3.08209912
 3.08216784 3.08258804 3.08286178 3.08320207 3.08332527 3.08343857
 3.08644475 3.0886886  3.0902357  3.09039959 3.09207676 3.09804657
 3.09969944 3.09992753 3.0999536  3.10088618 3.10124944 3.10190629
 3.10283009 3.10308783 3.10335529 3.10351528 3.10365877 3.10464319
 3.10469843 3.10539563 3.10590309 3.10596513 3.10770742 3.10917011
 3.10934341 3.109747   3.10993122 3.11173487 3.11192861 3.11345589
 3.11349773 3.11409984 3.11515113 3.11529931 3.11567682 3.11575898
 3.11575915 3.11615963 3.11636952 3.11672245 3.11719753 3.11728264
 3.11886943 3.11967488 3.12009545 3.1217629  3.12228196 3.12242451
 3.1229305  3.12426887 3.12437305 3.12460815 3.12461075 3.12464889
 3.12583367 3.12601026 3.1264973  3.12675783 3.12720364 3.12736513
 3.1273973  3.12749098 3.12797061 3.12978345 3.12992335 3.13004507
 3.13009865 3.13044581 3.1304654  3.13182794 3.13233036 3.13267102
 3.1327214  3.13326276 3.1333297  3.13342756 3.13344511 3.13350821
 3.133925   3.1339894  3.13409719 3.1356883  3.13570239 3.13570297
 3.13575923 3.13600771 3.13617802 3.13636108 3.13643205 3.13646614
 3.13666446 3.13722307 3.13758519 3.13768204 3.13801216 3.13900537
 3.13906843 3.13908869 3.13950063 3.13998742 3.14046125 3.14112725
 3.14133936 3.14135414 3.14159625 3.14167157 3.14208833 3.14216232
 3.14283797 3.1429561  3.1430707  3.14309325 3.14410679 3.14496004
 3.14531164 3.14562728 3.14593623 3.14595701 3.14596605 3.1461123
 3.14624789 3.14627677 3.14652001 3.14655276 3.14675198 3.14705032
 3.14773842 3.14774092 3.14775576 3.147804   3.14846826 3.14847735
 3.1485751  3.14858535 3.14882193 3.15002379 3.15029269 3.15060347
 3.15141154 3.15172037 3.15231822 3.15243256 3.15334689 3.15350737
 3.153536   3.15376678 3.15376792 3.15441851 3.15460295 3.15464219
 3.15468891 3.15474147 3.15514493 3.15518041 3.15557629 3.15638207
 3.15647625 3.15712711 3.15745529 3.15759806 3.15794172 3.15805378
 3.15835781 3.15847769 3.15852602 3.15955998 3.1597593  3.16002412
 3.16006318 3.16033545 3.16055613 3.16095804 3.16097305 3.16105692
 3.16135832 3.16158388 3.16163647 3.16175344 3.16187673 3.16205696
 3.16223775 3.16231626 3.16243158 3.16248154 3.16271641 3.16317504
 3.16442282 3.16488037 3.16544348 3.16554856 3.16558387 3.16625782
 3.16694896 3.16724921 3.16738494 3.1680706  3.16821797 3.168547
 3.16877826 3.16878012 3.16882748 3.16885371 3.16896068 3.1691104
 3.16949586 3.16961252 3.16965688 3.17017576 3.17027455 3.17038631
 3.1710881  3.17108941 3.17130517 3.17138515 3.17182288 3.17297376
 3.17302554 3.17313249 3.17356436 3.17383026 3.17447617 3.17449861
 3.1745962  3.17511341 3.17562247 3.17612621 3.17617576 3.17639517
 3.17648589 3.17661197 3.1766406  3.17700068 3.17854649 3.17857908
 3.17865993 3.17912758 3.17941867 3.17990565 3.17997368 3.1813462
 3.18147185 3.18161529 3.18179962 3.18187467 3.18197164 3.18235885
 3.18339952 3.18347713 3.18367377 3.18371586 3.18374154 3.18377771
 3.1838596  3.18397751 3.18414662 3.18418441 3.18453752 3.18534557
 3.18535743 3.18542894 3.18561967 3.18578494 3.1860369  3.18629956
 3.18663781 3.18726513 3.18756597 3.18821193 3.18829963 3.18844911
 3.18881477 3.18910816 3.18968573 3.18981601 3.190033   3.19004441
 3.19004838 3.19050086 3.19072502 3.19084391 3.19091306 3.19115378
 3.19138251 3.19151242 3.19193249 3.19260046 3.19308762 3.19317849
 3.19407858 3.19413745 3.19464485 3.19550155 3.1958563  3.19594633
 3.19605948 3.19616869 3.19685725 3.19721593 3.19806947 3.1985966
 3.19886262 3.19904775 3.19928036 3.19928046 3.19964451 3.19979169
 3.20018256 3.20062843 3.20081208 3.20123655 3.2012466  3.20150517
 3.20186859 3.20204532 3.20245988 3.20255907 3.20272086 3.2029799
 3.20302636 3.20349026 3.20357017 3.20363828 3.20385965 3.20445987
 3.20450992 3.20459868 3.20519638 3.20542975 3.20552437 3.20553465
 3.20555026 3.20636747 3.20646147 3.20676595 3.2071976  3.20769575
 3.20779995 3.20795863 3.2082757  3.20904926 3.20948577 3.20965968
 3.20977034 3.20998161 3.21045664 3.21066177 3.21089548 3.21153546
 3.21161857 3.21212457 3.21244227 3.21270616 3.2128346  3.21320213
 3.21348045 3.21349167 3.21353821 3.21359053 3.21387298 3.21390854
 3.21397368 3.21449841 3.2151025  3.21594955 3.21629259 3.21645953
 3.21651119 3.21752881 3.21795265 3.21797999 3.21799787 3.21846834
 3.21907526 3.21908968 3.21916745 3.21929609 3.21950372 3.21987672
 3.22002439 3.22091197 3.22115839 3.22151836 3.22239232 3.22371688
 3.22431725 3.22492314 3.225018   3.22515151 3.22519757 3.22521456
 3.22523142 3.2253027  3.22716507 3.22734685 3.2276851  3.22846096
 3.22920915 3.22926391 3.22931374 3.22993508 3.22997857 3.22999457
 3.23027668 3.23099901 3.23123286 3.23353183 3.2337757  3.23440717
 3.23449729 3.23452122 3.23510196 3.23523204 3.23591718 3.23663196
 3.23664264 3.23670181 3.23684264 3.23784569 3.23817053 3.24013359
 3.24037045 3.24092864 3.24146113 3.24179687 3.24179698 3.24187062
 3.24201329 3.24228876 3.24229454 3.24278552 3.24291987 3.244306
 3.24432608 3.24521537 3.24543815 3.24546701 3.24574871 3.24609609
 3.24627535 3.246428   3.24665753 3.24705901 3.24713898 3.24740385
 3.24747943 3.24758212 3.24799772 3.24819029 3.24844833 3.24925783
 3.2495545  3.24991868 3.25029077 3.25041221 3.25076265 3.25101474
 3.25119844 3.25263634 3.25379957 3.25392301 3.25434397 3.25457412
 3.25497867 3.25504504 3.255233   3.2565032  3.2575912  3.25780315
 3.2581097  3.25821715 3.25825863 3.2598296  3.25983944 3.26019812
 3.26032565 3.26045464 3.26088899 3.26238269 3.26288332 3.26447642
 3.26545738 3.26575003 3.26690202 3.26709054 3.26746429 3.26800095
 3.2683932  3.27127765 3.27342288 3.27444875 3.27458835 3.27494224
 3.27572844 3.27582461 3.2771714  3.27742393 3.27756214 3.27757735
 3.27763405 3.27778172 3.28003409 3.28065425 3.28112638 3.28236591
 3.28239311 3.2829636  3.28330779 3.28358087 3.28405155 3.28431249
 3.285125   3.28549427 3.28631521 3.28658246 3.28676887 3.28728042
 3.28741821 3.28779896 3.28851308 3.28927023 3.2900454  3.29065978
 3.29202168 3.29210511 3.29299746 3.29449169 3.29612923 3.29633152
 3.2964782  3.29841558 3.29947795 3.29952657 3.3009589  3.30112555
 3.30116201 3.30312813 3.30358307 3.3041557  3.30418368 3.30466881
 3.30521982 3.30570651 3.30584334 3.30678419 3.30792004 3.30971806
 3.31142722 3.31329567 3.31377497 3.31426219 3.31480771 3.31514859
 3.31845578 3.31883764 3.31916397 3.32011442 3.32095151 3.32178751
 3.32191351 3.32392276 3.32511502 3.32754699 3.32769512 3.32832752
 3.32961568 3.33133432 3.33327826 3.33346288 3.33346811 3.33446982
 3.33460918 3.33619398 3.33632195 3.33715328 3.34091949 3.34333247
 3.34394295 3.34578363 3.34702743 3.3478445  3.34963894 3.35023811
 3.35046262 3.35217431 3.35227914 3.35265255 3.35312775 3.35382101
 3.35519508 3.3575095  3.3581639  3.35960547 3.36108071 3.36172517
 3.36494699 3.36554343 3.36557195 3.36631411 3.36826683 3.36986199
 3.37044809 3.3714521  3.37151277 3.37240462 3.37242629 3.3746373
 3.37493959 3.37609478 3.37707326 3.37797764 3.38108917 3.38110344
 3.38285351 3.38334845 3.38353398 3.38390529 3.38701574 3.38764898
 3.3879975  3.38842921 3.38843307 3.38851986 3.38880487 3.38984807
 3.39122352 3.3955756  3.39946463 3.39975999 3.40149104 3.40150548
 3.40176814 3.40248761 3.4049042  3.40528412 3.40556436 3.40798891
 3.41614874 3.42003236 3.42390227 3.42419541 3.4315021  3.43191439
 3.43760937 3.44641827 3.44912686 3.45314284 3.45714734 3.46048775
 3.47305304 3.47554514 3.47606267 3.48390348 3.48523358 3.48639623
 3.48755167 3.49088904 3.49542809 3.49590298 3.5045796  3.50652785
 3.50942903 3.51750216 3.51841068 3.52603805 3.52606093 3.54411385
 3.6122824  3.64313441 3.65901107 3.6709777  3.68932693 3.71972853
 3.72227737 3.76900641 3.79607039 3.80233402 3.81857874 3.82199419
 3.83550399 3.86006372 3.86121838 3.86173716 3.86308667 3.91222888
 3.94136293 3.94233262 3.95300434 3.96304066 3.96666981 4.12262234
 4.1276387  4.16639679 4.33230062 4.45097314 4.7393713  4.763839
 4.76582805 4.76922625 4.77516754 4.77575844 4.78303485 4.79286986
 4.79990727 4.80082843 4.80140486 4.80353707 4.80404423 4.80554022
 4.81027497 4.81729526 4.81776286 4.81960672 4.82123832 4.82332613
 4.82516247 4.82720147 4.82786257 4.83514813 4.83532826 4.83953579
 4.83964274 4.84457817 4.84920297 4.8566534  4.86339569 4.86490686
 4.87057881 4.8817841  4.89292804 4.89403873 4.93065729 4.93610786
 4.96112465]

  warnings.warn(

2022-12-16 10:36:42,865:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.8640385  1.90820446 1.91085497 1.97449855 1.98126989 2.02055014
 2.63388496 2.72466243 2.8025042  2.82302973 2.8478872  2.85527548
 2.85610912 2.85919911 2.86684228 2.8755209  2.88082794 2.88187643
 2.8847523  2.88788033 2.89457409 2.8985383  2.90166376 2.9052092
 2.91096123 2.91491749 2.91979778 2.92686361 2.92796436 2.93077772
 2.93186    2.93649446 2.9396224  2.94234595 2.94342413 2.94719705
 2.94945398 2.95015994 2.95162296 2.95209671 2.9540953  2.95599339
 2.95705468 2.95798317 2.96403002 2.96406288 2.96440263 2.96492393
 2.966421   2.96726514 2.97235525 2.97379936 2.97539135 2.98023108
 2.98031779 2.9805223  2.98091567 2.98188444 2.98272664 2.98395717
 2.9842085  2.98608689 2.98784711 2.98862655 2.9892476  2.99185441
 2.99232241 2.99256831 2.99415076 2.99536133 2.9960478  2.99824276
 2.9985498  3.00135556 3.00377262 3.00403692 3.00512348 3.00524053
 3.00536734 3.00549913 3.00743064 3.00816199 3.00836035 3.00910444
 3.01024328 3.01188586 3.01237904 3.01275073 3.01485192 3.01555686
 3.01601845 3.01632093 3.01845997 3.02022214 3.02050766 3.02186166
 3.02394156 3.02400889 3.02811909 3.02857015 3.02908158 3.03120343
 3.032658   3.03339637 3.03468216 3.03555919 3.03579763 3.03620992
 3.03793812 3.03856608 3.03894328 3.04047337 3.04231256 3.0429933
 3.04303336 3.04534197 3.04535589 3.04536616 3.04689138 3.05019622
 3.05029838 3.05042243 3.05352241 3.05422989 3.05693888 3.05852694
 3.06184531 3.06215989 3.06264764 3.06403159 3.06492106 3.0661173
 3.06713447 3.06717128 3.0686147  3.06879115 3.06895116 3.07025058
 3.07273439 3.075382   3.07987626 3.07989133 3.08006613 3.08064076
 3.08130259 3.08245109 3.08481891 3.08554716 3.08573937 3.08604874
 3.08696643 3.08799402 3.08923314 3.08968167 3.08972249 3.09055997
 3.09155442 3.09248612 3.09255213 3.09258376 3.09265387 3.09282778
 3.09310722 3.09324224 3.09388874 3.09453822 3.09673584 3.09719635
 3.09726355 3.09800683 3.09851829 3.09981236 3.10071019 3.10325288
 3.10508306 3.10515355 3.10553553 3.10604602 3.10622437 3.10678735
 3.10742549 3.10801874 3.10874582 3.10944811 3.10953477 3.1102294
 3.11125927 3.11159709 3.11196454 3.11305278 3.11328336 3.11339862
 3.11376446 3.11415984 3.11618326 3.116565   3.1168787  3.11699988
 3.11703133 3.11785971 3.11825456 3.1187382  3.11883591 3.11889449
 3.12011759 3.12017798 3.12020816 3.1202366  3.12047293 3.12083566
 3.12119759 3.12350352 3.12372179 3.12396207 3.12441852 3.12499329
 3.12505811 3.12513947 3.125882   3.12590024 3.12599966 3.1263787
 3.1267138  3.12767746 3.12776467 3.12826556 3.12938728 3.12943474
 3.13092401 3.13098512 3.13112679 3.13183257 3.13266181 3.13302151
 3.13332947 3.13338514 3.13353361 3.13392735 3.1341212  3.13463066
 3.13539713 3.13628639 3.1363244  3.13696288 3.13724347 3.13742876
 3.13772195 3.13855826 3.13873933 3.13948329 3.13966478 3.1397856
 3.14002429 3.14005877 3.14010038 3.14057049 3.14102721 3.14160928
 3.14254851 3.14280475 3.14294458 3.14379256 3.14391045 3.14470022
 3.14514719 3.14557597 3.14690175 3.14931027 3.14951921 3.1504338
 3.15120181 3.15127394 3.15145041 3.15170395 3.15369475 3.153915
 3.15440354 3.15454908 3.15456278 3.15467095 3.15521074 3.15530895
 3.15536121 3.15549326 3.15589335 3.15609472 3.15642496 3.15643877
 3.156466   3.15705681 3.15744746 3.15763084 3.1577141  3.15773864
 3.15814488 3.15818326 3.15846213 3.15913362 3.15962584 3.15974603
 3.15997165 3.16084434 3.16100565 3.16128862 3.16132546 3.16140025
 3.16159517 3.16165378 3.1617235  3.16191478 3.16202263 3.16249274
 3.16299687 3.16302369 3.16333556 3.16349474 3.16364102 3.16393567
 3.16408697 3.16410445 3.16432281 3.16438037 3.16455159 3.16459211
 3.16464563 3.16480665 3.16523318 3.16524352 3.16606427 3.1675959
 3.16769525 3.16791085 3.16805973 3.16838756 3.16873985 3.16914795
 3.16927825 3.17009028 3.17009291 3.17074835 3.17078008 3.17094349
 3.17124936 3.17135924 3.17136873 3.1714224  3.17174696 3.17190363
 3.1729042  3.1734399  3.17344677 3.17383616 3.17414167 3.17427104
 3.17447451 3.17498839 3.17501421 3.17524192 3.1755361  3.17589752
 3.17607815 3.17697244 3.17715391 3.17729309 3.17756507 3.17807277
 3.17819655 3.17820572 3.17822995 3.17829545 3.17866407 3.17882783
 3.17886732 3.17910865 3.17913487 3.17914077 3.17940799 3.17954215
 3.17971456 3.17985162 3.18003271 3.18003919 3.18031533 3.18032264
 3.18058613 3.18083303 3.18093773 3.18109641 3.18112786 3.18124903
 3.18153059 3.18154156 3.18157878 3.18169429 3.18172574 3.18191111
 3.18215974 3.18217249 3.18235636 3.18254007 3.18406356 3.18414202
 3.18436187 3.18448094 3.18456641 3.18474313 3.18480695 3.18487234
 3.18490548 3.18511133 3.18557121 3.18572022 3.18608843 3.18684442
 3.18687555 3.18689973 3.18710171 3.1877299  3.1877375  3.18779968
 3.18841665 3.18851    3.18857533 3.18871536 3.18913749 3.18943335
 3.18968905 3.18971592 3.19022526 3.19032555 3.19061626 3.19126364
 3.19136945 3.19209684 3.19217894 3.19271063 3.19446849 3.19458063
 3.19462043 3.19473228 3.19487434 3.19490579 3.19502899 3.19508942
 3.19540466 3.19548284 3.19554723 3.19622694 3.19657218 3.19664064
 3.19683075 3.19690842 3.19700127 3.19766236 3.19796482 3.19831083
 3.1985379  3.19915324 3.19918807 3.20040634 3.20073022 3.20080808
 3.20088398 3.20099485 3.20131583 3.20164434 3.20169671 3.20223468
 3.2023679  3.20249681 3.20258262 3.20281574 3.20297407 3.20309469
 3.20309574 3.20380227 3.20416411 3.2041978  3.20444638 3.20454999
 3.20558653 3.20580531 3.2058973  3.20590216 3.2060091  3.20621139
 3.20622368 3.20704527 3.20711855 3.20748946 3.20769962 3.2079496
 3.20801655 3.20872827 3.2088429  3.20888581 3.20898525 3.20899614
 3.20900357 3.20917315 3.20980314 3.21000746 3.21033043 3.21050077
 3.21161567 3.21178104 3.21274692 3.21305123 3.21306546 3.21313198
 3.213138   3.21313843 3.21323638 3.2135813  3.21364561 3.21399318
 3.21399366 3.21415824 3.21435011 3.21449775 3.21451451 3.21476195
 3.21484416 3.21489033 3.21499121 3.21606311 3.21606833 3.21641983
 3.21654918 3.21700359 3.21751672 3.21753325 3.21806117 3.21851307
 3.2204498  3.22141274 3.22147087 3.22154384 3.22161627 3.22168774
 3.22198298 3.22204358 3.22209941 3.22235343 3.2223863  3.22257921
 3.22268062 3.22276464 3.22322306 3.2233854  3.22359354 3.22421865
 3.2244651  3.22456051 3.2247387  3.22544759 3.22610063 3.22696407
 3.22793178 3.22881826 3.22956801 3.23028109 3.23036686 3.23047861
 3.2310742  3.23118049 3.23158468 3.23162343 3.23206334 3.23289264
 3.23292819 3.23369177 3.23538953 3.23600325 3.23644878 3.23658438
 3.23671278 3.2373202  3.23732116 3.23806705 3.23832048 3.23959259
 3.24014278 3.24016811 3.24043672 3.24154519 3.24185354 3.24200928
 3.24381797 3.24385358 3.24421863 3.24575491 3.24612393 3.24663891
 3.24698609 3.24702898 3.24859137 3.24906808 3.24939388 3.25018985
 3.25062665 3.25146123 3.25209332 3.25307862 3.25348191 3.25444988
 3.25532761 3.25543108 3.25556667 3.25607538 3.2562608  3.25675126
 3.25819452 3.25827022 3.25859561 3.26023962 3.26062609 3.26096342
 3.26232716 3.26253218 3.26319469 3.26326103 3.26375348 3.26448674
 3.2657274  3.26603644 3.26606913 3.26681013 3.26698831 3.26738653
 3.2680346  3.26870783 3.26875515 3.26960621 3.26966583 3.27094191
 3.27097626 3.27222993 3.27499934 3.27604276 3.27671931 3.27706359
 3.27708766 3.27740833 3.27774071 3.27797325 3.28170728 3.2823895
 3.28248721 3.28292591 3.28300838 3.28315793 3.28429886 3.28484532
 3.28593044 3.28607484 3.28682735 3.28685604 3.28742703 3.2874456
 3.28769689 3.28832175 3.28905406 3.28928451 3.29028464 3.29180275
 3.2921726  3.29395645 3.29448992 3.29481922 3.29484898 3.29499217
 3.29565515 3.29707981 3.29864191 3.30055948 3.30157387 3.30169207
 3.30190339 3.30201076 3.30219401 3.30305257 3.30609807 3.30932927
 3.31034257 3.31117703 3.3142711  3.31506687 3.31580951 3.31980507
 3.32324433 3.32400408 3.32403735 3.32553749 3.32612779 3.32652355
 3.32857874 3.32983294 3.33014551 3.33022509 3.33029166 3.33058773
 3.33140004 3.33193968 3.34137857 3.34178634 3.34394917 3.34754684
 3.35272407 3.35547282 3.35638072 3.35664679 3.35730024 3.35786638
 3.36013977 3.36027604 3.36251432 3.36325621 3.36386296 3.36455177
 3.36633877 3.36738025 3.36865177 3.3690489  3.36943914 3.37012778
 3.37399313 3.37402206 3.37563718 3.37704492 3.37708857 3.37966896
 3.38056412 3.38059952 3.38135224 3.3814768  3.38190358 3.38201077
 3.38263718 3.38361637 3.38515925 3.38556619 3.38671875 3.38734683
 3.38739793 3.38806726 3.38889587 3.39047283 3.39238214 3.39518267
 3.39539043 3.39618117 3.39811593 3.39940131 3.3994389  3.40238774
 3.40323801 3.40680518 3.40761442 3.41333613 3.4140285  3.41545188
 3.41780713 3.41875927 3.42187556 3.42274575 3.42656483 3.4293898
 3.43079723 3.43086354 3.4311706  3.43206517 3.43286845 3.43287538
 3.43459234 3.43522172 3.43537052 3.44132417 3.44318582 3.46051913
 3.46826424 3.47782664 3.47998877 3.48338537 3.50135205 3.5127752
 3.53579033 3.54330918 3.54474102 3.57685042 3.5826695  3.58574443
 3.59047417 3.61308488 3.61847025 3.63546899 3.64155119 3.6466297
 3.70362089 3.75414633 3.75639114 3.75804812 3.77691784 3.78542175
 3.79522366 3.80628904 3.80690316 3.81154635 3.81312261 3.81877999
 3.82654993 3.82790834 3.82947457 3.83543877 3.84478519 3.87684071
 3.89221632 3.93292977 3.9936398  4.0155975  4.1087097  4.11846923
 4.22165351 4.34300113 4.38278411 4.76846253 4.76924624 4.77259426
 4.78176309 4.7897511  4.79683329 4.80380859 4.8053572  4.80797386
 4.8221114  4.82221196 4.82972177 4.82988738 4.8318422  4.83634159
 4.83652633 4.83919392 4.84149841 4.8599533  4.86083062 4.87620054
 4.88065626 4.88211805 4.89509678 4.89659126 4.90008497 4.90258636
 4.91259319 4.91646072 4.92314125 4.9271005  5.00637837 5.01187518]

  warnings.warn(

2022-12-16 10:36:42,891:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.60103031 1.85015073 1.86434124 1.92366013 2.03011142 2.20698402
 2.67022341 2.83160066 2.83378276 2.86961519 2.89131924 2.89827051
 2.9119398  2.91275574 2.91408743 2.91753112 2.91908796 2.92350877
 2.9267535  2.92847022 2.92984204 2.93473353 2.93549456 2.9426477
 2.94268552 2.94414944 2.94494741 2.9453678  2.94552082 2.94683255
 2.95392617 2.95623463 2.958734   2.95949345 2.96246523 2.96427054
 2.9664547  2.96669888 2.9683013  2.97010613 2.97165739 2.97428514
 2.97548    2.97584209 2.97905237 2.98089773 2.98127301 2.98207537
 2.98253255 2.9829655  2.98696087 2.98714594 2.99262104 2.99276904
 2.993468   2.9943758  2.99477602 2.99525468 2.99539355 2.9972799
 2.99776707 3.0025088  3.00355853 3.00434997 3.0051998  3.00575836
 3.00582451 3.00894811 3.01162395 3.01370932 3.01425743 3.0146949
 3.01591512 3.01631247 3.01645371 3.01742704 3.01747682 3.01790745
 3.01946664 3.02312412 3.02329787 3.02354572 3.02457868 3.02615686
 3.02695068 3.02819802 3.0306187  3.0308435  3.03426481 3.03452551
 3.03824829 3.03861802 3.04335806 3.04508878 3.04611364 3.04810028
 3.04859899 3.05009106 3.05035992 3.05217281 3.05269274 3.05273388
 3.05278143 3.05350883 3.05415289 3.05610074 3.05748717 3.05908881
 3.05997036 3.06011073 3.06235427 3.06310156 3.06400129 3.06452379
 3.06613934 3.06616459 3.06677187 3.06691892 3.06864572 3.06864719
 3.06897753 3.07048537 3.07089073 3.0725357  3.07421905 3.07465196
 3.07494655 3.08050157 3.08158478 3.08216385 3.08245224 3.08337833
 3.08549297 3.08551221 3.08651455 3.08709195 3.08723606 3.08725801
 3.08945873 3.08967977 3.08993339 3.09012537 3.09045638 3.09071855
 3.09108395 3.09135786 3.09137822 3.09415224 3.09598225 3.09803863
 3.09838374 3.09956712 3.10133744 3.10141574 3.10178342 3.1032346
 3.10557184 3.10647247 3.10664561 3.10670323 3.10924189 3.10954236
 3.11011817 3.11027389 3.11098174 3.1110974  3.11116228 3.1116425
 3.11181619 3.11202483 3.11260614 3.11265117 3.11293284 3.11293316
 3.11310626 3.11342368 3.11365643 3.11441432 3.11486096 3.11486619
 3.11536883 3.11634306 3.11635275 3.11662336 3.11675994 3.11753182
 3.11867244 3.11873772 3.11893333 3.11926072 3.11979396 3.12010398
 3.12086445 3.12145638 3.12147869 3.12264636 3.12274785 3.12363813
 3.12363845 3.12374239 3.12453978 3.12473636 3.1262506  3.126374
 3.12650254 3.12656263 3.12755397 3.12756015 3.1276981  3.12784181
 3.12958704 3.12990412 3.12992122 3.13004437 3.13018466 3.13069806
 3.13155288 3.13219804 3.13452817 3.13494381 3.13530134 3.13534197
 3.13552179 3.13553994 3.13557553 3.13576652 3.13587942 3.13611637
 3.13642002 3.13665465 3.13669329 3.13763516 3.13786792 3.13790697
 3.13919016 3.13967162 3.14150175 3.14181298 3.14225784 3.14228394
 3.14254162 3.14267978 3.14279142 3.14296056 3.14322314 3.14350555
 3.1437651  3.14389807 3.14442905 3.14459029 3.14493308 3.14534666
 3.14537604 3.14551549 3.14647688 3.14663054 3.14711488 3.14868074
 3.14891032 3.14894611 3.1491235  3.14913432 3.14935644 3.1494276
 3.14956967 3.14958518 3.14981676 3.1499726  3.15005674 3.15039532
 3.15054226 3.15143515 3.15151229 3.15262726 3.15268533 3.15282013
 3.15310708 3.15346137 3.15352421 3.15354016 3.15389947 3.15397843
 3.15422534 3.15429772 3.15476296 3.15493978 3.15570998 3.15571605
 3.15639988 3.15643304 3.15667376 3.15700595 3.15766252 3.15789489
 3.15861485 3.1591892  3.15991359 3.1599737  3.16104191 3.16107665
 3.16109889 3.16163249 3.16235534 3.1624323  3.16245699 3.16264816
 3.16333204 3.16338737 3.16346401 3.16352218 3.16362612 3.16364329
 3.16378714 3.16397441 3.16436533 3.16439211 3.16443621 3.1652736
 3.16537971 3.16552216 3.16572439 3.16637198 3.16658747 3.16696196
 3.16796581 3.16796837 3.16825634 3.16851754 3.16917579 3.16942841
 3.16944339 3.16983092 3.17059843 3.17136802 3.17151019 3.17175627
 3.17290127 3.1731271  3.17318913 3.17330001 3.17351635 3.17355031
 3.17402945 3.17425632 3.1742601  3.17443811 3.17464297 3.17473228
 3.17482786 3.1749318  3.17498517 3.17570825 3.17647354 3.17652088
 3.17762855 3.17884992 3.1789399  3.17894499 3.17901898 3.17979837
 3.18138337 3.18168672 3.18172178 3.18176126 3.18182572 3.18348382
 3.18376058 3.18454869 3.18562407 3.18568908 3.18610321 3.18629278
 3.18630721 3.18659254 3.18710339 3.18717673 3.18749313 3.18749345
 3.18771538 3.18799758 3.1885031  3.18866267 3.18890843 3.18905311
 3.18905598 3.189286   3.18940655 3.1896848  3.18979788 3.18998023
 3.19006837 3.19017366 3.19037477 3.190385   3.19084198 3.19086693
 3.19087623 3.1908971  3.19090355 3.19159665 3.19168918 3.19191567
 3.19207357 3.19276511 3.19295422 3.1929769  3.19326096 3.19377224
 3.19387618 3.1944588  3.19452745 3.19467162 3.19476592 3.19508585
 3.19523084 3.19557562 3.19558517 3.19595538 3.1963268  3.19662589
 3.19700117 3.19742306 3.19749516 3.19757239 3.1975844  3.19808135
 3.1981999  3.19847819 3.19853683 3.19886009 3.19897293 3.19903743
 3.19994527 3.20046057 3.20055356 3.20060631 3.2007947  3.20104527
 3.20173402 3.20260609 3.20290288 3.20385814 3.20399375 3.20450863
 3.20470736 3.20494745 3.20506209 3.20536899 3.20553053 3.20561372
 3.20592231 3.20706315 3.20719242 3.20764874 3.20801803 3.2081627
 3.20869776 3.20928934 3.20950086 3.20958888 3.20968856 3.20970832
 3.21035156 3.21076121 3.21085005 3.21133869 3.21148293 3.21149273
 3.21166534 3.21171572 3.21176654 3.21185747 3.21210893 3.21223097
 3.21227162 3.21241875 3.21242011 3.21282375 3.21297623 3.21304328
 3.21325627 3.21370958 3.21379721 3.21387352 3.2139743  3.21400947
 3.21407462 3.21420709 3.21438545 3.21439073 3.21481704 3.21500891
 3.21538909 3.21568661 3.21592307 3.21604421 3.21647757 3.2169292
 3.21696639 3.21703836 3.21753716 3.21757609 3.21883086 3.21922989
 3.21925106 3.21934208 3.219355   3.21943721 3.22005382 3.22038066
 3.2205396  3.22073597 3.22077483 3.22136281 3.22136939 3.22140727
 3.22210983 3.22216809 3.22246263 3.22261162 3.22297134 3.22320205
 3.22355829 3.22373017 3.22376618 3.22399177 3.22422697 3.22433504
 3.2244039  3.22468317 3.22506782 3.22509314 3.22523206 3.22563966
 3.22658171 3.22732651 3.2274551  3.22771362 3.22798259 3.22845035
 3.22874819 3.22940167 3.22985707 3.23034708 3.23058486 3.23143797
 3.23239055 3.23239824 3.23262627 3.23264366 3.23302039 3.23306699
 3.23317574 3.23336852 3.2336553  3.23368441 3.23402927 3.23460805
 3.23465011 3.23478311 3.23560028 3.23592351 3.2362003  3.23721282
 3.23815281 3.23885636 3.23921305 3.24016874 3.24036281 3.24069973
 3.24072832 3.24101645 3.24380965 3.24444066 3.24521156 3.245534
 3.2462328  3.24685367 3.24750101 3.24801227 3.24888506 3.24904401
 3.24918771 3.24955246 3.25107214 3.25111648 3.25143228 3.25273612
 3.252998   3.25319117 3.25333375 3.2533698  3.25357743 3.25384068
 3.25572513 3.25588564 3.2567962  3.25692634 3.25776456 3.25841381
 3.25844319 3.25884469 3.25967869 3.26077718 3.26133478 3.26144335
 3.26145528 3.26151798 3.26184536 3.26194483 3.26208048 3.26369753
 3.26387047 3.26443274 3.26451003 3.26458983 3.26555415 3.26620541
 3.26685451 3.26934559 3.27071424 3.27233049 3.27343653 3.27350517
 3.2736791  3.27496373 3.27501331 3.27661098 3.27767203 3.27785775
 3.28005714 3.28086155 3.28161015 3.28168734 3.28196739 3.28240891
 3.28248489 3.28415169 3.28550311 3.28586968 3.28590442 3.28640295
 3.28655046 3.28773505 3.28804592 3.29019127 3.29070302 3.291886
 3.29301704 3.29392147 3.29618479 3.29663052 3.29753854 3.29791118
 3.29796372 3.29977991 3.30038231 3.30143689 3.30227614 3.30269985
 3.30277367 3.30292046 3.30347997 3.30403939 3.30455538 3.30462074
 3.30668498 3.3071072  3.30761438 3.3089184  3.30944847 3.30998833
 3.3116041  3.3119071  3.31380741 3.31455107 3.321563   3.32171779
 3.32368366 3.32425326 3.32446498 3.32533176 3.32604755 3.32663403
 3.32776117 3.32866838 3.33132391 3.33219682 3.33234287 3.3333755
 3.33369008 3.33386508 3.33415019 3.33765042 3.33787484 3.33866577
 3.3414325  3.34205254 3.3439042  3.34537062 3.34621126 3.34632804
 3.34761563 3.34769746 3.3486909  3.35045534 3.3515425  3.35272817
 3.35287325 3.35319643 3.3578004  3.35916499 3.35923936 3.36008358
 3.36032003 3.36217269 3.36466439 3.36559864 3.36789505 3.37060307
 3.37167926 3.3737246  3.37691912 3.37729834 3.37759351 3.37856235
 3.38072912 3.380952   3.38155872 3.38447514 3.38512022 3.38566152
 3.38599093 3.38696818 3.38744516 3.39011887 3.39286496 3.39301499
 3.3937495  3.39489057 3.39513173 3.39661333 3.39753527 3.39754966
 3.39814708 3.39930687 3.40112906 3.40201988 3.40373372 3.40392465
 3.40442285 3.40674234 3.4069284  3.40723596 3.40744043 3.40822037
 3.40913302 3.41018715 3.41030278 3.41915124 3.41947036 3.42392348
 3.43113127 3.43143205 3.43149846 3.43677176 3.44303398 3.44385085
 3.44396305 3.44898755 3.45091539 3.45308065 3.45833774 3.46277495
 3.46413739 3.46476229 3.46559126 3.46799216 3.46830423 3.47013841
 3.48812972 3.48925955 3.49468241 3.51710848 3.51765127 3.53457309
 3.54311402 3.54489868 3.55037424 3.55076022 3.56745938 3.57044371
 3.59156956 3.59535304 3.60453002 3.62244036 3.62306545 3.63697672
 3.64005635 3.65479085 3.67995771 3.69484441 3.77312084 3.78007706
 3.78364572 3.79048478 3.81777376 3.81884411 3.84314747 3.84542897
 3.8475902  3.84856309 3.86448672 3.91331117 3.9903345  4.0548471
 4.07944188 4.13826795 4.14005436 4.14356478 4.15227418 4.20558651
 4.21258312 4.39091032 4.39173228 4.44505034 4.59894268 4.69438426
 4.72846189 4.75337345 4.76391159 4.76790532 4.79652306 4.79733171
 4.8008411  4.80132415 4.80728059 4.80793402 4.81590655 4.81893448
 4.8220443  4.83286431 4.83384475 4.84487378 4.84791572 4.85941982
 4.863382   4.88228899 4.88299687 4.88493503 4.88787382 4.89056742
 4.9046427  4.91057252 4.92298065 4.92659558 4.97026424 4.97147728]

  warnings.warn(

2022-12-16 10:36:42,941:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.55650859 1.74506841 1.78814076 1.8092177  1.93464115 2.04107423
 2.42701422 2.42947641 2.84838283 2.86729212 2.89960326 2.91243795
 2.92741401 2.9301026  2.93328472 2.95259509 2.95345602 2.95387892
 2.95734047 2.95823859 2.95850149 2.9616254  2.96179368 2.96251332
 2.96345712 2.96386781 2.96693526 2.96947746 2.96969669 2.97040318
 2.97168806 2.97278725 2.97654845 2.97807952 2.97864249 2.97935231
 2.98027985 2.9810388  2.98126448 2.9814758  2.982263   2.98346187
 2.98390942 2.98433596 2.98558036 2.98583182 2.98839846 2.98913597
 2.98974474 2.99010025 2.99190101 2.99420651 2.99427502 2.9982062
 2.99886057 3.0015666  3.00188151 3.00197193 3.00239704 3.00481774
 3.00563619 3.00599693 3.00743902 3.00745177 3.00809107 3.00838889
 3.00858495 3.00914155 3.00969852 3.01003337 3.01064583 3.01078947
 3.01210508 3.01232924 3.01349876 3.01474571 3.01635461 3.01642797
 3.01752478 3.01847868 3.01891044 3.02034623 3.02148405 3.02184147
 3.02247938 3.02355529 3.03057046 3.03084132 3.03100124 3.0312604
 3.03136257 3.03189785 3.03234879 3.0328016  3.03317718 3.03438501
 3.03616262 3.03951438 3.0424877  3.04445872 3.04883849 3.04908175
 3.04917384 3.04991913 3.05250115 3.0563384  3.05867621 3.06238169
 3.06299629 3.06347879 3.0643547  3.06671631 3.06699583 3.06837838
 3.06895861 3.06910836 3.07932177 3.08075517 3.08128699 3.08213146
 3.0821681  3.08266846 3.08319976 3.0853606  3.08542361 3.08543137
 3.0855288  3.08909535 3.08955389 3.09005486 3.09115398 3.09131993
 3.09167206 3.09239044 3.09361582 3.09473003 3.09787403 3.09814541
 3.09836997 3.10008898 3.10359184 3.10378838 3.10410951 3.10432982
 3.10553904 3.10733351 3.10964503 3.11152627 3.11189136 3.11195984
 3.11203843 3.11217814 3.11228861 3.11464733 3.11467634 3.11505594
 3.11598604 3.11654098 3.11672803 3.1171922  3.11750659 3.11771508
 3.11794507 3.11901071 3.11901858 3.11908036 3.1195175  3.120366
 3.12040755 3.12060709 3.12103742 3.12113863 3.12119541 3.12128015
 3.12198453 3.12269214 3.12279274 3.12380572 3.1240005  3.12501423
 3.12515356 3.1253436  3.1259635  3.12640497 3.12655652 3.12660027
 3.12686325 3.1270412  3.12715984 3.12863701 3.12911814 3.12920321
 3.12961506 3.12980994 3.13004209 3.13051271 3.13101739 3.1314103
 3.13151421 3.13175011 3.13186706 3.13225896 3.13234505 3.13306301
 3.13311308 3.13314481 3.13344748 3.13352779 3.13406369 3.13429381
 3.13476313 3.13477869 3.13483303 3.1356334  3.13637723 3.13772784
 3.13799755 3.13811971 3.13819596 3.13824125 3.1389755  3.13916293
 3.13985588 3.14036455 3.1407338  3.14182255 3.14182266 3.14184034
 3.14191002 3.14226636 3.14256646 3.14304422 3.14306682 3.14328508
 3.14343348 3.14371991 3.14375716 3.14394879 3.14403409 3.14412024
 3.14425286 3.14428664 3.14429869 3.14431499 3.14487927 3.14515339
 3.14546359 3.14553449 3.14595709 3.14620855 3.14645702 3.14659649
 3.14673438 3.14678861 3.14684978 3.14694546 3.147459   3.14746711
 3.14754615 3.14765574 3.14776854 3.14785077 3.14788126 3.14814575
 3.14817539 3.14831722 3.14848768 3.14859676 3.14934974 3.14943685
 3.14955739 3.14962381 3.14982572 3.14997812 3.15008762 3.15022161
 3.15029217 3.15060095 3.151104   3.15176691 3.15189502 3.15211672
 3.15253103 3.15288242 3.15450798 3.15462462 3.15466286 3.15515826
 3.15551226 3.15568277 3.15578678 3.15585996 3.15602793 3.15606219
 3.15624837 3.15651285 3.15652055 3.15721632 3.15777955 3.15780835
 3.15810046 3.15825578 3.15828539 3.15841671 3.1585328  3.15927784
 3.15956942 3.15998713 3.1600786  3.16072623 3.16171333 3.16189522
 3.16240993 3.16282152 3.16287231 3.16317177 3.16396633 3.16435311
 3.16478472 3.16498038 3.16518737 3.16523957 3.16546221 3.16582895
 3.16591623 3.16596799 3.16640319 3.16654381 3.1668067  3.16713545
 3.16733585 3.16737933 3.16739862 3.16764542 3.16786803 3.16792123
 3.16832553 3.16902136 3.16906339 3.16931403 3.16951081 3.16989791
 3.17020814 3.17023168 3.17069868 3.17071925 3.17092137 3.17126721
 3.17128298 3.17179019 3.17195722 3.17200499 3.17208233 3.17228001
 3.17233926 3.17236702 3.17241173 3.17262568 3.17268892 3.17270174
 3.17278269 3.17290285 3.1730172  3.17302064 3.17349593 3.17352018
 3.17356642 3.17383816 3.1739661  3.17404951 3.17405461 3.17417314
 3.17441699 3.17442781 3.17470275 3.1747361  3.17483502 3.17488807
 3.17494445 3.17505563 3.17511783 3.17519579 3.17520251 3.17530087
 3.17602095 3.17625736 3.17635501 3.17640918 3.176443   3.17652558
 3.17668073 3.17701545 3.17702491 3.17703652 3.17712009 3.17759486
 3.17771559 3.17772692 3.17777597 3.17803431 3.17818633 3.178195
 3.17826992 3.17828369 3.17847127 3.17849839 3.17875513 3.17883776
 3.17899331 3.17919421 3.1792539  3.17971761 3.1797546  3.18043396
 3.18059679 3.18064284 3.18066148 3.18104444 3.18110044 3.18115765
 3.18119661 3.18150835 3.18176548 3.18179905 3.18182261 3.1818956
 3.18203677 3.18230199 3.18241758 3.18296264 3.18321579 3.18324508
 3.18407414 3.18455764 3.18503177 3.18504875 3.18519287 3.18524921
 3.1853817  3.18578536 3.18668544 3.18674004 3.18678736 3.18703229
 3.18711941 3.18715206 3.1872207  3.18728541 3.18754534 3.18774286
 3.18811964 3.18812295 3.18814871 3.18839202 3.18850494 3.18852264
 3.18855452 3.18893129 3.18916895 3.18985967 3.18990197 3.19032427
 3.19038243 3.19043657 3.19045403 3.19053571 3.19112517 3.19117204
 3.19121758 3.19135128 3.19154787 3.19196859 3.19240743 3.19286597
 3.19304588 3.19306693 3.1930941  3.19329608 3.19366889 3.19378725
 3.19388878 3.19447388 3.19452328 3.19485516 3.1951514  3.1952785
 3.1956107  3.19568773 3.19593771 3.1961502  3.19646234 3.19673454
 3.19697198 3.19706774 3.19770451 3.19794435 3.19796144 3.19832338
 3.19877642 3.19892474 3.19919384 3.19933925 3.1994178  3.19942916
 3.19980097 3.20013637 3.20017643 3.20039674 3.20061987 3.20090528
 3.20106012 3.20106579 3.20119748 3.20135785 3.20188096 3.20306876
 3.20399473 3.20456172 3.20465235 3.2048806  3.20493647 3.20530259
 3.20545536 3.2056902  3.20577341 3.20581861 3.20601172 3.20615842
 3.20654888 3.20694875 3.2071277  3.20769258 3.20795311 3.20810445
 3.20827756 3.20886966 3.2091562  3.20920899 3.20983987 3.20990737
 3.21037619 3.21076545 3.21092225 3.2124434  3.2137593  3.21394907
 3.21417718 3.21434697 3.21476752 3.21492064 3.21561052 3.21580398
 3.21655134 3.21677943 3.2167848  3.2169318  3.21720062 3.21738761
 3.21743279 3.21822077 3.2188888  3.21924148 3.21940432 3.21953811
 3.22036671 3.2206842  3.22120831 3.22170962 3.22290886 3.22335033
 3.2235621  3.22371843 3.22457154 3.22534939 3.22560934 3.22574985
 3.22622001 3.22638894 3.22740702 3.22796315 3.22856822 3.22892402
 3.22893318 3.22909818 3.22926245 3.22930132 3.23062529 3.23119218
 3.23140253 3.23145277 3.2317288  3.23183173 3.2330867  3.23325229
 3.23455068 3.23547932 3.23583653 3.23611979 3.2365119  3.23742855
 3.23826964 3.23979449 3.2399154  3.24380634 3.24395435 3.24493507
 3.24505912 3.24544365 3.24590779 3.24748901 3.24910023 3.24926896
 3.24953082 3.24966341 3.24968019 3.25023022 3.25031415 3.25309118
 3.25373866 3.25393276 3.2542094  3.25447983 3.25537438 3.25613777
 3.25840682 3.25876721 3.25943473 3.26051275 3.2612174  3.26179671
 3.26207264 3.26309517 3.26319293 3.26345272 3.26384416 3.263979
 3.26401138 3.26416051 3.26433991 3.26508038 3.26521662 3.26574014
 3.26603848 3.26695244 3.27010826 3.27053631 3.27072209 3.2719375
 3.27252602 3.27281436 3.27442946 3.2758116  3.27702022 3.27702637
 3.27757932 3.27815873 3.27858641 3.27860576 3.27880002 3.27902996
 3.27930842 3.27962752 3.2796954  3.27987998 3.2804854  3.2810302
 3.28138002 3.28276747 3.28324371 3.28330279 3.28417128 3.28475048
 3.28534626 3.28617296 3.2868209  3.28761588 3.28937262 3.29061505
 3.29214137 3.29276814 3.29300773 3.29377744 3.29549433 3.29582072
 3.296659   3.29805255 3.29848446 3.29859812 3.29887828 3.2991596
 3.29939138 3.30060644 3.3010308  3.30106228 3.30181629 3.30457524
 3.30482203 3.30504717 3.30535049 3.30602828 3.30654499 3.31103723
 3.31121235 3.31143584 3.31163134 3.31420015 3.3192659  3.32127501
 3.32141193 3.32144277 3.32255162 3.32385498 3.32469125 3.33223798
 3.33300306 3.33501649 3.33508495 3.33672707 3.33740587 3.33852697
 3.33881157 3.34021919 3.34454551 3.34735188 3.35093174 3.35187076
 3.35364535 3.35401161 3.35568159 3.35634463 3.35708299 3.3606854
 3.36141864 3.36189316 3.36269073 3.36365009 3.36379207 3.3692286
 3.3711855  3.37131028 3.37166879 3.37192073 3.37388787 3.37550313
 3.37720247 3.37779868 3.37829371 3.37876349 3.3795951  3.38238337
 3.38348997 3.38402091 3.38528812 3.38975782 3.38992011 3.39129187
 3.39496732 3.3953263  3.40441234 3.40927908 3.40942407 3.4126617
 3.42368535 3.42818504 3.43087218 3.43249935 3.440449   3.44346283
 3.45354924 3.45409929 3.45592961 3.46440035 3.4659104  3.4666987
 3.4764197  3.47677146 3.4777487  3.4952278  3.53701595 3.60616055
 3.6166314  3.62737205 3.63741915 3.65693037 3.65882159 3.66002725
 3.68129018 3.68817265 3.75110207 3.77063755 3.77408012 3.79233228
 3.7958496  3.80037386 3.80171063 3.81128738 3.81996349 3.82329722
 3.82828155 3.82864729 3.83101239 3.83707614 3.83883964 3.84055976
 3.84406512 3.84722133 3.92529979 3.93021476 3.94381729 3.99226166
 4.14508482 4.14881997 4.17019715 4.24057396 4.39252976 4.72793022
 4.74498939 4.74818824 4.77979246 4.78485769 4.80097044 4.8049187
 4.80953085 4.80960988 4.81199819 4.81430867 4.81860973 4.82163883
 4.8217663  4.82383046 4.82394877 4.82460087 4.82582504 4.82637554
 4.83106214 4.83174042 4.8329841  4.83395168 4.84120837 4.8431589
 4.84619023 4.85068736 4.85445451 4.85475728 4.86204142 4.86419421
 4.86836336 4.87050419 4.8706908  4.88527552 4.9156359  4.92204487
 4.92793853 4.9354248 ]

  warnings.warn(

2022-12-16 10:36:42,976:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.6415445  1.91230585 1.92150258 1.94230338 1.94420169 1.94561387
 1.97354444 1.97429443 1.98743869 1.99975598 2.12856719 2.16360495
 2.85023125 2.86678217 2.86866113 2.87366164 2.88297912 2.89265975
 2.89456345 2.89544688 2.8956469  2.89786282 2.90105853 2.90291984
 2.90461657 2.90529674 2.90530025 2.90683219 2.91007792 2.91008944
 2.91432835 2.91513586 2.91527672 2.91620668 2.91751309 2.91922331
 2.9209299  2.92373944 2.92382598 2.92918258 2.92936152 2.93556833
 2.94046737 2.9410926  2.94146645 2.94355497 2.94639234 2.94765692
 2.9487905  2.9524227  2.95412009 2.95444626 2.95461939 2.95478805
 2.95696664 2.95798204 2.95828178 2.95844475 2.96010178 2.96027129
 2.96109575 2.96211224 2.96283239 2.96488067 2.96660489 2.96748843
 2.96772069 2.96878261 2.97087935 2.97153454 2.97205544 2.97255766
 2.97351133 2.97364565 2.97638614 2.97819422 2.97931031 2.97973437
 2.98035154 2.98404712 2.98766203 2.98821484 2.98934188 2.99001919
 2.99091828 2.99108377 2.99316403 2.9958115  3.00243409 3.00291578
 3.00409431 3.00678213 3.00693325 3.00896547 3.00980778 3.01077858
 3.01153437 3.01206278 3.01226367 3.01248889 3.0146018  3.01505026
 3.01688719 3.01754951 3.02080192 3.02763302 3.02809658 3.03120274
 3.03304553 3.03334215 3.03534136 3.03559915 3.03807821 3.03837006
 3.04937219 3.0540898  3.05731923 3.06046461 3.06640939 3.06699384
 3.06918641 3.07203676 3.07210012 3.07531615 3.076722   3.08179609
 3.08361102 3.08389477 3.08479662 3.08847111 3.09286427 3.09375485
 3.09519748 3.09524657 3.09623745 3.09729742 3.09737348 3.0977599
 3.09840836 3.09905324 3.10108926 3.10120006 3.10148029 3.10636788
 3.10803779 3.10835644 3.10934751 3.10946011 3.10997707 3.11014114
 3.11065607 3.11227675 3.11443781 3.11673832 3.11681574 3.1174629
 3.11753095 3.11798078 3.11884001 3.11926887 3.11977201 3.11979727
 3.12073971 3.12175546 3.12203234 3.12353233 3.12370304 3.12379141
 3.12395883 3.12438989 3.12449547 3.12567075 3.1260329  3.12631911
 3.1270848  3.12714954 3.12724216 3.12852882 3.1300423  3.13022925
 3.13267467 3.13282618 3.1329411  3.13302928 3.13339125 3.13352889
 3.13365175 3.13416971 3.13459934 3.13472583 3.13479607 3.13500257
 3.13549717 3.13638659 3.13692811 3.13851306 3.13864477 3.13873975
 3.13942224 3.14035397 3.14075022 3.14112876 3.1413994  3.1414944
 3.14210366 3.14228468 3.14294334 3.1433973  3.14354995 3.1435792
 3.14388276 3.14411068 3.14532031 3.14539031 3.1457264  3.14580687
 3.14653942 3.14674564 3.14759702 3.14784755 3.14806585 3.14823452
 3.1482967  3.14850895 3.14889371 3.14944772 3.14946724 3.15002859
 3.15004231 3.15004416 3.15071702 3.15081405 3.15105209 3.15154172
 3.15199388 3.15256974 3.15261059 3.15281026 3.15319951 3.15346256
 3.15366685 3.15405438 3.15474581 3.15475417 3.15499031 3.1549951
 3.15506273 3.1558618  3.15715321 3.15748126 3.15792292 3.15802894
 3.15809763 3.1588132  3.15899577 3.15917387 3.15948399 3.15965331
 3.1600362  3.16015096 3.1601772  3.16069581 3.16079713 3.16118986
 3.16122644 3.16139306 3.16143097 3.1615943  3.16179441 3.16190238
 3.16264358 3.16305701 3.16338401 3.16357004 3.16375893 3.16395586
 3.16399345 3.16408656 3.16411044 3.16424892 3.16445988 3.16489763
 3.1649356  3.16544986 3.16577577 3.16608757 3.16628474 3.16631508
 3.16645712 3.16652554 3.16688411 3.16697726 3.16769778 3.16770565
 3.16778171 3.16834863 3.16856427 3.16936254 3.16980836 3.17035438
 3.17043275 3.17074441 3.17082336 3.17082371 3.17124753 3.1712839
 3.17149491 3.17194668 3.17199275 3.17220201 3.17232773 3.17290179
 3.17342229 3.17357409 3.17401155 3.17406455 3.17414227 3.17442559
 3.1745752  3.17477981 3.17529493 3.17534255 3.17626056 3.1763739
 3.17640378 3.17646547 3.17687806 3.17689396 3.17698017 3.1770324
 3.17762011 3.17836796 3.17843299 3.17845863 3.17847791 3.17866169
 3.17881051 3.17908729 3.1792351  3.17923941 3.17932066 3.17952259
 3.18012632 3.18015181 3.18025731 3.18030283 3.18033714 3.18037402
 3.18037889 3.18050404 3.18070515 3.18114604 3.18115951 3.18130612
 3.18169265 3.18176714 3.1818897  3.1821403  3.18247014 3.18261406
 3.18279907 3.18302911 3.18307932 3.18334616 3.18340175 3.18342485
 3.18413242 3.18434692 3.18435329 3.18443899 3.18446516 3.18456706
 3.18463392 3.18478814 3.18532002 3.18532989 3.18537324 3.18555788
 3.18590937 3.1864982  3.18656526 3.1869861  3.18780258 3.1878658
 3.18818861 3.18842372 3.18849978 3.18858539 3.18869505 3.18899628
 3.1895937  3.18987888 3.18987919 3.19010496 3.19010812 3.19013192
 3.19022929 3.19054372 3.19084403 3.19119214 3.19144824 3.19165489
 3.19184788 3.19190174 3.1921228  3.19266825 3.19307698 3.19314883
 3.19317233 3.19335559 3.19337627 3.19354477 3.1937913  3.19379576
 3.19381599 3.19389632 3.19405934 3.19418893 3.19433479 3.19440462
 3.19445723 3.19449216 3.19471148 3.19499193 3.1950862  3.19546305
 3.1962052  3.1963821  3.19654934 3.19670197 3.19674614 3.19712354
 3.19727842 3.19752282 3.19770488 3.19798439 3.19800444 3.19823932
 3.19835165 3.19847154 3.19848081 3.19871696 3.19872921 3.19930578
 3.19941965 3.19982212 3.19997233 3.20045473 3.20126196 3.2013131
 3.20159986 3.20217747 3.20222233 3.20223531 3.20252935 3.2025702
 3.20286786 3.20308725 3.20317962 3.20333402 3.20343267 3.20353264
 3.20363917 3.20367602 3.20397892 3.20419093 3.20441452 3.20459664
 3.20470612 3.20514475 3.20545418 3.20546765 3.20557618 3.20578543
 3.20594571 3.20632292 3.20659007 3.20692632 3.20812733 3.20816195
 3.20824347 3.20901966 3.20903569 3.20910335 3.20965841 3.20969446
 3.2103793  3.21041879 3.21061165 3.21064764 3.21101056 3.21125076
 3.21146545 3.21151102 3.21224437 3.21261823 3.21281776 3.21287512
 3.21290185 3.21317919 3.21318926 3.21321455 3.21339118 3.21367754
 3.21405538 3.21408561 3.21417489 3.21486604 3.21543904 3.21558673
 3.2158429  3.21623041 3.21653819 3.21657408 3.21658729 3.21671127
 3.21681224 3.21746949 3.21752228 3.21769383 3.2178354  3.2179793
 3.21807247 3.21825675 3.21868663 3.2191419  3.21926804 3.22016077
 3.22025838 3.22069024 3.22075178 3.22099072 3.22110241 3.22173091
 3.22176072 3.22274994 3.22303166 3.22327409 3.22349974 3.22350062
 3.22366384 3.2237148  3.22400672 3.22420221 3.22473089 3.22497421
 3.22500353 3.22504728 3.22522004 3.22528963 3.22539473 3.22540489
 3.22541494 3.22542892 3.22570165 3.22591505 3.22600366 3.22607403
 3.22620132 3.22634475 3.22668685 3.22694755 3.22754902 3.22799335
 3.22838949 3.22841418 3.2286566  3.22904228 3.22925243 3.22976138
 3.22981853 3.23047898 3.23156434 3.23173055 3.23202215 3.23250673
 3.23256735 3.23294745 3.23323844 3.23402888 3.23410228 3.23473279
 3.23475073 3.2348665  3.23499936 3.23511134 3.23526607 3.2358846
 3.23626782 3.2365349  3.23680314 3.23761552 3.23768029 3.23786825
 3.23850317 3.2386655  3.23893999 3.23916417 3.23951975 3.23954967
 3.24051824 3.24068672 3.24133216 3.24146138 3.24206005 3.24267623
 3.24386681 3.24421585 3.24511457 3.24518475 3.2456611  3.24607186
 3.24659725 3.24662966 3.24678284 3.24759155 3.24969697 3.25032451
 3.25333367 3.25343623 3.25358639 3.25471869 3.25563637 3.25600318
 3.25721138 3.25778073 3.2584019  3.25851408 3.26019666 3.26047343
 3.26206827 3.2628851  3.26391184 3.26486336 3.2652124  3.26549418
 3.2687771  3.2702794  3.2707963  3.27127413 3.27409123 3.27458151
 3.2747606  3.27479942 3.27505851 3.27571644 3.27571818 3.27577878
 3.27795376 3.27988569 3.28023787 3.28256761 3.28258498 3.28283942
 3.2834163  3.28489836 3.28539876 3.28719284 3.28754903 3.2896505
 3.29218321 3.29227607 3.2933483  3.29344967 3.29424162 3.29560148
 3.29657223 3.29801742 3.29975082 3.30058958 3.30073809 3.3040049
 3.30416681 3.30487155 3.3056944  3.3059295  3.30707921 3.30767303
 3.30794581 3.30908409 3.31146317 3.31236111 3.31356538 3.31415632
 3.31431709 3.31559756 3.31947374 3.31977021 3.32031143 3.32655026
 3.32700875 3.32802971 3.32846731 3.33179968 3.33533211 3.33798594
 3.33938192 3.34020446 3.34152294 3.3423575  3.34469052 3.34501943
 3.34680536 3.35060252 3.35256468 3.35293358 3.35293935 3.35313076
 3.35340409 3.35761497 3.35846769 3.35864706 3.35915897 3.36163353
 3.36490347 3.36517964 3.36633121 3.36759701 3.36782433 3.36796342
 3.36949535 3.37214958 3.37221017 3.37532954 3.37557543 3.37632582
 3.37974505 3.38045965 3.38171941 3.38218264 3.38293902 3.38343316
 3.3843997  3.38700426 3.38906225 3.38911181 3.39121845 3.3920952
 3.39437039 3.39455795 3.39585143 3.39613213 3.39743818 3.39851216
 3.40174762 3.40288031 3.40319061 3.40432379 3.40508938 3.40575309
 3.40669498 3.40870273 3.40987857 3.41074918 3.41108803 3.4119477
 3.41211098 3.41276184 3.4145902  3.41547986 3.4172156  3.41920427
 3.42262109 3.42272382 3.42340245 3.42360424 3.42386626 3.42459059
 3.42479912 3.42614525 3.42644095 3.42737572 3.4282792  3.42934835
 3.42971555 3.43501006 3.4360811  3.4397672  3.44974305 3.45059263
 3.45434523 3.46597487 3.48528746 3.49690395 3.51591062 3.52410635
 3.53376163 3.53874096 3.55291564 3.56639544 3.61238863 3.63570562
 3.66207249 3.66400685 3.67200048 3.67550981 3.70890263 3.74006317
 3.79922493 3.83716567 3.8412604  3.86723805 3.8718112  3.87341368
 3.87651899 3.88212947 3.88390965 3.9031585  3.90551939 3.90668676
 3.91897852 3.93172452 3.97264058 3.98945396 3.98982162 4.06480207
 4.108938   4.13498866 4.2140423  4.31486882 4.33412968 4.38090634
 4.50499568 4.52233872 4.69859665 4.76727117 4.79215093 4.79864803
 4.80507737 4.80775138 4.81403293 4.81638414 4.81979655 4.82124647
 4.82328688 4.82616859 4.83151259 4.83355531 4.83594202 4.83615927
 4.83721285 4.83862003 4.83890106 4.83971211 4.84036052 4.84037506
 4.84417349 4.84426009 4.84473767 4.8476399  4.85377408 4.86410692
 4.87800002 4.89469059 4.91512495 4.93824873 4.95398086 4.96178069
 4.96505318]

  warnings.warn(

2022-12-16 10:36:43,001:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.88161803 1.90296708 1.93598404 1.97433769 1.98281756 2.05638675
 2.187574   2.57419658 2.71401601 2.84495143 2.85051481 2.85743287
 2.86458263 2.88161275 2.88432378 2.89784612 2.90279427 2.90371493
 2.90501919 2.90929586 2.91292051 2.91338868 2.91615408 2.92325029
 2.92419444 2.92522594 2.9305105  2.93515909 2.93554171 2.93791817
 2.94032951 2.94105157 2.94215189 2.94657562 2.94691281 2.94823895
 2.94875218 2.94947374 2.9514532  2.95429068 2.95596553 2.95854557
 2.95886679 2.96074226 2.96101639 2.96130208 2.96146209 2.96273741
 2.96332948 2.96423504 2.96500198 2.9652092  2.96535307 2.96557988
 2.96562534 2.96588013 2.96655229 2.96777995 2.9683289  2.96836876
 2.9686707  2.96882689 2.96894383 2.97025481 2.97205426 2.97237577
 2.97270711 2.97343345 2.97605665 2.97679886 2.97895597 2.97918775
 2.98070468 2.98106962 2.98122635 2.98291438 2.98399441 2.9844218
 2.99112701 2.99363034 2.99618837 2.99679992 2.99688033 2.99814495
 2.99876008 2.99947233 3.00136656 3.00498841 3.00503338 3.00559971
 3.007129   3.00767259 3.00979998 3.01228759 3.01329813 3.01479809
 3.01549219 3.01630288 3.01788344 3.01881778 3.01885927 3.0200824
 3.02124477 3.02279355 3.02356404 3.02708387 3.03146237 3.03471539
 3.0367605  3.03820709 3.03869262 3.04271101 3.04356363 3.04378685
 3.04404225 3.04410647 3.04497391 3.04598252 3.04895345 3.05059857
 3.05285569 3.05358662 3.05447032 3.05452808 3.05531856 3.05544891
 3.05742727 3.05820258 3.05943037 3.05956092 3.06099733 3.06263974
 3.06344611 3.06529469 3.06611881 3.06667985 3.0667306  3.0673878
 3.06783834 3.06803826 3.06992062 3.07009717 3.07247051 3.07535238
 3.0755204  3.07792071 3.07929779 3.08218495 3.0825341  3.08281302
 3.08300783 3.08313738 3.08387835 3.08429773 3.08451729 3.08467892
 3.08538051 3.08538968 3.0855162  3.08555647 3.0877799  3.08928609
 3.08932947 3.08991372 3.09019011 3.09060779 3.09094778 3.09119657
 3.092271   3.09270063 3.09344197 3.094403   3.09525292 3.09653845
 3.09696064 3.09707433 3.09759247 3.09849273 3.09855018 3.09861504
 3.0988431  3.10061796 3.10160673 3.10287467 3.10352268 3.10356003
 3.10397885 3.10444848 3.10528234 3.10579924 3.10607144 3.10609828
 3.10694197 3.10783482 3.10861228 3.10890472 3.10971476 3.1098038
 3.11035653 3.11048827 3.11076997 3.11152655 3.11173144 3.11208885
 3.11273917 3.11296986 3.11370055 3.11371141 3.11443613 3.11593764
 3.11677729 3.11778194 3.11782414 3.11959134 3.12052746 3.12102491
 3.12123373 3.12139965 3.12147434 3.12162012 3.12216009 3.12238719
 3.12322265 3.12335938 3.12486258 3.12514226 3.12625355 3.12674634
 3.12681356 3.1268503  3.12773475 3.12898636 3.1303521  3.13056351
 3.13077198 3.13127247 3.13189561 3.13196478 3.13198235 3.1322528
 3.13262251 3.13329482 3.13342462 3.13404034 3.13451229 3.13551993
 3.13555911 3.13559276 3.13576776 3.13590982 3.13600588 3.13629345
 3.13662665 3.13738273 3.13746521 3.13749203 3.13753183 3.13769664
 3.13771157 3.13827134 3.13862195 3.13923335 3.13975315 3.13988221
 3.13996704 3.14058602 3.14086865 3.14110647 3.1414634  3.14162742
 3.14220177 3.14223884 3.14225853 3.1425733  3.14295064 3.14299971
 3.14318966 3.14324171 3.14342892 3.1435262  3.14406117 3.14452238
 3.14472263 3.1449166  3.14588912 3.14691523 3.14708135 3.14719107
 3.14728392 3.14744249 3.14744383 3.14820292 3.14846686 3.14864096
 3.14896853 3.14899218 3.14907158 3.14912977 3.14913922 3.14924757
 3.14925913 3.14937941 3.14951936 3.14995309 3.14995685 3.15000002
 3.15016531 3.15018791 3.15029654 3.15039674 3.15039981 3.15044129
 3.15066629 3.15066722 3.15085692 3.15088607 3.15175669 3.15222392
 3.1525287  3.15268595 3.15277201 3.15307359 3.15310203 3.15316719
 3.15336648 3.15352968 3.15354267 3.15399093 3.15448605 3.15467986
 3.15499944 3.15512626 3.1552034  3.15540172 3.15554302 3.15583897
 3.15682233 3.15705223 3.15710357 3.15711742 3.15753922 3.15755674
 3.15762037 3.15811411 3.15837817 3.15852814 3.15888316 3.15897598
 3.15908337 3.15928278 3.15958036 3.15959899 3.15981158 3.15999708
 3.16010842 3.16012418 3.16045018 3.16060389 3.16067085 3.16098227
 3.1609901  3.16128778 3.16131365 3.16156552 3.16173032 3.16196687
 3.16255964 3.16271123 3.16274381 3.16278328 3.16294853 3.16305761
 3.16309719 3.16371573 3.1643689  3.16464707 3.16507185 3.1653983
 3.16557403 3.16573365 3.16614331 3.16624411 3.16641855 3.16680259
 3.16702608 3.16759346 3.16894298 3.1691306  3.16915636 3.16941622
 3.16964286 3.16982107 3.16987153 3.16993405 3.17002801 3.1701367
 3.17038322 3.17038434 3.17066218 3.1711348  3.17126551 3.17129689
 3.1715482  3.1716494  3.17171404 3.17171706 3.17186216 3.17199141
 3.17235788 3.17244075 3.17278356 3.17294728 3.17331509 3.17401599
 3.17410725 3.1742151  3.17445437 3.17476334 3.17503182 3.17505036
 3.17645455 3.17732057 3.17764555 3.17782648 3.17812665 3.17816968
 3.17823449 3.17829737 3.17838121 3.17845254 3.17872925 3.17888058
 3.17910429 3.17981732 3.17987671 3.18017562 3.18150977 3.1815977
 3.18167689 3.18180224 3.18212431 3.18270408 3.18296092 3.18298514
 3.1836546  3.1839471  3.18441547 3.18539609 3.18583551 3.18653323
 3.18703108 3.18732789 3.18742966 3.18748382 3.18760632 3.18772105
 3.18773163 3.18781104 3.18842639 3.18865658 3.18893644 3.18953457
 3.18995719 3.19044435 3.19148426 3.19160204 3.19181324 3.19195988
 3.19233988 3.19246779 3.19258224 3.19315149 3.19319827 3.19373109
 3.1943722  3.19462718 3.19471104 3.19474997 3.19496421 3.1950456
 3.1950467  3.19587392 3.19625072 3.19649367 3.1968919  3.19704259
 3.19705372 3.19711295 3.19728522 3.197591   3.19783237 3.19790302
 3.19871507 3.19881921 3.19920059 3.19936872 3.19940088 3.19975598
 3.19984001 3.20066592 3.20122081 3.20122516 3.20130261 3.20183291
 3.20265051 3.20293572 3.20317016 3.20321244 3.20348836 3.20416218
 3.20438436 3.20481667 3.20498429 3.20547641 3.20550915 3.20577859
 3.20578549 3.20608511 3.20609947 3.20610346 3.20617075 3.20657415
 3.20680771 3.20686154 3.2074827  3.20756337 3.20796947 3.20810126
 3.20819814 3.20826481 3.20830017 3.2085704  3.20858717 3.20864719
 3.20985551 3.20986229 3.20995188 3.21003768 3.21059016 3.21081748
 3.21124818 3.21130803 3.21136046 3.21217906 3.21280127 3.21286867
 3.21304775 3.21316791 3.21342443 3.21382548 3.2140553  3.2144152
 3.21474435 3.21493621 3.21499665 3.21537521 3.21564932 3.21578384
 3.21626437 3.21640463 3.21656297 3.2173736  3.21765313 3.21768311
 3.21794346 3.21818976 3.21828556 3.21858483 3.21860668 3.22018136
 3.22026607 3.22118173 3.22158578 3.22306388 3.22375302 3.22379549
 3.22431338 3.22465575 3.22587493 3.22660384 3.22739499 3.2274727
 3.22810879 3.22826654 3.22882816 3.22911858 3.22972352 3.22978134
 3.22979119 3.23024652 3.23043967 3.23064412 3.23138719 3.23175663
 3.23210184 3.23229072 3.23252382 3.23318207 3.23494696 3.23512924
 3.23760691 3.23956934 3.24039969 3.24099845 3.24194045 3.24201097
 3.24243176 3.24321    3.24377321 3.24480168 3.24585788 3.24609558
 3.24667241 3.24806829 3.24903502 3.25039507 3.25071424 3.251138
 3.25145767 3.2514647  3.25165994 3.25256305 3.25259653 3.25281585
 3.25396728 3.25453965 3.254784   3.25485096 3.25531093 3.25564128
 3.25592558 3.25642799 3.25736431 3.25752965 3.26079114 3.26178435
 3.26217101 3.26260727 3.26823568 3.27086424 3.27244559 3.2728256
 3.2732092  3.27451291 3.27477074 3.27488371 3.27599085 3.27692876
 3.27771831 3.28002126 3.28049888 3.28065128 3.2811175  3.28128721
 3.28153633 3.28172978 3.28183629 3.28196033 3.28200553 3.28375868
 3.28640799 3.28667896 3.28776502 3.28840917 3.28966745 3.29084991
 3.29100782 3.29193448 3.2948834  3.29605697 3.29729087 3.29818713
 3.29944971 3.30221069 3.30328822 3.30355492 3.30390683 3.30466229
 3.30580502 3.3077096  3.30884008 3.30998057 3.31090343 3.31114702
 3.31130009 3.31134886 3.31603337 3.31603847 3.316327   3.31638329
 3.31673771 3.31862424 3.31993531 3.32069226 3.32181824 3.32276582
 3.32464763 3.32521168 3.32652804 3.32654394 3.32679542 3.32736197
 3.32780418 3.32880927 3.32892401 3.33140411 3.33222778 3.33315659
 3.33669895 3.34052571 3.34191307 3.34356951 3.3451861  3.34642407
 3.34720341 3.34817792 3.34847868 3.34861933 3.34887355 3.34942216
 3.3516324  3.35369415 3.35398103 3.35545954 3.35574072 3.35624813
 3.35670893 3.35683257 3.35716009 3.35794272 3.35872699 3.3596541
 3.3597923  3.35995217 3.36421608 3.36441765 3.36597865 3.36635341
 3.36635466 3.36642127 3.36712773 3.36713437 3.36733795 3.36773332
 3.36788564 3.36971304 3.37014421 3.37057386 3.37079433 3.37601212
 3.37776728 3.37872999 3.37926214 3.38035251 3.38073106 3.38084591
 3.38262272 3.38327431 3.3839508  3.38426676 3.38698961 3.38888186
 3.39212578 3.39243121 3.39610788 3.39660131 3.39912566 3.39944231
 3.40318254 3.40676818 3.40881228 3.40927474 3.40956835 3.41373998
 3.41494996 3.41676516 3.41718796 3.4179767  3.42243608 3.42667022
 3.42891888 3.43128439 3.43610761 3.44432074 3.44473028 3.44521782
 3.45469345 3.45579289 3.45980814 3.47061806 3.47601277 3.48195702
 3.49388586 3.49547254 3.49904282 3.50074281 3.50281429 3.50706637
 3.5111433  3.51836189 3.52871517 3.52969156 3.53025266 3.54278474
 3.63180205 3.64651995 3.76215388 3.78335195 3.7916333  3.80561921
 3.80680918 3.82535163 3.8374043  3.83743255 3.84446826 3.85620872
 3.85730712 3.85973671 3.87145901 3.89848984 3.91667842 3.92637704
 4.34585445 4.41192869 4.47686156 4.55012586 4.70415415 4.74991228
 4.76540315 4.81373617 4.81395174 4.81474304 4.81494201 4.81508061
 4.81631207 4.81962652 4.81963234 4.82236739 4.82540675 4.82743762
 4.83321979 4.83356939 4.83702536 4.84506727 4.85019617 4.85640716
 4.85890803 4.87231344 4.88712348 4.92550659 4.93353662 4.93408525
 4.94997448 4.95299128 4.98371117]

  warnings.warn(

2022-12-16 10:36:43,554:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:36:43,572:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:36:43,706:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.90478344 2.46614092 2.84688236 2.84799321 2.8480219  2.850055
 2.88347091 2.89662065 2.90906656 2.91811663 2.92490136 2.93297378
 2.93389455 2.93393526 2.9380361  2.93935612 2.94170416 2.94589892
 2.94822186 2.94867708 2.95046384 2.95086523 2.9518776  2.9527269
 2.95363826 2.95399156 2.95496943 2.95559083 2.95638951 2.95639375
 2.9572985  2.9596742  2.9597159  2.96143548 2.9614989  2.96158886
 2.9647284  2.96475222 2.96872298 2.96874633 2.96937782 2.96970031
 2.97464963 2.97713661 2.97805454 2.98302391 2.98625622 2.9862608
 2.98701254 2.98818265 2.98829167 2.98869524 2.99270916 2.99415707
 2.994788   2.99619976 2.99689014 3.00064275 3.00073225 3.00160468
 3.0027809  3.0032692  3.00469424 3.00630405 3.0067983  3.00841815
 3.00891719 3.00937468 3.01198212 3.01338875 3.01540201 3.01904319
 3.02155864 3.02233268 3.02426898 3.02462918 3.02484351 3.02641911
 3.02697644 3.03170782 3.03176367 3.03217255 3.03637622 3.03915899
 3.04118523 3.04467365 3.04508532 3.04580034 3.04914825 3.04955525
 3.05055333 3.05071598 3.05548865 3.05644592 3.05680171 3.06659361
 3.06816916 3.06987938 3.06997888 3.07043143 3.07163061 3.0725363
 3.07474503 3.07475626 3.07491452 3.07629181 3.07845654 3.08216981
 3.08266932 3.08418839 3.08810604 3.09025518 3.0904615  3.09129652
 3.09163513 3.09184488 3.09436004 3.09517063 3.09573907 3.09708828
 3.09781141 3.10086265 3.10348803 3.10415569 3.10465588 3.10517434
 3.10535949 3.10537811 3.10673771 3.10739469 3.10769176 3.10918494
 3.10971771 3.11051819 3.11187891 3.11203451 3.11210486 3.11222237
 3.11259181 3.11310104 3.11346368 3.11420508 3.11513425 3.11551716
 3.11640089 3.1164919  3.11650069 3.11710913 3.11828182 3.11896325
 3.1194233  3.11990737 3.12080879 3.12127349 3.12214091 3.1224007
 3.12297976 3.12308801 3.12358056 3.1242673  3.12444006 3.12461659
 3.12530644 3.12707023 3.12736521 3.12824691 3.1285777  3.12876808
 3.12934655 3.12952239 3.12958885 3.13013331 3.13078068 3.1309238
 3.13112754 3.13163605 3.13208164 3.13241528 3.1326769  3.13269736
 3.13305539 3.13316156 3.13334017 3.13432903 3.13487895 3.13506664
 3.13536259 3.13538092 3.13562035 3.1357678  3.13698917 3.13701129
 3.13734012 3.13808097 3.13817161 3.1392041  3.13922999 3.14105367
 3.14130695 3.14131639 3.14165111 3.14168334 3.14184925 3.14206343
 3.14221596 3.14222503 3.14226955 3.14234071 3.14362533 3.14386441
 3.14402461 3.14403317 3.14453882 3.14473477 3.14478349 3.14486565
 3.14502218 3.14546524 3.14584318 3.14650684 3.14653853 3.14659833
 3.14695793 3.14723116 3.14749469 3.14751435 3.14760335 3.14760588
 3.14766836 3.14804004 3.1480605  3.14817846 3.14834091 3.14834808
 3.1483942  3.1489704  3.14912632 3.1493786  3.14968476 3.14969679
 3.15014463 3.1504525  3.15079555 3.15085919 3.15113039 3.15142551
 3.15207133 3.15232984 3.15247025 3.15299507 3.15341672 3.15360048
 3.15380467 3.15403994 3.15409466 3.15424013 3.15426524 3.15452477
 3.1549795  3.15551154 3.15570967 3.15571078 3.15617759 3.1567616
 3.15695533 3.15713986 3.15747184 3.15752659 3.15762854 3.15769955
 3.15859773 3.1588654  3.1590349  3.15949295 3.15953222 3.1596506
 3.15984708 3.16039831 3.16071936 3.1607568  3.16092317 3.1615438
 3.16196433 3.16202141 3.16213645 3.16247356 3.16253308 3.16301706
 3.16302414 3.16319378 3.1632096  3.16329053 3.16349883 3.16354847
 3.16364158 3.16459477 3.16463436 3.16476505 3.1648229  3.16490594
 3.16493339 3.16526824 3.16564371 3.16612555 3.16616724 3.16656553
 3.16657449 3.16725009 3.16756715 3.16761015 3.16836949 3.16840321
 3.16856867 3.1685969  3.16872424 3.16881075 3.16961871 3.16972728
 3.16998677 3.17022857 3.17057049 3.17067301 3.17138997 3.17141315
 3.17221306 3.17252258 3.17301591 3.17316214 3.17317631 3.17327523
 3.17331786 3.17361314 3.17363664 3.17379981 3.17386751 3.17420171
 3.1760307  3.17644845 3.17651934 3.17666914 3.17671905 3.17689191
 3.17705163 3.17732057 3.17734846 3.17736295 3.17822802 3.17828187
 3.17859331 3.17888408 3.17911286 3.17928933 3.17933335 3.17985241
 3.17990043 3.180006   3.18023767 3.18031249 3.18042587 3.18051676
 3.18084983 3.18111202 3.18136464 3.18143114 3.18144038 3.18149182
 3.18169651 3.18185207 3.18188179 3.18193751 3.18200826 3.18232205
 3.18237971 3.18415606 3.18416815 3.18432525 3.18473382 3.18514212
 3.18558723 3.18576148 3.18580286 3.18600988 3.18610405 3.18632792
 3.18660225 3.18697147 3.1872485  3.1872605  3.18769519 3.18780636
 3.18805376 3.1882417  3.18855314 3.18906846 3.18907562 3.18921352
 3.1894949  3.18978043 3.18986605 3.18990319 3.19019836 3.1902874
 3.19072957 3.19077497 3.19114293 3.19127249 3.19134612 3.19149891
 3.19161675 3.19165668 3.191733   3.19207794 3.19217058 3.19241324
 3.19241496 3.19242378 3.19264939 3.19305037 3.19320793 3.19329164
 3.19344136 3.19347627 3.19350056 3.1938236  3.19435687 3.19460482
 3.19478949 3.19495521 3.19539318 3.19552566 3.19560796 3.19560893
 3.1956849  3.19578497 3.19584687 3.196211   3.19633984 3.19639057
 3.19640775 3.19645221 3.19682413 3.19691034 3.19742994 3.19747735
 3.19756967 3.19757433 3.19766388 3.19807252 3.19847053 3.19850741
 3.19855145 3.19888139 3.19897258 3.19904083 3.19912081 3.19912208
 3.19913515 3.20008177 3.20035303 3.20044587 3.20072451 3.20136674
 3.20139595 3.20153564 3.20173117 3.20213719 3.20251705 3.20294444
 3.20300122 3.20322196 3.20324524 3.20325636 3.20348524 3.20431292
 3.20432332 3.20449024 3.20469826 3.2047898  3.20511996 3.20517498
 3.20551137 3.20552293 3.20552675 3.20553171 3.2058929  3.20617895
 3.20670095 3.20682083 3.20686679 3.20689    3.20692061 3.20700181
 3.20735466 3.20738456 3.20798284 3.2080574  3.20814118 3.20820035
 3.20820461 3.20836572 3.20860056 3.20900746 3.20910193 3.20962679
 3.21019956 3.21025314 3.21068651 3.21073521 3.21078657 3.21086626
 3.21148238 3.21229776 3.21272592 3.21296154 3.21325843 3.21342627
 3.21411358 3.21427567 3.21445836 3.21454625 3.21533058 3.21552239
 3.21562885 3.21582977 3.21671997 3.2168508  3.21718485 3.21726726
 3.2175768  3.21768618 3.21777173 3.21795981 3.21801295 3.21804193
 3.21822036 3.21833313 3.21897718 3.21912743 3.2192282  3.21932551
 3.21965894 3.21978395 3.21996453 3.22033671 3.22038506 3.22096692
 3.22103154 3.22132875 3.22145    3.22165212 3.22168514 3.22195877
 3.22347492 3.22356327 3.22371122 3.22374184 3.22389769 3.22449062
 3.22493286 3.22596956 3.22640617 3.22686855 3.22692924 3.2269397
 3.22707631 3.22855349 3.2295125  3.22977123 3.23035786 3.23067638
 3.23073022 3.23097393 3.23114188 3.23204011 3.23243767 3.23246179
 3.23398936 3.23455816 3.23499363 3.23530203 3.23595175 3.23659182
 3.23733241 3.23744166 3.23769669 3.23792589 3.23924721 3.23949327
 3.23951796 3.2404715  3.24087356 3.24141506 3.24286806 3.24309328
 3.24309718 3.24321518 3.24540582 3.24687563 3.24691404 3.24702965
 3.2481948  3.24837102 3.24913883 3.24939799 3.24966612 3.2501716
 3.25103927 3.25297311 3.25326359 3.25335778 3.25430915 3.25448027
 3.25456249 3.25472162 3.25480276 3.25500318 3.25515864 3.25564885
 3.25650454 3.2565789  3.25665301 3.25678553 3.25816265 3.25852081
 3.25864748 3.25865832 3.25901055 3.25949584 3.25979149 3.25979667
 3.26109818 3.26116541 3.26182494 3.26389326 3.26403058 3.26442803
 3.26469807 3.26489619 3.26588923 3.26637273 3.26664996 3.26778177
 3.26807956 3.26840663 3.27014439 3.27107571 3.27147421 3.27158693
 3.27325789 3.27340824 3.27350378 3.27389636 3.27521722 3.27580989
 3.2766599  3.27672047 3.27716139 3.27773178 3.27909058 3.27912134
 3.27982967 3.28301799 3.28397397 3.28421181 3.28466101 3.28487326
 3.28623218 3.28661274 3.28845764 3.2899942  3.29030264 3.29037788
 3.29051513 3.2910187  3.292239   3.29402879 3.29593137 3.29651523
 3.29873011 3.29916525 3.30374979 3.30431157 3.30592274 3.30656798
 3.30728914 3.3073546  3.30813693 3.31061525 3.31076143 3.31098991
 3.31147091 3.31204734 3.31291749 3.31625006 3.31758714 3.31844423
 3.3195968  3.3203918  3.321031   3.32491908 3.32737938 3.3279195
 3.32955625 3.32957394 3.33077015 3.33085125 3.33120646 3.33221741
 3.332294   3.33303796 3.33414441 3.33476497 3.3355251  3.3359114
 3.33707466 3.33831084 3.34028297 3.34028455 3.34079225 3.34245711
 3.34473205 3.34556359 3.34705894 3.34969453 3.35056671 3.35150112
 3.35266337 3.35270583 3.35372947 3.35426459 3.35434471 3.35438556
 3.35882835 3.35884183 3.36166141 3.3619876  3.36325255 3.36334412
 3.36335528 3.36336572 3.36394409 3.36613365 3.36719277 3.36744814
 3.36946103 3.37000874 3.37067279 3.37351408 3.37511145 3.37657743
 3.37664608 3.37764329 3.37791693 3.37900907 3.37912224 3.37916761
 3.38034731 3.38165408 3.38220928 3.38537542 3.38651295 3.38741017
 3.38763149 3.38788477 3.390138   3.39106211 3.3911416  3.39393789
 3.3960551  3.39633411 3.39678036 3.39911468 3.40074281 3.40156315
 3.40162111 3.40240132 3.40273362 3.40368625 3.40501586 3.40778038
 3.40823761 3.41083847 3.41145566 3.4136671  3.4269668  3.4280252
 3.43293527 3.4392363  3.46320654 3.47133877 3.49285102 3.49847647
 3.51171734 3.53502896 3.56016806 3.56040698 3.57700781 3.58729542
 3.5912936  3.59466898 3.59494261 3.61310513 3.62582945 3.6506369
 3.654395   3.74241774 3.74336168 3.75656746 3.7618094  3.76681383
 3.77277758 3.78065736 3.78742179 3.79354679 3.81922467 4.18225473
 4.21607658 4.24912096 4.32889872 4.35999521 4.39249423 4.69533235
 4.70088563 4.70848444 4.71768913 4.75359853 4.75921253 4.77313356
 4.77465189 4.7802516  4.78622615 4.78625485 4.79404771 4.79755928
 4.79950973 4.8013645  4.80258681 4.80274939 4.80473986 4.80778921
 4.81001123 4.8183938  4.82196385 4.82403179 4.82404833 4.82602001
 4.82758035 4.82968304 4.8305135  4.83119922 4.83857659 4.85074883
 4.89631221 4.92518244 4.96278373 5.00224991]

  warnings.warn(

2022-12-16 10:36:43,716:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.55895636 1.5605789  1.83939422 1.87792203 1.90231831 1.90243698
 1.91738313 1.93556974 1.9403809  1.95493282 1.9606319  1.97343141
 2.02229399 2.14496664 2.58417668 2.73705228 2.75170988 2.797469
 2.80562496 2.81433108 2.82704674 2.83958683 2.84113724 2.84252651
 2.85210843 2.872923   2.87369547 2.88105393 2.90823579 2.90824412
 2.91073209 2.91120646 2.9168146  2.91949007 2.93293323 2.9329733
 2.94054876 2.9448746  2.94519787 2.94645433 2.94767886 2.94822743
 2.95021408 2.95106697 2.95176643 2.95195653 2.95271343 2.95320482
 2.95413492 2.95630631 2.95657159 2.95669774 2.95945981 2.96174955
 2.96294649 2.96296556 2.9709512  2.97141866 2.97300039 2.97363733
 2.97380836 2.97402914 2.97539872 2.97569435 2.97572657 2.97624004
 2.97656987 2.97673826 2.97720077 2.97743415 2.97816754 2.97972892
 2.9799146  2.9802239  2.98039943 2.9807578  2.98089264 2.9809604
 2.98111464 2.98206202 2.98213541 2.98237324 2.98260882 2.98310801
 2.98359365 2.98467401 2.98469862 2.98503643 2.98639188 2.98671276
 2.98935916 2.98953229 2.98983133 2.99088187 2.994265   2.99447701
 2.99507165 2.99610967 2.9968581  2.99776658 2.99849739 2.99878183
 2.99961485 3.00097015 3.00152541 3.00235831 3.0048107  3.00489024
 3.00541633 3.00566864 3.00624076 3.00689635 3.0075913  3.0093887
 3.00973235 3.01026348 3.01218665 3.01252056 3.01474266 3.0159506
 3.01755181 3.01769803 3.01858851 3.01964715 3.02015857 3.02294886
 3.02340761 3.02487119 3.02733645 3.02832318 3.02875309 3.03011037
 3.0305121  3.0314248  3.03811276 3.03882722 3.03906279 3.03984067
 3.04159424 3.0433432  3.04363879 3.0464057  3.04825041 3.04850921
 3.05104537 3.05450027 3.05558144 3.05742803 3.05849193 3.05868959
 3.06105303 3.06477623 3.06711319 3.06723307 3.06779742 3.06922407
 3.0699233  3.07026839 3.07130343 3.07303881 3.07376235 3.07430597
 3.07526067 3.0757875  3.07689519 3.07731901 3.07785815 3.0796332
 3.0809863  3.08290072 3.08846995 3.08882448 3.09079946 3.09124572
 3.09215674 3.09313592 3.09408817 3.09829849 3.09843981 3.09927117
 3.09938354 3.10061826 3.10118274 3.10137846 3.10189594 3.10226889
 3.1024798  3.10421505 3.10517109 3.10699536 3.10840201 3.11001098
 3.11030116 3.11044784 3.11051336 3.11067113 3.11089441 3.1115094
 3.11155163 3.1125564  3.11310001 3.11332615 3.11339476 3.11377024
 3.11388146 3.11486253 3.11510086 3.11512837 3.11684264 3.11737608
 3.11750749 3.11812905 3.11852496 3.11871509 3.11895715 3.11906094
 3.11990127 3.12044134 3.12212429 3.12456688 3.12506633 3.1256845
 3.12644156 3.12664446 3.12710455 3.12730551 3.12835878 3.12906519
 3.12943937 3.13013513 3.13014227 3.13025626 3.13060919 3.13144359
 3.13215556 3.13328522 3.13397167 3.13450354 3.13515849 3.13517432
 3.1360228  3.13689353 3.13726422 3.1372961  3.13779522 3.13802749
 3.13868483 3.13909412 3.13916109 3.13925383 3.13935472 3.13964834
 3.1397731  3.14001938 3.14005078 3.1401523  3.14049448 3.14066923
 3.14104638 3.14150873 3.14163031 3.14173572 3.14230966 3.14236211
 3.14263773 3.14315598 3.14447983 3.14458861 3.14498632 3.14506473
 3.14515192 3.14543093 3.14565948 3.14705327 3.14785632 3.14793239
 3.14846726 3.14854061 3.14883128 3.14902536 3.15017435 3.15038698
 3.15055401 3.15058538 3.15092955 3.15113576 3.15116043 3.15152346
 3.15153454 3.15161924 3.15175251 3.15176625 3.15178381 3.15211597
 3.15258647 3.1527245  3.15298248 3.15306633 3.15313018 3.15319578
 3.15335427 3.15349697 3.15352556 3.15354906 3.15362099 3.15365909
 3.15385557 3.15389712 3.15430145 3.15441091 3.15444028 3.15467009
 3.15540523 3.15548203 3.15612316 3.15654595 3.15673619 3.15775086
 3.15795274 3.15861629 3.15864251 3.15864769 3.15943165 3.15986424
 3.1601497  3.16070296 3.16109956 3.16194752 3.16252271 3.16268237
 3.16326458 3.16344237 3.16397984 3.16418671 3.16467748 3.16554494
 3.16605487 3.1662429  3.16798936 3.1683223  3.16985185 3.17086715
 3.17134213 3.17158975 3.17179643 3.17246644 3.17266418 3.1733636
 3.1733898  3.17347309 3.17448593 3.17530133 3.17545147 3.17567301
 3.17587638 3.17593672 3.1760918  3.17617267 3.17636711 3.1763934
 3.17647031 3.17698236 3.17706863 3.17725129 3.17729271 3.17745711
 3.17750126 3.1775176  3.17775249 3.17777512 3.17822958 3.1783728
 3.17858257 3.17868326 3.17876238 3.17877733 3.17882696 3.17904772
 3.17914675 3.17917719 3.17929194 3.17933421 3.17956643 3.18027148
 3.18063972 3.18091898 3.18097906 3.18128962 3.18143758 3.18147563
 3.18183881 3.18184761 3.18189853 3.18234604 3.1823577  3.18243603
 3.18249939 3.18260066 3.18261434 3.18291586 3.18339691 3.18343744
 3.18357506 3.18377731 3.1838641  3.18401983 3.18408904 3.18429865
 3.18437214 3.18493683 3.18504282 3.18514461 3.18529933 3.18552959
 3.18569415 3.18619846 3.1862067  3.18643491 3.18680074 3.18743388
 3.1880809  3.18849821 3.18884619 3.18946046 3.1897904  3.19047584
 3.19050494 3.19112882 3.1917661  3.19222446 3.19233219 3.19240571
 3.19243256 3.19266898 3.19291311 3.19305035 3.19333149 3.19333491
 3.19378532 3.19408133 3.19445818 3.19451283 3.19482426 3.19496103
 3.19509226 3.19538596 3.19625838 3.19637138 3.19688018 3.19692173
 3.19710851 3.19729168 3.19769411 3.19794455 3.19810078 3.1988674
 3.19930027 3.19976961 3.20019057 3.20022086 3.20030522 3.2003908
 3.20052546 3.20056401 3.20082825 3.20094142 3.2015909  3.20224706
 3.20259944 3.20278954 3.20281463 3.20292902 3.2030006  3.20305466
 3.20350994 3.20352492 3.20352806 3.20378665 3.20433557 3.20438015
 3.20446625 3.20487454 3.2051314  3.2053099  3.20541822 3.20572766
 3.20576733 3.20587641 3.20600706 3.20638113 3.20645671 3.20670445
 3.20676475 3.20683956 3.20686779 3.2072723  3.20728475 3.20751481
 3.20752894 3.20806401 3.20841134 3.20899376 3.20908988 3.2091838
 3.2093522  3.2094813  3.20966944 3.20983719 3.20991512 3.21094218
 3.21230008 3.21297017 3.21311651 3.2137356  3.21387014 3.21395213
 3.21409099 3.21481106 3.2154183  3.21548153 3.21565057 3.21596734
 3.21642409 3.21663488 3.21723032 3.21750617 3.21755824 3.21769275
 3.21853817 3.21952977 3.22025698 3.22032054 3.22073112 3.22080699
 3.22096029 3.22143358 3.22182586 3.2220061  3.22211516 3.22222009
 3.22287162 3.2229999  3.2233836  3.22370706 3.22378356 3.22409111
 3.22516817 3.22527362 3.2253721  3.22624842 3.22626955 3.22632006
 3.22646586 3.22648353 3.22672477 3.2269885  3.22711116 3.22718
 3.22735491 3.22766163 3.22832147 3.22855098 3.22874573 3.22879135
 3.22912904 3.22919919 3.22931794 3.23002806 3.23025941 3.23059128
 3.23060952 3.23172843 3.23255145 3.23257972 3.23289587 3.23467182
 3.23568996 3.2357408  3.23654145 3.2384934  3.23867265 3.23893322
 3.23961343 3.24026985 3.24088569 3.24443668 3.24479725 3.24543423
 3.24565174 3.2459961  3.24762775 3.24813001 3.24831718 3.24966796
 3.25034282 3.25054592 3.25064223 3.25109295 3.25260446 3.25333283
 3.25432385 3.25506846 3.25679516 3.25699356 3.25924194 3.25934417
 3.25978348 3.25995845 3.26000315 3.26048966 3.26085156 3.26280133
 3.26591601 3.26599571 3.2662225  3.26644204 3.26691744 3.26803901
 3.26895809 3.26921114 3.26946526 3.27036833 3.27047311 3.27092567
 3.27123569 3.27153636 3.27388547 3.27501033 3.27559513 3.27626183
 3.27713278 3.2777393  3.27953582 3.28005811 3.28062802 3.28131097
 3.28269273 3.2847942  3.28853048 3.28938876 3.2899575  3.29040213
 3.29154277 3.29172065 3.29221721 3.29361475 3.29392249 3.29462088
 3.29554657 3.29642171 3.29781196 3.29837454 3.30177678 3.30262649
 3.30341625 3.3049623  3.30528639 3.3065208  3.30670223 3.30724529
 3.30779434 3.30783212 3.30832574 3.30839181 3.30944664 3.31421121
 3.31541931 3.31577171 3.3161422  3.31614393 3.31626945 3.31691309
 3.31796522 3.31846386 3.31893049 3.32024161 3.32110765 3.32217288
 3.32245161 3.32392257 3.32603803 3.32691689 3.32705004 3.32741415
 3.32790678 3.32983439 3.33137257 3.33202056 3.33252565 3.33451844
 3.33494272 3.33558297 3.33560841 3.33579965 3.33648682 3.33662041
 3.33663061 3.33686507 3.3385421  3.33902722 3.33955866 3.34159861
 3.34213266 3.34265612 3.34349769 3.34353218 3.3442565  3.34435545
 3.34488393 3.34493589 3.34603338 3.34680952 3.34839542 3.35266711
 3.35343127 3.35345734 3.35399229 3.35550507 3.35824394 3.35973357
 3.36052684 3.3618779  3.36670131 3.36702619 3.36872963 3.3694913
 3.37039754 3.37098043 3.37160268 3.37281558 3.3746304  3.37532432
 3.37555024 3.37592017 3.37610203 3.3769761  3.37740429 3.38009802
 3.38011274 3.38103407 3.38449118 3.38596    3.38703623 3.38753679
 3.38823154 3.38882054 3.39113295 3.39128202 3.39285041 3.39326683
 3.39352355 3.39353068 3.39409426 3.39412579 3.39532492 3.39647813
 3.39712529 3.4002564  3.40040345 3.40084754 3.40106991 3.4016599
 3.40659503 3.40686342 3.40990624 3.40998741 3.41188644 3.41345169
 3.41449545 3.41965858 3.42298562 3.42434935 3.4315917  3.43480173
 3.44362879 3.44422344 3.44767687 3.44805267 3.44861379 3.45278311
 3.46243598 3.48418722 3.498827   3.51051324 3.51423789 3.51626329
 3.51670147 3.51843603 3.51910579 3.51991276 3.52586543 3.52982017
 3.53002676 3.53308991 3.54347074 3.55365554 3.55735969 3.57670494
 3.60816708 3.63454525 3.63983046 3.65184684 3.67172041 3.67329325
 3.70079305 3.78323765 3.78801897 3.84092663 3.8433069  3.84585948
 3.86068518 3.86469215 3.87148086 3.90995817 3.93602804 3.96320567
 4.06671694 4.10101045 4.10811235 4.13176906 4.33945743 4.36741975
 4.72328868 4.74958532 4.7771366  4.78038975 4.7845717  4.80652457
 4.80940948 4.81358907 4.81366755 4.81490551 4.81726218 4.81753573
 4.82272561 4.82788331 4.83109566 4.83257327 4.8335519  4.83581175
 4.836759   4.84169835 4.84408637 4.84427224 4.8552787  4.86801304
 4.87115602 4.90271698 4.90938151 4.91766899 4.9417024  4.95982677
 4.97967631 5.02564313 5.03420502 5.1023632 ]

  warnings.warn(

2022-12-16 10:36:43,816:INFO:Calculating mean and std
2022-12-16 10:36:43,819:INFO:Creating metrics dataframe
2022-12-16 10:36:43,824:INFO:Uploading results into container
2022-12-16 10:36:43,825:INFO:Uploading model into container now
2022-12-16 10:36:43,825:INFO:master_model_container: 9
2022-12-16 10:36:43,825:INFO:display_container: 2
2022-12-16 10:36:43,826:INFO:Lars(random_state=5099)
2022-12-16 10:36:43,826:INFO:create_model() successfully completed......................................
2022-12-16 10:36:43,962:WARNING:create_model() for Lars(random_state=5099) raised an exception or returned all 0.0, trying without fit_kwargs:
2022-12-16 10:36:43,963:WARNING:Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 795, in compare_models
    assert (
AssertionError

2022-12-16 10:36:43,963:INFO:Initializing create_model()
2022-12-16 10:36:43,963:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002281239F8E0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022810EC8B20>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:36:43,963:INFO:Checking exceptions
2022-12-16 10:36:43,966:INFO:Importing libraries
2022-12-16 10:36:43,966:INFO:Copying training dataset
2022-12-16 10:36:43,971:INFO:Defining folds
2022-12-16 10:36:43,971:INFO:Declaring metric variables
2022-12-16 10:36:43,972:INFO:Importing untrained model
2022-12-16 10:36:43,972:INFO:Least Angle Regression Imported successfully
2022-12-16 10:36:43,973:INFO:Starting cross validation
2022-12-16 10:36:43,974:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:36:45,544:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:36:45,624:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:36:45,651:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:36:45,702:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:36:45,722:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:36:45,777:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:36:45,809:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:36:45,889:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:36:45,937:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.552531   1.56467038 1.59033579 1.73910471 1.78661731 1.8341153
 1.835671   1.83732994 1.84980316 1.877411   1.9044356  2.06936281
 2.40069236 2.67731307 2.82516621 2.88535327 2.88872943 2.89317987
 2.90474467 2.90551601 2.9056882  2.91196396 2.91246877 2.91508491
 2.91603287 2.91862225 2.92229327 2.93076166 2.93500176 2.93635454
 2.93929335 2.94768077 2.9514766  2.95172319 2.95374071 2.95469232
 2.95725359 2.96386456 2.96466542 2.96842579 2.97069105 2.97156934
 2.97256881 2.97488625 2.97579023 2.97596245 2.97603506 2.97655031
 2.97936121 2.97991995 2.98142739 2.982066   2.9839014  2.98521988
 2.98630791 2.98807401 2.98815904 2.98877966 2.98928759 2.98945592
 2.99174499 2.99415341 2.99605068 2.99608737 2.9967802  2.9992121
 2.99929628 2.99998368 3.00008934 3.00152775 3.00162066 3.00272804
 3.00307775 3.00406496 3.00451295 3.00504455 3.00704805 3.00812309
 3.00858496 3.00960643 3.01123367 3.01154354 3.0123489  3.01517616
 3.0160732  3.01745928 3.01746127 3.01803186 3.01899818 3.01913571
 3.01983643 3.01986657 3.02296476 3.02309714 3.02538805 3.02633821
 3.02705241 3.02772335 3.02807756 3.02957367 3.02960894 3.0314714
 3.03175387 3.03232996 3.03351356 3.03496627 3.03519163 3.03637164
 3.03778457 3.037933   3.03971312 3.04022658 3.04031028 3.04150676
 3.04187782 3.0421388  3.04236693 3.04274962 3.04301673 3.04449009
 3.04458606 3.04487041 3.04572234 3.04649398 3.04654759 3.04923857
 3.04935941 3.04947848 3.05067867 3.05205469 3.05447946 3.05499235
 3.05499891 3.05502462 3.05633472 3.05696223 3.05702209 3.05824595
 3.0588903  3.05939414 3.06058758 3.06077244 3.06235282 3.06628472
 3.06652632 3.06754955 3.07098689 3.07136777 3.07185131 3.07240795
 3.07296006 3.07421617 3.07778068 3.07801945 3.07821745 3.07839732
 3.07957509 3.08005171 3.08065968 3.08096584 3.08180356 3.08291497
 3.08384577 3.08432776 3.08454955 3.08532632 3.08546301 3.08575408
 3.08674452 3.08706711 3.08724238 3.08795611 3.08892271 3.09016118
 3.0902469  3.09144888 3.09175227 3.09185525 3.09193155 3.0920396
 3.09422731 3.09514913 3.09547133 3.09547823 3.09644964 3.09680011
 3.09694934 3.09734847 3.09866506 3.09867086 3.09921197 3.09951996
 3.10007184 3.10010321 3.10019814 3.10081295 3.10143657 3.10145309
 3.10158058 3.10163181 3.10184062 3.1019589  3.10326861 3.1033698
 3.10446663 3.10447251 3.1058165  3.10615112 3.11006511 3.11027156
 3.11322366 3.11407513 3.11435573 3.1153886  3.1155107  3.11588482
 3.11607185 3.11687615 3.11717857 3.11764037 3.11777426 3.11868773
 3.11996934 3.11997462 3.12029929 3.12038797 3.1207233  3.12116569
 3.12185808 3.12214892 3.12267329 3.1237192  3.12645567 3.1269826
 3.12759412 3.12791639 3.12854681 3.12967773 3.12983204 3.13010851
 3.13012194 3.13205684 3.13261283 3.13281598 3.13294603 3.13508461
 3.135232   3.13571824 3.13639317 3.13662367 3.13716144 3.13748851
 3.13758106 3.1383226  3.13894781 3.13897886 3.13967538 3.14009336
 3.14018143 3.14111428 3.14119563 3.14149573 3.14164148 3.14222561
 3.14226273 3.14229538 3.14250334 3.14290974 3.14355908 3.14362345
 3.14443168 3.14461377 3.14462715 3.14572191 3.14589246 3.14668768
 3.14774588 3.14789672 3.14822394 3.14828344 3.14876358 3.14887429
 3.14905446 3.14955442 3.14982484 3.1511433  3.15133826 3.15181432
 3.15197014 3.15232465 3.15282406 3.15334079 3.1538929  3.15394633
 3.15472877 3.15505849 3.15512569 3.15528528 3.1553233  3.15609571
 3.15657177 3.15752641 3.15802232 3.15847807 3.158692   3.15937954
 3.15943235 3.15950092 3.15977422 3.15996265 3.16102714 3.16126309
 3.16132254 3.1615562  3.16168338 3.16179043 3.16223419 3.16225495
 3.1636274  3.16378292 3.16444982 3.16446392 3.16503723 3.16510023
 3.16539957 3.16558278 3.16570903 3.16587098 3.16637994 3.16677069
 3.16704962 3.16706596 3.16717737 3.16718558 3.16754553 3.16764923
 3.16778814 3.1687824  3.16913135 3.16961092 3.1702292  3.17050989
 3.17081486 3.17118938 3.1712503  3.17129187 3.1714136  3.17170256
 3.17208145 3.17236595 3.17278869 3.17300353 3.17338658 3.17355835
 3.17367149 3.17420177 3.17422461 3.17467737 3.17487778 3.17543307
 3.17544678 3.17564445 3.17603623 3.17607592 3.17622675 3.17650178
 3.17687291 3.17694152 3.17715499 3.17786865 3.17794942 3.17807842
 3.17835323 3.17859531 3.1786548  3.17865605 3.17871551 3.17879015
 3.17985612 3.18024162 3.1804416  3.18067117 3.18074385 3.18075031
 3.18100594 3.18151623 3.18164779 3.18195822 3.18205908 3.18215817
 3.18278422 3.18322292 3.18333633 3.18343205 3.18345844 3.18367723
 3.18390663 3.18396154 3.18417317 3.18442317 3.18562629 3.1860676
 3.18794444 3.18804176 3.18804338 3.18838666 3.18861666 3.18886423
 3.18901224 3.18947622 3.19003367 3.19010591 3.19028256 3.19054377
 3.19070684 3.19103537 3.19121025 3.19199956 3.19216665 3.19223245
 3.19272538 3.19308832 3.19342046 3.19376759 3.19403746 3.19487328
 3.19594547 3.19670559 3.19671621 3.1969496  3.1969991  3.19759537
 3.19771268 3.19802669 3.19878923 3.19909105 3.19933931 3.19938583
 3.1997326  3.20010631 3.20050255 3.20132462 3.20144594 3.20168781
 3.20254625 3.20377293 3.20385629 3.20406614 3.20442401 3.20470947
 3.20478938 3.20483922 3.20550158 3.2056212  3.20584491 3.2059935
 3.20612593 3.20616164 3.2065794  3.20728672 3.20734884 3.20752822
 3.20756806 3.20784017 3.20830468 3.20843645 3.20849953 3.20857627
 3.20866192 3.20887752 3.20891143 3.20927857 3.2096601  3.21015225
 3.2102683  3.21082648 3.21102742 3.21157633 3.21207263 3.21275778
 3.21280286 3.21282573 3.21294108 3.21335551 3.21348493 3.2138825
 3.21410417 3.21494566 3.2150736  3.21535685 3.21586038 3.21592421
 3.21638498 3.21655466 3.21716361 3.21737551 3.21749881 3.21829981
 3.21898366 3.21925054 3.21927524 3.2194657  3.21974186 3.21999593
 3.22013455 3.22066842 3.22089814 3.22184909 3.22185979 3.22218568
 3.22222876 3.22238277 3.22243312 3.22262431 3.22285788 3.22318963
 3.22335894 3.22340113 3.22340922 3.22362756 3.22379869 3.22390552
 3.22439452 3.22520352 3.22525865 3.22534117 3.22535282 3.22589329
 3.22602443 3.22609048 3.22737218 3.22758065 3.22808982 3.22811481
 3.22842191 3.22878983 3.22927494 3.2294147  3.2302584  3.23029768
 3.23065638 3.23107988 3.23143975 3.23206116 3.23259834 3.23271743
 3.23286523 3.23413101 3.23442511 3.2344972  3.23485492 3.23564462
 3.23571832 3.23574212 3.23581724 3.23608584 3.23625224 3.23637051
 3.23692944 3.23717708 3.23733355 3.23734079 3.23750253 3.23772693
 3.23781305 3.23792018 3.23818724 3.23821204 3.23829751 3.23904333
 3.23956754 3.23981119 3.23991833 3.2399189  3.24001436 3.24041688
 3.24136498 3.242355   3.24276067 3.24277622 3.24328067 3.24375737
 3.24435104 3.24446444 3.24457    3.24459726 3.24466722 3.24476147
 3.24575536 3.24591345 3.24607781 3.24630071 3.24686172 3.24696976
 3.24717615 3.24826446 3.24828885 3.24839886 3.24883051 3.24905866
 3.24917718 3.25012206 3.25165221 3.25260518 3.2533793  3.25337972
 3.25344454 3.25423502 3.25425233 3.25495899 3.25521625 3.25583486
 3.25590843 3.25683697 3.25739888 3.25749021 3.25791625 3.25831642
 3.25910057 3.25988275 3.2599137  3.26008026 3.26078593 3.260921
 3.2611423  3.26184474 3.26209478 3.26219641 3.26253029 3.26272467
 3.26314108 3.26425658 3.26459356 3.26578238 3.26789118 3.26890481
 3.26975742 3.27050774 3.27089048 3.27113812 3.27341781 3.27364683
 3.273784   3.27418622 3.27429365 3.27510542 3.27521076 3.2758837
 3.27731726 3.27734581 3.27735071 3.27764412 3.27790329 3.27807532
 3.28028958 3.28072597 3.28103232 3.28211055 3.28295154 3.2836012
 3.28475392 3.28540831 3.2860081  3.28759221 3.28867103 3.28876243
 3.29047737 3.29105618 3.29147724 3.29185237 3.29251606 3.292595
 3.29413492 3.29417961 3.29521672 3.29528297 3.30008995 3.30044532
 3.30245187 3.3026811  3.30296491 3.30388441 3.30477295 3.30578895
 3.30877607 3.31001813 3.31357688 3.31454153 3.31507168 3.31562832
 3.31581403 3.31607909 3.31778172 3.31791571 3.31797931 3.31876908
 3.31958052 3.32049882 3.32158757 3.32196712 3.32256852 3.32262244
 3.32331144 3.32409176 3.33005486 3.33018156 3.33197593 3.33449575
 3.3374986  3.33811987 3.33900416 3.33966337 3.34301431 3.34332979
 3.34395083 3.34502956 3.34503391 3.34542743 3.34565081 3.3456956
 3.34600478 3.3467274  3.3477674  3.35010206 3.35012482 3.35023949
 3.35069108 3.35124463 3.35190973 3.35327948 3.353659   3.35431115
 3.35447389 3.35482241 3.35603416 3.35748501 3.35780344 3.35802877
 3.35918134 3.36032225 3.36147119 3.36314899 3.36371609 3.36507829
 3.36578993 3.36682306 3.36698807 3.3681368  3.3681641  3.369128
 3.36946131 3.37358916 3.37465749 3.37530187 3.37740129 3.37961784
 3.38025055 3.38059691 3.38179161 3.3823075  3.3829788  3.38311185
 3.38349744 3.38501303 3.38516035 3.38817547 3.39055591 3.39224193
 3.39269945 3.39467497 3.39552131 3.397857   3.39853264 3.3988626
 3.40084519 3.4014935  3.40384256 3.40438584 3.40515522 3.40630689
 3.41068466 3.41395482 3.4148719  3.41565192 3.4157353  3.41712734
 3.42311936 3.42627665 3.42786959 3.42982121 3.43013072 3.43828202
 3.44481755 3.44734183 3.45379501 3.45633359 3.45634083 3.46104858
 3.46114241 3.4808492  3.48159928 3.48485755 3.51475363 3.52934254
 3.53428867 3.56775972 3.56901919 3.58110635 3.63709492 3.64785349
 3.71985815 3.77322924 3.78079003 3.78342094 3.79233233 3.80572396
 3.81474951 3.84402665 3.85270571 3.91653639 3.95214365 4.16479264
 4.17582004 4.18308193 4.53046741 4.6272437  4.77339064 4.78875094
 4.79368631 4.80113838 4.80153693 4.80446065 4.81362454 4.83006692
 4.83666249 4.8427805  4.8442306  4.85590733 4.85664522 4.86054792
 4.86133654 4.86141579 4.86265048 4.8643786  4.87068137 4.88447023
 4.88590743 4.88888038 4.9070527  4.93865185 4.94225137 4.94833571
 4.95522619 4.95880867 4.98896627 4.98901946 5.12788891]

  warnings.warn(

2022-12-16 10:36:46,021:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.60103031 1.85015073 1.86434124 1.92366013 2.03011142 2.20698402
 2.67022341 2.83160066 2.83378276 2.86961519 2.89131924 2.89827051
 2.9119398  2.91275574 2.91408743 2.91753112 2.91908796 2.92350877
 2.9267535  2.92847022 2.92984204 2.93473353 2.93549456 2.9426477
 2.94268552 2.94414944 2.94494741 2.9453678  2.94552082 2.94683255
 2.95392617 2.95623463 2.958734   2.95949345 2.96246523 2.96427054
 2.9664547  2.96669888 2.9683013  2.97010613 2.97165739 2.97428514
 2.97548    2.97584209 2.97905237 2.98089773 2.98127301 2.98207537
 2.98253255 2.9829655  2.98696087 2.98714594 2.99262104 2.99276904
 2.993468   2.9943758  2.99477602 2.99525468 2.99539355 2.9972799
 2.99776707 3.0025088  3.00355853 3.00434997 3.0051998  3.00575836
 3.00582451 3.00894811 3.01162395 3.01370932 3.01425743 3.0146949
 3.01591512 3.01631247 3.01645371 3.01742704 3.01747682 3.01790745
 3.01946664 3.02312412 3.02329787 3.02354572 3.02457868 3.02615686
 3.02695068 3.02819802 3.0306187  3.0308435  3.03426481 3.03452551
 3.03824829 3.03861802 3.04335806 3.04508878 3.04611364 3.04810028
 3.04859899 3.05009106 3.05035992 3.05217281 3.05269274 3.05273388
 3.05278143 3.05350883 3.05415289 3.05610074 3.05748717 3.05908881
 3.05997036 3.06011073 3.06235427 3.06310156 3.06400129 3.06452379
 3.06613934 3.06616459 3.06677187 3.06691892 3.06864572 3.06864719
 3.06897753 3.07048537 3.07089073 3.0725357  3.07421905 3.07465196
 3.07494655 3.08050157 3.08158478 3.08216385 3.08245224 3.08337833
 3.08549297 3.08551221 3.08651455 3.08709195 3.08723606 3.08725801
 3.08945873 3.08967977 3.08993339 3.09012537 3.09045638 3.09071855
 3.09108395 3.09135786 3.09137822 3.09415224 3.09598225 3.09803863
 3.09838374 3.09956712 3.10133744 3.10141574 3.10178342 3.1032346
 3.10557184 3.10647247 3.10664561 3.10670323 3.10924189 3.10954236
 3.11011817 3.11027389 3.11098174 3.1110974  3.11116228 3.1116425
 3.11181619 3.11202483 3.11260614 3.11265117 3.11293284 3.11293316
 3.11310626 3.11342368 3.11365643 3.11441432 3.11486096 3.11486619
 3.11536883 3.11634306 3.11635275 3.11662336 3.11675994 3.11753182
 3.11867244 3.11873772 3.11893333 3.11926072 3.11979396 3.12010398
 3.12086445 3.12145638 3.12147869 3.12264636 3.12274785 3.12363813
 3.12363845 3.12374239 3.12453978 3.12473636 3.1262506  3.126374
 3.12650254 3.12656263 3.12755397 3.12756015 3.1276981  3.12784181
 3.12958704 3.12990412 3.12992122 3.13004437 3.13018466 3.13069806
 3.13155288 3.13219804 3.13452817 3.13494381 3.13530134 3.13534197
 3.13552179 3.13553994 3.13557553 3.13576652 3.13587942 3.13611637
 3.13642002 3.13665465 3.13669329 3.13763516 3.13786792 3.13790697
 3.13919016 3.13967162 3.14150175 3.14181298 3.14225784 3.14228394
 3.14254162 3.14267978 3.14279142 3.14296056 3.14322314 3.14350555
 3.1437651  3.14389807 3.14442905 3.14459029 3.14493308 3.14534666
 3.14537604 3.14551549 3.14647688 3.14663054 3.14711488 3.14868074
 3.14891032 3.14894611 3.1491235  3.14913432 3.14935644 3.1494276
 3.14956967 3.14958518 3.14981676 3.1499726  3.15005674 3.15039532
 3.15054226 3.15143515 3.15151229 3.15262726 3.15268533 3.15282013
 3.15310708 3.15346137 3.15352421 3.15354016 3.15389947 3.15397843
 3.15422534 3.15429772 3.15476296 3.15493978 3.15570998 3.15571605
 3.15639988 3.15643304 3.15667376 3.15700595 3.15766252 3.15789489
 3.15861485 3.1591892  3.15991359 3.1599737  3.16104191 3.16107665
 3.16109889 3.16163249 3.16235534 3.1624323  3.16245699 3.16264816
 3.16333204 3.16338737 3.16346401 3.16352218 3.16362612 3.16364329
 3.16378714 3.16397441 3.16436533 3.16439211 3.16443621 3.1652736
 3.16537971 3.16552216 3.16572439 3.16637198 3.16658747 3.16696196
 3.16796581 3.16796837 3.16825634 3.16851754 3.16917579 3.16942841
 3.16944339 3.16983092 3.17059843 3.17136802 3.17151019 3.17175627
 3.17290127 3.1731271  3.17318913 3.17330001 3.17351635 3.17355031
 3.17402945 3.17425632 3.1742601  3.17443811 3.17464297 3.17473228
 3.17482786 3.1749318  3.17498517 3.17570825 3.17647354 3.17652088
 3.17762855 3.17884992 3.1789399  3.17894499 3.17901898 3.17979837
 3.18138337 3.18168672 3.18172178 3.18176126 3.18182572 3.18348382
 3.18376058 3.18454869 3.18562407 3.18568908 3.18610321 3.18629278
 3.18630721 3.18659254 3.18710339 3.18717673 3.18749313 3.18749345
 3.18771538 3.18799758 3.1885031  3.18866267 3.18890843 3.18905311
 3.18905598 3.189286   3.18940655 3.1896848  3.18979788 3.18998023
 3.19006837 3.19017366 3.19037477 3.190385   3.19084198 3.19086693
 3.19087623 3.1908971  3.19090355 3.19159665 3.19168918 3.19191567
 3.19207357 3.19276511 3.19295422 3.1929769  3.19326096 3.19377224
 3.19387618 3.1944588  3.19452745 3.19467162 3.19476592 3.19508585
 3.19523084 3.19557562 3.19558517 3.19595538 3.1963268  3.19662589
 3.19700117 3.19742306 3.19749516 3.19757239 3.1975844  3.19808135
 3.1981999  3.19847819 3.19853683 3.19886009 3.19897293 3.19903743
 3.19994527 3.20046057 3.20055356 3.20060631 3.2007947  3.20104527
 3.20173402 3.20260609 3.20290288 3.20385814 3.20399375 3.20450863
 3.20470736 3.20494745 3.20506209 3.20536899 3.20553053 3.20561372
 3.20592231 3.20706315 3.20719242 3.20764874 3.20801803 3.2081627
 3.20869776 3.20928934 3.20950086 3.20958888 3.20968856 3.20970832
 3.21035156 3.21076121 3.21085005 3.21133869 3.21148293 3.21149273
 3.21166534 3.21171572 3.21176654 3.21185747 3.21210893 3.21223097
 3.21227162 3.21241875 3.21242011 3.21282375 3.21297623 3.21304328
 3.21325627 3.21370958 3.21379721 3.21387352 3.2139743  3.21400947
 3.21407462 3.21420709 3.21438545 3.21439073 3.21481704 3.21500891
 3.21538909 3.21568661 3.21592307 3.21604421 3.21647757 3.2169292
 3.21696639 3.21703836 3.21753716 3.21757609 3.21883086 3.21922989
 3.21925106 3.21934208 3.219355   3.21943721 3.22005382 3.22038066
 3.2205396  3.22073597 3.22077483 3.22136281 3.22136939 3.22140727
 3.22210983 3.22216809 3.22246263 3.22261162 3.22297134 3.22320205
 3.22355829 3.22373017 3.22376618 3.22399177 3.22422697 3.22433504
 3.2244039  3.22468317 3.22506782 3.22509314 3.22523206 3.22563966
 3.22658171 3.22732651 3.2274551  3.22771362 3.22798259 3.22845035
 3.22874819 3.22940167 3.22985707 3.23034708 3.23058486 3.23143797
 3.23239055 3.23239824 3.23262627 3.23264366 3.23302039 3.23306699
 3.23317574 3.23336852 3.2336553  3.23368441 3.23402927 3.23460805
 3.23465011 3.23478311 3.23560028 3.23592351 3.2362003  3.23721282
 3.23815281 3.23885636 3.23921305 3.24016874 3.24036281 3.24069973
 3.24072832 3.24101645 3.24380965 3.24444066 3.24521156 3.245534
 3.2462328  3.24685367 3.24750101 3.24801227 3.24888506 3.24904401
 3.24918771 3.24955246 3.25107214 3.25111648 3.25143228 3.25273612
 3.252998   3.25319117 3.25333375 3.2533698  3.25357743 3.25384068
 3.25572513 3.25588564 3.2567962  3.25692634 3.25776456 3.25841381
 3.25844319 3.25884469 3.25967869 3.26077718 3.26133478 3.26144335
 3.26145528 3.26151798 3.26184536 3.26194483 3.26208048 3.26369753
 3.26387047 3.26443274 3.26451003 3.26458983 3.26555415 3.26620541
 3.26685451 3.26934559 3.27071424 3.27233049 3.27343653 3.27350517
 3.2736791  3.27496373 3.27501331 3.27661098 3.27767203 3.27785775
 3.28005714 3.28086155 3.28161015 3.28168734 3.28196739 3.28240891
 3.28248489 3.28415169 3.28550311 3.28586968 3.28590442 3.28640295
 3.28655046 3.28773505 3.28804592 3.29019127 3.29070302 3.291886
 3.29301704 3.29392147 3.29618479 3.29663052 3.29753854 3.29791118
 3.29796372 3.29977991 3.30038231 3.30143689 3.30227614 3.30269985
 3.30277367 3.30292046 3.30347997 3.30403939 3.30455538 3.30462074
 3.30668498 3.3071072  3.30761438 3.3089184  3.30944847 3.30998833
 3.3116041  3.3119071  3.31380741 3.31455107 3.321563   3.32171779
 3.32368366 3.32425326 3.32446498 3.32533176 3.32604755 3.32663403
 3.32776117 3.32866838 3.33132391 3.33219682 3.33234287 3.3333755
 3.33369008 3.33386508 3.33415019 3.33765042 3.33787484 3.33866577
 3.3414325  3.34205254 3.3439042  3.34537062 3.34621126 3.34632804
 3.34761563 3.34769746 3.3486909  3.35045534 3.3515425  3.35272817
 3.35287325 3.35319643 3.3578004  3.35916499 3.35923936 3.36008358
 3.36032003 3.36217269 3.36466439 3.36559864 3.36789505 3.37060307
 3.37167926 3.3737246  3.37691912 3.37729834 3.37759351 3.37856235
 3.38072912 3.380952   3.38155872 3.38447514 3.38512022 3.38566152
 3.38599093 3.38696818 3.38744516 3.39011887 3.39286496 3.39301499
 3.3937495  3.39489057 3.39513173 3.39661333 3.39753527 3.39754966
 3.39814708 3.39930687 3.40112906 3.40201988 3.40373372 3.40392465
 3.40442285 3.40674234 3.4069284  3.40723596 3.40744043 3.40822037
 3.40913302 3.41018715 3.41030278 3.41915124 3.41947036 3.42392348
 3.43113127 3.43143205 3.43149846 3.43677176 3.44303398 3.44385085
 3.44396305 3.44898755 3.45091539 3.45308065 3.45833774 3.46277495
 3.46413739 3.46476229 3.46559126 3.46799216 3.46830423 3.47013841
 3.48812972 3.48925955 3.49468241 3.51710848 3.51765127 3.53457309
 3.54311402 3.54489868 3.55037424 3.55076022 3.56745938 3.57044371
 3.59156956 3.59535304 3.60453002 3.62244036 3.62306545 3.63697672
 3.64005635 3.65479085 3.67995771 3.69484441 3.77312084 3.78007706
 3.78364572 3.79048478 3.81777376 3.81884411 3.84314747 3.84542897
 3.8475902  3.84856309 3.86448672 3.91331117 3.9903345  4.0548471
 4.07944188 4.13826795 4.14005436 4.14356478 4.15227418 4.20558651
 4.21258312 4.39091032 4.39173228 4.44505034 4.59894268 4.69438426
 4.72846189 4.75337345 4.76391159 4.76790532 4.79652306 4.79733171
 4.8008411  4.80132415 4.80728059 4.80793402 4.81590655 4.81893448
 4.8220443  4.83286431 4.83384475 4.84487378 4.84791572 4.85941982
 4.863382   4.88228899 4.88299687 4.88493503 4.88787382 4.89056742
 4.9046427  4.91057252 4.92298065 4.92659558 4.97026424 4.97147728]

  warnings.warn(

2022-12-16 10:36:46,039:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.55650859 1.74506841 1.78814076 1.8092177  1.93464115 2.04107423
 2.42701422 2.42947641 2.84838283 2.86729212 2.89960326 2.91243795
 2.92741401 2.9301026  2.93328472 2.95259509 2.95345602 2.95387892
 2.95734047 2.95823859 2.95850149 2.9616254  2.96179368 2.96251332
 2.96345712 2.96386781 2.96693526 2.96947746 2.96969669 2.97040318
 2.97168806 2.97278725 2.97654845 2.97807952 2.97864249 2.97935231
 2.98027985 2.9810388  2.98126448 2.9814758  2.982263   2.98346187
 2.98390942 2.98433596 2.98558036 2.98583182 2.98839846 2.98913597
 2.98974474 2.99010025 2.99190101 2.99420651 2.99427502 2.9982062
 2.99886057 3.0015666  3.00188151 3.00197193 3.00239704 3.00481774
 3.00563619 3.00599693 3.00743902 3.00745177 3.00809107 3.00838889
 3.00858495 3.00914155 3.00969852 3.01003337 3.01064583 3.01078947
 3.01210508 3.01232924 3.01349876 3.01474571 3.01635461 3.01642797
 3.01752478 3.01847868 3.01891044 3.02034623 3.02148405 3.02184147
 3.02247938 3.02355529 3.03057046 3.03084132 3.03100124 3.0312604
 3.03136257 3.03189785 3.03234879 3.0328016  3.03317718 3.03438501
 3.03616262 3.03951438 3.0424877  3.04445872 3.04883849 3.04908175
 3.04917384 3.04991913 3.05250115 3.0563384  3.05867621 3.06238169
 3.06299629 3.06347879 3.0643547  3.06671631 3.06699583 3.06837838
 3.06895861 3.06910836 3.07932177 3.08075517 3.08128699 3.08213146
 3.0821681  3.08266846 3.08319976 3.0853606  3.08542361 3.08543137
 3.0855288  3.08909535 3.08955389 3.09005486 3.09115398 3.09131993
 3.09167206 3.09239044 3.09361582 3.09473003 3.09787403 3.09814541
 3.09836997 3.10008898 3.10359184 3.10378838 3.10410951 3.10432982
 3.10553904 3.10733351 3.10964503 3.11152627 3.11189136 3.11195984
 3.11203843 3.11217814 3.11228861 3.11464733 3.11467634 3.11505594
 3.11598604 3.11654098 3.11672803 3.1171922  3.11750659 3.11771508
 3.11794507 3.11901071 3.11901858 3.11908036 3.1195175  3.120366
 3.12040755 3.12060709 3.12103742 3.12113863 3.12119541 3.12128015
 3.12198453 3.12269214 3.12279274 3.12380572 3.1240005  3.12501423
 3.12515356 3.1253436  3.1259635  3.12640497 3.12655652 3.12660027
 3.12686325 3.1270412  3.12715984 3.12863701 3.12911814 3.12920321
 3.12961506 3.12980994 3.13004209 3.13051271 3.13101739 3.1314103
 3.13151421 3.13175011 3.13186706 3.13225896 3.13234505 3.13306301
 3.13311308 3.13314481 3.13344748 3.13352779 3.13406369 3.13429381
 3.13476313 3.13477869 3.13483303 3.1356334  3.13637723 3.13772784
 3.13799755 3.13811971 3.13819596 3.13824125 3.1389755  3.13916293
 3.13985588 3.14036455 3.1407338  3.14182255 3.14182266 3.14184034
 3.14191002 3.14226636 3.14256646 3.14304422 3.14306682 3.14328508
 3.14343348 3.14371991 3.14375716 3.14394879 3.14403409 3.14412024
 3.14425286 3.14428664 3.14429869 3.14431499 3.14487927 3.14515339
 3.14546359 3.14553449 3.14595709 3.14620855 3.14645702 3.14659649
 3.14673438 3.14678861 3.14684978 3.14694546 3.147459   3.14746711
 3.14754615 3.14765574 3.14776854 3.14785077 3.14788126 3.14814575
 3.14817539 3.14831722 3.14848768 3.14859676 3.14934974 3.14943685
 3.14955739 3.14962381 3.14982572 3.14997812 3.15008762 3.15022161
 3.15029217 3.15060095 3.151104   3.15176691 3.15189502 3.15211672
 3.15253103 3.15288242 3.15450798 3.15462462 3.15466286 3.15515826
 3.15551226 3.15568277 3.15578678 3.15585996 3.15602793 3.15606219
 3.15624837 3.15651285 3.15652055 3.15721632 3.15777955 3.15780835
 3.15810046 3.15825578 3.15828539 3.15841671 3.1585328  3.15927784
 3.15956942 3.15998713 3.1600786  3.16072623 3.16171333 3.16189522
 3.16240993 3.16282152 3.16287231 3.16317177 3.16396633 3.16435311
 3.16478472 3.16498038 3.16518737 3.16523957 3.16546221 3.16582895
 3.16591623 3.16596799 3.16640319 3.16654381 3.1668067  3.16713545
 3.16733585 3.16737933 3.16739862 3.16764542 3.16786803 3.16792123
 3.16832553 3.16902136 3.16906339 3.16931403 3.16951081 3.16989791
 3.17020814 3.17023168 3.17069868 3.17071925 3.17092137 3.17126721
 3.17128298 3.17179019 3.17195722 3.17200499 3.17208233 3.17228001
 3.17233926 3.17236702 3.17241173 3.17262568 3.17268892 3.17270174
 3.17278269 3.17290285 3.1730172  3.17302064 3.17349593 3.17352018
 3.17356642 3.17383816 3.1739661  3.17404951 3.17405461 3.17417314
 3.17441699 3.17442781 3.17470275 3.1747361  3.17483502 3.17488807
 3.17494445 3.17505563 3.17511783 3.17519579 3.17520251 3.17530087
 3.17602095 3.17625736 3.17635501 3.17640918 3.176443   3.17652558
 3.17668073 3.17701545 3.17702491 3.17703652 3.17712009 3.17759486
 3.17771559 3.17772692 3.17777597 3.17803431 3.17818633 3.178195
 3.17826992 3.17828369 3.17847127 3.17849839 3.17875513 3.17883776
 3.17899331 3.17919421 3.1792539  3.17971761 3.1797546  3.18043396
 3.18059679 3.18064284 3.18066148 3.18104444 3.18110044 3.18115765
 3.18119661 3.18150835 3.18176548 3.18179905 3.18182261 3.1818956
 3.18203677 3.18230199 3.18241758 3.18296264 3.18321579 3.18324508
 3.18407414 3.18455764 3.18503177 3.18504875 3.18519287 3.18524921
 3.1853817  3.18578536 3.18668544 3.18674004 3.18678736 3.18703229
 3.18711941 3.18715206 3.1872207  3.18728541 3.18754534 3.18774286
 3.18811964 3.18812295 3.18814871 3.18839202 3.18850494 3.18852264
 3.18855452 3.18893129 3.18916895 3.18985967 3.18990197 3.19032427
 3.19038243 3.19043657 3.19045403 3.19053571 3.19112517 3.19117204
 3.19121758 3.19135128 3.19154787 3.19196859 3.19240743 3.19286597
 3.19304588 3.19306693 3.1930941  3.19329608 3.19366889 3.19378725
 3.19388878 3.19447388 3.19452328 3.19485516 3.1951514  3.1952785
 3.1956107  3.19568773 3.19593771 3.1961502  3.19646234 3.19673454
 3.19697198 3.19706774 3.19770451 3.19794435 3.19796144 3.19832338
 3.19877642 3.19892474 3.19919384 3.19933925 3.1994178  3.19942916
 3.19980097 3.20013637 3.20017643 3.20039674 3.20061987 3.20090528
 3.20106012 3.20106579 3.20119748 3.20135785 3.20188096 3.20306876
 3.20399473 3.20456172 3.20465235 3.2048806  3.20493647 3.20530259
 3.20545536 3.2056902  3.20577341 3.20581861 3.20601172 3.20615842
 3.20654888 3.20694875 3.2071277  3.20769258 3.20795311 3.20810445
 3.20827756 3.20886966 3.2091562  3.20920899 3.20983987 3.20990737
 3.21037619 3.21076545 3.21092225 3.2124434  3.2137593  3.21394907
 3.21417718 3.21434697 3.21476752 3.21492064 3.21561052 3.21580398
 3.21655134 3.21677943 3.2167848  3.2169318  3.21720062 3.21738761
 3.21743279 3.21822077 3.2188888  3.21924148 3.21940432 3.21953811
 3.22036671 3.2206842  3.22120831 3.22170962 3.22290886 3.22335033
 3.2235621  3.22371843 3.22457154 3.22534939 3.22560934 3.22574985
 3.22622001 3.22638894 3.22740702 3.22796315 3.22856822 3.22892402
 3.22893318 3.22909818 3.22926245 3.22930132 3.23062529 3.23119218
 3.23140253 3.23145277 3.2317288  3.23183173 3.2330867  3.23325229
 3.23455068 3.23547932 3.23583653 3.23611979 3.2365119  3.23742855
 3.23826964 3.23979449 3.2399154  3.24380634 3.24395435 3.24493507
 3.24505912 3.24544365 3.24590779 3.24748901 3.24910023 3.24926896
 3.24953082 3.24966341 3.24968019 3.25023022 3.25031415 3.25309118
 3.25373866 3.25393276 3.2542094  3.25447983 3.25537438 3.25613777
 3.25840682 3.25876721 3.25943473 3.26051275 3.2612174  3.26179671
 3.26207264 3.26309517 3.26319293 3.26345272 3.26384416 3.263979
 3.26401138 3.26416051 3.26433991 3.26508038 3.26521662 3.26574014
 3.26603848 3.26695244 3.27010826 3.27053631 3.27072209 3.2719375
 3.27252602 3.27281436 3.27442946 3.2758116  3.27702022 3.27702637
 3.27757932 3.27815873 3.27858641 3.27860576 3.27880002 3.27902996
 3.27930842 3.27962752 3.2796954  3.27987998 3.2804854  3.2810302
 3.28138002 3.28276747 3.28324371 3.28330279 3.28417128 3.28475048
 3.28534626 3.28617296 3.2868209  3.28761588 3.28937262 3.29061505
 3.29214137 3.29276814 3.29300773 3.29377744 3.29549433 3.29582072
 3.296659   3.29805255 3.29848446 3.29859812 3.29887828 3.2991596
 3.29939138 3.30060644 3.3010308  3.30106228 3.30181629 3.30457524
 3.30482203 3.30504717 3.30535049 3.30602828 3.30654499 3.31103723
 3.31121235 3.31143584 3.31163134 3.31420015 3.3192659  3.32127501
 3.32141193 3.32144277 3.32255162 3.32385498 3.32469125 3.33223798
 3.33300306 3.33501649 3.33508495 3.33672707 3.33740587 3.33852697
 3.33881157 3.34021919 3.34454551 3.34735188 3.35093174 3.35187076
 3.35364535 3.35401161 3.35568159 3.35634463 3.35708299 3.3606854
 3.36141864 3.36189316 3.36269073 3.36365009 3.36379207 3.3692286
 3.3711855  3.37131028 3.37166879 3.37192073 3.37388787 3.37550313
 3.37720247 3.37779868 3.37829371 3.37876349 3.3795951  3.38238337
 3.38348997 3.38402091 3.38528812 3.38975782 3.38992011 3.39129187
 3.39496732 3.3953263  3.40441234 3.40927908 3.40942407 3.4126617
 3.42368535 3.42818504 3.43087218 3.43249935 3.440449   3.44346283
 3.45354924 3.45409929 3.45592961 3.46440035 3.4659104  3.4666987
 3.4764197  3.47677146 3.4777487  3.4952278  3.53701595 3.60616055
 3.6166314  3.62737205 3.63741915 3.65693037 3.65882159 3.66002725
 3.68129018 3.68817265 3.75110207 3.77063755 3.77408012 3.79233228
 3.7958496  3.80037386 3.80171063 3.81128738 3.81996349 3.82329722
 3.82828155 3.82864729 3.83101239 3.83707614 3.83883964 3.84055976
 3.84406512 3.84722133 3.92529979 3.93021476 3.94381729 3.99226166
 4.14508482 4.14881997 4.17019715 4.24057396 4.39252976 4.72793022
 4.74498939 4.74818824 4.77979246 4.78485769 4.80097044 4.8049187
 4.80953085 4.80960988 4.81199819 4.81430867 4.81860973 4.82163883
 4.8217663  4.82383046 4.82394877 4.82460087 4.82582504 4.82637554
 4.83106214 4.83174042 4.8329841  4.83395168 4.84120837 4.8431589
 4.84619023 4.85068736 4.85445451 4.85475728 4.86204142 4.86419421
 4.86836336 4.87050419 4.8706908  4.88527552 4.9156359  4.92204487
 4.92793853 4.9354248 ]

  warnings.warn(

2022-12-16 10:36:46,113:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.75236179 1.90805496 1.93131937 1.93343454 1.94766262 1.99550885
 2.00943647 2.01972218 2.04298853 2.06888875 2.18952565 2.79592469
 2.80373121 2.8080597  2.81836196 2.82550179 2.8286418  2.85008061
 2.8642022  2.8658445  2.88138763 2.92873152 2.93126729 2.94553253
 2.94881246 2.94899426 2.95440884 2.9622745  2.96356045 2.96428408
 2.97121847 2.97201274 2.97688895 2.97694153 2.9777487  2.98757256
 2.98872012 2.98990446 2.99009535 2.99019089 2.99299522 2.99330389
 2.99375189 2.99655426 2.99674731 2.99700727 2.99730368 2.99759617
 2.99856822 2.99863711 2.99991036 3.00162138 3.00506692 3.00720753
 3.00925001 3.00941223 3.00946962 3.0105     3.01063011 3.01238531
 3.01299509 3.01320012 3.01579842 3.01765147 3.01935997 3.01997685
 3.02080831 3.02292954 3.02488523 3.02509333 3.02653288 3.02681065
 3.02855021 3.03040583 3.03087554 3.03141265 3.03416437 3.03420938
 3.03584396 3.03695972 3.03714585 3.03718316 3.03769712 3.03996514
 3.04029211 3.04271124 3.04315614 3.04385305 3.04463708 3.04514686
 3.04617143 3.04860321 3.04899593 3.05012294 3.05522829 3.05584074
 3.05647125 3.05847646 3.05970489 3.05974578 3.06038332 3.06262443
 3.06336241 3.0650792  3.06608536 3.06775677 3.06944417 3.07293665
 3.07429461 3.07478022 3.07531332 3.07791714 3.08058982 3.08209912
 3.08216784 3.08258804 3.08286178 3.08320207 3.08332527 3.08343857
 3.08644475 3.0886886  3.0902357  3.09039959 3.09207676 3.09804657
 3.09969944 3.09992753 3.0999536  3.10088618 3.10124944 3.10190629
 3.10283009 3.10308783 3.10335529 3.10351528 3.10365877 3.10464319
 3.10469843 3.10539563 3.10590309 3.10596513 3.10770742 3.10917011
 3.10934341 3.109747   3.10993122 3.11173487 3.11192861 3.11345589
 3.11349773 3.11409984 3.11515113 3.11529931 3.11567682 3.11575898
 3.11575915 3.11615963 3.11636952 3.11672245 3.11719753 3.11728264
 3.11886943 3.11967488 3.12009545 3.1217629  3.12228196 3.12242451
 3.1229305  3.12426887 3.12437305 3.12460815 3.12461075 3.12464889
 3.12583367 3.12601026 3.1264973  3.12675783 3.12720364 3.12736513
 3.1273973  3.12749098 3.12797061 3.12978345 3.12992335 3.13004507
 3.13009865 3.13044581 3.1304654  3.13182794 3.13233036 3.13267102
 3.1327214  3.13326276 3.1333297  3.13342756 3.13344511 3.13350821
 3.133925   3.1339894  3.13409719 3.1356883  3.13570239 3.13570297
 3.13575923 3.13600771 3.13617802 3.13636108 3.13643205 3.13646614
 3.13666446 3.13722307 3.13758519 3.13768204 3.13801216 3.13900537
 3.13906843 3.13908869 3.13950063 3.13998742 3.14046125 3.14112725
 3.14133936 3.14135414 3.14159625 3.14167157 3.14208833 3.14216232
 3.14283797 3.1429561  3.1430707  3.14309325 3.14410679 3.14496004
 3.14531164 3.14562728 3.14593623 3.14595701 3.14596605 3.1461123
 3.14624789 3.14627677 3.14652001 3.14655276 3.14675198 3.14705032
 3.14773842 3.14774092 3.14775576 3.147804   3.14846826 3.14847735
 3.1485751  3.14858535 3.14882193 3.15002379 3.15029269 3.15060347
 3.15141154 3.15172037 3.15231822 3.15243256 3.15334689 3.15350737
 3.153536   3.15376678 3.15376792 3.15441851 3.15460295 3.15464219
 3.15468891 3.15474147 3.15514493 3.15518041 3.15557629 3.15638207
 3.15647625 3.15712711 3.15745529 3.15759806 3.15794172 3.15805378
 3.15835781 3.15847769 3.15852602 3.15955998 3.1597593  3.16002412
 3.16006318 3.16033545 3.16055613 3.16095804 3.16097305 3.16105692
 3.16135832 3.16158388 3.16163647 3.16175344 3.16187673 3.16205696
 3.16223775 3.16231626 3.16243158 3.16248154 3.16271641 3.16317504
 3.16442282 3.16488037 3.16544348 3.16554856 3.16558387 3.16625782
 3.16694896 3.16724921 3.16738494 3.1680706  3.16821797 3.168547
 3.16877826 3.16878012 3.16882748 3.16885371 3.16896068 3.1691104
 3.16949586 3.16961252 3.16965688 3.17017576 3.17027455 3.17038631
 3.1710881  3.17108941 3.17130517 3.17138515 3.17182288 3.17297376
 3.17302554 3.17313249 3.17356436 3.17383026 3.17447617 3.17449861
 3.1745962  3.17511341 3.17562247 3.17612621 3.17617576 3.17639517
 3.17648589 3.17661197 3.1766406  3.17700068 3.17854649 3.17857908
 3.17865993 3.17912758 3.17941867 3.17990565 3.17997368 3.1813462
 3.18147185 3.18161529 3.18179962 3.18187467 3.18197164 3.18235885
 3.18339952 3.18347713 3.18367377 3.18371586 3.18374154 3.18377771
 3.1838596  3.18397751 3.18414662 3.18418441 3.18453752 3.18534557
 3.18535743 3.18542894 3.18561967 3.18578494 3.1860369  3.18629956
 3.18663781 3.18726513 3.18756597 3.18821193 3.18829963 3.18844911
 3.18881477 3.18910816 3.18968573 3.18981601 3.190033   3.19004441
 3.19004838 3.19050086 3.19072502 3.19084391 3.19091306 3.19115378
 3.19138251 3.19151242 3.19193249 3.19260046 3.19308762 3.19317849
 3.19407858 3.19413745 3.19464485 3.19550155 3.1958563  3.19594633
 3.19605948 3.19616869 3.19685725 3.19721593 3.19806947 3.1985966
 3.19886262 3.19904775 3.19928036 3.19928046 3.19964451 3.19979169
 3.20018256 3.20062843 3.20081208 3.20123655 3.2012466  3.20150517
 3.20186859 3.20204532 3.20245988 3.20255907 3.20272086 3.2029799
 3.20302636 3.20349026 3.20357017 3.20363828 3.20385965 3.20445987
 3.20450992 3.20459868 3.20519638 3.20542975 3.20552437 3.20553465
 3.20555026 3.20636747 3.20646147 3.20676595 3.2071976  3.20769575
 3.20779995 3.20795863 3.2082757  3.20904926 3.20948577 3.20965968
 3.20977034 3.20998161 3.21045664 3.21066177 3.21089548 3.21153546
 3.21161857 3.21212457 3.21244227 3.21270616 3.2128346  3.21320213
 3.21348045 3.21349167 3.21353821 3.21359053 3.21387298 3.21390854
 3.21397368 3.21449841 3.2151025  3.21594955 3.21629259 3.21645953
 3.21651119 3.21752881 3.21795265 3.21797999 3.21799787 3.21846834
 3.21907526 3.21908968 3.21916745 3.21929609 3.21950372 3.21987672
 3.22002439 3.22091197 3.22115839 3.22151836 3.22239232 3.22371688
 3.22431725 3.22492314 3.225018   3.22515151 3.22519757 3.22521456
 3.22523142 3.2253027  3.22716507 3.22734685 3.2276851  3.22846096
 3.22920915 3.22926391 3.22931374 3.22993508 3.22997857 3.22999457
 3.23027668 3.23099901 3.23123286 3.23353183 3.2337757  3.23440717
 3.23449729 3.23452122 3.23510196 3.23523204 3.23591718 3.23663196
 3.23664264 3.23670181 3.23684264 3.23784569 3.23817053 3.24013359
 3.24037045 3.24092864 3.24146113 3.24179687 3.24179698 3.24187062
 3.24201329 3.24228876 3.24229454 3.24278552 3.24291987 3.244306
 3.24432608 3.24521537 3.24543815 3.24546701 3.24574871 3.24609609
 3.24627535 3.246428   3.24665753 3.24705901 3.24713898 3.24740385
 3.24747943 3.24758212 3.24799772 3.24819029 3.24844833 3.24925783
 3.2495545  3.24991868 3.25029077 3.25041221 3.25076265 3.25101474
 3.25119844 3.25263634 3.25379957 3.25392301 3.25434397 3.25457412
 3.25497867 3.25504504 3.255233   3.2565032  3.2575912  3.25780315
 3.2581097  3.25821715 3.25825863 3.2598296  3.25983944 3.26019812
 3.26032565 3.26045464 3.26088899 3.26238269 3.26288332 3.26447642
 3.26545738 3.26575003 3.26690202 3.26709054 3.26746429 3.26800095
 3.2683932  3.27127765 3.27342288 3.27444875 3.27458835 3.27494224
 3.27572844 3.27582461 3.2771714  3.27742393 3.27756214 3.27757735
 3.27763405 3.27778172 3.28003409 3.28065425 3.28112638 3.28236591
 3.28239311 3.2829636  3.28330779 3.28358087 3.28405155 3.28431249
 3.285125   3.28549427 3.28631521 3.28658246 3.28676887 3.28728042
 3.28741821 3.28779896 3.28851308 3.28927023 3.2900454  3.29065978
 3.29202168 3.29210511 3.29299746 3.29449169 3.29612923 3.29633152
 3.2964782  3.29841558 3.29947795 3.29952657 3.3009589  3.30112555
 3.30116201 3.30312813 3.30358307 3.3041557  3.30418368 3.30466881
 3.30521982 3.30570651 3.30584334 3.30678419 3.30792004 3.30971806
 3.31142722 3.31329567 3.31377497 3.31426219 3.31480771 3.31514859
 3.31845578 3.31883764 3.31916397 3.32011442 3.32095151 3.32178751
 3.32191351 3.32392276 3.32511502 3.32754699 3.32769512 3.32832752
 3.32961568 3.33133432 3.33327826 3.33346288 3.33346811 3.33446982
 3.33460918 3.33619398 3.33632195 3.33715328 3.34091949 3.34333247
 3.34394295 3.34578363 3.34702743 3.3478445  3.34963894 3.35023811
 3.35046262 3.35217431 3.35227914 3.35265255 3.35312775 3.35382101
 3.35519508 3.3575095  3.3581639  3.35960547 3.36108071 3.36172517
 3.36494699 3.36554343 3.36557195 3.36631411 3.36826683 3.36986199
 3.37044809 3.3714521  3.37151277 3.37240462 3.37242629 3.3746373
 3.37493959 3.37609478 3.37707326 3.37797764 3.38108917 3.38110344
 3.38285351 3.38334845 3.38353398 3.38390529 3.38701574 3.38764898
 3.3879975  3.38842921 3.38843307 3.38851986 3.38880487 3.38984807
 3.39122352 3.3955756  3.39946463 3.39975999 3.40149104 3.40150548
 3.40176814 3.40248761 3.4049042  3.40528412 3.40556436 3.40798891
 3.41614874 3.42003236 3.42390227 3.42419541 3.4315021  3.43191439
 3.43760937 3.44641827 3.44912686 3.45314284 3.45714734 3.46048775
 3.47305304 3.47554514 3.47606267 3.48390348 3.48523358 3.48639623
 3.48755167 3.49088904 3.49542809 3.49590298 3.5045796  3.50652785
 3.50942903 3.51750216 3.51841068 3.52603805 3.52606093 3.54411385
 3.6122824  3.64313441 3.65901107 3.6709777  3.68932693 3.71972853
 3.72227737 3.76900641 3.79607039 3.80233402 3.81857874 3.82199419
 3.83550399 3.86006372 3.86121838 3.86173716 3.86308667 3.91222888
 3.94136293 3.94233262 3.95300434 3.96304066 3.96666981 4.12262234
 4.1276387  4.16639679 4.33230062 4.45097314 4.7393713  4.763839
 4.76582805 4.76922625 4.77516754 4.77575844 4.78303485 4.79286986
 4.79990727 4.80082843 4.80140486 4.80353707 4.80404423 4.80554022
 4.81027497 4.81729526 4.81776286 4.81960672 4.82123832 4.82332613
 4.82516247 4.82720147 4.82786257 4.83514813 4.83532826 4.83953579
 4.83964274 4.84457817 4.84920297 4.8566534  4.86339569 4.86490686
 4.87057881 4.8817841  4.89292804 4.89403873 4.93065729 4.93610786
 4.96112465]

  warnings.warn(

2022-12-16 10:36:46,123:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.6765099  1.85136065 1.9066638  1.92525143 1.92948757 1.95844074
 2.14361077 2.15906158 2.82161991 2.82690176 2.84345146 2.86368035
 2.91028007 2.91157449 2.91837488 2.91949781 2.92106434 2.92613428
 2.94676707 2.95331486 2.95603747 2.95971775 2.95992548 2.96298153
 2.96969248 2.97238685 2.97269729 2.97584399 2.9777742  2.97929794
 2.98001169 2.98032548 2.98213355 2.98462971 2.98646207 2.99034361
 2.99122137 2.99242143 2.99342738 2.99350987 2.99385837 2.99447171
 2.99460077 2.99581526 2.99902613 3.00401349 3.00410654 3.00550668
 3.00702029 3.0078337  3.0085114  3.00891979 3.0121329  3.01366058
 3.01389528 3.01564379 3.01599358 3.01644216 3.01730029 3.01736691
 3.01748447 3.01788458 3.01804209 3.01959805 3.02020251 3.02090038
 3.02097337 3.02122176 3.021242   3.02201956 3.02333892 3.02505487
 3.02741564 3.02755428 3.02860459 3.02927957 3.02961375 3.03192528
 3.03208502 3.03318535 3.03429999 3.03619467 3.03801591 3.03803808
 3.03851589 3.03886967 3.03937456 3.03951522 3.04024007 3.04084636
 3.0410909  3.04110329 3.04120049 3.04206946 3.042721   3.04282143
 3.04322088 3.04322737 3.0466487  3.0488838  3.04898018 3.0495406
 3.05259221 3.05374854 3.05411928 3.05489137 3.05530822 3.05591639
 3.05743498 3.05839887 3.05846693 3.05952832 3.05974114 3.05993066
 3.06063616 3.0631928  3.06322139 3.06402531 3.06417581 3.06421345
 3.06433506 3.06484004 3.06627328 3.06649224 3.06679239 3.06683044
 3.06701073 3.06739744 3.06758341 3.06902802 3.06951836 3.07111423
 3.07134162 3.07177218 3.07216508 3.07310556 3.07326001 3.07402615
 3.07459568 3.07536625 3.07548432 3.07640245 3.07722186 3.07789905
 3.07829017 3.08172818 3.08267749 3.08320524 3.08373574 3.08406348
 3.08450174 3.08746087 3.08974341 3.09020551 3.09021825 3.09072028
 3.09175989 3.0920668  3.09482991 3.09653401 3.09679542 3.09690697
 3.0985485  3.09963766 3.10013292 3.10071848 3.10190605 3.10341587
 3.10433009 3.10563179 3.10715127 3.10795461 3.10917351 3.10977382
 3.1109533  3.1117427  3.11310332 3.11325944 3.11381767 3.11527607
 3.11574143 3.11755734 3.11762169 3.11809936 3.11856789 3.11882188
 3.11912927 3.11943237 3.11981166 3.12063718 3.12120352 3.12198978
 3.12372119 3.1247726  3.12489168 3.12527743 3.12595288 3.12620219
 3.12744796 3.12760288 3.12773309 3.12776394 3.12782192 3.12810867
 3.12958808 3.13084159 3.13086831 3.13167446 3.13180244 3.1318858
 3.13190597 3.13232864 3.13309285 3.13313985 3.13381843 3.1340929
 3.13473143 3.13489695 3.13510844 3.13565918 3.13582628 3.13610413
 3.13629231 3.13782465 3.13839885 3.13849266 3.13849295 3.13888063
 3.13907317 3.13991489 3.14013996 3.14020847 3.14075128 3.14138086
 3.14148366 3.14232627 3.14251513 3.14268425 3.14290977 3.14317727
 3.14344771 3.14377415 3.14520002 3.14534649 3.1457265  3.14635924
 3.14642539 3.14643061 3.14663865 3.14675554 3.14780251 3.14794876
 3.14812915 3.14822039 3.1489634  3.1495301  3.15031898 3.15045477
 3.15065008 3.15083784 3.15120085 3.15159347 3.15183457 3.15223923
 3.1526703  3.15290956 3.1530781  3.15341161 3.15350554 3.15351797
 3.15374659 3.15419686 3.15421596 3.15429154 3.15453982 3.15469611
 3.15481262 3.15521185 3.15562271 3.15660373 3.15783751 3.1580894
 3.15822121 3.15837221 3.15846108 3.15871153 3.15880762 3.15898393
 3.15920499 3.15964809 3.15978491 3.15991948 3.1601346  3.16018728
 3.16123125 3.16133907 3.16146275 3.16164138 3.1618605  3.16218859
 3.16273686 3.16352426 3.16396812 3.16396839 3.16400142 3.16421886
 3.16433215 3.16436909 3.16440276 3.16462141 3.1646913  3.16478889
 3.16510163 3.16531018 3.166009   3.16622329 3.16628911 3.16633266
 3.16633842 3.1664929  3.16680338 3.16711822 3.1672299  3.16739772
 3.16749631 3.16876633 3.16902741 3.16912313 3.16938005 3.16939896
 3.16967367 3.17047647 3.17060674 3.17092497 3.17105761 3.17110313
 3.17117932 3.17127684 3.17150393 3.17163877 3.17194615 3.17211312
 3.1721395  3.17220158 3.17222943 3.17236901 3.17262935 3.17277973
 3.17341973 3.17345326 3.17360255 3.17383335 3.17391797 3.17410582
 3.17423287 3.17427431 3.1748798  3.1759212  3.17598594 3.17624078
 3.17636194 3.17671498 3.17725272 3.17760145 3.17791175 3.17801594
 3.17802845 3.17852511 3.17854326 3.17864584 3.17876508 3.17960783
 3.17972641 3.18045103 3.18051045 3.18062305 3.18131036 3.18137286
 3.181439   3.18154131 3.18168529 3.18205409 3.18211872 3.1833797
 3.18350686 3.18407199 3.18430122 3.18432079 3.18434426 3.18437399
 3.18442609 3.18447967 3.18484133 3.18558065 3.18579431 3.18627161
 3.18642204 3.18643512 3.186445   3.18687531 3.18691124 3.18691234
 3.18718243 3.18724281 3.18739106 3.18771701 3.18805452 3.188118
 3.18820212 3.18832009 3.18845652 3.18861091 3.18901102 3.18902597
 3.18915288 3.18951653 3.18956124 3.18956393 3.18977986 3.18989523
 3.18995438 3.19051026 3.19072319 3.19076351 3.19097183 3.19112022
 3.19122892 3.19179718 3.19291935 3.19305692 3.19323778 3.19354355
 3.19425558 3.1942625  3.19443082 3.19453    3.19455521 3.1947208
 3.19509637 3.19543483 3.19546673 3.19559009 3.19560156 3.19596333
 3.19620784 3.19627907 3.19630779 3.19631002 3.19712825 3.19725739
 3.19728982 3.1972922  3.19785193 3.19789778 3.19843047 3.19899325
 3.19909459 3.19940833 3.19941303 3.1995596  3.19962582 3.19991675
 3.20001066 3.20015371 3.20017313 3.20017978 3.20031024 3.20034207
 3.20044059 3.20076658 3.20081091 3.2011173  3.20133704 3.2014525
 3.20171636 3.20173451 3.20185282 3.20233452 3.20235509 3.20270845
 3.20320642 3.20337807 3.20425565 3.20439271 3.20482317 3.20489174
 3.20495842 3.20531814 3.20547455 3.20553845 3.20600687 3.206023
 3.2061533  3.20712889 3.20734296 3.20783669 3.20784769 3.20803683
 3.20846425 3.20857586 3.20861102 3.20878476 3.20945892 3.20973341
 3.20978992 3.20993776 3.20999819 3.21072629 3.2107482  3.21084653
 3.2111477  3.21123483 3.21131968 3.21142142 3.21192262 3.21193946
 3.21229275 3.21252027 3.21272894 3.21280693 3.21300407 3.21387663
 3.2142138  3.21449188 3.21457087 3.21483374 3.21486608 3.21502072
 3.21503803 3.21570483 3.21572032 3.21574256 3.2158539  3.21604591
 3.21623013 3.2164667  3.21648243 3.21667786 3.21754523 3.21762385
 3.21771076 3.21778339 3.217994   3.21811449 3.21819061 3.21847068
 3.21849054 3.21873427 3.21946923 3.21972081 3.22007678 3.22054407
 3.22151211 3.22195132 3.22247767 3.22260158 3.22280747 3.22296636
 3.22342654 3.22424858 3.22451693 3.22486109 3.22492228 3.22502669
 3.22649551 3.22817195 3.2285869  3.22873298 3.22927769 3.23072979
 3.23094961 3.23181256 3.23214696 3.23317371 3.23351945 3.23404421
 3.23419534 3.23491527 3.23509488 3.23536068 3.23539615 3.23551497
 3.23601373 3.23677294 3.23751812 3.23774956 3.23791986 3.23933059
 3.23965225 3.24011603 3.2402728  3.24060367 3.24080694 3.2411548
 3.2418094  3.24282468 3.24432648 3.24614402 3.24701965 3.24852703
 3.24912042 3.24925538 3.25015366 3.25034676 3.25036958 3.25109786
 3.25113961 3.25365472 3.25372847 3.25385631 3.25392565 3.25426872
 3.25505087 3.25629566 3.25680876 3.25772648 3.25815322 3.26035008
 3.26169702 3.26262926 3.26316358 3.26355963 3.2641454  3.26512446
 3.26632852 3.26646248 3.26728311 3.26765272 3.26810139 3.26889421
 3.26946118 3.27171939 3.27225499 3.27240212 3.27245701 3.27353294
 3.27592871 3.27869283 3.27985032 3.28030538 3.28091151 3.28263761
 3.28337474 3.28464109 3.29236968 3.29253625 3.29351421 3.29712642
 3.29914172 3.2992816  3.29993478 3.30029818 3.3003907  3.30078774
 3.3024927  3.3032413  3.30394943 3.30896269 3.31140166 3.31250161
 3.31310161 3.31623726 3.31734345 3.31817877 3.31836393 3.32049551
 3.32144969 3.32332328 3.32339751 3.3237752  3.32450161 3.32472718
 3.32598727 3.32606541 3.32729517 3.32783115 3.32792575 3.32866185
 3.32922222 3.32946096 3.32993504 3.33005879 3.33411719 3.3348394
 3.33521274 3.33571248 3.33617929 3.33764993 3.33889443 3.33930339
 3.34021075 3.34031849 3.34076962 3.34126432 3.34239917 3.34282143
 3.34454721 3.34473086 3.34615523 3.34714217 3.34789527 3.34905218
 3.35041561 3.3538901  3.35433532 3.35438068 3.35471142 3.35645251
 3.35735135 3.35896729 3.35933424 3.36054838 3.36107758 3.36208102
 3.36261769 3.3639882  3.36491767 3.36572416 3.36684194 3.36711001
 3.36723444 3.36993333 3.37014933 3.37016669 3.37165223 3.37180752
 3.37294167 3.37471765 3.37491232 3.37666939 3.37686709 3.37733911
 3.37875779 3.37921734 3.38003798 3.38070725 3.38075132 3.38089856
 3.38108156 3.38276577 3.38356877 3.38494412 3.38861555 3.39060555
 3.39076404 3.39148141 3.3951359  3.39597914 3.39651213 3.40174391
 3.40205813 3.40308658 3.40370383 3.40519781 3.40633614 3.40640205
 3.40659108 3.40736094 3.4079265  3.40889264 3.40938427 3.41077615
 3.4134212  3.41879522 3.4218045  3.42274076 3.42282486 3.42410511
 3.43303741 3.43368522 3.45270464 3.45306031 3.45371381 3.45425237
 3.46220141 3.48896715 3.4935366  3.49678642 3.50498486 3.53021744
 3.54126925 3.55718554 3.56108922 3.60836496 3.62041694 3.64434231
 3.6632576  3.67004757 3.67642424 3.68752727 3.69956235 3.7068061
 3.71024757 3.73862813 3.74357767 3.76860776 3.7882591  3.78881874
 3.79437363 3.80267532 3.80395481 3.81611287 3.81708194 3.82930463
 3.83315217 3.84148055 3.84512967 3.85202791 3.85904062 3.86512186
 3.88795234 3.93663109 4.1333494  4.1446078  4.16242675 4.18977908
 4.3297335  4.52692543 4.61940842 4.70056403 4.73238859 4.76092825
 4.77093845 4.77473051 4.78162968 4.7830993  4.7842153  4.79349932
 4.7942904  4.79627011 4.80267826 4.8109834  4.81558037 4.81635678
 4.81834415 4.81882882 4.82276251 4.82838289 4.8365524  4.83858646
 4.83867768 4.84323494 4.85513793 4.86089856 4.86132887 4.86159747
 4.86796071 4.86971713 4.87348889 4.88082307 4.90636889 4.9165705
 4.92552738 4.93131816 4.93233014 5.03905364 5.21145402]

  warnings.warn(

2022-12-16 10:36:46,172:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.8640385  1.90820446 1.91085497 1.97449855 1.98126989 2.02055014
 2.63388496 2.72466243 2.8025042  2.82302973 2.8478872  2.85527548
 2.85610912 2.85919911 2.86684228 2.8755209  2.88082794 2.88187643
 2.8847523  2.88788033 2.89457409 2.8985383  2.90166376 2.9052092
 2.91096123 2.91491749 2.91979778 2.92686361 2.92796436 2.93077772
 2.93186    2.93649446 2.9396224  2.94234595 2.94342413 2.94719705
 2.94945398 2.95015994 2.95162296 2.95209671 2.9540953  2.95599339
 2.95705468 2.95798317 2.96403002 2.96406288 2.96440263 2.96492393
 2.966421   2.96726514 2.97235525 2.97379936 2.97539135 2.98023108
 2.98031779 2.9805223  2.98091567 2.98188444 2.98272664 2.98395717
 2.9842085  2.98608689 2.98784711 2.98862655 2.9892476  2.99185441
 2.99232241 2.99256831 2.99415076 2.99536133 2.9960478  2.99824276
 2.9985498  3.00135556 3.00377262 3.00403692 3.00512348 3.00524053
 3.00536734 3.00549913 3.00743064 3.00816199 3.00836035 3.00910444
 3.01024328 3.01188586 3.01237904 3.01275073 3.01485192 3.01555686
 3.01601845 3.01632093 3.01845997 3.02022214 3.02050766 3.02186166
 3.02394156 3.02400889 3.02811909 3.02857015 3.02908158 3.03120343
 3.032658   3.03339637 3.03468216 3.03555919 3.03579763 3.03620992
 3.03793812 3.03856608 3.03894328 3.04047337 3.04231256 3.0429933
 3.04303336 3.04534197 3.04535589 3.04536616 3.04689138 3.05019622
 3.05029838 3.05042243 3.05352241 3.05422989 3.05693888 3.05852694
 3.06184531 3.06215989 3.06264764 3.06403159 3.06492106 3.0661173
 3.06713447 3.06717128 3.0686147  3.06879115 3.06895116 3.07025058
 3.07273439 3.075382   3.07987626 3.07989133 3.08006613 3.08064076
 3.08130259 3.08245109 3.08481891 3.08554716 3.08573937 3.08604874
 3.08696643 3.08799402 3.08923314 3.08968167 3.08972249 3.09055997
 3.09155442 3.09248612 3.09255213 3.09258376 3.09265387 3.09282778
 3.09310722 3.09324224 3.09388874 3.09453822 3.09673584 3.09719635
 3.09726355 3.09800683 3.09851829 3.09981236 3.10071019 3.10325288
 3.10508306 3.10515355 3.10553553 3.10604602 3.10622437 3.10678735
 3.10742549 3.10801874 3.10874582 3.10944811 3.10953477 3.1102294
 3.11125927 3.11159709 3.11196454 3.11305278 3.11328336 3.11339862
 3.11376446 3.11415984 3.11618326 3.116565   3.1168787  3.11699988
 3.11703133 3.11785971 3.11825456 3.1187382  3.11883591 3.11889449
 3.12011759 3.12017798 3.12020816 3.1202366  3.12047293 3.12083566
 3.12119759 3.12350352 3.12372179 3.12396207 3.12441852 3.12499329
 3.12505811 3.12513947 3.125882   3.12590024 3.12599966 3.1263787
 3.1267138  3.12767746 3.12776467 3.12826556 3.12938728 3.12943474
 3.13092401 3.13098512 3.13112679 3.13183257 3.13266181 3.13302151
 3.13332947 3.13338514 3.13353361 3.13392735 3.1341212  3.13463066
 3.13539713 3.13628639 3.1363244  3.13696288 3.13724347 3.13742876
 3.13772195 3.13855826 3.13873933 3.13948329 3.13966478 3.1397856
 3.14002429 3.14005877 3.14010038 3.14057049 3.14102721 3.14160928
 3.14254851 3.14280475 3.14294458 3.14379256 3.14391045 3.14470022
 3.14514719 3.14557597 3.14690175 3.14931027 3.14951921 3.1504338
 3.15120181 3.15127394 3.15145041 3.15170395 3.15369475 3.153915
 3.15440354 3.15454908 3.15456278 3.15467095 3.15521074 3.15530895
 3.15536121 3.15549326 3.15589335 3.15609472 3.15642496 3.15643877
 3.156466   3.15705681 3.15744746 3.15763084 3.1577141  3.15773864
 3.15814488 3.15818326 3.15846213 3.15913362 3.15962584 3.15974603
 3.15997165 3.16084434 3.16100565 3.16128862 3.16132546 3.16140025
 3.16159517 3.16165378 3.1617235  3.16191478 3.16202263 3.16249274
 3.16299687 3.16302369 3.16333556 3.16349474 3.16364102 3.16393567
 3.16408697 3.16410445 3.16432281 3.16438037 3.16455159 3.16459211
 3.16464563 3.16480665 3.16523318 3.16524352 3.16606427 3.1675959
 3.16769525 3.16791085 3.16805973 3.16838756 3.16873985 3.16914795
 3.16927825 3.17009028 3.17009291 3.17074835 3.17078008 3.17094349
 3.17124936 3.17135924 3.17136873 3.1714224  3.17174696 3.17190363
 3.1729042  3.1734399  3.17344677 3.17383616 3.17414167 3.17427104
 3.17447451 3.17498839 3.17501421 3.17524192 3.1755361  3.17589752
 3.17607815 3.17697244 3.17715391 3.17729309 3.17756507 3.17807277
 3.17819655 3.17820572 3.17822995 3.17829545 3.17866407 3.17882783
 3.17886732 3.17910865 3.17913487 3.17914077 3.17940799 3.17954215
 3.17971456 3.17985162 3.18003271 3.18003919 3.18031533 3.18032264
 3.18058613 3.18083303 3.18093773 3.18109641 3.18112786 3.18124903
 3.18153059 3.18154156 3.18157878 3.18169429 3.18172574 3.18191111
 3.18215974 3.18217249 3.18235636 3.18254007 3.18406356 3.18414202
 3.18436187 3.18448094 3.18456641 3.18474313 3.18480695 3.18487234
 3.18490548 3.18511133 3.18557121 3.18572022 3.18608843 3.18684442
 3.18687555 3.18689973 3.18710171 3.1877299  3.1877375  3.18779968
 3.18841665 3.18851    3.18857533 3.18871536 3.18913749 3.18943335
 3.18968905 3.18971592 3.19022526 3.19032555 3.19061626 3.19126364
 3.19136945 3.19209684 3.19217894 3.19271063 3.19446849 3.19458063
 3.19462043 3.19473228 3.19487434 3.19490579 3.19502899 3.19508942
 3.19540466 3.19548284 3.19554723 3.19622694 3.19657218 3.19664064
 3.19683075 3.19690842 3.19700127 3.19766236 3.19796482 3.19831083
 3.1985379  3.19915324 3.19918807 3.20040634 3.20073022 3.20080808
 3.20088398 3.20099485 3.20131583 3.20164434 3.20169671 3.20223468
 3.2023679  3.20249681 3.20258262 3.20281574 3.20297407 3.20309469
 3.20309574 3.20380227 3.20416411 3.2041978  3.20444638 3.20454999
 3.20558653 3.20580531 3.2058973  3.20590216 3.2060091  3.20621139
 3.20622368 3.20704527 3.20711855 3.20748946 3.20769962 3.2079496
 3.20801655 3.20872827 3.2088429  3.20888581 3.20898525 3.20899614
 3.20900357 3.20917315 3.20980314 3.21000746 3.21033043 3.21050077
 3.21161567 3.21178104 3.21274692 3.21305123 3.21306546 3.21313198
 3.213138   3.21313843 3.21323638 3.2135813  3.21364561 3.21399318
 3.21399366 3.21415824 3.21435011 3.21449775 3.21451451 3.21476195
 3.21484416 3.21489033 3.21499121 3.21606311 3.21606833 3.21641983
 3.21654918 3.21700359 3.21751672 3.21753325 3.21806117 3.21851307
 3.2204498  3.22141274 3.22147087 3.22154384 3.22161627 3.22168774
 3.22198298 3.22204358 3.22209941 3.22235343 3.2223863  3.22257921
 3.22268062 3.22276464 3.22322306 3.2233854  3.22359354 3.22421865
 3.2244651  3.22456051 3.2247387  3.22544759 3.22610063 3.22696407
 3.22793178 3.22881826 3.22956801 3.23028109 3.23036686 3.23047861
 3.2310742  3.23118049 3.23158468 3.23162343 3.23206334 3.23289264
 3.23292819 3.23369177 3.23538953 3.23600325 3.23644878 3.23658438
 3.23671278 3.2373202  3.23732116 3.23806705 3.23832048 3.23959259
 3.24014278 3.24016811 3.24043672 3.24154519 3.24185354 3.24200928
 3.24381797 3.24385358 3.24421863 3.24575491 3.24612393 3.24663891
 3.24698609 3.24702898 3.24859137 3.24906808 3.24939388 3.25018985
 3.25062665 3.25146123 3.25209332 3.25307862 3.25348191 3.25444988
 3.25532761 3.25543108 3.25556667 3.25607538 3.2562608  3.25675126
 3.25819452 3.25827022 3.25859561 3.26023962 3.26062609 3.26096342
 3.26232716 3.26253218 3.26319469 3.26326103 3.26375348 3.26448674
 3.2657274  3.26603644 3.26606913 3.26681013 3.26698831 3.26738653
 3.2680346  3.26870783 3.26875515 3.26960621 3.26966583 3.27094191
 3.27097626 3.27222993 3.27499934 3.27604276 3.27671931 3.27706359
 3.27708766 3.27740833 3.27774071 3.27797325 3.28170728 3.2823895
 3.28248721 3.28292591 3.28300838 3.28315793 3.28429886 3.28484532
 3.28593044 3.28607484 3.28682735 3.28685604 3.28742703 3.2874456
 3.28769689 3.28832175 3.28905406 3.28928451 3.29028464 3.29180275
 3.2921726  3.29395645 3.29448992 3.29481922 3.29484898 3.29499217
 3.29565515 3.29707981 3.29864191 3.30055948 3.30157387 3.30169207
 3.30190339 3.30201076 3.30219401 3.30305257 3.30609807 3.30932927
 3.31034257 3.31117703 3.3142711  3.31506687 3.31580951 3.31980507
 3.32324433 3.32400408 3.32403735 3.32553749 3.32612779 3.32652355
 3.32857874 3.32983294 3.33014551 3.33022509 3.33029166 3.33058773
 3.33140004 3.33193968 3.34137857 3.34178634 3.34394917 3.34754684
 3.35272407 3.35547282 3.35638072 3.35664679 3.35730024 3.35786638
 3.36013977 3.36027604 3.36251432 3.36325621 3.36386296 3.36455177
 3.36633877 3.36738025 3.36865177 3.3690489  3.36943914 3.37012778
 3.37399313 3.37402206 3.37563718 3.37704492 3.37708857 3.37966896
 3.38056412 3.38059952 3.38135224 3.3814768  3.38190358 3.38201077
 3.38263718 3.38361637 3.38515925 3.38556619 3.38671875 3.38734683
 3.38739793 3.38806726 3.38889587 3.39047283 3.39238214 3.39518267
 3.39539043 3.39618117 3.39811593 3.39940131 3.3994389  3.40238774
 3.40323801 3.40680518 3.40761442 3.41333613 3.4140285  3.41545188
 3.41780713 3.41875927 3.42187556 3.42274575 3.42656483 3.4293898
 3.43079723 3.43086354 3.4311706  3.43206517 3.43286845 3.43287538
 3.43459234 3.43522172 3.43537052 3.44132417 3.44318582 3.46051913
 3.46826424 3.47782664 3.47998877 3.48338537 3.50135205 3.5127752
 3.53579033 3.54330918 3.54474102 3.57685042 3.5826695  3.58574443
 3.59047417 3.61308488 3.61847025 3.63546899 3.64155119 3.6466297
 3.70362089 3.75414633 3.75639114 3.75804812 3.77691784 3.78542175
 3.79522366 3.80628904 3.80690316 3.81154635 3.81312261 3.81877999
 3.82654993 3.82790834 3.82947457 3.83543877 3.84478519 3.87684071
 3.89221632 3.93292977 3.9936398  4.0155975  4.1087097  4.11846923
 4.22165351 4.34300113 4.38278411 4.76846253 4.76924624 4.77259426
 4.78176309 4.7897511  4.79683329 4.80380859 4.8053572  4.80797386
 4.8221114  4.82221196 4.82972177 4.82988738 4.8318422  4.83634159
 4.83652633 4.83919392 4.84149841 4.8599533  4.86083062 4.87620054
 4.88065626 4.88211805 4.89509678 4.89659126 4.90008497 4.90258636
 4.91259319 4.91646072 4.92314125 4.9271005  5.00637837 5.01187518]

  warnings.warn(

2022-12-16 10:36:46,193:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.6415445  1.91230585 1.92150258 1.94230338 1.94420169 1.94561387
 1.97354444 1.97429443 1.98743869 1.99975598 2.12856719 2.16360495
 2.85023125 2.86678217 2.86866113 2.87366164 2.88297912 2.89265975
 2.89456345 2.89544688 2.8956469  2.89786282 2.90105853 2.90291984
 2.90461657 2.90529674 2.90530025 2.90683219 2.91007792 2.91008944
 2.91432835 2.91513586 2.91527672 2.91620668 2.91751309 2.91922331
 2.9209299  2.92373944 2.92382598 2.92918258 2.92936152 2.93556833
 2.94046737 2.9410926  2.94146645 2.94355497 2.94639234 2.94765692
 2.9487905  2.9524227  2.95412009 2.95444626 2.95461939 2.95478805
 2.95696664 2.95798204 2.95828178 2.95844475 2.96010178 2.96027129
 2.96109575 2.96211224 2.96283239 2.96488067 2.96660489 2.96748843
 2.96772069 2.96878261 2.97087935 2.97153454 2.97205544 2.97255766
 2.97351133 2.97364565 2.97638614 2.97819422 2.97931031 2.97973437
 2.98035154 2.98404712 2.98766203 2.98821484 2.98934188 2.99001919
 2.99091828 2.99108377 2.99316403 2.9958115  3.00243409 3.00291578
 3.00409431 3.00678213 3.00693325 3.00896547 3.00980778 3.01077858
 3.01153437 3.01206278 3.01226367 3.01248889 3.0146018  3.01505026
 3.01688719 3.01754951 3.02080192 3.02763302 3.02809658 3.03120274
 3.03304553 3.03334215 3.03534136 3.03559915 3.03807821 3.03837006
 3.04937219 3.0540898  3.05731923 3.06046461 3.06640939 3.06699384
 3.06918641 3.07203676 3.07210012 3.07531615 3.076722   3.08179609
 3.08361102 3.08389477 3.08479662 3.08847111 3.09286427 3.09375485
 3.09519748 3.09524657 3.09623745 3.09729742 3.09737348 3.0977599
 3.09840836 3.09905324 3.10108926 3.10120006 3.10148029 3.10636788
 3.10803779 3.10835644 3.10934751 3.10946011 3.10997707 3.11014114
 3.11065607 3.11227675 3.11443781 3.11673832 3.11681574 3.1174629
 3.11753095 3.11798078 3.11884001 3.11926887 3.11977201 3.11979727
 3.12073971 3.12175546 3.12203234 3.12353233 3.12370304 3.12379141
 3.12395883 3.12438989 3.12449547 3.12567075 3.1260329  3.12631911
 3.1270848  3.12714954 3.12724216 3.12852882 3.1300423  3.13022925
 3.13267467 3.13282618 3.1329411  3.13302928 3.13339125 3.13352889
 3.13365175 3.13416971 3.13459934 3.13472583 3.13479607 3.13500257
 3.13549717 3.13638659 3.13692811 3.13851306 3.13864477 3.13873975
 3.13942224 3.14035397 3.14075022 3.14112876 3.1413994  3.1414944
 3.14210366 3.14228468 3.14294334 3.1433973  3.14354995 3.1435792
 3.14388276 3.14411068 3.14532031 3.14539031 3.1457264  3.14580687
 3.14653942 3.14674564 3.14759702 3.14784755 3.14806585 3.14823452
 3.1482967  3.14850895 3.14889371 3.14944772 3.14946724 3.15002859
 3.15004231 3.15004416 3.15071702 3.15081405 3.15105209 3.15154172
 3.15199388 3.15256974 3.15261059 3.15281026 3.15319951 3.15346256
 3.15366685 3.15405438 3.15474581 3.15475417 3.15499031 3.1549951
 3.15506273 3.1558618  3.15715321 3.15748126 3.15792292 3.15802894
 3.15809763 3.1588132  3.15899577 3.15917387 3.15948399 3.15965331
 3.1600362  3.16015096 3.1601772  3.16069581 3.16079713 3.16118986
 3.16122644 3.16139306 3.16143097 3.1615943  3.16179441 3.16190238
 3.16264358 3.16305701 3.16338401 3.16357004 3.16375893 3.16395586
 3.16399345 3.16408656 3.16411044 3.16424892 3.16445988 3.16489763
 3.1649356  3.16544986 3.16577577 3.16608757 3.16628474 3.16631508
 3.16645712 3.16652554 3.16688411 3.16697726 3.16769778 3.16770565
 3.16778171 3.16834863 3.16856427 3.16936254 3.16980836 3.17035438
 3.17043275 3.17074441 3.17082336 3.17082371 3.17124753 3.1712839
 3.17149491 3.17194668 3.17199275 3.17220201 3.17232773 3.17290179
 3.17342229 3.17357409 3.17401155 3.17406455 3.17414227 3.17442559
 3.1745752  3.17477981 3.17529493 3.17534255 3.17626056 3.1763739
 3.17640378 3.17646547 3.17687806 3.17689396 3.17698017 3.1770324
 3.17762011 3.17836796 3.17843299 3.17845863 3.17847791 3.17866169
 3.17881051 3.17908729 3.1792351  3.17923941 3.17932066 3.17952259
 3.18012632 3.18015181 3.18025731 3.18030283 3.18033714 3.18037402
 3.18037889 3.18050404 3.18070515 3.18114604 3.18115951 3.18130612
 3.18169265 3.18176714 3.1818897  3.1821403  3.18247014 3.18261406
 3.18279907 3.18302911 3.18307932 3.18334616 3.18340175 3.18342485
 3.18413242 3.18434692 3.18435329 3.18443899 3.18446516 3.18456706
 3.18463392 3.18478814 3.18532002 3.18532989 3.18537324 3.18555788
 3.18590937 3.1864982  3.18656526 3.1869861  3.18780258 3.1878658
 3.18818861 3.18842372 3.18849978 3.18858539 3.18869505 3.18899628
 3.1895937  3.18987888 3.18987919 3.19010496 3.19010812 3.19013192
 3.19022929 3.19054372 3.19084403 3.19119214 3.19144824 3.19165489
 3.19184788 3.19190174 3.1921228  3.19266825 3.19307698 3.19314883
 3.19317233 3.19335559 3.19337627 3.19354477 3.1937913  3.19379576
 3.19381599 3.19389632 3.19405934 3.19418893 3.19433479 3.19440462
 3.19445723 3.19449216 3.19471148 3.19499193 3.1950862  3.19546305
 3.1962052  3.1963821  3.19654934 3.19670197 3.19674614 3.19712354
 3.19727842 3.19752282 3.19770488 3.19798439 3.19800444 3.19823932
 3.19835165 3.19847154 3.19848081 3.19871696 3.19872921 3.19930578
 3.19941965 3.19982212 3.19997233 3.20045473 3.20126196 3.2013131
 3.20159986 3.20217747 3.20222233 3.20223531 3.20252935 3.2025702
 3.20286786 3.20308725 3.20317962 3.20333402 3.20343267 3.20353264
 3.20363917 3.20367602 3.20397892 3.20419093 3.20441452 3.20459664
 3.20470612 3.20514475 3.20545418 3.20546765 3.20557618 3.20578543
 3.20594571 3.20632292 3.20659007 3.20692632 3.20812733 3.20816195
 3.20824347 3.20901966 3.20903569 3.20910335 3.20965841 3.20969446
 3.2103793  3.21041879 3.21061165 3.21064764 3.21101056 3.21125076
 3.21146545 3.21151102 3.21224437 3.21261823 3.21281776 3.21287512
 3.21290185 3.21317919 3.21318926 3.21321455 3.21339118 3.21367754
 3.21405538 3.21408561 3.21417489 3.21486604 3.21543904 3.21558673
 3.2158429  3.21623041 3.21653819 3.21657408 3.21658729 3.21671127
 3.21681224 3.21746949 3.21752228 3.21769383 3.2178354  3.2179793
 3.21807247 3.21825675 3.21868663 3.2191419  3.21926804 3.22016077
 3.22025838 3.22069024 3.22075178 3.22099072 3.22110241 3.22173091
 3.22176072 3.22274994 3.22303166 3.22327409 3.22349974 3.22350062
 3.22366384 3.2237148  3.22400672 3.22420221 3.22473089 3.22497421
 3.22500353 3.22504728 3.22522004 3.22528963 3.22539473 3.22540489
 3.22541494 3.22542892 3.22570165 3.22591505 3.22600366 3.22607403
 3.22620132 3.22634475 3.22668685 3.22694755 3.22754902 3.22799335
 3.22838949 3.22841418 3.2286566  3.22904228 3.22925243 3.22976138
 3.22981853 3.23047898 3.23156434 3.23173055 3.23202215 3.23250673
 3.23256735 3.23294745 3.23323844 3.23402888 3.23410228 3.23473279
 3.23475073 3.2348665  3.23499936 3.23511134 3.23526607 3.2358846
 3.23626782 3.2365349  3.23680314 3.23761552 3.23768029 3.23786825
 3.23850317 3.2386655  3.23893999 3.23916417 3.23951975 3.23954967
 3.24051824 3.24068672 3.24133216 3.24146138 3.24206005 3.24267623
 3.24386681 3.24421585 3.24511457 3.24518475 3.2456611  3.24607186
 3.24659725 3.24662966 3.24678284 3.24759155 3.24969697 3.25032451
 3.25333367 3.25343623 3.25358639 3.25471869 3.25563637 3.25600318
 3.25721138 3.25778073 3.2584019  3.25851408 3.26019666 3.26047343
 3.26206827 3.2628851  3.26391184 3.26486336 3.2652124  3.26549418
 3.2687771  3.2702794  3.2707963  3.27127413 3.27409123 3.27458151
 3.2747606  3.27479942 3.27505851 3.27571644 3.27571818 3.27577878
 3.27795376 3.27988569 3.28023787 3.28256761 3.28258498 3.28283942
 3.2834163  3.28489836 3.28539876 3.28719284 3.28754903 3.2896505
 3.29218321 3.29227607 3.2933483  3.29344967 3.29424162 3.29560148
 3.29657223 3.29801742 3.29975082 3.30058958 3.30073809 3.3040049
 3.30416681 3.30487155 3.3056944  3.3059295  3.30707921 3.30767303
 3.30794581 3.30908409 3.31146317 3.31236111 3.31356538 3.31415632
 3.31431709 3.31559756 3.31947374 3.31977021 3.32031143 3.32655026
 3.32700875 3.32802971 3.32846731 3.33179968 3.33533211 3.33798594
 3.33938192 3.34020446 3.34152294 3.3423575  3.34469052 3.34501943
 3.34680536 3.35060252 3.35256468 3.35293358 3.35293935 3.35313076
 3.35340409 3.35761497 3.35846769 3.35864706 3.35915897 3.36163353
 3.36490347 3.36517964 3.36633121 3.36759701 3.36782433 3.36796342
 3.36949535 3.37214958 3.37221017 3.37532954 3.37557543 3.37632582
 3.37974505 3.38045965 3.38171941 3.38218264 3.38293902 3.38343316
 3.3843997  3.38700426 3.38906225 3.38911181 3.39121845 3.3920952
 3.39437039 3.39455795 3.39585143 3.39613213 3.39743818 3.39851216
 3.40174762 3.40288031 3.40319061 3.40432379 3.40508938 3.40575309
 3.40669498 3.40870273 3.40987857 3.41074918 3.41108803 3.4119477
 3.41211098 3.41276184 3.4145902  3.41547986 3.4172156  3.41920427
 3.42262109 3.42272382 3.42340245 3.42360424 3.42386626 3.42459059
 3.42479912 3.42614525 3.42644095 3.42737572 3.4282792  3.42934835
 3.42971555 3.43501006 3.4360811  3.4397672  3.44974305 3.45059263
 3.45434523 3.46597487 3.48528746 3.49690395 3.51591062 3.52410635
 3.53376163 3.53874096 3.55291564 3.56639544 3.61238863 3.63570562
 3.66207249 3.66400685 3.67200048 3.67550981 3.70890263 3.74006317
 3.79922493 3.83716567 3.8412604  3.86723805 3.8718112  3.87341368
 3.87651899 3.88212947 3.88390965 3.9031585  3.90551939 3.90668676
 3.91897852 3.93172452 3.97264058 3.98945396 3.98982162 4.06480207
 4.108938   4.13498866 4.2140423  4.31486882 4.33412968 4.38090634
 4.50499568 4.52233872 4.69859665 4.76727117 4.79215093 4.79864803
 4.80507737 4.80775138 4.81403293 4.81638414 4.81979655 4.82124647
 4.82328688 4.82616859 4.83151259 4.83355531 4.83594202 4.83615927
 4.83721285 4.83862003 4.83890106 4.83971211 4.84036052 4.84037506
 4.84417349 4.84426009 4.84473767 4.8476399  4.85377408 4.86410692
 4.87800002 4.89469059 4.91512495 4.93824873 4.95398086 4.96178069
 4.96505318]

  warnings.warn(

2022-12-16 10:36:46,228:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.88161803 1.90296708 1.93598404 1.97433769 1.98281756 2.05638675
 2.187574   2.57419658 2.71401601 2.84495143 2.85051481 2.85743287
 2.86458263 2.88161275 2.88432378 2.89784612 2.90279427 2.90371493
 2.90501919 2.90929586 2.91292051 2.91338868 2.91615408 2.92325029
 2.92419444 2.92522594 2.9305105  2.93515909 2.93554171 2.93791817
 2.94032951 2.94105157 2.94215189 2.94657562 2.94691281 2.94823895
 2.94875218 2.94947374 2.9514532  2.95429068 2.95596553 2.95854557
 2.95886679 2.96074226 2.96101639 2.96130208 2.96146209 2.96273741
 2.96332948 2.96423504 2.96500198 2.9652092  2.96535307 2.96557988
 2.96562534 2.96588013 2.96655229 2.96777995 2.9683289  2.96836876
 2.9686707  2.96882689 2.96894383 2.97025481 2.97205426 2.97237577
 2.97270711 2.97343345 2.97605665 2.97679886 2.97895597 2.97918775
 2.98070468 2.98106962 2.98122635 2.98291438 2.98399441 2.9844218
 2.99112701 2.99363034 2.99618837 2.99679992 2.99688033 2.99814495
 2.99876008 2.99947233 3.00136656 3.00498841 3.00503338 3.00559971
 3.007129   3.00767259 3.00979998 3.01228759 3.01329813 3.01479809
 3.01549219 3.01630288 3.01788344 3.01881778 3.01885927 3.0200824
 3.02124477 3.02279355 3.02356404 3.02708387 3.03146237 3.03471539
 3.0367605  3.03820709 3.03869262 3.04271101 3.04356363 3.04378685
 3.04404225 3.04410647 3.04497391 3.04598252 3.04895345 3.05059857
 3.05285569 3.05358662 3.05447032 3.05452808 3.05531856 3.05544891
 3.05742727 3.05820258 3.05943037 3.05956092 3.06099733 3.06263974
 3.06344611 3.06529469 3.06611881 3.06667985 3.0667306  3.0673878
 3.06783834 3.06803826 3.06992062 3.07009717 3.07247051 3.07535238
 3.0755204  3.07792071 3.07929779 3.08218495 3.0825341  3.08281302
 3.08300783 3.08313738 3.08387835 3.08429773 3.08451729 3.08467892
 3.08538051 3.08538968 3.0855162  3.08555647 3.0877799  3.08928609
 3.08932947 3.08991372 3.09019011 3.09060779 3.09094778 3.09119657
 3.092271   3.09270063 3.09344197 3.094403   3.09525292 3.09653845
 3.09696064 3.09707433 3.09759247 3.09849273 3.09855018 3.09861504
 3.0988431  3.10061796 3.10160673 3.10287467 3.10352268 3.10356003
 3.10397885 3.10444848 3.10528234 3.10579924 3.10607144 3.10609828
 3.10694197 3.10783482 3.10861228 3.10890472 3.10971476 3.1098038
 3.11035653 3.11048827 3.11076997 3.11152655 3.11173144 3.11208885
 3.11273917 3.11296986 3.11370055 3.11371141 3.11443613 3.11593764
 3.11677729 3.11778194 3.11782414 3.11959134 3.12052746 3.12102491
 3.12123373 3.12139965 3.12147434 3.12162012 3.12216009 3.12238719
 3.12322265 3.12335938 3.12486258 3.12514226 3.12625355 3.12674634
 3.12681356 3.1268503  3.12773475 3.12898636 3.1303521  3.13056351
 3.13077198 3.13127247 3.13189561 3.13196478 3.13198235 3.1322528
 3.13262251 3.13329482 3.13342462 3.13404034 3.13451229 3.13551993
 3.13555911 3.13559276 3.13576776 3.13590982 3.13600588 3.13629345
 3.13662665 3.13738273 3.13746521 3.13749203 3.13753183 3.13769664
 3.13771157 3.13827134 3.13862195 3.13923335 3.13975315 3.13988221
 3.13996704 3.14058602 3.14086865 3.14110647 3.1414634  3.14162742
 3.14220177 3.14223884 3.14225853 3.1425733  3.14295064 3.14299971
 3.14318966 3.14324171 3.14342892 3.1435262  3.14406117 3.14452238
 3.14472263 3.1449166  3.14588912 3.14691523 3.14708135 3.14719107
 3.14728392 3.14744249 3.14744383 3.14820292 3.14846686 3.14864096
 3.14896853 3.14899218 3.14907158 3.14912977 3.14913922 3.14924757
 3.14925913 3.14937941 3.14951936 3.14995309 3.14995685 3.15000002
 3.15016531 3.15018791 3.15029654 3.15039674 3.15039981 3.15044129
 3.15066629 3.15066722 3.15085692 3.15088607 3.15175669 3.15222392
 3.1525287  3.15268595 3.15277201 3.15307359 3.15310203 3.15316719
 3.15336648 3.15352968 3.15354267 3.15399093 3.15448605 3.15467986
 3.15499944 3.15512626 3.1552034  3.15540172 3.15554302 3.15583897
 3.15682233 3.15705223 3.15710357 3.15711742 3.15753922 3.15755674
 3.15762037 3.15811411 3.15837817 3.15852814 3.15888316 3.15897598
 3.15908337 3.15928278 3.15958036 3.15959899 3.15981158 3.15999708
 3.16010842 3.16012418 3.16045018 3.16060389 3.16067085 3.16098227
 3.1609901  3.16128778 3.16131365 3.16156552 3.16173032 3.16196687
 3.16255964 3.16271123 3.16274381 3.16278328 3.16294853 3.16305761
 3.16309719 3.16371573 3.1643689  3.16464707 3.16507185 3.1653983
 3.16557403 3.16573365 3.16614331 3.16624411 3.16641855 3.16680259
 3.16702608 3.16759346 3.16894298 3.1691306  3.16915636 3.16941622
 3.16964286 3.16982107 3.16987153 3.16993405 3.17002801 3.1701367
 3.17038322 3.17038434 3.17066218 3.1711348  3.17126551 3.17129689
 3.1715482  3.1716494  3.17171404 3.17171706 3.17186216 3.17199141
 3.17235788 3.17244075 3.17278356 3.17294728 3.17331509 3.17401599
 3.17410725 3.1742151  3.17445437 3.17476334 3.17503182 3.17505036
 3.17645455 3.17732057 3.17764555 3.17782648 3.17812665 3.17816968
 3.17823449 3.17829737 3.17838121 3.17845254 3.17872925 3.17888058
 3.17910429 3.17981732 3.17987671 3.18017562 3.18150977 3.1815977
 3.18167689 3.18180224 3.18212431 3.18270408 3.18296092 3.18298514
 3.1836546  3.1839471  3.18441547 3.18539609 3.18583551 3.18653323
 3.18703108 3.18732789 3.18742966 3.18748382 3.18760632 3.18772105
 3.18773163 3.18781104 3.18842639 3.18865658 3.18893644 3.18953457
 3.18995719 3.19044435 3.19148426 3.19160204 3.19181324 3.19195988
 3.19233988 3.19246779 3.19258224 3.19315149 3.19319827 3.19373109
 3.1943722  3.19462718 3.19471104 3.19474997 3.19496421 3.1950456
 3.1950467  3.19587392 3.19625072 3.19649367 3.1968919  3.19704259
 3.19705372 3.19711295 3.19728522 3.197591   3.19783237 3.19790302
 3.19871507 3.19881921 3.19920059 3.19936872 3.19940088 3.19975598
 3.19984001 3.20066592 3.20122081 3.20122516 3.20130261 3.20183291
 3.20265051 3.20293572 3.20317016 3.20321244 3.20348836 3.20416218
 3.20438436 3.20481667 3.20498429 3.20547641 3.20550915 3.20577859
 3.20578549 3.20608511 3.20609947 3.20610346 3.20617075 3.20657415
 3.20680771 3.20686154 3.2074827  3.20756337 3.20796947 3.20810126
 3.20819814 3.20826481 3.20830017 3.2085704  3.20858717 3.20864719
 3.20985551 3.20986229 3.20995188 3.21003768 3.21059016 3.21081748
 3.21124818 3.21130803 3.21136046 3.21217906 3.21280127 3.21286867
 3.21304775 3.21316791 3.21342443 3.21382548 3.2140553  3.2144152
 3.21474435 3.21493621 3.21499665 3.21537521 3.21564932 3.21578384
 3.21626437 3.21640463 3.21656297 3.2173736  3.21765313 3.21768311
 3.21794346 3.21818976 3.21828556 3.21858483 3.21860668 3.22018136
 3.22026607 3.22118173 3.22158578 3.22306388 3.22375302 3.22379549
 3.22431338 3.22465575 3.22587493 3.22660384 3.22739499 3.2274727
 3.22810879 3.22826654 3.22882816 3.22911858 3.22972352 3.22978134
 3.22979119 3.23024652 3.23043967 3.23064412 3.23138719 3.23175663
 3.23210184 3.23229072 3.23252382 3.23318207 3.23494696 3.23512924
 3.23760691 3.23956934 3.24039969 3.24099845 3.24194045 3.24201097
 3.24243176 3.24321    3.24377321 3.24480168 3.24585788 3.24609558
 3.24667241 3.24806829 3.24903502 3.25039507 3.25071424 3.251138
 3.25145767 3.2514647  3.25165994 3.25256305 3.25259653 3.25281585
 3.25396728 3.25453965 3.254784   3.25485096 3.25531093 3.25564128
 3.25592558 3.25642799 3.25736431 3.25752965 3.26079114 3.26178435
 3.26217101 3.26260727 3.26823568 3.27086424 3.27244559 3.2728256
 3.2732092  3.27451291 3.27477074 3.27488371 3.27599085 3.27692876
 3.27771831 3.28002126 3.28049888 3.28065128 3.2811175  3.28128721
 3.28153633 3.28172978 3.28183629 3.28196033 3.28200553 3.28375868
 3.28640799 3.28667896 3.28776502 3.28840917 3.28966745 3.29084991
 3.29100782 3.29193448 3.2948834  3.29605697 3.29729087 3.29818713
 3.29944971 3.30221069 3.30328822 3.30355492 3.30390683 3.30466229
 3.30580502 3.3077096  3.30884008 3.30998057 3.31090343 3.31114702
 3.31130009 3.31134886 3.31603337 3.31603847 3.316327   3.31638329
 3.31673771 3.31862424 3.31993531 3.32069226 3.32181824 3.32276582
 3.32464763 3.32521168 3.32652804 3.32654394 3.32679542 3.32736197
 3.32780418 3.32880927 3.32892401 3.33140411 3.33222778 3.33315659
 3.33669895 3.34052571 3.34191307 3.34356951 3.3451861  3.34642407
 3.34720341 3.34817792 3.34847868 3.34861933 3.34887355 3.34942216
 3.3516324  3.35369415 3.35398103 3.35545954 3.35574072 3.35624813
 3.35670893 3.35683257 3.35716009 3.35794272 3.35872699 3.3596541
 3.3597923  3.35995217 3.36421608 3.36441765 3.36597865 3.36635341
 3.36635466 3.36642127 3.36712773 3.36713437 3.36733795 3.36773332
 3.36788564 3.36971304 3.37014421 3.37057386 3.37079433 3.37601212
 3.37776728 3.37872999 3.37926214 3.38035251 3.38073106 3.38084591
 3.38262272 3.38327431 3.3839508  3.38426676 3.38698961 3.38888186
 3.39212578 3.39243121 3.39610788 3.39660131 3.39912566 3.39944231
 3.40318254 3.40676818 3.40881228 3.40927474 3.40956835 3.41373998
 3.41494996 3.41676516 3.41718796 3.4179767  3.42243608 3.42667022
 3.42891888 3.43128439 3.43610761 3.44432074 3.44473028 3.44521782
 3.45469345 3.45579289 3.45980814 3.47061806 3.47601277 3.48195702
 3.49388586 3.49547254 3.49904282 3.50074281 3.50281429 3.50706637
 3.5111433  3.51836189 3.52871517 3.52969156 3.53025266 3.54278474
 3.63180205 3.64651995 3.76215388 3.78335195 3.7916333  3.80561921
 3.80680918 3.82535163 3.8374043  3.83743255 3.84446826 3.85620872
 3.85730712 3.85973671 3.87145901 3.89848984 3.91667842 3.92637704
 4.34585445 4.41192869 4.47686156 4.55012586 4.70415415 4.74991228
 4.76540315 4.81373617 4.81395174 4.81474304 4.81494201 4.81508061
 4.81631207 4.81962652 4.81963234 4.82236739 4.82540675 4.82743762
 4.83321979 4.83356939 4.83702536 4.84506727 4.85019617 4.85640716
 4.85890803 4.87231344 4.88712348 4.92550659 4.93353662 4.93408525
 4.94997448 4.95299128 4.98371117]

  warnings.warn(

2022-12-16 10:36:46,781:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:36:46,835:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:36:46,910:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.90478344 2.46614092 2.84688236 2.84799321 2.8480219  2.850055
 2.88347091 2.89662065 2.90906656 2.91811663 2.92490136 2.93297378
 2.93389455 2.93393526 2.9380361  2.93935612 2.94170416 2.94589892
 2.94822186 2.94867708 2.95046384 2.95086523 2.9518776  2.9527269
 2.95363826 2.95399156 2.95496943 2.95559083 2.95638951 2.95639375
 2.9572985  2.9596742  2.9597159  2.96143548 2.9614989  2.96158886
 2.9647284  2.96475222 2.96872298 2.96874633 2.96937782 2.96970031
 2.97464963 2.97713661 2.97805454 2.98302391 2.98625622 2.9862608
 2.98701254 2.98818265 2.98829167 2.98869524 2.99270916 2.99415707
 2.994788   2.99619976 2.99689014 3.00064275 3.00073225 3.00160468
 3.0027809  3.0032692  3.00469424 3.00630405 3.0067983  3.00841815
 3.00891719 3.00937468 3.01198212 3.01338875 3.01540201 3.01904319
 3.02155864 3.02233268 3.02426898 3.02462918 3.02484351 3.02641911
 3.02697644 3.03170782 3.03176367 3.03217255 3.03637622 3.03915899
 3.04118523 3.04467365 3.04508532 3.04580034 3.04914825 3.04955525
 3.05055333 3.05071598 3.05548865 3.05644592 3.05680171 3.06659361
 3.06816916 3.06987938 3.06997888 3.07043143 3.07163061 3.0725363
 3.07474503 3.07475626 3.07491452 3.07629181 3.07845654 3.08216981
 3.08266932 3.08418839 3.08810604 3.09025518 3.0904615  3.09129652
 3.09163513 3.09184488 3.09436004 3.09517063 3.09573907 3.09708828
 3.09781141 3.10086265 3.10348803 3.10415569 3.10465588 3.10517434
 3.10535949 3.10537811 3.10673771 3.10739469 3.10769176 3.10918494
 3.10971771 3.11051819 3.11187891 3.11203451 3.11210486 3.11222237
 3.11259181 3.11310104 3.11346368 3.11420508 3.11513425 3.11551716
 3.11640089 3.1164919  3.11650069 3.11710913 3.11828182 3.11896325
 3.1194233  3.11990737 3.12080879 3.12127349 3.12214091 3.1224007
 3.12297976 3.12308801 3.12358056 3.1242673  3.12444006 3.12461659
 3.12530644 3.12707023 3.12736521 3.12824691 3.1285777  3.12876808
 3.12934655 3.12952239 3.12958885 3.13013331 3.13078068 3.1309238
 3.13112754 3.13163605 3.13208164 3.13241528 3.1326769  3.13269736
 3.13305539 3.13316156 3.13334017 3.13432903 3.13487895 3.13506664
 3.13536259 3.13538092 3.13562035 3.1357678  3.13698917 3.13701129
 3.13734012 3.13808097 3.13817161 3.1392041  3.13922999 3.14105367
 3.14130695 3.14131639 3.14165111 3.14168334 3.14184925 3.14206343
 3.14221596 3.14222503 3.14226955 3.14234071 3.14362533 3.14386441
 3.14402461 3.14403317 3.14453882 3.14473477 3.14478349 3.14486565
 3.14502218 3.14546524 3.14584318 3.14650684 3.14653853 3.14659833
 3.14695793 3.14723116 3.14749469 3.14751435 3.14760335 3.14760588
 3.14766836 3.14804004 3.1480605  3.14817846 3.14834091 3.14834808
 3.1483942  3.1489704  3.14912632 3.1493786  3.14968476 3.14969679
 3.15014463 3.1504525  3.15079555 3.15085919 3.15113039 3.15142551
 3.15207133 3.15232984 3.15247025 3.15299507 3.15341672 3.15360048
 3.15380467 3.15403994 3.15409466 3.15424013 3.15426524 3.15452477
 3.1549795  3.15551154 3.15570967 3.15571078 3.15617759 3.1567616
 3.15695533 3.15713986 3.15747184 3.15752659 3.15762854 3.15769955
 3.15859773 3.1588654  3.1590349  3.15949295 3.15953222 3.1596506
 3.15984708 3.16039831 3.16071936 3.1607568  3.16092317 3.1615438
 3.16196433 3.16202141 3.16213645 3.16247356 3.16253308 3.16301706
 3.16302414 3.16319378 3.1632096  3.16329053 3.16349883 3.16354847
 3.16364158 3.16459477 3.16463436 3.16476505 3.1648229  3.16490594
 3.16493339 3.16526824 3.16564371 3.16612555 3.16616724 3.16656553
 3.16657449 3.16725009 3.16756715 3.16761015 3.16836949 3.16840321
 3.16856867 3.1685969  3.16872424 3.16881075 3.16961871 3.16972728
 3.16998677 3.17022857 3.17057049 3.17067301 3.17138997 3.17141315
 3.17221306 3.17252258 3.17301591 3.17316214 3.17317631 3.17327523
 3.17331786 3.17361314 3.17363664 3.17379981 3.17386751 3.17420171
 3.1760307  3.17644845 3.17651934 3.17666914 3.17671905 3.17689191
 3.17705163 3.17732057 3.17734846 3.17736295 3.17822802 3.17828187
 3.17859331 3.17888408 3.17911286 3.17928933 3.17933335 3.17985241
 3.17990043 3.180006   3.18023767 3.18031249 3.18042587 3.18051676
 3.18084983 3.18111202 3.18136464 3.18143114 3.18144038 3.18149182
 3.18169651 3.18185207 3.18188179 3.18193751 3.18200826 3.18232205
 3.18237971 3.18415606 3.18416815 3.18432525 3.18473382 3.18514212
 3.18558723 3.18576148 3.18580286 3.18600988 3.18610405 3.18632792
 3.18660225 3.18697147 3.1872485  3.1872605  3.18769519 3.18780636
 3.18805376 3.1882417  3.18855314 3.18906846 3.18907562 3.18921352
 3.1894949  3.18978043 3.18986605 3.18990319 3.19019836 3.1902874
 3.19072957 3.19077497 3.19114293 3.19127249 3.19134612 3.19149891
 3.19161675 3.19165668 3.191733   3.19207794 3.19217058 3.19241324
 3.19241496 3.19242378 3.19264939 3.19305037 3.19320793 3.19329164
 3.19344136 3.19347627 3.19350056 3.1938236  3.19435687 3.19460482
 3.19478949 3.19495521 3.19539318 3.19552566 3.19560796 3.19560893
 3.1956849  3.19578497 3.19584687 3.196211   3.19633984 3.19639057
 3.19640775 3.19645221 3.19682413 3.19691034 3.19742994 3.19747735
 3.19756967 3.19757433 3.19766388 3.19807252 3.19847053 3.19850741
 3.19855145 3.19888139 3.19897258 3.19904083 3.19912081 3.19912208
 3.19913515 3.20008177 3.20035303 3.20044587 3.20072451 3.20136674
 3.20139595 3.20153564 3.20173117 3.20213719 3.20251705 3.20294444
 3.20300122 3.20322196 3.20324524 3.20325636 3.20348524 3.20431292
 3.20432332 3.20449024 3.20469826 3.2047898  3.20511996 3.20517498
 3.20551137 3.20552293 3.20552675 3.20553171 3.2058929  3.20617895
 3.20670095 3.20682083 3.20686679 3.20689    3.20692061 3.20700181
 3.20735466 3.20738456 3.20798284 3.2080574  3.20814118 3.20820035
 3.20820461 3.20836572 3.20860056 3.20900746 3.20910193 3.20962679
 3.21019956 3.21025314 3.21068651 3.21073521 3.21078657 3.21086626
 3.21148238 3.21229776 3.21272592 3.21296154 3.21325843 3.21342627
 3.21411358 3.21427567 3.21445836 3.21454625 3.21533058 3.21552239
 3.21562885 3.21582977 3.21671997 3.2168508  3.21718485 3.21726726
 3.2175768  3.21768618 3.21777173 3.21795981 3.21801295 3.21804193
 3.21822036 3.21833313 3.21897718 3.21912743 3.2192282  3.21932551
 3.21965894 3.21978395 3.21996453 3.22033671 3.22038506 3.22096692
 3.22103154 3.22132875 3.22145    3.22165212 3.22168514 3.22195877
 3.22347492 3.22356327 3.22371122 3.22374184 3.22389769 3.22449062
 3.22493286 3.22596956 3.22640617 3.22686855 3.22692924 3.2269397
 3.22707631 3.22855349 3.2295125  3.22977123 3.23035786 3.23067638
 3.23073022 3.23097393 3.23114188 3.23204011 3.23243767 3.23246179
 3.23398936 3.23455816 3.23499363 3.23530203 3.23595175 3.23659182
 3.23733241 3.23744166 3.23769669 3.23792589 3.23924721 3.23949327
 3.23951796 3.2404715  3.24087356 3.24141506 3.24286806 3.24309328
 3.24309718 3.24321518 3.24540582 3.24687563 3.24691404 3.24702965
 3.2481948  3.24837102 3.24913883 3.24939799 3.24966612 3.2501716
 3.25103927 3.25297311 3.25326359 3.25335778 3.25430915 3.25448027
 3.25456249 3.25472162 3.25480276 3.25500318 3.25515864 3.25564885
 3.25650454 3.2565789  3.25665301 3.25678553 3.25816265 3.25852081
 3.25864748 3.25865832 3.25901055 3.25949584 3.25979149 3.25979667
 3.26109818 3.26116541 3.26182494 3.26389326 3.26403058 3.26442803
 3.26469807 3.26489619 3.26588923 3.26637273 3.26664996 3.26778177
 3.26807956 3.26840663 3.27014439 3.27107571 3.27147421 3.27158693
 3.27325789 3.27340824 3.27350378 3.27389636 3.27521722 3.27580989
 3.2766599  3.27672047 3.27716139 3.27773178 3.27909058 3.27912134
 3.27982967 3.28301799 3.28397397 3.28421181 3.28466101 3.28487326
 3.28623218 3.28661274 3.28845764 3.2899942  3.29030264 3.29037788
 3.29051513 3.2910187  3.292239   3.29402879 3.29593137 3.29651523
 3.29873011 3.29916525 3.30374979 3.30431157 3.30592274 3.30656798
 3.30728914 3.3073546  3.30813693 3.31061525 3.31076143 3.31098991
 3.31147091 3.31204734 3.31291749 3.31625006 3.31758714 3.31844423
 3.3195968  3.3203918  3.321031   3.32491908 3.32737938 3.3279195
 3.32955625 3.32957394 3.33077015 3.33085125 3.33120646 3.33221741
 3.332294   3.33303796 3.33414441 3.33476497 3.3355251  3.3359114
 3.33707466 3.33831084 3.34028297 3.34028455 3.34079225 3.34245711
 3.34473205 3.34556359 3.34705894 3.34969453 3.35056671 3.35150112
 3.35266337 3.35270583 3.35372947 3.35426459 3.35434471 3.35438556
 3.35882835 3.35884183 3.36166141 3.3619876  3.36325255 3.36334412
 3.36335528 3.36336572 3.36394409 3.36613365 3.36719277 3.36744814
 3.36946103 3.37000874 3.37067279 3.37351408 3.37511145 3.37657743
 3.37664608 3.37764329 3.37791693 3.37900907 3.37912224 3.37916761
 3.38034731 3.38165408 3.38220928 3.38537542 3.38651295 3.38741017
 3.38763149 3.38788477 3.390138   3.39106211 3.3911416  3.39393789
 3.3960551  3.39633411 3.39678036 3.39911468 3.40074281 3.40156315
 3.40162111 3.40240132 3.40273362 3.40368625 3.40501586 3.40778038
 3.40823761 3.41083847 3.41145566 3.4136671  3.4269668  3.4280252
 3.43293527 3.4392363  3.46320654 3.47133877 3.49285102 3.49847647
 3.51171734 3.53502896 3.56016806 3.56040698 3.57700781 3.58729542
 3.5912936  3.59466898 3.59494261 3.61310513 3.62582945 3.6506369
 3.654395   3.74241774 3.74336168 3.75656746 3.7618094  3.76681383
 3.77277758 3.78065736 3.78742179 3.79354679 3.81922467 4.18225473
 4.21607658 4.24912096 4.32889872 4.35999521 4.39249423 4.69533235
 4.70088563 4.70848444 4.71768913 4.75359853 4.75921253 4.77313356
 4.77465189 4.7802516  4.78622615 4.78625485 4.79404771 4.79755928
 4.79950973 4.8013645  4.80258681 4.80274939 4.80473986 4.80778921
 4.81001123 4.8183938  4.82196385 4.82403179 4.82404833 4.82602001
 4.82758035 4.82968304 4.8305135  4.83119922 4.83857659 4.85074883
 4.89631221 4.92518244 4.96278373 5.00224991]

  warnings.warn(

2022-12-16 10:36:46,955:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.55895636 1.5605789  1.83939422 1.87792203 1.90231831 1.90243698
 1.91738313 1.93556974 1.9403809  1.95493282 1.9606319  1.97343141
 2.02229399 2.14496664 2.58417668 2.73705228 2.75170988 2.797469
 2.80562496 2.81433108 2.82704674 2.83958683 2.84113724 2.84252651
 2.85210843 2.872923   2.87369547 2.88105393 2.90823579 2.90824412
 2.91073209 2.91120646 2.9168146  2.91949007 2.93293323 2.9329733
 2.94054876 2.9448746  2.94519787 2.94645433 2.94767886 2.94822743
 2.95021408 2.95106697 2.95176643 2.95195653 2.95271343 2.95320482
 2.95413492 2.95630631 2.95657159 2.95669774 2.95945981 2.96174955
 2.96294649 2.96296556 2.9709512  2.97141866 2.97300039 2.97363733
 2.97380836 2.97402914 2.97539872 2.97569435 2.97572657 2.97624004
 2.97656987 2.97673826 2.97720077 2.97743415 2.97816754 2.97972892
 2.9799146  2.9802239  2.98039943 2.9807578  2.98089264 2.9809604
 2.98111464 2.98206202 2.98213541 2.98237324 2.98260882 2.98310801
 2.98359365 2.98467401 2.98469862 2.98503643 2.98639188 2.98671276
 2.98935916 2.98953229 2.98983133 2.99088187 2.994265   2.99447701
 2.99507165 2.99610967 2.9968581  2.99776658 2.99849739 2.99878183
 2.99961485 3.00097015 3.00152541 3.00235831 3.0048107  3.00489024
 3.00541633 3.00566864 3.00624076 3.00689635 3.0075913  3.0093887
 3.00973235 3.01026348 3.01218665 3.01252056 3.01474266 3.0159506
 3.01755181 3.01769803 3.01858851 3.01964715 3.02015857 3.02294886
 3.02340761 3.02487119 3.02733645 3.02832318 3.02875309 3.03011037
 3.0305121  3.0314248  3.03811276 3.03882722 3.03906279 3.03984067
 3.04159424 3.0433432  3.04363879 3.0464057  3.04825041 3.04850921
 3.05104537 3.05450027 3.05558144 3.05742803 3.05849193 3.05868959
 3.06105303 3.06477623 3.06711319 3.06723307 3.06779742 3.06922407
 3.0699233  3.07026839 3.07130343 3.07303881 3.07376235 3.07430597
 3.07526067 3.0757875  3.07689519 3.07731901 3.07785815 3.0796332
 3.0809863  3.08290072 3.08846995 3.08882448 3.09079946 3.09124572
 3.09215674 3.09313592 3.09408817 3.09829849 3.09843981 3.09927117
 3.09938354 3.10061826 3.10118274 3.10137846 3.10189594 3.10226889
 3.1024798  3.10421505 3.10517109 3.10699536 3.10840201 3.11001098
 3.11030116 3.11044784 3.11051336 3.11067113 3.11089441 3.1115094
 3.11155163 3.1125564  3.11310001 3.11332615 3.11339476 3.11377024
 3.11388146 3.11486253 3.11510086 3.11512837 3.11684264 3.11737608
 3.11750749 3.11812905 3.11852496 3.11871509 3.11895715 3.11906094
 3.11990127 3.12044134 3.12212429 3.12456688 3.12506633 3.1256845
 3.12644156 3.12664446 3.12710455 3.12730551 3.12835878 3.12906519
 3.12943937 3.13013513 3.13014227 3.13025626 3.13060919 3.13144359
 3.13215556 3.13328522 3.13397167 3.13450354 3.13515849 3.13517432
 3.1360228  3.13689353 3.13726422 3.1372961  3.13779522 3.13802749
 3.13868483 3.13909412 3.13916109 3.13925383 3.13935472 3.13964834
 3.1397731  3.14001938 3.14005078 3.1401523  3.14049448 3.14066923
 3.14104638 3.14150873 3.14163031 3.14173572 3.14230966 3.14236211
 3.14263773 3.14315598 3.14447983 3.14458861 3.14498632 3.14506473
 3.14515192 3.14543093 3.14565948 3.14705327 3.14785632 3.14793239
 3.14846726 3.14854061 3.14883128 3.14902536 3.15017435 3.15038698
 3.15055401 3.15058538 3.15092955 3.15113576 3.15116043 3.15152346
 3.15153454 3.15161924 3.15175251 3.15176625 3.15178381 3.15211597
 3.15258647 3.1527245  3.15298248 3.15306633 3.15313018 3.15319578
 3.15335427 3.15349697 3.15352556 3.15354906 3.15362099 3.15365909
 3.15385557 3.15389712 3.15430145 3.15441091 3.15444028 3.15467009
 3.15540523 3.15548203 3.15612316 3.15654595 3.15673619 3.15775086
 3.15795274 3.15861629 3.15864251 3.15864769 3.15943165 3.15986424
 3.1601497  3.16070296 3.16109956 3.16194752 3.16252271 3.16268237
 3.16326458 3.16344237 3.16397984 3.16418671 3.16467748 3.16554494
 3.16605487 3.1662429  3.16798936 3.1683223  3.16985185 3.17086715
 3.17134213 3.17158975 3.17179643 3.17246644 3.17266418 3.1733636
 3.1733898  3.17347309 3.17448593 3.17530133 3.17545147 3.17567301
 3.17587638 3.17593672 3.1760918  3.17617267 3.17636711 3.1763934
 3.17647031 3.17698236 3.17706863 3.17725129 3.17729271 3.17745711
 3.17750126 3.1775176  3.17775249 3.17777512 3.17822958 3.1783728
 3.17858257 3.17868326 3.17876238 3.17877733 3.17882696 3.17904772
 3.17914675 3.17917719 3.17929194 3.17933421 3.17956643 3.18027148
 3.18063972 3.18091898 3.18097906 3.18128962 3.18143758 3.18147563
 3.18183881 3.18184761 3.18189853 3.18234604 3.1823577  3.18243603
 3.18249939 3.18260066 3.18261434 3.18291586 3.18339691 3.18343744
 3.18357506 3.18377731 3.1838641  3.18401983 3.18408904 3.18429865
 3.18437214 3.18493683 3.18504282 3.18514461 3.18529933 3.18552959
 3.18569415 3.18619846 3.1862067  3.18643491 3.18680074 3.18743388
 3.1880809  3.18849821 3.18884619 3.18946046 3.1897904  3.19047584
 3.19050494 3.19112882 3.1917661  3.19222446 3.19233219 3.19240571
 3.19243256 3.19266898 3.19291311 3.19305035 3.19333149 3.19333491
 3.19378532 3.19408133 3.19445818 3.19451283 3.19482426 3.19496103
 3.19509226 3.19538596 3.19625838 3.19637138 3.19688018 3.19692173
 3.19710851 3.19729168 3.19769411 3.19794455 3.19810078 3.1988674
 3.19930027 3.19976961 3.20019057 3.20022086 3.20030522 3.2003908
 3.20052546 3.20056401 3.20082825 3.20094142 3.2015909  3.20224706
 3.20259944 3.20278954 3.20281463 3.20292902 3.2030006  3.20305466
 3.20350994 3.20352492 3.20352806 3.20378665 3.20433557 3.20438015
 3.20446625 3.20487454 3.2051314  3.2053099  3.20541822 3.20572766
 3.20576733 3.20587641 3.20600706 3.20638113 3.20645671 3.20670445
 3.20676475 3.20683956 3.20686779 3.2072723  3.20728475 3.20751481
 3.20752894 3.20806401 3.20841134 3.20899376 3.20908988 3.2091838
 3.2093522  3.2094813  3.20966944 3.20983719 3.20991512 3.21094218
 3.21230008 3.21297017 3.21311651 3.2137356  3.21387014 3.21395213
 3.21409099 3.21481106 3.2154183  3.21548153 3.21565057 3.21596734
 3.21642409 3.21663488 3.21723032 3.21750617 3.21755824 3.21769275
 3.21853817 3.21952977 3.22025698 3.22032054 3.22073112 3.22080699
 3.22096029 3.22143358 3.22182586 3.2220061  3.22211516 3.22222009
 3.22287162 3.2229999  3.2233836  3.22370706 3.22378356 3.22409111
 3.22516817 3.22527362 3.2253721  3.22624842 3.22626955 3.22632006
 3.22646586 3.22648353 3.22672477 3.2269885  3.22711116 3.22718
 3.22735491 3.22766163 3.22832147 3.22855098 3.22874573 3.22879135
 3.22912904 3.22919919 3.22931794 3.23002806 3.23025941 3.23059128
 3.23060952 3.23172843 3.23255145 3.23257972 3.23289587 3.23467182
 3.23568996 3.2357408  3.23654145 3.2384934  3.23867265 3.23893322
 3.23961343 3.24026985 3.24088569 3.24443668 3.24479725 3.24543423
 3.24565174 3.2459961  3.24762775 3.24813001 3.24831718 3.24966796
 3.25034282 3.25054592 3.25064223 3.25109295 3.25260446 3.25333283
 3.25432385 3.25506846 3.25679516 3.25699356 3.25924194 3.25934417
 3.25978348 3.25995845 3.26000315 3.26048966 3.26085156 3.26280133
 3.26591601 3.26599571 3.2662225  3.26644204 3.26691744 3.26803901
 3.26895809 3.26921114 3.26946526 3.27036833 3.27047311 3.27092567
 3.27123569 3.27153636 3.27388547 3.27501033 3.27559513 3.27626183
 3.27713278 3.2777393  3.27953582 3.28005811 3.28062802 3.28131097
 3.28269273 3.2847942  3.28853048 3.28938876 3.2899575  3.29040213
 3.29154277 3.29172065 3.29221721 3.29361475 3.29392249 3.29462088
 3.29554657 3.29642171 3.29781196 3.29837454 3.30177678 3.30262649
 3.30341625 3.3049623  3.30528639 3.3065208  3.30670223 3.30724529
 3.30779434 3.30783212 3.30832574 3.30839181 3.30944664 3.31421121
 3.31541931 3.31577171 3.3161422  3.31614393 3.31626945 3.31691309
 3.31796522 3.31846386 3.31893049 3.32024161 3.32110765 3.32217288
 3.32245161 3.32392257 3.32603803 3.32691689 3.32705004 3.32741415
 3.32790678 3.32983439 3.33137257 3.33202056 3.33252565 3.33451844
 3.33494272 3.33558297 3.33560841 3.33579965 3.33648682 3.33662041
 3.33663061 3.33686507 3.3385421  3.33902722 3.33955866 3.34159861
 3.34213266 3.34265612 3.34349769 3.34353218 3.3442565  3.34435545
 3.34488393 3.34493589 3.34603338 3.34680952 3.34839542 3.35266711
 3.35343127 3.35345734 3.35399229 3.35550507 3.35824394 3.35973357
 3.36052684 3.3618779  3.36670131 3.36702619 3.36872963 3.3694913
 3.37039754 3.37098043 3.37160268 3.37281558 3.3746304  3.37532432
 3.37555024 3.37592017 3.37610203 3.3769761  3.37740429 3.38009802
 3.38011274 3.38103407 3.38449118 3.38596    3.38703623 3.38753679
 3.38823154 3.38882054 3.39113295 3.39128202 3.39285041 3.39326683
 3.39352355 3.39353068 3.39409426 3.39412579 3.39532492 3.39647813
 3.39712529 3.4002564  3.40040345 3.40084754 3.40106991 3.4016599
 3.40659503 3.40686342 3.40990624 3.40998741 3.41188644 3.41345169
 3.41449545 3.41965858 3.42298562 3.42434935 3.4315917  3.43480173
 3.44362879 3.44422344 3.44767687 3.44805267 3.44861379 3.45278311
 3.46243598 3.48418722 3.498827   3.51051324 3.51423789 3.51626329
 3.51670147 3.51843603 3.51910579 3.51991276 3.52586543 3.52982017
 3.53002676 3.53308991 3.54347074 3.55365554 3.55735969 3.57670494
 3.60816708 3.63454525 3.63983046 3.65184684 3.67172041 3.67329325
 3.70079305 3.78323765 3.78801897 3.84092663 3.8433069  3.84585948
 3.86068518 3.86469215 3.87148086 3.90995817 3.93602804 3.96320567
 4.06671694 4.10101045 4.10811235 4.13176906 4.33945743 4.36741975
 4.72328868 4.74958532 4.7771366  4.78038975 4.7845717  4.80652457
 4.80940948 4.81358907 4.81366755 4.81490551 4.81726218 4.81753573
 4.82272561 4.82788331 4.83109566 4.83257327 4.8335519  4.83581175
 4.836759   4.84169835 4.84408637 4.84427224 4.8552787  4.86801304
 4.87115602 4.90271698 4.90938151 4.91766899 4.9417024  4.95982677
 4.97967631 5.02564313 5.03420502 5.1023632 ]

  warnings.warn(

2022-12-16 10:36:46,956:INFO:Calculating mean and std
2022-12-16 10:36:46,958:INFO:Creating metrics dataframe
2022-12-16 10:36:46,961:INFO:Uploading results into container
2022-12-16 10:36:46,962:INFO:Uploading model into container now
2022-12-16 10:36:46,962:INFO:master_model_container: 10
2022-12-16 10:36:46,963:INFO:display_container: 2
2022-12-16 10:36:46,963:INFO:Lars(random_state=5099)
2022-12-16 10:36:46,963:INFO:create_model() successfully completed......................................
2022-12-16 10:36:47,107:ERROR:create_model() for Lars(random_state=5099) raised an exception or returned all 0.0:
2022-12-16 10:36:47,108:ERROR:Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 795, in compare_models
    assert (
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 811, in compare_models
    assert (
AssertionError

2022-12-16 10:36:47,108:INFO:Initializing Lasso Least Angle Regression
2022-12-16 10:36:47,108:INFO:Total runtime is 0.8308423837025961 minutes
2022-12-16 10:36:47,108:INFO:SubProcess create_model() called ==================================
2022-12-16 10:36:47,108:INFO:Initializing create_model()
2022-12-16 10:36:47,108:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002281239F8E0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022810EC8B20>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:36:47,108:INFO:Checking exceptions
2022-12-16 10:36:47,111:INFO:Importing libraries
2022-12-16 10:36:47,111:INFO:Copying training dataset
2022-12-16 10:36:47,115:INFO:Defining folds
2022-12-16 10:36:47,115:INFO:Declaring metric variables
2022-12-16 10:36:47,115:INFO:Importing untrained model
2022-12-16 10:36:47,116:INFO:Lasso Least Angle Regression Imported successfully
2022-12-16 10:36:47,116:INFO:Starting cross validation
2022-12-16 10:36:47,118:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:36:48,759:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-16 10:36:48,793:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-16 10:36:48,796:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-16 10:36:48,890:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-16 10:36:48,910:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-16 10:36:48,910:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-16 10:36:48,973:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-16 10:36:48,990:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-16 10:36:49,083:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.25673412]

  warnings.warn(

2022-12-16 10:36:49,124:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.26859131]

  warnings.warn(

2022-12-16 10:36:49,127:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.27146172]

  warnings.warn(

2022-12-16 10:36:49,227:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.26511148]

  warnings.warn(

2022-12-16 10:36:49,250:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.2657559]

  warnings.warn(

2022-12-16 10:36:49,267:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.27104008]

  warnings.warn(

2022-12-16 10:36:49,302:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.26446707]

  warnings.warn(

2022-12-16 10:36:49,306:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.26214718]

  warnings.warn(

2022-12-16 10:36:49,895:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-16 10:36:49,916:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-16 10:36:50,024:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.26072948]

  warnings.warn(

2022-12-16 10:36:50,044:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.26562701]

  warnings.warn(

2022-12-16 10:36:50,045:INFO:Calculating mean and std
2022-12-16 10:36:50,046:INFO:Creating metrics dataframe
2022-12-16 10:36:50,052:INFO:Uploading results into container
2022-12-16 10:36:50,053:INFO:Uploading model into container now
2022-12-16 10:36:50,053:INFO:master_model_container: 11
2022-12-16 10:36:50,053:INFO:display_container: 2
2022-12-16 10:36:50,054:INFO:LassoLars(random_state=5099)
2022-12-16 10:36:50,054:INFO:create_model() successfully completed......................................
2022-12-16 10:36:50,203:WARNING:create_model() for LassoLars(random_state=5099) raised an exception or returned all 0.0, trying without fit_kwargs:
2022-12-16 10:36:50,204:WARNING:Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 795, in compare_models
    assert (
AssertionError

2022-12-16 10:36:50,204:INFO:Initializing create_model()
2022-12-16 10:36:50,204:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002281239F8E0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022810EC8B20>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:36:50,204:INFO:Checking exceptions
2022-12-16 10:36:50,207:INFO:Importing libraries
2022-12-16 10:36:50,207:INFO:Copying training dataset
2022-12-16 10:36:50,212:INFO:Defining folds
2022-12-16 10:36:50,212:INFO:Declaring metric variables
2022-12-16 10:36:50,212:INFO:Importing untrained model
2022-12-16 10:36:50,213:INFO:Lasso Least Angle Regression Imported successfully
2022-12-16 10:36:50,213:INFO:Starting cross validation
2022-12-16 10:36:50,215:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:36:51,825:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-16 10:36:51,837:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-16 10:36:51,846:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-16 10:36:51,849:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-16 10:36:52,004:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-16 10:36:52,048:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-16 10:36:52,054:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-16 10:36:52,104:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-16 10:36:52,176:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.25673412]

  warnings.warn(

2022-12-16 10:36:52,194:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.27146172]

  warnings.warn(

2022-12-16 10:36:52,202:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.2657559]

  warnings.warn(

2022-12-16 10:36:52,204:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.26859131]

  warnings.warn(

2022-12-16 10:36:52,346:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.27104008]

  warnings.warn(

2022-12-16 10:36:52,381:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.26511148]

  warnings.warn(

2022-12-16 10:36:52,386:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.26446707]

  warnings.warn(

2022-12-16 10:36:52,410:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.26214718]

  warnings.warn(

2022-12-16 10:36:52,978:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-16 10:36:52,981:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-16 10:36:53,099:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.26072948]

  warnings.warn(

2022-12-16 10:36:53,103:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.26562701]

  warnings.warn(

2022-12-16 10:36:53,104:INFO:Calculating mean and std
2022-12-16 10:36:53,105:INFO:Creating metrics dataframe
2022-12-16 10:36:53,109:INFO:Uploading results into container
2022-12-16 10:36:53,110:INFO:Uploading model into container now
2022-12-16 10:36:53,110:INFO:master_model_container: 12
2022-12-16 10:36:53,111:INFO:display_container: 2
2022-12-16 10:36:53,111:INFO:LassoLars(random_state=5099)
2022-12-16 10:36:53,111:INFO:create_model() successfully completed......................................
2022-12-16 10:36:53,256:ERROR:create_model() for LassoLars(random_state=5099) raised an exception or returned all 0.0:
2022-12-16 10:36:53,257:ERROR:Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 795, in compare_models
    assert (
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 811, in compare_models
    assert (
AssertionError

2022-12-16 10:36:53,257:INFO:Initializing Orthogonal Matching Pursuit
2022-12-16 10:36:53,257:INFO:Total runtime is 0.9333204706509909 minutes
2022-12-16 10:36:53,257:INFO:SubProcess create_model() called ==================================
2022-12-16 10:36:53,257:INFO:Initializing create_model()
2022-12-16 10:36:53,258:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002281239F8E0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022810EC8B20>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:36:53,258:INFO:Checking exceptions
2022-12-16 10:36:53,261:INFO:Importing libraries
2022-12-16 10:36:53,262:INFO:Copying training dataset
2022-12-16 10:36:53,267:INFO:Defining folds
2022-12-16 10:36:53,267:INFO:Declaring metric variables
2022-12-16 10:36:53,268:INFO:Importing untrained model
2022-12-16 10:36:53,268:INFO:Orthogonal Matching Pursuit Imported successfully
2022-12-16 10:36:53,269:INFO:Starting cross validation
2022-12-16 10:36:53,270:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:36:54,918:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:36:54,930:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:36:54,979:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:36:55,034:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:36:55,063:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:36:55,082:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:36:55,112:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:36:55,178:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:36:55,253:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.91463415 3.20886336 4.76502732]

  warnings.warn(

2022-12-16 10:36:55,267:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.86666667 3.20954726 4.77150538]

  warnings.warn(

2022-12-16 10:36:55,302:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.         3.21125991 4.74175824]

  warnings.warn(

2022-12-16 10:36:55,387:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.98684211 3.20371635 4.75274725]

  warnings.warn(

2022-12-16 10:36:55,390:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.9875     3.20585019 4.75482094]

  warnings.warn(

2022-12-16 10:36:55,445:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.02439024 3.20364034 4.75405405]

  warnings.warn(

2022-12-16 10:36:55,449:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.8125     3.19767601 4.76098901]

  warnings.warn(

2022-12-16 10:36:55,462:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.9375     3.19934283 4.768     ]

  warnings.warn(

2022-12-16 10:36:56,088:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:36:56,102:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:36:56,219:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.91860465 3.20175198 4.7493188 ]

  warnings.warn(

2022-12-16 10:36:56,242:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.98648649 3.20388084 4.75476839]

  warnings.warn(

2022-12-16 10:36:56,243:INFO:Calculating mean and std
2022-12-16 10:36:56,244:INFO:Creating metrics dataframe
2022-12-16 10:36:56,248:INFO:Uploading results into container
2022-12-16 10:36:56,249:INFO:Uploading model into container now
2022-12-16 10:36:56,249:INFO:master_model_container: 13
2022-12-16 10:36:56,249:INFO:display_container: 2
2022-12-16 10:36:56,249:INFO:OrthogonalMatchingPursuit()
2022-12-16 10:36:56,249:INFO:create_model() successfully completed......................................
2022-12-16 10:36:56,404:WARNING:create_model() for OrthogonalMatchingPursuit() raised an exception or returned all 0.0, trying without fit_kwargs:
2022-12-16 10:36:56,404:WARNING:Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 795, in compare_models
    assert (
AssertionError

2022-12-16 10:36:56,405:INFO:Initializing create_model()
2022-12-16 10:36:56,405:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002281239F8E0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022810EC8B20>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:36:56,405:INFO:Checking exceptions
2022-12-16 10:36:56,408:INFO:Importing libraries
2022-12-16 10:36:56,408:INFO:Copying training dataset
2022-12-16 10:36:56,412:INFO:Defining folds
2022-12-16 10:36:56,412:INFO:Declaring metric variables
2022-12-16 10:36:56,412:INFO:Importing untrained model
2022-12-16 10:36:56,412:INFO:Orthogonal Matching Pursuit Imported successfully
2022-12-16 10:36:56,413:INFO:Starting cross validation
2022-12-16 10:36:56,414:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:36:58,039:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:36:58,053:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:36:58,054:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:36:58,092:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:36:58,115:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:36:58,226:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:36:58,266:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:36:58,288:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:36:58,397:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.86666667 3.20954726 4.77150538]

  warnings.warn(

2022-12-16 10:36:58,400:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.9875     3.20585019 4.75482094]

  warnings.warn(

2022-12-16 10:36:58,402:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.91463415 3.20886336 4.76502732]

  warnings.warn(

2022-12-16 10:36:58,425:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.         3.21125991 4.74175824]

  warnings.warn(

2022-12-16 10:36:58,455:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.02439024 3.20364034 4.75405405]

  warnings.warn(

2022-12-16 10:36:58,538:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.8125     3.19767601 4.76098901]

  warnings.warn(

2022-12-16 10:36:58,553:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.98684211 3.20371635 4.75274725]

  warnings.warn(

2022-12-16 10:36:58,589:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.9375     3.19934283 4.768     ]

  warnings.warn(

2022-12-16 10:36:59,146:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:36:59,152:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-16 10:36:59,273:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.91860465 3.20175198 4.7493188 ]

  warnings.warn(

2022-12-16 10:36:59,277:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.98648649 3.20388084 4.75476839]

  warnings.warn(

2022-12-16 10:36:59,278:INFO:Calculating mean and std
2022-12-16 10:36:59,279:INFO:Creating metrics dataframe
2022-12-16 10:36:59,285:INFO:Uploading results into container
2022-12-16 10:36:59,286:INFO:Uploading model into container now
2022-12-16 10:36:59,286:INFO:master_model_container: 14
2022-12-16 10:36:59,287:INFO:display_container: 2
2022-12-16 10:36:59,287:INFO:OrthogonalMatchingPursuit()
2022-12-16 10:36:59,287:INFO:create_model() successfully completed......................................
2022-12-16 10:36:59,439:ERROR:create_model() for OrthogonalMatchingPursuit() raised an exception or returned all 0.0:
2022-12-16 10:36:59,439:ERROR:Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 795, in compare_models
    assert (
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 811, in compare_models
    assert (
AssertionError

2022-12-16 10:36:59,439:INFO:Initializing Bayesian Ridge
2022-12-16 10:36:59,439:INFO:Total runtime is 1.0363599459330242 minutes
2022-12-16 10:36:59,440:INFO:SubProcess create_model() called ==================================
2022-12-16 10:36:59,440:INFO:Initializing create_model()
2022-12-16 10:36:59,440:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002281239F8E0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022810EC8B20>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:36:59,440:INFO:Checking exceptions
2022-12-16 10:36:59,442:INFO:Importing libraries
2022-12-16 10:36:59,442:INFO:Copying training dataset
2022-12-16 10:36:59,447:INFO:Defining folds
2022-12-16 10:36:59,448:INFO:Declaring metric variables
2022-12-16 10:36:59,448:INFO:Importing untrained model
2022-12-16 10:36:59,448:INFO:Bayesian Ridge Imported successfully
2022-12-16 10:36:59,448:INFO:Starting cross validation
2022-12-16 10:36:59,450:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:37:01,401:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.81304626 2.03824123 2.07351931 2.07421897 2.09995333 2.10838352
 2.2836984  2.31598431 2.83786623 2.84437153 2.85647644 2.85695568
 2.89490756 2.89983935 2.92720937 2.94110921 2.94278374 2.95303581
 2.96352145 2.97142025 2.97314437 2.97369014 2.97524586 2.97658707
 2.97810228 2.98156098 2.98158417 2.98412717 2.98907167 2.99111404
 2.99490088 2.99784058 2.99807111 2.99826922 2.99866897 2.99946518
 3.00212681 3.00260468 3.00291119 3.00680838 3.00716071 3.00865699
 3.00922156 3.01164331 3.01258711 3.01331034 3.01368798 3.01473714
 3.01493708 3.01525555 3.01556311 3.0158648  3.01604408 3.01818905
 3.01919535 3.01977015 3.01978299 3.02069592 3.02137032 3.02195052
 3.02212547 3.02273122 3.02298314 3.02320207 3.02363557 3.02447394
 3.02488137 3.02580245 3.02671506 3.02673756 3.02748189 3.02904668
 3.02989337 3.03071288 3.03235102 3.03287833 3.03435609 3.03556099
 3.03610457 3.03640302 3.03768641 3.03956604 3.04129528 3.04131206
 3.04131976 3.042031   3.04210108 3.04228728 3.04251488 3.04339187
 3.04436175 3.04655948 3.04689855 3.0476452  3.04777125 3.04868302
 3.04971908 3.04997723 3.0504015  3.05059011 3.05064856 3.05287333
 3.05405863 3.05459749 3.05519588 3.05589376 3.05679442 3.05690438
 3.0570043  3.05732323 3.05734869 3.05788944 3.05791789 3.0583885
 3.05908316 3.05909394 3.06000919 3.0611211  3.06393357 3.06408773
 3.06439698 3.06462607 3.06718398 3.06793555 3.06892786 3.06928123
 3.06930976 3.06983367 3.07347246 3.07351807 3.07632857 3.07879362
 3.07915706 3.0791593  3.08186686 3.08226842 3.08658175 3.0869973
 3.08818923 3.08845711 3.08936596 3.08979721 3.09125572 3.09148456
 3.09279294 3.09367596 3.09433242 3.09458196 3.09460993 3.09557714
 3.09822443 3.09935634 3.10345025 3.1060558  3.10640552 3.10737559
 3.10813101 3.10835579 3.11038539 3.11039618 3.11070234 3.11425107
 3.11428876 3.11523502 3.11632734 3.11746153 3.1178705  3.11867478
 3.11899434 3.11914892 3.12002569 3.12180134 3.12188821 3.12189973
 3.12202781 3.12240874 3.12326728 3.12348803 3.12352864 3.12435274
 3.1245434  3.12504535 3.12533115 3.12553721 3.1264021  3.12690029
 3.12703464 3.12769866 3.12828737 3.12940141 3.12977934 3.13226811
 3.13245016 3.13358984 3.13401024 3.13452515 3.1350089  3.13538701
 3.13613907 3.13636781 3.13662894 3.13664605 3.1366693  3.13693586
 3.13759519 3.13801385 3.13833959 3.13887993 3.13933781 3.13957945
 3.14042919 3.14097229 3.1410327  3.14118718 3.14125778 3.14127895
 3.14187527 3.14215996 3.14229341 3.1425277  3.1429534  3.14296798
 3.14300013 3.14325846 3.14326176 3.1432636  3.14360071 3.14396991
 3.14416968 3.14434009 3.14566803 3.14569235 3.14612184 3.14644368
 3.14697412 3.14722091 3.14737055 3.14741731 3.14763461 3.14797208
 3.14822823 3.14823427 3.14849514 3.1487263  3.14874133 3.1496426
 3.15008679 3.15025178 3.15112572 3.15116584 3.15118502 3.15188669
 3.15199225 3.15208091 3.1521994  3.15262332 3.15264034 3.15304384
 3.15335118 3.15350861 3.1536125  3.15380592 3.15400085 3.15436206
 3.15444383 3.15445992 3.15471989 3.15501517 3.15504261 3.15506335
 3.15626599 3.15751786 3.15786092 3.15820145 3.15828916 3.15904865
 3.1590596  3.15913439 3.15933721 3.15946181 3.1598922  3.16037186
 3.16040916 3.16042264 3.16043686 3.16046361 3.16065428 3.16098537
 3.16111863 3.16201823 3.16210372 3.16244712 3.16290024 3.16306616
 3.16333795 3.16379146 3.16391626 3.16396859 3.16398082 3.16410912
 3.16430583 3.16435032 3.1644708  3.1645329  3.164887   3.16495121
 3.16577129 3.16597513 3.16611401 3.16641059 3.16649472 3.16658448
 3.16697643 3.16716303 3.16721824 3.16747832 3.16751448 3.16754732
 3.16786677 3.16789879 3.16817065 3.16831807 3.16832188 3.16832976
 3.16838892 3.16854276 3.16941991 3.1695836  3.16990265 3.17067919
 3.17072436 3.17077276 3.17096936 3.17111188 3.17120994 3.17191613
 3.17201845 3.17208181 3.17272833 3.17274301 3.17283244 3.17287388
 3.17298633 3.17302065 3.17314173 3.17318755 3.17343233 3.17347215
 3.17402772 3.17449934 3.17454128 3.17460047 3.17473523 3.17497482
 3.1753952  3.17549304 3.17586714 3.17596346 3.17598775 3.17671695
 3.1771331  3.17748573 3.17772069 3.17774311 3.17779691 3.17823694
 3.17864134 3.17864246 3.17885832 3.17890601 3.17903455 3.17928137
 3.17945922 3.17978062 3.17984897 3.18002839 3.18016138 3.18036623
 3.1804462  3.18088959 3.18124325 3.18158217 3.18162129 3.18184436
 3.18191157 3.18199895 3.18206809 3.18230367 3.18231051 3.18242949
 3.18274257 3.18285137 3.18310208 3.18324535 3.18331643 3.18345932
 3.18347633 3.18354964 3.18393929 3.18404141 3.18449137 3.18450397
 3.18481019 3.18487428 3.18493727 3.18502494 3.18509704 3.18615033
 3.18627219 3.18644604 3.18653626 3.18657887 3.18660859 3.18664195
 3.18724327 3.18751422 3.187535   3.18772033 3.18784508 3.18784787
 3.18798437 3.18805617 3.18843486 3.18884435 3.188872   3.1892996
 3.18962325 3.189637   3.18967969 3.18973372 3.19027339 3.19066488
 3.19073774 3.19087721 3.19090044 3.19090549 3.19128066 3.19150382
 3.19182304 3.19189617 3.19194671 3.19197364 3.19213782 3.19237625
 3.19318942 3.19326436 3.19343285 3.19364917 3.19379504 3.19383191
 3.19435039 3.19450659 3.19494316 3.19522966 3.19542139 3.19566704
 3.19583771 3.19596784 3.19605823 3.1961831  3.19626091 3.19651091
 3.19690584 3.19801899 3.1982839  3.19835691 3.19847531 3.19857493
 3.19859915 3.19907389 3.1991398  3.1993324  3.19935236 3.19950631
 3.19958847 3.20027252 3.20034803 3.20078941 3.20082342 3.20086326
 3.20096542 3.20107259 3.2014665  3.20151774 3.20158207 3.20197174
 3.20211032 3.20218641 3.20276587 3.20294429 3.20325472 3.20356331
 3.20375054 3.20376746 3.20430914 3.20436031 3.20453017 3.20454206
 3.20455622 3.20457385 3.20470783 3.2047403  3.20512741 3.20554424
 3.20578767 3.20587744 3.20591003 3.20621619 3.20627675 3.20637511
 3.20770377 3.20770498 3.20780546 3.20848028 3.20881791 3.20888976
 3.20889698 3.20901695 3.20926754 3.20927127 3.20992305 3.20996048
 3.21001513 3.2100208  3.21013339 3.21047589 3.21054957 3.21060109
 3.21060848 3.21095753 3.21115879 3.2116361  3.2121639  3.21219685
 3.21220341 3.21241098 3.21276273 3.21296037 3.21311227 3.21316822
 3.21330046 3.21334907 3.21385745 3.21392935 3.21411453 3.21440538
 3.21478031 3.21478255 3.21486502 3.21517926 3.21558541 3.21656667
 3.21669984 3.21681413 3.21692819 3.21698019 3.21709944 3.21711533
 3.21738468 3.21820011 3.21887324 3.21935012 3.2194211  3.21957534
 3.22000334 3.22017645 3.22144984 3.22171892 3.22211747 3.2223377
 3.22286508 3.2229567  3.22299988 3.22313482 3.22375588 3.22378848
 3.22435141 3.22446454 3.22458968 3.22495681 3.22525555 3.22561857
 3.2258621  3.22626442 3.22702276 3.22705849 3.22716952 3.22753715
 3.22774149 3.22841311 3.22861481 3.22937845 3.22975082 3.22983574
 3.23004568 3.23009932 3.23097632 3.23147438 3.23173303 3.23229636
 3.23256912 3.2329129  3.23293215 3.23319772 3.23337148 3.23471405
 3.23557709 3.23635666 3.23654424 3.23747595 3.2377748  3.23871503
 3.23986723 3.24018242 3.24082556 3.24088801 3.24301802 3.24315408
 3.24516331 3.24624334 3.24651625 3.24748076 3.24922464 3.24987696
 3.25049636 3.25084171 3.25260614 3.2531028  3.25593806 3.25871119
 3.25990874 3.26036966 3.2624174  3.26254033 3.26304993 3.26322988
 3.26464187 3.26523767 3.26744707 3.26826713 3.26841113 3.27011917
 3.27069844 3.27150895 3.27281608 3.27318941 3.27428836 3.27473391
 3.27639927 3.27734084 3.27786899 3.27921942 3.27961137 3.28092762
 3.28225049 3.28266183 3.28316311 3.28350297 3.28363919 3.28831835
 3.29052741 3.29300396 3.29497469 3.29511942 3.29566154 3.30034542
 3.30125935 3.30149546 3.30335442 3.30382226 3.30470945 3.3071792
 3.30756085 3.30801861 3.30835172 3.31132354 3.31494466 3.31506109
 3.3160665  3.31794833 3.32011652 3.32099904 3.32215866 3.32231539
 3.32267865 3.32276857 3.32415294 3.3256441  3.32710027 3.32767223
 3.32797129 3.33083477 3.33142389 3.33362007 3.33482874 3.33672692
 3.34176407 3.34289871 3.34726554 3.34736517 3.34801771 3.34915738
 3.34978455 3.35117054 3.35207649 3.35228774 3.35353101 3.35354639
 3.35406    3.35559649 3.35565123 3.35602812 3.35604553 3.3571164
 3.36030778 3.36035691 3.363746   3.36413412 3.36473728 3.36668728
 3.36838124 3.36838722 3.36952265 3.37063979 3.37224411 3.37291765
 3.37421896 3.37495371 3.37513979 3.37646435 3.37729196 3.38029355
 3.38151862 3.38165986 3.38212762 3.38314008 3.38322054 3.38329053
 3.38333542 3.38479644 3.38616037 3.38687772 3.38822222 3.38852712
 3.3885823  3.38897129 3.38929825 3.39080239 3.39361789 3.39615315
 3.39643944 3.3977781  3.39810369 3.39832761 3.39833854 3.39901954
 3.39962434 3.40069172 3.40296806 3.40328875 3.40344976 3.40424099
 3.40803527 3.40972356 3.4112319  3.41207946 3.41216512 3.41293994
 3.41685855 3.4216027  3.43171379 3.43388883 3.43661086 3.44307955
 3.45216056 3.45411187 3.4550073  3.45763326 3.46046271 3.52054108
 3.54499592 3.55468821 3.56919088 3.61969894 3.65448714 3.65615344
 3.66713934 3.6775458  3.68369492 3.68522782 3.69565485 3.71343191
 3.72773541 3.746622   3.79595109 3.79871548 3.8094265  3.8128339
 3.81514802 3.82151827 3.8228332  3.82602491 3.83204136 3.8357023
 3.84174951 3.84264155 3.84745922 3.85404834 3.86345275 3.87385171
 3.90406094 3.94720707 4.0900788  4.09612628 4.105773   4.13217636
 4.30927754 4.48857942 4.67123311 4.69968258 4.72184531 4.72514601
 4.75166784 4.75359222 4.75681025 4.76213673 4.7630316  4.7662041
 4.76631305 4.77106493 4.77345468 4.7806165  4.782495   4.78284472
 4.78512028 4.78716585 4.78975535 4.79538583 4.79821799 4.80067709
 4.8059223  4.80975386 4.81054192 4.81134376 4.81641388 4.8190344
 4.8212775  4.82771615 4.8309743  4.83903545 4.85815467 4.90899757
 4.90960161 4.91903117 4.92017044 5.01887496 5.12308096]

  warnings.warn(

2022-12-16 10:37:01,410:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.70060262 1.99214942 1.99794328 2.04933133 2.16740638 2.19606315
 2.73607067 2.82187796 2.84505187 2.85896924 2.88543852 2.90483659
 2.91615533 2.94117151 2.9424389  2.94541101 2.94697509 2.94728071
 2.94763775 2.95108722 2.95111023 2.9537791  2.9585677  2.96478999
 2.96621285 2.96739971 2.96955644 2.97099528 2.97196466 2.97290411
 2.97345043 2.9739405  2.97590395 2.97642778 2.97707238 2.97717362
 2.98078326 2.98146947 2.98349068 2.9848304  2.98526203 2.98783478
 2.98875849 2.98911749 2.99122531 2.99162929 2.9925839  2.99275506
 2.99521551 2.99548689 2.99647727 2.99703573 2.99824839 2.99991848
 3.00092453 3.00232291 3.00536165 3.00662794 3.00762697 3.00776565
 3.00790866 3.00848934 3.00954262 3.01048339 3.01336436 3.01827096
 3.01944325 3.02038423 3.02330341 3.0240764  3.02472266 3.02493006
 3.02553202 3.02637807 3.02644896 3.02704699 3.02758274 3.02841919
 3.02886933 3.02922023 3.03045616 3.03123692 3.03174687 3.0324147
 3.03320576 3.03483255 3.03548383 3.03843338 3.04168241 3.04544801
 3.04735763 3.04789043 3.04830636 3.05026141 3.05270337 3.05469005
 3.06183572 3.0622214  3.06264987 3.06505983 3.06664815 3.06730967
 3.06777191 3.06815115 3.0711041  3.07414332 3.07479506 3.07542623
 3.07656593 3.07672862 3.07711713 3.07954233 3.08035019 3.08082872
 3.08187224 3.08234895 3.08342423 3.08441297 3.08449501 3.0872832
 3.08750174 3.08822246 3.09052188 3.09360968 3.09378416 3.09392501
 3.09538117 3.09597315 3.09597714 3.09999204 3.1003395  3.10047535
 3.10052559 3.10164179 3.10192816 3.10393487 3.10398517 3.10473896
 3.10539595 3.10594739 3.10894278 3.10898315 3.10973832 3.1101166
 3.11014355 3.1108701  3.11172453 3.11240025 3.11247137 3.11264778
 3.11279098 3.11279643 3.11351098 3.11361089 3.11482058 3.11492807
 3.11537905 3.1156191  3.11637571 3.11678204 3.11753169 3.11842024
 3.11863484 3.11925092 3.12084577 3.12104621 3.12139341 3.12397211
 3.12500149 3.12558971 3.12696337 3.12740204 3.12740241 3.12741523
 3.12752262 3.12755657 3.12798953 3.12844246 3.12923765 3.12932417
 3.12944712 3.12953262 3.1296717  3.12985837 3.13015887 3.13094061
 3.13121301 3.13143967 3.13179236 3.13191611 3.13192294 3.13194905
 3.13218008 3.13388924 3.13411928 3.13441999 3.13460786 3.13505023
 3.13519966 3.13572513 3.13578533 3.13615774 3.13622111 3.13631078
 3.13657707 3.13689063 3.13689357 3.13703963 3.13723226 3.13771112
 3.13774291 3.13853416 3.13861282 3.13954973 3.13955061 3.13965517
 3.14023091 3.14055665 3.14055703 3.14186739 3.14195265 3.14204955
 3.14229711 3.14264101 3.14296709 3.14326795 3.14327538 3.14402851
 3.14625165 3.1466277  3.14718368 3.14720656 3.14743604 3.14749779
 3.14752511 3.14753517 3.14762011 3.14768503 3.14780936 3.14824346
 3.14850698 3.14872667 3.14901894 3.14910383 3.15028516 3.15099205
 3.15151532 3.15250794 3.15258882 3.15308436 3.15337573 3.15357948
 3.15396015 3.15429197 3.15447482 3.15452543 3.15497583 3.15539039
 3.15548769 3.15563312 3.15574508 3.15580253 3.1560492  3.15607175
 3.1562015  3.15684823 3.15703094 3.15707302 3.15720947 3.15731427
 3.15761791 3.15856511 3.15862481 3.15911024 3.15922719 3.15930318
 3.15935175 3.1601994  3.1603923  3.16074469 3.16074943 3.1613749
 3.16167481 3.16172664 3.16211968 3.16268812 3.16289184 3.16335668
 3.16448649 3.16463764 3.16528377 3.16581205 3.1660776  3.1666086
 3.16731289 3.16780026 3.16780091 3.16806088 3.16818619 3.16818998
 3.1683064  3.16832987 3.16838703 3.16910627 3.16913079 3.16978233
 3.16995605 3.17041971 3.17059658 3.17063124 3.17146459 3.17163523
 3.17177869 3.17179958 3.17190153 3.17211383 3.17212614 3.17252286
 3.17255731 3.17259893 3.1727332  3.17285341 3.17290638 3.17327858
 3.17348104 3.17388274 3.17395483 3.17404103 3.17409209 3.17440043
 3.17490306 3.17503276 3.17523669 3.17561723 3.1757595  3.17578511
 3.17601667 3.17623724 3.17630671 3.17650777 3.17656546 3.17663095
 3.17664547 3.17671425 3.17690893 3.17766288 3.17881817 3.1789138
 3.17898667 3.17905789 3.17931046 3.17932153 3.17950954 3.17974764
 3.17987561 3.1803721  3.18062613 3.18066077 3.18066419 3.18099466
 3.18135755 3.18146749 3.18196441 3.18207398 3.1825406  3.18282781
 3.18294273 3.18329997 3.18391164 3.18404024 3.18408952 3.18411886
 3.18435508 3.18440518 3.18451724 3.18461751 3.1846768  3.18473646
 3.18474982 3.18525581 3.18546439 3.18586203 3.18605114 3.18617192
 3.18633797 3.18684948 3.18737618 3.18743309 3.18760465 3.18765741
 3.18769619 3.18782881 3.1881434  3.18826361 3.18842583 3.18899291
 3.18946614 3.18947812 3.18978696 3.19011374 3.19023571 3.19031882
 3.19054576 3.1908662  3.19126296 3.19143306 3.19147205 3.1914793
 3.19165053 3.19179293 3.19181916 3.19236024 3.19246223 3.19255589
 3.19267455 3.19279153 3.19289345 3.19307352 3.19317324 3.19324168
 3.19356964 3.19360426 3.19368871 3.19385811 3.19424425 3.19425516
 3.19432955 3.19438389 3.19449027 3.19475265 3.19493272 3.1952547
 3.19529623 3.1957967  3.19594908 3.19630566 3.1963617  3.1963897
 3.19639859 3.19651837 3.19658671 3.19664726 3.19666059 3.19686187
 3.19730785 3.19732073 3.19794363 3.1982346  3.19898621 3.19907631
 3.19908021 3.19920838 3.19941747 3.19954896 3.19977699 3.19988629
 3.19997758 3.20024438 3.20039506 3.20055238 3.20056742 3.20068763
 3.20123347 3.20195427 3.20212585 3.20215934 3.20235908 3.20252473
 3.20260213 3.20345276 3.20379928 3.20389119 3.20414046 3.20424412
 3.20471726 3.20478669 3.20505559 3.20522224 3.20537305 3.20549326
 3.20557893 3.20636392 3.20646478 3.20671345 3.20673262 3.20673458
 3.20679106 3.20685069 3.20705289 3.20733927 3.2076783  3.20838556
 3.20842964 3.20850284 3.20888646 3.20899991 3.20920471 3.20954955
 3.20956843 3.20962902 3.20978554 3.2098562  3.21029842 3.21054388
 3.21094392 3.21094495 3.21099394 3.21100055 3.21111442 3.21134663
 3.21135452 3.21172097 3.21183857 3.21190688 3.21265575 3.21305162
 3.21313702 3.21342067 3.21379691 3.2140504  3.21419095 3.21453976
 3.21547994 3.2162123  3.2164351  3.21661504 3.21721995 3.21741576
 3.21747402 3.2175328  3.21763795 3.21819163 3.21826496 3.21833914
 3.21833951 3.218745   3.21932814 3.2195582  3.21987696 3.22087188
 3.22159753 3.22177841 3.22196314 3.22257931 3.22279892 3.22351083
 3.22419126 3.22483043 3.22513544 3.22550218 3.22579204 3.22638547
 3.22704524 3.22708371 3.22834087 3.22886879 3.22888916 3.22973461
 3.22981475 3.22981706 3.2302025  3.23093071 3.23096652 3.23101252
 3.23110225 3.23156422 3.23163724 3.23194006 3.23211941 3.23271317
 3.23281779 3.23294406 3.23329356 3.23362713 3.23384469 3.23435759
 3.23484565 3.23526609 3.23568068 3.23639981 3.23647482 3.23665953
 3.23667328 3.23787106 3.23844314 3.23845816 3.23962585 3.23984008
 3.2398442  3.24032843 3.24047563 3.24050683 3.24090728 3.24220249
 3.24225681 3.242333   3.24237908 3.24278246 3.24356659 3.24408132
 3.24466222 3.24473916 3.24687157 3.24695668 3.24788622 3.24862935
 3.24865869 3.24989606 3.25078126 3.25130802 3.25171246 3.25178591
 3.25216786 3.25220507 3.25230377 3.25255044 3.25376626 3.25392577
 3.25401249 3.25414048 3.25435867 3.25634523 3.25703475 3.25824723
 3.25912395 3.25914124 3.25923368 3.2608988  3.26141057 3.26370433
 3.26446455 3.26459011 3.26562158 3.26680001 3.26683725 3.26840016
 3.26965372 3.26991776 3.27003482 3.27142205 3.27233588 3.27297105
 3.27364827 3.27416934 3.27460714 3.274997   3.27734449 3.27756093
 3.28187641 3.28198065 3.28335135 3.28492819 3.28507915 3.28582537
 3.28707006 3.28735992 3.28739223 3.29072847 3.29098405 3.29110136
 3.29142339 3.29232434 3.29287965 3.29288479 3.29295479 3.29370301
 3.29477068 3.29531147 3.2958944  3.29642481 3.29695432 3.29728097
 3.2973152  3.29784105 3.29872893 3.29955799 3.30154865 3.30189083
 3.30194982 3.30468188 3.30506863 3.30756095 3.30871954 3.30873048
 3.30945639 3.30993635 3.31272033 3.31408249 3.3156827  3.31723358
 3.31808725 3.32139638 3.32165435 3.321702   3.32177186 3.32327191
 3.32359874 3.32499354 3.32599412 3.32679742 3.32745211 3.32965807
 3.33228528 3.33267992 3.33504185 3.33571434 3.34356417 3.34409629
 3.34493487 3.34615858 3.34620583 3.34919642 3.34968275 3.35040575
 3.35189455 3.35225318 3.35679479 3.3583742  3.35896715 3.36286717
 3.36298024 3.36372922 3.36411035 3.36418306 3.36519464 3.36637991
 3.36650196 3.36774741 3.36797321 3.36939467 3.37121648 3.37818452
 3.37830047 3.37832178 3.38165549 3.3817721  3.38251543 3.38267919
 3.38368701 3.38527488 3.38579438 3.38610439 3.38768908 3.3879713
 3.38844406 3.38890734 3.3923838  3.39700697 3.39943845 3.40097438
 3.40140941 3.40234492 3.40262653 3.40494822 3.40768236 3.40805482
 3.40942708 3.41039175 3.41073042 3.41197996 3.41329444 3.4145235
 3.41514082 3.42036388 3.42276573 3.42279271 3.42486828 3.42661971
 3.42976864 3.43017296 3.43281442 3.44015614 3.44554573 3.44758358
 3.45279764 3.45500153 3.45842378 3.46287492 3.46656393 3.46887733
 3.47142034 3.47161332 3.47173962 3.47242072 3.48995593 3.49309721
 3.49758515 3.4992043  3.50177759 3.51352256 3.52092681 3.52201602
 3.54506314 3.54789911 3.60157168 3.62760479 3.64631658 3.65667811
 3.67261874 3.68349547 3.73211037 3.74256373 3.77713714 3.81180217
 3.82369518 3.82778264 3.8324748  3.83457282 3.84831371 3.85430991
 3.86257073 3.86648778 3.87731051 3.8787747  3.93629878 4.00163495
 4.04678401 4.10420656 4.10997672 4.11531107 4.12498023 4.16170355
 4.17360061 4.33318186 4.35249888 4.41576196 4.62781814 4.69471009
 4.70855144 4.73910493 4.75645866 4.76640695 4.77458434 4.77785155
 4.77997661 4.78212047 4.78492643 4.78525681 4.78554275 4.79174249
 4.7951825  4.79939032 4.79948818 4.80198101 4.81040454 4.82077266
 4.82638753 4.83362792 4.84099219 4.84118538 4.85463197 4.85679208
 4.86192237 4.86944206 4.87380882 4.87709416 4.88246949 4.938501  ]

  warnings.warn(

2022-12-16 10:37:01,481:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.69554868 1.70016723 1.7078496  1.91382892 1.95625996 1.97610903
 1.97853834 1.98243821 1.99135543 2.005331   2.02165768 2.20510007
 2.56828976 2.78252209 2.86346406 2.90072804 2.9048025  2.9147401
 2.92770079 2.94046497 2.94171419 2.94180193 2.94333382 2.94896163
 2.95532411 2.95643648 2.95739878 2.95910272 2.96006316 2.96197618
 2.96437536 2.96598277 2.96606786 2.96710729 2.96853452 2.97182417
 2.97251686 2.97283864 2.97474797 2.97519685 2.97633094 2.97765105
 2.9787463  2.98043642 2.98489974 2.98528975 2.98619627 2.98676605
 2.98730342 2.98884964 2.99008638 2.99034404 2.99149919 2.99182263
 2.9933293  2.99399377 2.99469472 2.99615058 2.99668499 2.99735599
 2.99787848 2.99881757 2.99909149 2.99925283 3.0000144  3.0001518
 3.0005897  3.00088076 3.00140817 3.0017161  3.00224199 3.00259793
 3.00377987 3.00398301 3.00469811 3.00497335 3.00497842 3.00611054
 3.00627871 3.00794867 3.00859827 3.00869297 3.01140206 3.01267962
 3.01272034 3.01380791 3.01385383 3.01469352 3.01475968 3.01564918
 3.01574764 3.01732064 3.01779044 3.01803235 3.01858327 3.01873499
 3.02063968 3.02134972 3.02144505 3.02287425 3.02788666 3.02893728
 3.02944782 3.02993669 3.03032064 3.03098617 3.03116001 3.03117335
 3.03282088 3.03285744 3.03315675 3.03338265 3.03344195 3.03511603
 3.03551555 3.03721956 3.03759717 3.03807772 3.03974736 3.04255774
 3.04393156 3.0446834  3.0464588  3.04690035 3.0469754  3.04793124
 3.04866055 3.05134416 3.05151842 3.05602256 3.0597744  3.06127723
 3.06351162 3.06578931 3.06762962 3.06993464 3.07087295 3.07239964
 3.07254208 3.07979672 3.08069674 3.08302237 3.08706977 3.08713525
 3.08837091 3.08854919 3.08931152 3.09163555 3.09386925 3.09496446
 3.09535585 3.09778336 3.09883992 3.09938249 3.09942708 3.10064856
 3.10073134 3.10138578 3.10277345 3.10407609 3.10501478 3.10556091
 3.10569182 3.10718122 3.10730643 3.10918018 3.10927488 3.11281153
 3.11340095 3.11371886 3.11442146 3.11498332 3.11574759 3.11587927
 3.11649675 3.11832506 3.11846366 3.11848657 3.11851581 3.11903112
 3.1196555  3.11982834 3.11994229 3.11995021 3.12016534 3.12086217
 3.12107698 3.12149644 3.12181299 3.12228434 3.12439907 3.1263721
 3.12659165 3.12726316 3.12748813 3.12793915 3.12882782 3.1304857
 3.1305466  3.13128918 3.13177264 3.13186192 3.13186262 3.13220429
 3.13271162 3.13293128 3.13316547 3.13366345 3.13519509 3.13519821
 3.13558979 3.13696512 3.13719238 3.13724027 3.13758245 3.13801012
 3.13846802 3.13944215 3.13987778 3.14111534 3.14128948 3.14197302
 3.14307649 3.14314751 3.14347878 3.1437969  3.14409574 3.14459733
 3.1449533  3.14524126 3.14527632 3.14557364 3.1457661  3.14579068
 3.14673576 3.14693375 3.14701055 3.1474245  3.14797579 3.14831435
 3.14832692 3.14848568 3.14852649 3.1493529  3.14936399 3.14980449
 3.14995495 3.15021785 3.15028309 3.1504154  3.15044602 3.15054125
 3.15055373 3.15112475 3.15151236 3.1525369  3.15258972 3.15280988
 3.15379462 3.15410042 3.15444631 3.15447886 3.15457072 3.15464431
 3.15467406 3.15474869 3.15505978 3.15510119 3.15545003 3.1557541
 3.15705812 3.15718947 3.15732388 3.15765361 3.15769249 3.15811781
 3.15816186 3.15840479 3.15849655 3.15853647 3.15898876 3.15965067
 3.15975537 3.16061346 3.16061423 3.16088311 3.16091635 3.16122833
 3.16125777 3.16126182 3.16129947 3.16206267 3.16228103 3.16275898
 3.16286908 3.16347871 3.16360852 3.1636346  3.16406215 3.16447475
 3.164634   3.16484564 3.16499314 3.16528887 3.16554874 3.16555061
 3.16555459 3.1656308  3.1657367  3.1658543  3.16601578 3.16624596
 3.16625844 3.16632905 3.1666903  3.16675953 3.16685841 3.16745985
 3.16790768 3.16799758 3.16811157 3.16815471 3.16831245 3.16835091
 3.16859153 3.16860907 3.16867845 3.16873775 3.16900607 3.16908784
 3.16909108 3.16935181 3.16962076 3.1706544  3.17120467 3.17124286
 3.17129741 3.17142088 3.17146966 3.17201509 3.17212085 3.17239059
 3.1727801  3.17297757 3.17359025 3.17398452 3.17427254 3.17434839
 3.17455507 3.17464359 3.17465011 3.17500771 3.17515624 3.1752936
 3.17538806 3.17638942 3.17646118 3.17655991 3.17660537 3.176815
 3.17689982 3.17743693 3.17754971 3.1775914  3.17781871 3.17798714
 3.17809779 3.17818553 3.17829107 3.17829705 3.1783876  3.17850255
 3.17885923 3.17887678 3.17911979 3.17944953 3.17962195 3.1797326
 3.18044812 3.18076159 3.18078353 3.18096312 3.18112008 3.18113256
 3.18117308 3.18119202 3.18147333 3.18172574 3.18195766 3.18204181
 3.18204377 3.18220575 3.18226937 3.18228009 3.1826888  3.18303282
 3.18321588 3.18338051 3.18364194 3.1841239  3.18433449 3.18434517
 3.1843734  3.18521571 3.1854631  3.18587243 3.1859025  3.18599701
 3.1864507  3.18668499 3.18672348 3.18683564 3.18690201 3.18691344
 3.18714505 3.18731248 3.18738188 3.18765418 3.18772936 3.18816374
 3.1882021  3.18900373 3.1891975  3.18972251 3.18990149 3.18990631
 3.18992973 3.19034176 3.19076504 3.19078527 3.19091467 3.19096783
 3.19155465 3.19162131 3.19164196 3.19173181 3.19180286 3.19187187
 3.19205018 3.19212769 3.19213609 3.19231485 3.19250939 3.19274356
 3.19275562 3.19308872 3.19341683 3.1937275  3.19373667 3.19376554
 3.19408724 3.19419484 3.19439067 3.19463424 3.19467586 3.19516013
 3.19535066 3.19590671 3.19648104 3.1964919  3.19659723 3.19698418
 3.19698766 3.19721644 3.19781027 3.19781347 3.19789678 3.19792999
 3.19838279 3.19839688 3.19848997 3.19868983 3.19877924 3.19882038
 3.19887419 3.19919275 3.1992175  3.2001999  3.20116867 3.20155356
 3.20184321 3.20186973 3.20192036 3.20199236 3.20206725 3.20232391
 3.20233564 3.2023562  3.20246387 3.2026405  3.20331543 3.20334974
 3.20348856 3.20377866 3.20391403 3.20417756 3.20517255 3.20532896
 3.20538637 3.20579642 3.20583005 3.20583617 3.20600907 3.20647463
 3.20656501 3.20662279 3.20698978 3.20763218 3.20773582 3.20785789
 3.20809029 3.20825971 3.20911549 3.20933632 3.20977908 3.21003776
 3.21009478 3.21009718 3.21016459 3.210305   3.21039138 3.21047707
 3.21070713 3.21076677 3.2111098  3.21126649 3.21146425 3.21161063
 3.21187011 3.21201364 3.2120722  3.21226869 3.21280397 3.21292882
 3.21303292 3.2146229  3.21530305 3.21547839 3.2155443  3.2156212
 3.21565483 3.21568784 3.21571158 3.2165459  3.21743812 3.21757543
 3.21849977 3.21890682 3.21922388 3.21927824 3.21934217 3.21971726
 3.22045678 3.22051997 3.22053615 3.22123964 3.22150642 3.22195272
 3.22215798 3.22219262 3.22231235 3.22238747 3.22255821 3.22275473
 3.22295415 3.22303421 3.22337523 3.22362205 3.22414084 3.2243848
 3.2246457  3.224654   3.22475907 3.22566834 3.22589938 3.22618091
 3.22675172 3.22676357 3.22734754 3.22759786 3.22843518 3.22883625
 3.22958673 3.22971586 3.22989537 3.22995624 3.23006999 3.23044026
 3.23073139 3.23171036 3.23209135 3.23224219 3.23254486 3.23366685
 3.23411231 3.23452202 3.23472494 3.23579272 3.23606744 3.23639293
 3.23661464 3.23799909 3.2381471  3.238245   3.23890226 3.23909015
 3.23943448 3.23972187 3.24008623 3.24048621 3.24048622 3.24174956
 3.24242498 3.24303187 3.24381596 3.2443246  3.24522802 3.24570294
 3.24660629 3.24723075 3.24757978 3.24761782 3.24785712 3.24820557
 3.24864551 3.2493623  3.24959381 3.24974193 3.25012458 3.25033347
 3.25215034 3.25242794 3.25331182 3.25375114 3.25486926 3.25537766
 3.25587088 3.25600465 3.2569424  3.25839155 3.25840227 3.25849871
 3.25851257 3.25866526 3.25903803 3.25908842 3.25996418 3.26066742
 3.26078228 3.26312278 3.26343499 3.26375584 3.26382359 3.26541693
 3.26568778 3.26780972 3.26788543 3.2685235  3.26859666 3.26876664
 3.26936868 3.26938041 3.27130106 3.27156647 3.27640507 3.27787279
 3.2781054  3.27892934 3.27929713 3.27964961 3.28208232 3.28355049
 3.28382622 3.28383011 3.2849186  3.28584714 3.2873406  3.28764831
 3.28802858 3.28865538 3.29058028 3.29110312 3.29212439 3.29386758
 3.29588152 3.29740452 3.29797894 3.30002487 3.30046185 3.30288254
 3.3029578  3.30299978 3.30366334 3.3057937  3.30588109 3.30613181
 3.3080735  3.30917265 3.30917285 3.3101603  3.31095825 3.31323494
 3.31437365 3.31498423 3.31688133 3.31723738 3.31744318 3.31909813
 3.32158556 3.32307024 3.32339534 3.32417619 3.32486051 3.32707622
 3.32895218 3.33113825 3.33360598 3.33691552 3.33715294 3.33807651
 3.33814843 3.33831829 3.33953404 3.34167955 3.3435168  3.34455597
 3.34582941 3.34604742 3.34667288 3.3484356  3.35037016 3.35456242
 3.35574336 3.35713797 3.35726386 3.35930021 3.35995247 3.36196656
 3.3621847  3.36240403 3.36246585 3.36363687 3.36435586 3.36445009
 3.36464218 3.36605499 3.36842387 3.37330437 3.37351256 3.3748795
 3.37583105 3.37646352 3.37730372 3.37758573 3.37782436 3.37850632
 3.3788119  3.37883123 3.37958458 3.37974789 3.38065446 3.38068629
 3.38106077 3.38158275 3.38162075 3.38207967 3.38367026 3.38461862
 3.38906041 3.38956248 3.39001435 3.39058182 3.39120677 3.39171349
 3.39188717 3.39300418 3.39324832 3.3935757  3.39362534 3.39563135
 3.3956489  3.40063134 3.40184366 3.4032743  3.40424558 3.40532712
 3.4057675  3.40599686 3.40731365 3.4129386  3.41433    3.41606371
 3.41731449 3.41810611 3.43494375 3.43764823 3.43937359 3.44840444
 3.44977433 3.45332995 3.46400661 3.46619169 3.46887616 3.47104646
 3.49592075 3.53361241 3.55069029 3.57808948 3.65276035 3.66754087
 3.75186106 3.79826716 3.80681565 3.80682146 3.80834287 3.81336947
 3.83417671 3.84799004 3.88358685 3.9403446  3.98152931 4.12092223
 4.1271373  4.14065091 4.50161678 4.53732247 4.75941827 4.77366203
 4.78830069 4.80044247 4.80464877 4.80677034 4.80830785 4.80916331
 4.81077326 4.81247153 4.81418309 4.81787663 4.81828627 4.81879552
 4.8207391  4.82103124 4.82294313 4.82822724 4.82844529 4.83905285
 4.84271061 4.8448199  4.86828185 4.87754468 4.88277862 4.91050332
 4.9275422  4.9368458  4.94055622 4.94241258 5.05206816]

  warnings.warn(

2022-12-16 10:37:01,518:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.87932224 2.08771814 2.09534641 2.11179821 2.12332552 2.16177996
 2.16785655 2.18370794 2.18729637 2.2427499  2.34953431 2.80105311
 2.8030466  2.80931148 2.81983767 2.82270276 2.83269044 2.83937887
 2.86856379 2.92106945 2.92787964 2.93835519 2.95877759 2.96161442
 2.97377112 2.97497211 2.97535425 2.9772327  2.97857424 2.97933817
 2.97953885 2.98173941 2.98467481 2.9852759  2.9857309  2.98784028
 2.98874671 2.98917574 2.98942915 2.99134079 2.99167232 2.9931453
 2.99362448 2.99733298 2.99823891 2.99878483 2.99981221 2.99994607
 3.00220952 3.00322785 3.00425462 3.00465638 3.00700535 3.00744757
 3.00830112 3.00900953 3.01222669 3.01389862 3.01462602 3.01490794
 3.01506455 3.0151823  3.01686938 3.01696544 3.01844357 3.01899431
 3.01915221 3.02059766 3.02121943 3.02124953 3.02179581 3.02390028
 3.02427058 3.02506484 3.0251023  3.0262851  3.02784699 3.02871713
 3.02945954 3.02965503 3.02967281 3.03002431 3.03035443 3.03405754
 3.03420172 3.03439132 3.03456182 3.03474701 3.03549712 3.03674153
 3.03877304 3.03963226 3.04035181 3.04119123 3.04287932 3.043798
 3.04410814 3.0452689  3.05062031 3.05289067 3.0568263  3.05783464
 3.06107495 3.06650388 3.06763292 3.06910715 3.07183902 3.0725463
 3.07680592 3.08001396 3.08150634 3.08230155 3.08247988 3.08330287
 3.08523008 3.08642394 3.08744838 3.08890069 3.08946384 3.09264752
 3.09919183 3.09936701 3.10201067 3.10322868 3.10598981 3.10784291
 3.10906783 3.11079694 3.1118616  3.11194897 3.11321254 3.11349429
 3.11365895 3.11369028 3.11404146 3.11451906 3.11494846 3.11526614
 3.11564039 3.11607947 3.11785189 3.11800874 3.11821141 3.11924385
 3.11975324 3.12047207 3.12140809 3.12171501 3.12254706 3.1227191
 3.12303018 3.12324273 3.1237569  3.12470568 3.12515292 3.12526121
 3.12543355 3.12644791 3.1269469  3.12741804 3.12771691 3.12820902
 3.12832477 3.12881437 3.12910924 3.12917079 3.12918639 3.13002631
 3.13023785 3.13061033 3.13085377 3.13131387 3.1315128  3.13172376
 3.13203697 3.13228449 3.13229838 3.13241102 3.13350015 3.13454186
 3.13580871 3.13592379 3.13778644 3.13784147 3.13807699 3.13832194
 3.13833278 3.13833738 3.13836192 3.13879477 3.13882275 3.1391284
 3.1392819  3.13997603 3.1404164  3.14043908 3.14069461 3.14136664
 3.14144358 3.14146116 3.14200825 3.14206211 3.14209296 3.14216231
 3.14251579 3.14281898 3.14349491 3.14352921 3.14354805 3.14410916
 3.14425167 3.14444944 3.14455808 3.14485906 3.1448902  3.14532457
 3.14544304 3.14550982 3.14577715 3.14599446 3.14603385 3.14630063
 3.14661732 3.14681982 3.14693362 3.14695215 3.14714653 3.14756641
 3.1475684  3.14760711 3.14762891 3.14764976 3.14780446 3.14843717
 3.14851755 3.14865393 3.14879149 3.14925826 3.14930073 3.14953061
 3.15009115 3.15048501 3.15098576 3.15108172 3.15128115 3.15147285
 3.15160894 3.1518538  3.15206105 3.15258084 3.15269935 3.15316913
 3.15331301 3.1536209  3.15366    3.15380343 3.15413948 3.15440789
 3.15505743 3.15585174 3.15592127 3.15661436 3.15664102 3.15683428
 3.15730543 3.15741209 3.15745629 3.15762758 3.15762848 3.15788264
 3.1579898  3.15812345 3.15817683 3.15874856 3.15887012 3.15896861
 3.15946704 3.15949    3.15955104 3.15960916 3.15973065 3.15979164
 3.15982362 3.15992882 3.15999084 3.16059424 3.16083058 3.16095776
 3.16126843 3.16132355 3.16165524 3.16168869 3.16185631 3.1622473
 3.16264234 3.16283072 3.16312596 3.16317748 3.16337003 3.16353647
 3.16362292 3.16365192 3.1637278  3.16384637 3.16464828 3.16477845
 3.16489823 3.16496271 3.16498813 3.16522292 3.16534695 3.16555775
 3.16557461 3.16604864 3.16611199 3.16640927 3.16709437 3.16714123
 3.16721568 3.16734081 3.16758611 3.1679097  3.16793235 3.16798934
 3.16831918 3.16884487 3.16895607 3.16895619 3.16921471 3.16944654
 3.16945339 3.16971082 3.16997203 3.17010395 3.17031764 3.17033667
 3.17041891 3.17056888 3.17079496 3.17085155 3.1712212  3.17163338
 3.17176513 3.1721062  3.17253099 3.17265311 3.17291371 3.17319941
 3.17324357 3.17397618 3.17402226 3.17425069 3.17447238 3.1745506
 3.17471452 3.17527884 3.17541276 3.17563874 3.17596118 3.17597916
 3.17645757 3.17647195 3.1768424  3.17687899 3.17708416 3.1771036
 3.17715207 3.17717403 3.17730375 3.17731647 3.17759377 3.17780884
 3.17833203 3.17850507 3.17852382 3.17863667 3.17906283 3.1793404
 3.18029332 3.1803501  3.18060948 3.18105655 3.18149627 3.18242415
 3.18244873 3.18250587 3.18269864 3.1827742  3.18300421 3.18324734
 3.1833096  3.18335845 3.18389476 3.18408419 3.18477694 3.18498888
 3.18527467 3.18546595 3.18584325 3.1863306  3.18636532 3.18696054
 3.18709714 3.18763069 3.1879578  3.18844933 3.18884525 3.18884934
 3.18937063 3.18960605 3.18991737 3.19058278 3.19161602 3.1916222
 3.19189244 3.1925217  3.19256281 3.19258741 3.19269471 3.19288272
 3.19339183 3.19345621 3.19416823 3.1944431  3.19475759 3.19538081
 3.19626362 3.19647893 3.1965022  3.1966012  3.19748848 3.19756551
 3.19796162 3.19808494 3.19822186 3.19880955 3.1989563  3.19903367
 3.19907919 3.19915395 3.201892   3.20202846 3.20226319 3.20251447
 3.20292007 3.20324101 3.20335435 3.20371917 3.20418992 3.20449363
 3.20512735 3.20527628 3.20530426 3.20555516 3.2056683  3.20570054
 3.20577633 3.20581907 3.20588327 3.20653935 3.20656869 3.20671041
 3.20808757 3.208207   3.20959156 3.21003413 3.21018686 3.21041154
 3.21048185 3.21057465 3.21096125 3.21136634 3.21140239 3.21141815
 3.21144442 3.21153358 3.21156811 3.21161958 3.21221328 3.2138009
 3.21383399 3.21406264 3.2145102  3.21468698 3.21475484 3.21479672
 3.21509886 3.21598137 3.21599899 3.21625657 3.21626975 3.21628064
 3.21676719 3.21773551 3.2178197  3.21797489 3.21836135 3.21838513
 3.2185214  3.21877614 3.21878069 3.21880122 3.21901263 3.21921225
 3.21953971 3.2195784  3.2197164  3.22044107 3.22059166 3.22065397
 3.22065564 3.22077215 3.22164177 3.22192986 3.22265377 3.22285395
 3.22313057 3.22429719 3.22470763 3.22519058 3.22615188 3.22622235
 3.22675794 3.22684586 3.22687947 3.22757264 3.22787122 3.22839928
 3.22892766 3.22959998 3.229644   3.22973364 3.22984214 3.23005246
 3.23142876 3.23153685 3.23232215 3.23257626 3.23269258 3.232729
 3.23301867 3.2335438  3.23368824 3.23414073 3.23414948 3.23461373
 3.23588017 3.23591384 3.23609319 3.23643708 3.23655997 3.23678189
 3.23713897 3.23735916 3.23785563 3.23790753 3.23799082 3.23813893
 3.23820774 3.23835127 3.23836881 3.23841299 3.23870551 3.23937858
 3.23985753 3.24039555 3.24133542 3.24147053 3.24226458 3.24230439
 3.24375124 3.24387851 3.24485203 3.24517492 3.24538807 3.24595845
 3.24597966 3.24624811 3.24631926 3.24899212 3.24909559 3.24938394
 3.25001304 3.2500999  3.25030328 3.25111804 3.2516066  3.25168872
 3.25171936 3.25210273 3.25219124 3.25226924 3.25260914 3.2530153
 3.2539872  3.2544461  3.25464235 3.25521689 3.25572578 3.25596567
 3.25601508 3.25677701 3.2573239  3.25732519 3.2582988  3.25913345
 3.25953915 3.25976184 3.2606065  3.26218013 3.26255827 3.26298194
 3.26411363 3.2642327  3.2648487  3.26516877 3.26529901 3.26633553
 3.26834389 3.26856904 3.26915998 3.26940591 3.26953902 3.26980022
 3.27019164 3.27036545 3.27190755 3.27216305 3.27306127 3.2731145
 3.27396929 3.2741567  3.27508081 3.27534145 3.2756776  3.27793828
 3.27922941 3.27948917 3.28052904 3.28067709 3.2812274  3.28130087
 3.28245216 3.28333474 3.28334828 3.28700922 3.28814878 3.28822197
 3.28988115 3.29006448 3.29010501 3.29021205 3.29258992 3.29313165
 3.29355666 3.29401746 3.2941097  3.29460639 3.29716297 3.29934258
 3.30149931 3.3023116  3.30322333 3.3071964  3.30870089 3.31072166
 3.31080294 3.31146747 3.31163813 3.31236027 3.31328883 3.31338223
 3.31480582 3.31642038 3.31651334 3.31802952 3.31807106 3.31914865
 3.32170848 3.326807   3.32783081 3.32848348 3.32851763 3.32880914
 3.32959731 3.33216177 3.33464793 3.33771049 3.33818252 3.33953461
 3.34002829 3.34253653 3.34253956 3.34410503 3.34543893 3.351551
 3.35255146 3.35258619 3.35312066 3.35448483 3.35502826 3.35506364
 3.35651079 3.35688939 3.35745591 3.35965992 3.36091829 3.36119507
 3.36236321 3.36368932 3.36614401 3.36923746 3.36947567 3.36986383
 3.37016688 3.371722   3.37216801 3.37257536 3.37285719 3.37352981
 3.3738829  3.37596205 3.37649909 3.3774826  3.37748552 3.37791563
 3.37855917 3.37900339 3.37969672 3.38201237 3.38251666 3.38304214
 3.38403122 3.38438968 3.38462494 3.38594649 3.38656571 3.38671669
 3.38682235 3.38765682 3.38777543 3.38788833 3.38844226 3.38873604
 3.38885752 3.38909531 3.38955402 3.39112265 3.39161826 3.39272398
 3.39330893 3.39378232 3.39389512 3.39705352 3.3972448  3.40213536
 3.40510493 3.40540941 3.40744156 3.407696   3.41393316 3.41417848
 3.41712025 3.4241171  3.43055538 3.43104046 3.43641285 3.45311424
 3.45596043 3.46837904 3.47023536 3.47851875 3.48674624 3.48960975
 3.49398651 3.49432192 3.49621786 3.49744939 3.5016542  3.50299235
 3.50946479 3.51398366 3.51980814 3.52258927 3.52378589 3.52709964
 3.62373326 3.65119632 3.66933432 3.68511154 3.71824223 3.72259804
 3.72471714 3.77452278 3.81822936 3.82759566 3.84886402 3.86980063
 3.86994919 3.87174065 3.87633978 3.87769567 3.89727205 3.93768589
 3.94917781 3.96303854 3.96666408 3.96980959 3.97519947 4.06359027
 4.07295969 4.12740012 4.29031363 4.41469848 4.74364732 4.74929127
 4.74939383 4.75242898 4.75959235 4.76269659 4.76474803 4.76829911
 4.76902116 4.76950126 4.77360335 4.77378282 4.77572607 4.77943725
 4.7804555  4.78244768 4.78485105 4.78519134 4.7866658  4.78676022
 4.78848398 4.78963078 4.7899077  4.79107551 4.79284662 4.79429647
 4.79569583 4.79870127 4.79874014 4.80042707 4.80845519 4.8138419
 4.82552477 4.83201694 4.84530778 4.87721699 4.89823028 4.89967287
 4.90680877]

  warnings.warn(

2022-12-16 10:37:01,531:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.80299521 2.08618584 2.10367117 2.12401365 2.13317081 2.13998225
 2.14518695 2.14613732 2.16891692 2.18412542 2.28834535 2.33310057
 2.85785809 2.86608013 2.86742614 2.89195076 2.89305555 2.89957269
 2.90265042 2.90950548 2.90970207 2.91036307 2.91059672 2.91124847
 2.91149708 2.91173317 2.91231201 2.91256556 2.91434866 2.9146408
 2.9148755  2.91874385 2.91892027 2.92045312 2.92244612 2.92716132
 2.92864265 2.93618943 2.93755155 2.93875019 2.94508392 2.94551259
 2.9462143  2.94701586 2.94789541 2.94861317 2.95036686 2.95176629
 2.95206351 2.9522145  2.95278153 2.95411059 2.9575736  2.96072399
 2.96079822 2.96080316 2.96104454 2.9610553  2.96133961 2.96229831
 2.96405767 2.96417673 2.96528712 2.96549331 2.96562774 2.96657713
 2.96697105 2.96855162 2.96902873 2.97044344 2.97221515 2.9726963
 2.97319352 2.97380642 2.97444717 2.97577161 2.97849676 2.97891621
 2.97969246 2.97987891 2.98006492 2.9806149  2.9811757  2.98232319
 2.98353625 2.98735663 2.98852866 2.99344977 2.99514485 2.99706484
 2.99707947 2.99759193 3.00054988 3.0006551  3.00121869 3.00175337
 3.00412108 3.00715823 3.01200932 3.01361862 3.01433728 3.01473091
 3.01487213 3.01731797 3.01852385 3.02110188 3.03080132 3.03476267
 3.03790771 3.03809497 3.04770598 3.05007315 3.05031252 3.05508439
 3.06255583 3.07112575 3.0717357  3.07247095 3.08051386 3.08548496
 3.0856846  3.08780162 3.08838947 3.0892136  3.09369016 3.09513083
 3.09894238 3.09903205 3.10252058 3.10414417 3.10515081 3.10576524
 3.1060431  3.10697849 3.11063902 3.11134284 3.11202381 3.11331903
 3.11431419 3.11512887 3.11543551 3.11549039 3.11576629 3.11621649
 3.11822658 3.11941996 3.11980371 3.12014118 3.12019737 3.12089096
 3.1225474  3.12298596 3.12323152 3.12434371 3.12467061 3.12470058
 3.12482149 3.12484038 3.12506834 3.1252901  3.1256832  3.12662737
 3.12675055 3.12745494 3.12766072 3.12790587 3.12946715 3.12976894
 3.13081972 3.13128797 3.13163253 3.13227321 3.13279114 3.13364727
 3.1345452  3.13491821 3.13577495 3.1362829  3.13688983 3.1382287
 3.13831939 3.13868658 3.13875083 3.13904208 3.13947299 3.1396255
 3.13969174 3.13981414 3.140301   3.14053457 3.1408928  3.140949
 3.14189429 3.14199431 3.14232343 3.1426419  3.14328494 3.14351409
 3.14375067 3.14379517 3.14491294 3.1454063  3.14544189 3.14583654
 3.14604247 3.14627117 3.14652818 3.14671824 3.14720177 3.14831938
 3.14845799 3.14854929 3.14886028 3.14891416 3.1495175  3.14954137
 3.14984869 3.15033526 3.15054381 3.150557   3.1516178  3.15182577
 3.15248677 3.15321341 3.15323527 3.15346496 3.15389844 3.15477322
 3.15505269 3.15527304 3.1553809  3.15563113 3.1560162  3.15638405
 3.15644295 3.1567622  3.15706765 3.15725082 3.15798168 3.15808166
 3.1581476  3.15916088 3.15974338 3.15978985 3.15986546 3.15990019
 3.16003733 3.16012719 3.1601812  3.16031289 3.16086827 3.16155568
 3.16169118 3.16193643 3.16199638 3.16215165 3.16217414 3.16217764
 3.16235748 3.16258974 3.16259952 3.16297404 3.16320238 3.16326313
 3.1634359  3.1634976  3.16352049 3.16378405 3.164113   3.16419037
 3.16475519 3.16491346 3.16519068 3.16533362 3.16555401 3.16597109
 3.16605991 3.16611352 3.16622411 3.16627899 3.16630914 3.16680411
 3.16681807 3.16709352 3.16731375 3.16744246 3.16773598 3.16782791
 3.16799284 3.16817548 3.16822361 3.16843249 3.16866138 3.16905654
 3.16931458 3.17033614 3.17042789 3.17053847 3.17128341 3.17136638
 3.17152775 3.17153496 3.17195245 3.17199145 3.17208048 3.17236421
 3.17299    3.17321372 3.17332469 3.1734464  3.17349975 3.17374436
 3.17406379 3.17448788 3.17483534 3.17523598 3.17542802 3.1754615
 3.17599021 3.17635661 3.17653014 3.17678227 3.17693324 3.177264
 3.17739978 3.17746798 3.17773467 3.17820999 3.17824225 3.17906334
 3.17910896 3.17966819 3.17979229 3.17988872 3.18003586 3.18057421
 3.18086313 3.18106466 3.18112905 3.18116542 3.18122029 3.18123621
 3.18123956 3.18128041 3.18161146 3.18193361 3.18198987 3.18220512
 3.18224148 3.18230821 3.18236497 3.18264549 3.18269143 3.18281145
 3.18283824 3.18316452 3.18326904 3.18333601 3.18334052 3.18335243
 3.18341782 3.18343185 3.18381378 3.18436202 3.18454447 3.18465602
 3.18503712 3.1851822  3.18558886 3.18566822 3.18579463 3.18585999
 3.18590636 3.18601825 3.186109   3.18612798 3.18619456 3.18628606
 3.18639688 3.18661443 3.18672793 3.1867555  3.18684252 3.18686787
 3.18698112 3.18707291 3.18714076 3.18725468 3.18727189 3.18732562
 3.18738294 3.18744689 3.18745809 3.18762789 3.18768711 3.18800572
 3.18824081 3.18858439 3.18859125 3.18906632 3.1891133  3.18916484
 3.18955359 3.18956677 3.18957565 3.1899125  3.19025857 3.19056437
 3.19064353 3.19077941 3.19086209 3.19107312 3.19139449 3.19163604
 3.19206679 3.19215447 3.19248131 3.19302996 3.19314285 3.19351327
 3.19377606 3.19383074 3.19398747 3.19402424 3.19429553 3.19440712
 3.19453265 3.19458752 3.19473936 3.19526422 3.19601701 3.19615419
 3.19641953 3.19642127 3.19650771 3.19695694 3.1971866  3.19722518
 3.19726521 3.19741281 3.19751271 3.1976406  3.19799485 3.19829322
 3.19861715 3.19873999 3.19932861 3.19975907 3.19981627 3.19982408
 3.19990701 3.19991689 3.19994174 3.20055033 3.20109987 3.2011118
 3.20124017 3.20127955 3.20164624 3.2018743  3.20257325 3.20266404
 3.2028243  3.20309024 3.2033463  3.20334885 3.20336324 3.20336813
 3.20339836 3.20349982 3.20388578 3.20420259 3.20434398 3.20448613
 3.20451105 3.20469001 3.20487509 3.20515792 3.20522287 3.20539422
 3.20608777 3.20656072 3.20681423 3.20689942 3.20695659 3.20709187
 3.2071098  3.20725825 3.20726012 3.20767354 3.20777378 3.20809902
 3.20818331 3.20858599 3.20860641 3.20867265 3.20890461 3.20919394
 3.20944252 3.20947272 3.20950792 3.20970813 3.20994447 3.21036128
 3.21040517 3.21072707 3.21078837 3.21087014 3.21097295 3.21148669
 3.21156091 3.21157972 3.21213384 3.21230096 3.21233167 3.21284987
 3.21285446 3.21310082 3.21329034 3.21333281 3.21360965 3.2137942
 3.21380941 3.21383512 3.21393833 3.2139924  3.21436356 3.21462814
 3.21477564 3.21548304 3.21556044 3.21567852 3.2163196  3.21634578
 3.21642429 3.21659762 3.21723288 3.2178343  3.21803334 3.21848912
 3.21856817 3.21868706 3.21918739 3.21923561 3.21971185 3.21973468
 3.21977118 3.2200386  3.22011465 3.22038404 3.22063102 3.2207814
 3.22079659 3.22212761 3.22224227 3.22231231 3.22264737 3.22303005
 3.22354913 3.22365875 3.22382785 3.22385471 3.22395677 3.22401564
 3.22413657 3.22510698 3.22540273 3.22571117 3.22633727 3.22653171
 3.2265326  3.22700772 3.2270864  3.22711271 3.22725208 3.22727297
 3.22736842 3.23016831 3.23020433 3.23028301 3.2304147  3.2304928
 3.23057824 3.23106294 3.23115996 3.23150546 3.23184056 3.23355145
 3.23375392 3.23406849 3.23407447 3.23433648 3.23437819 3.23447019
 3.23494447 3.23570118 3.23571802 3.23586193 3.23587114 3.23640522
 3.23697982 3.23714401 3.2372765  3.23799087 3.23866448 3.23891924
 3.23896316 3.23961791 3.23972704 3.2399402  3.24014263 3.24112846
 3.24167628 3.24198156 3.2429749  3.24347038 3.24357277 3.24486314
 3.24531591 3.24536181 3.2455149  3.24570219 3.24613315 3.2462476
 3.24704375 3.24743184 3.2474513  3.2476172  3.24809904 3.2486828
 3.24943713 3.24950525 3.25028889 3.25153744 3.25228199 3.252322
 3.25261428 3.25328044 3.254604   3.2552851  3.25584269 3.25730351
 3.25797789 3.2593463  3.26217724 3.26311877 3.26711612 3.27089509
 3.27197577 3.27213469 3.27258199 3.27599973 3.2768656  3.276929
 3.27836275 3.27954334 3.28097229 3.28109425 3.28187838 3.28238501
 3.28252724 3.28312813 3.28569932 3.28743237 3.28747905 3.28768268
 3.28797175 3.29269357 3.29312629 3.29361437 3.29565112 3.29577212
 3.29751511 3.29922228 3.29932943 3.2996382  3.30189701 3.30244637
 3.30269174 3.30848189 3.30865945 3.30867222 3.30965851 3.31042297
 3.31172381 3.31443533 3.31882934 3.3190299  3.32140688 3.32351306
 3.3250125  3.32561104 3.32608557 3.32756746 3.32778621 3.3296915
 3.33175419 3.33194664 3.3376408  3.33960107 3.34406043 3.34602687
 3.34606024 3.34909493 3.35016117 3.35036579 3.35108264 3.35240745
 3.35482825 3.35586106 3.35630853 3.35637129 3.36084931 3.36341698
 3.3635271  3.36543023 3.36763284 3.36765365 3.36890321 3.37490491
 3.37881786 3.38244758 3.38336277 3.38340848 3.38407749 3.38419709
 3.38478352 3.38683072 3.38792525 3.38860509 3.38897598 3.39075391
 3.39378611 3.39389048 3.39416889 3.3947495  3.39672906 3.39727068
 3.39990832 3.40081501 3.4016583  3.40193652 3.40300689 3.40457459
 3.40483694 3.40489224 3.40653639 3.40816984 3.40819316 3.40880865
 3.41059179 3.41207303 3.41228088 3.4123011  3.41356305 3.41369297
 3.41636214 3.41665362 3.416814   3.41802869 3.41804623 3.41824923
 3.41947279 3.41950232 3.41994247 3.4200928  3.42038546 3.42094672
 3.4219532  3.42199943 3.42579731 3.42607875 3.42677982 3.43114717
 3.43218834 3.43386661 3.43753709 3.4376781  3.44131556 3.44369149
 3.44383347 3.46347553 3.48311521 3.48854788 3.49550449 3.52244451
 3.52666378 3.52940066 3.54838231 3.56396435 3.60576445 3.65987855
 3.68305642 3.68739876 3.68974845 3.6903626  3.72467903 3.72615487
 3.84938705 3.86391683 3.87073469 3.88287143 3.88425199 3.89065445
 3.89731819 3.89934505 3.9000972  3.91094122 3.91279495 3.91830517
 3.92401379 3.94431119 3.9886491  3.99348384 3.99374909 4.00664454
 4.05007735 4.08287083 4.16186042 4.28242095 4.29059047 4.32664398
 4.38778928 4.44401996 4.69492868 4.74309786 4.75816687 4.76414768
 4.76655213 4.77104373 4.77605876 4.77821193 4.77863253 4.78694545
 4.7877209  4.78796008 4.78875486 4.79012786 4.79411287 4.79837372
 4.79962529 4.79969724 4.80358735 4.80392941 4.80627635 4.80867785
 4.81095603 4.81628723 4.81982149 4.82396204 4.82644661 4.83186596
 4.83297878 4.84376855 4.84487999 4.86909949 4.89236716 4.89933847
 4.92110386]

  warnings.warn(

2022-12-16 10:37:01,582:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.72307187 1.92337644 1.96260522 1.97265793 2.12155281 2.18271353
 2.60633368 2.61745456 2.88234363 2.90647462 2.90871976 2.9123764
 2.92433271 2.94399865 2.94665062 2.95150849 2.95387004 2.95585661
 2.95697807 2.95703292 2.96179714 2.9623623  2.96446655 2.96597012
 2.96784041 2.97078174 2.9710683  2.97308594 2.9744938  2.97504237
 2.97585577 2.97597412 2.97703587 2.97929909 2.9810201  2.98108952
 2.98227837 2.98272007 2.98463164 2.98549143 2.9860479  2.98668006
 2.98749054 2.98992941 2.99074254 2.99110225 2.99142872 2.99175572
 2.992133   2.99214224 2.99257929 2.99292657 2.99447394 2.99589732
 2.99598379 2.9975029  2.99760501 2.99839331 2.99879903 2.99929549
 2.99935412 3.00185397 3.00226345 3.00304894 3.00517861 3.00578791
 3.00759701 3.0081203  3.00824476 3.00926394 3.00973393 3.01082189
 3.01115982 3.01187128 3.01311002 3.01335619 3.0138577  3.01453485
 3.01566402 3.01654818 3.01676715 3.01865406 3.0193914  3.01973176
 3.02022348 3.020671   3.0219743  3.02309304 3.02352413 3.02549398
 3.02550377 3.02553509 3.02683068 3.0278487  3.03266162 3.03545179
 3.04373569 3.04492875 3.04561843 3.0473355  3.0490227  3.05209093
 3.05464239 3.05485363 3.05725281 3.0576192  3.05880934 3.0620419
 3.06326354 3.06747177 3.07562189 3.07732808 3.07765997 3.07924089
 3.08150524 3.08648152 3.0878057  3.08910686 3.09098214 3.09150795
 3.09232799 3.09322321 3.09362352 3.09420366 3.09732751 3.09764569
 3.0985123  3.09918062 3.09929081 3.1002786  3.1036038  3.10586558
 3.10642449 3.10753895 3.10974332 3.11079798 3.11089829 3.11097786
 3.11173991 3.11232606 3.11257921 3.11282402 3.11293934 3.1134984
 3.11361855 3.11404848 3.11406092 3.11421287 3.11451289 3.11496869
 3.11822846 3.11876354 3.11883486 3.11909718 3.11970685 3.12059967
 3.12062552 3.12106495 3.12217217 3.12244862 3.12252878 3.12332209
 3.12384649 3.12402811 3.12412768 3.1249741  3.12532605 3.12571334
 3.12760296 3.12764738 3.12863621 3.12892068 3.12906118 3.12942677
 3.12956626 3.12958426 3.12961318 3.12962776 3.12983403 3.13006331
 3.13058354 3.13087362 3.13175294 3.13190119 3.1320126  3.13201496
 3.13244782 3.13246772 3.13309659 3.13348179 3.13369786 3.13402533
 3.13405233 3.13447458 3.13467258 3.13494156 3.1356957  3.13575505
 3.13577042 3.13589378 3.13631888 3.13655995 3.13665298 3.13674273
 3.13713984 3.13716191 3.13770838 3.1379599  3.13835911 3.13858848
 3.1386096  3.13880019 3.13907073 3.13928341 3.13929076 3.13935943
 3.13942084 3.13944602 3.13953055 3.13961956 3.13995994 3.14037097
 3.14051638 3.14085432 3.14110081 3.14129675 3.141329   3.1417461
 3.14186207 3.14262372 3.14312311 3.14313862 3.14377699 3.14404499
 3.14413857 3.14417533 3.14418802 3.14419163 3.14446719 3.14490612
 3.14499167 3.14534225 3.14558494 3.14601339 3.14682497 3.14720397
 3.14752961 3.14763727 3.14772849 3.14775427 3.14778955 3.14847319
 3.14890094 3.14934334 3.14960419 3.14964297 3.14982867 3.14995571
 3.15001251 3.1501354  3.15014408 3.15020123 3.1506921  3.15082233
 3.15101052 3.1510834  3.15156812 3.1518235  3.15230903 3.15236362
 3.15283234 3.15305356 3.15321382 3.1532828  3.15337655 3.15345649
 3.15401554 3.15491464 3.15495452 3.1553375  3.15542914 3.15585665
 3.155923   3.15605636 3.15637539 3.15641179 3.1572405  3.15735233
 3.15740753 3.15749636 3.15801451 3.15812251 3.15827079 3.15874248
 3.15916008 3.15924038 3.1593957  3.15945365 3.16032121 3.16056019
 3.16064522 3.1606616  3.16088785 3.16092337 3.16096743 3.16128696
 3.16151618 3.16161685 3.16167425 3.16171664 3.16182585 3.16210439
 3.16216732 3.16217509 3.1622436  3.16244958 3.16256895 3.16270116
 3.16285431 3.16288053 3.16296979 3.16299343 3.16322828 3.16376576
 3.16414355 3.1641529  3.16437922 3.16465003 3.16494712 3.16513677
 3.16530129 3.16545871 3.16549719 3.16557485 3.16560408 3.16575311
 3.1657665  3.16585915 3.16616495 3.16636967 3.16641617 3.16657284
 3.16693548 3.16708321 3.16712801 3.16756701 3.16765781 3.16769083
 3.16773375 3.16785987 3.1679072  3.16852615 3.16896141 3.16902662
 3.16908396 3.16938962 3.16943609 3.16957956 3.16966436 3.16976418
 3.17008212 3.17028905 3.17040332 3.17049086 3.17067113 3.17072877
 3.17084196 3.1711232  3.17133585 3.17149944 3.17158288 3.17165052
 3.17167082 3.17171052 3.17173883 3.17188184 3.17191574 3.17219272
 3.17305309 3.17306619 3.17306779 3.17308844 3.17309729 3.1732414
 3.17338323 3.17341465 3.17358944 3.17373428 3.17379778 3.17411947
 3.17414376 3.17441921 3.17449903 3.17477689 3.17490567 3.17514467
 3.17530474 3.17531262 3.17534256 3.17544316 3.17549556 3.17556798
 3.17574382 3.17587946 3.17602134 3.1760957  3.17620868 3.17629608
 3.17684207 3.17720806 3.1773296  3.1776461  3.17772622 3.17785924
 3.17789884 3.1781961  3.17822578 3.1783973  3.17849466 3.1791771
 3.17926353 3.17940122 3.17955676 3.17991026 3.1799287  3.18022992
 3.18080531 3.18086997 3.18087813 3.18134565 3.18134743 3.18143408
 3.18150159 3.18150513 3.18158704 3.18175269 3.18178059 3.18227323
 3.182507   3.1825968  3.18287087 3.18301481 3.18308852 3.18346556
 3.18373906 3.18380073 3.18395792 3.18425806 3.18435045 3.18446138
 3.18496736 3.18524369 3.18535173 3.18543478 3.18557963 3.18594358
 3.18605147 3.18611559 3.18673725 3.18746841 3.18808958 3.18819594
 3.1882124  3.18825166 3.18846729 3.18877658 3.18911519 3.18990742
 3.19018434 3.19021288 3.19029447 3.19178923 3.19195017 3.1922619
 3.19275951 3.1930771  3.19310434 3.19369588 3.19375466 3.1939503
 3.1945502  3.19467516 3.19475914 3.19493485 3.19531165 3.19537912
 3.19545283 3.19591694 3.19640253 3.19693842 3.19697151 3.1970018
 3.19714651 3.19721862 3.19747006 3.19763049 3.1977694  3.1982337
 3.19832282 3.1985377  3.19876525 3.19923685 3.19972896 3.20004125
 3.20010515 3.20029095 3.20031405 3.20095908 3.20104032 3.20113915
 3.20148634 3.20193797 3.20202291 3.20205767 3.20210563 3.20240237
 3.20244988 3.20285803 3.20295058 3.2035497  3.20386861 3.20387857
 3.20393926 3.20416788 3.20421162 3.20423716 3.20425398 3.20448203
 3.20531286 3.20534138 3.2053802  3.20544904 3.20548361 3.20603526
 3.20609621 3.20637853 3.20687657 3.20693253 3.20798236 3.20809244
 3.20819814 3.2084794  3.20873287 3.20880139 3.20897887 3.21008608
 3.21010378 3.21064898 3.21237079 3.2124959  3.21280879 3.21304936
 3.21373076 3.21406518 3.21467549 3.21509516 3.21557037 3.21608517
 3.21635389 3.21643176 3.21649464 3.21689331 3.21694111 3.21727118
 3.21771194 3.21784426 3.2181911  3.21871732 3.21891814 3.21895238
 3.21919384 3.2203396  3.22063049 3.22071773 3.22089908 3.22298845
 3.22371477 3.22396433 3.22410306 3.22411667 3.22423569 3.22577654
 3.22594478 3.22695171 3.22742059 3.22802524 3.22837572 3.22840644
 3.22998812 3.23087731 3.2309526  3.23133356 3.23160658 3.23168848
 3.23218599 3.23252477 3.23468006 3.23682817 3.23855068 3.23925387
 3.23938991 3.23985402 3.24133663 3.24148556 3.24151289 3.24168831
 3.2423997  3.24284261 3.24325152 3.24355856 3.24465547 3.2453665
 3.24547744 3.24571563 3.24631065 3.24657347 3.24761253 3.24874364
 3.24909658 3.25041036 3.25156297 3.25223141 3.25242206 3.25262116
 3.25283914 3.25358586 3.25411284 3.25454436 3.25459348 3.25511514
 3.25643472 3.25732795 3.25806385 3.25834501 3.25845165 3.25894607
 3.25902988 3.25909228 3.25917962 3.25927362 3.25967494 3.26108259
 3.26235354 3.262599   3.26555868 3.26583037 3.2658477  3.26605511
 3.26682323 3.26739591 3.26780538 3.26813989 3.2688039  3.26882367
 3.26922409 3.27156519 3.27300888 3.27430485 3.27498358 3.27518076
 3.27576336 3.27603415 3.27619016 3.27703353 3.2773222  3.27734734
 3.27809053 3.27862706 3.27871251 3.27898828 3.27928747 3.28078271
 3.2807889  3.28326624 3.28382    3.28397569 3.284725   3.28490192
 3.28512021 3.28558295 3.28665464 3.28665524 3.28737264 3.28855863
 3.28866956 3.28998602 3.29077609 3.29106301 3.29113606 3.29168796
 3.29234095 3.29337264 3.2935847  3.2944033  3.29637406 3.2967715
 3.29887731 3.30235808 3.30284002 3.3036528  3.30690887 3.30693662
 3.30701044 3.30842302 3.31213824 3.31259628 3.31522127 3.31539921
 3.31765176 3.3233016  3.32567    3.32733541 3.32880005 3.33308374
 3.33523284 3.33539906 3.33671174 3.33705111 3.33738503 3.33838555
 3.340025   3.3401796  3.34195964 3.34892479 3.35409626 3.35615963
 3.35751684 3.35777276 3.35880845 3.36451879 3.36595522 3.36599184
 3.36695673 3.36730449 3.36806819 3.37026689 3.37044093 3.37089161
 3.37188347 3.37276728 3.37385953 3.37414642 3.3742071  3.37690169
 3.37758169 3.37974081 3.38053973 3.38226034 3.38241896 3.3835295
 3.38673813 3.38778892 3.3877929  3.38851384 3.3887337  3.39079102
 3.39094808 3.39449788 3.39468937 3.40392535 3.40743549 3.41217027
 3.41354526 3.41648818 3.43533488 3.45058255 3.45460895 3.45648327
 3.4569562  3.46045369 3.46090927 3.46529862 3.4731854  3.47657412
 3.4778338  3.48303185 3.48495575 3.49252016 3.54772261 3.63524768
 3.63888004 3.64784429 3.65664103 3.66306786 3.68112151 3.68134593
 3.69214112 3.72984056 3.77042987 3.77788361 3.78523246 3.81525892
 3.81787641 3.81900789 3.8214455  3.8218695  3.82694857 3.83144778
 3.83256252 3.83588053 3.83869581 3.84159996 3.84264459 3.85307509
 3.85554067 3.85845583 3.9215509  3.93740203 3.93860606 3.96923428
 4.09708737 4.0977161  4.11854824 4.16674814 4.35405864 4.72256305
 4.73110053 4.73157807 4.75405895 4.77277303 4.77362001 4.77804416
 4.78075084 4.78156345 4.7874386  4.78963823 4.79019067 4.79043283
 4.79178967 4.79236439 4.79297923 4.7930016  4.79339208 4.79374558
 4.79390069 4.79402406 4.7969364  4.79766749 4.80596334 4.80684358
 4.8102186  4.81128811 4.81925686 4.82265251 4.82335423 4.82714791
 4.83178034 4.83480266 4.83945939 4.84462333 4.86296762 4.88303341
 4.88814221 4.89661229]

  warnings.warn(

2022-12-16 10:37:01,610:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.04575053 2.07805459 2.08071343 2.12206598 2.12210169 2.1961984
 2.73599822 2.80148421 2.83319181 2.85428888 2.85728937 2.86200521
 2.87241259 2.88718254 2.89716055 2.90372647 2.91458707 2.91628964
 2.92307131 2.92388243 2.925234   2.92695751 2.92718665 2.93096024
 2.93399101 2.9379467  2.93853138 2.94334538 2.94349252 2.94791307
 2.95160393 2.9561694  2.95991752 2.96370041 2.96494693 2.9653939
 2.96565394 2.96860599 2.96932912 2.97075401 2.97283135 2.97453704
 2.97551953 2.97583484 2.97692342 2.98064883 2.98097502 2.98225961
 2.98320756 2.98334981 2.98375132 2.98402912 2.98472481 2.98553458
 2.98810107 2.98872217 2.98915334 2.98925505 2.99134999 2.99375498
 2.99428727 2.99509186 2.99580325 2.99586004 2.99744914 2.9980227
 2.9987018  2.99881542 2.9988496  2.99913694 3.00342376 3.00352485
 3.00363107 3.00380062 3.00507082 3.00694769 3.00924546 3.01002356
 3.0114204  3.01255484 3.0127034  3.0129849  3.01493367 3.01493637
 3.01788365 3.01817776 3.01954649 3.0203651  3.02254199 3.02350409
 3.02469113 3.02565867 3.02705998 3.02822348 3.02880356 3.02937921
 3.03087233 3.03330172 3.03550824 3.03789769 3.03925129 3.03972802
 3.04023082 3.04266792 3.04336588 3.04346456 3.04392159 3.04407038
 3.04450747 3.04498969 3.04562839 3.04563892 3.04822488 3.04988282
 3.05004894 3.05141511 3.05233241 3.05531539 3.05536575 3.05578225
 3.05715141 3.05738914 3.05912863 3.06076157 3.06173066 3.06254817
 3.06298206 3.06565766 3.0658813  3.06881316 3.07026854 3.07179816
 3.07271413 3.07702398 3.07832934 3.08080383 3.0812794  3.08160273
 3.08287077 3.08329747 3.08366183 3.08409881 3.08446685 3.0847995
 3.08518654 3.08555593 3.08613745 3.08642596 3.08735696 3.08819708
 3.09248877 3.09287645 3.0930331  3.09731964 3.09888026 3.10026119
 3.10177198 3.10262096 3.10285856 3.10410388 3.10432347 3.10443479
 3.10476273 3.10648878 3.10783467 3.10957651 3.11152785 3.1117141
 3.11258479 3.11266655 3.11286797 3.11294767 3.11296237 3.11377471
 3.11397688 3.11475488 3.11486045 3.11541589 3.11560947 3.11572792
 3.11572835 3.11574831 3.11641701 3.11702573 3.11805727 3.11921956
 3.11935776 3.12013192 3.12036409 3.12052546 3.12084079 3.12187474
 3.12346362 3.12352157 3.12356579 3.12357327 3.12403773 3.12460167
 3.12466323 3.12480356 3.12482658 3.12490796 3.12535959 3.12538937
 3.12631745 3.12656762 3.12708297 3.12805003 3.12872479 3.12919911
 3.12929194 3.12947804 3.12986652 3.13030815 3.13066919 3.13159745
 3.13181765 3.13273165 3.13306397 3.13327903 3.13346548 3.13371861
 3.13375757 3.13405566 3.13406133 3.13488366 3.13541541 3.13571669
 3.13572229 3.13634606 3.13643766 3.13649001 3.13652189 3.13672799
 3.13700674 3.13770596 3.13811947 3.1384458  3.13888456 3.13918552
 3.1402528  3.14045379 3.14109183 3.14183682 3.14197557 3.14212312
 3.14286349 3.14291337 3.14384157 3.14394349 3.14435558 3.1445874
 3.14476605 3.14526129 3.1454878  3.14559968 3.14625364 3.14635
 3.14652681 3.1467257  3.14740484 3.14766496 3.14821155 3.14868495
 3.14989748 3.1500635  3.1503545  3.15051745 3.15226504 3.15292624
 3.15307225 3.15341893 3.15437718 3.15560128 3.15648603 3.15757512
 3.15776094 3.1579223  3.15830553 3.15854528 3.15873763 3.15937298
 3.15951391 3.15956724 3.15998442 3.16079685 3.16146484 3.16204252
 3.16242034 3.16309878 3.16325245 3.16334726 3.16389292 3.1639259
 3.16434265 3.16437965 3.16457355 3.16462202 3.16574604 3.16617824
 3.16644906 3.16650733 3.16681749 3.16693557 3.16697697 3.16702093
 3.16708559 3.16729959 3.16766504 3.16860439 3.16912483 3.16929705
 3.16939365 3.1697795  3.16988661 3.17027803 3.17054256 3.17054647
 3.17058629 3.17067236 3.17068435 3.1706881  3.17080582 3.17116907
 3.17149128 3.17157174 3.17207334 3.17208185 3.17214838 3.17220371
 3.1722887  3.1724853  3.17259685 3.17269039 3.17293985 3.17297146
 3.17325998 3.17338694 3.17360288 3.17365972 3.17366493 3.1736765
 3.17373847 3.17406122 3.17459096 3.17467954 3.17477747 3.17520412
 3.17539963 3.17567598 3.17595761 3.17598271 3.17602063 3.17602746
 3.17624655 3.17639393 3.17642008 3.17692426 3.17726464 3.17745942
 3.17748132 3.17751858 3.17757003 3.17793704 3.17794396 3.1780532
 3.17815865 3.1783718  3.17879796 3.17886496 3.17897341 3.17898447
 3.17899112 3.17934653 3.17970742 3.18002755 3.18047709 3.18099153
 3.18114929 3.18130253 3.18156246 3.1815748  3.18163306 3.18175878
 3.18181349 3.18184906 3.18189711 3.18196397 3.18200089 3.1820784
 3.18227718 3.18229861 3.18258163 3.18272658 3.18272899 3.18274888
 3.18289324 3.18300765 3.18305741 3.18318707 3.18404215 3.18441861
 3.18456555 3.18460525 3.18500796 3.18538918 3.18542191 3.18571394
 3.18579531 3.1857965  3.18580131 3.18585747 3.18611544 3.18613022
 3.18670991 3.18671821 3.18677836 3.18678423 3.18718241 3.18754247
 3.18763647 3.18835375 3.18869815 3.18891139 3.18915534 3.18955457
 3.18961572 3.18981288 3.18990753 3.19008817 3.19028594 3.19054301
 3.19056164 3.19112571 3.19209969 3.19246953 3.19276347 3.19310662
 3.19311541 3.19331772 3.19350966 3.19360259 3.19361661 3.1937136
 3.19408733 3.1941151  3.19441529 3.1946155  3.19472245 3.19478183
 3.19487677 3.19518761 3.19540486 3.19552958 3.19576258 3.19599318
 3.19635846 3.19656542 3.1970987  3.19746189 3.19764698 3.19778457
 3.19794865 3.19814596 3.19835581 3.1985871  3.1989146  3.19909591
 3.19927905 3.19940736 3.19960071 3.19976324 3.2006431  3.20108608
 3.20137063 3.20221904 3.20235292 3.20263251 3.2026392  3.20301921
 3.20317228 3.20343428 3.20353484 3.2035797  3.20398664 3.20409958
 3.20410243 3.20429552 3.20509536 3.20520728 3.20548642 3.20621683
 3.20650248 3.2069772  3.20763543 3.2079114  3.20798554 3.20811102
 3.20811901 3.20848767 3.20852003 3.20875036 3.20926083 3.20931052
 3.2096138  3.21006421 3.21048023 3.21052569 3.21068829 3.21134566
 3.21178715 3.21192786 3.21254891 3.21286318 3.21335292 3.21376687
 3.21378279 3.21417511 3.21465893 3.21499767 3.21530473 3.21558775
 3.21583487 3.21602228 3.21633775 3.21638907 3.21669884 3.21692126
 3.21695253 3.21706168 3.2172043  3.21724138 3.2175535  3.21755618
 3.21780084 3.21801135 3.21809904 3.21858651 3.21912902 3.21913232
 3.21917684 3.21970211 3.21977009 3.21986179 3.22018853 3.22065005
 3.22073142 3.22087971 3.22108169 3.22231901 3.22254996 3.22260869
 3.22284203 3.2230788  3.22311936 3.22346209 3.22496033 3.22555635
 3.22578309 3.2258747  3.22599622 3.22609125 3.22678888 3.22695745
 3.22704003 3.22712411 3.22753966 3.22760597 3.22784234 3.22818536
 3.22881445 3.22925592 3.22987929 3.22990092 3.23026257 3.23026755
 3.230786   3.23090411 3.23140187 3.23183786 3.23232369 3.2330298
 3.23303907 3.23353148 3.23377453 3.23392561 3.23411209 3.23420381
 3.23443956 3.23458733 3.23484507 3.23542395 3.23760321 3.23824054
 3.23841123 3.23863735 3.23937663 3.23939415 3.23942509 3.24132414
 3.2415164  3.24164427 3.24189202 3.24297068 3.24429737 3.24432303
 3.24436153 3.24623258 3.24652149 3.24876025 3.24945035 3.25000642
 3.25016672 3.25099065 3.25190126 3.25326607 3.25333044 3.25483763
 3.25503182 3.25580077 3.25607033 3.25734919 3.2594211  3.26015385
 3.26120571 3.26241005 3.26297244 3.26315135 3.26336312 3.26424407
 3.26592721 3.26609795 3.26612861 3.26623797 3.26635195 3.26641487
 3.26652783 3.26680506 3.26820505 3.26857666 3.27001994 3.27030918
 3.27056157 3.27106247 3.27110187 3.2720379  3.27276608 3.2732174
 3.27354418 3.27387312 3.27473082 3.27524044 3.2760089  3.27742833
 3.27832798 3.27966439 3.27966549 3.27982556 3.28001803 3.28014649
 3.28055503 3.28112199 3.28127716 3.28139977 3.28211051 3.28296821
 3.28373383 3.28419391 3.28477187 3.28503212 3.28553065 3.28589316
 3.28619859 3.28716399 3.28716783 3.28778481 3.28852897 3.29007934
 3.29205166 3.29229047 3.29378747 3.29410777 3.29541778 3.2966244
 3.30087123 3.30229656 3.30252131 3.30364781 3.30448325 3.30925729
 3.31286414 3.31360733 3.31416339 3.31518438 3.31542674 3.31557703
 3.31829376 3.32165571 3.32215141 3.32278476 3.32348748 3.32357143
 3.32517088 3.32564676 3.32609152 3.32835358 3.32934455 3.33082078
 3.33403002 3.33489681 3.33708017 3.33730664 3.34067914 3.34785786
 3.34931228 3.34989442 3.35132415 3.35509715 3.35777543 3.35957221
 3.36670317 3.36712246 3.36823066 3.37340195 3.37434664 3.37513351
 3.37624254 3.377185   3.37792202 3.38119935 3.38201507 3.38291625
 3.38352945 3.38364351 3.38735188 3.38819848 3.38821729 3.38898884
 3.38904704 3.3890811  3.38962707 3.39023336 3.39025384 3.39190932
 3.39306496 3.39350195 3.39418153 3.39459112 3.39608353 3.39722454
 3.39731849 3.39899568 3.39911655 3.39977138 3.40008528 3.40011697
 3.40055277 3.40076905 3.40247635 3.40444409 3.4057219  3.40745253
 3.40970793 3.4113184  3.41296337 3.41349837 3.41355945 3.41547166
 3.41705172 3.41797581 3.41868032 3.42371583 3.43041798 3.43059801
 3.436478   3.43761127 3.44040073 3.440871   3.44470313 3.45362492
 3.45457442 3.45608933 3.47227938 3.48315433 3.48982873 3.49560645
 3.50136509 3.50399694 3.51000057 3.5192016  3.59078176 3.59106597
 3.63878921 3.64485342 3.66201884 3.66478373 3.6657573  3.68343884
 3.76514781 3.77489895 3.78913829 3.79504962 3.79565686 3.81245954
 3.81814898 3.81861664 3.82550575 3.82894791 3.8302917  3.83393223
 3.84232281 3.84363252 3.84609352 3.84793249 3.8608745  3.86788884
 3.88065946 3.93514077 3.94783488 4.03765184 4.07652447 4.0926798
 4.17836865 4.31193956 4.34070508 4.75481913 4.76346173 4.76596413
 4.77164003 4.77660526 4.77917327 4.78309503 4.78578491 4.78623349
 4.79117653 4.79693721 4.79751755 4.79839291 4.8016956  4.80173766
 4.80546493 4.8063793  4.81139534 4.81457548 4.82486145 4.82654287
 4.83629378 4.83665076 4.84562325 4.85203302 4.85735079 4.86460809
 4.87588455 4.88820654 4.89211816 4.89852561 4.91303027 4.95299473]

  warnings.warn(

2022-12-16 10:37:01,616:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.04822606 2.07043377 2.09124741 2.10691535 2.11100979 2.19343128
 2.35428304 2.7209589  2.78861781 2.87332092 2.87971643 2.88899491
 2.89373235 2.90365148 2.9136811  2.91377624 2.91513765 2.91798984
 2.92483162 2.92725204 2.92973424 2.93178477 2.93227581 2.93230802
 2.93344768 2.93418744 2.93518993 2.93559337 2.93710153 2.94224437
 2.94273353 2.94406748 2.94561018 2.95012461 2.95034515 2.95171901
 2.95172664 2.95635857 2.95684541 2.95685662 2.95796715 2.95910385
 2.95924814 2.96174375 2.96176387 2.96188516 2.96537587 2.96540467
 2.96695795 2.96714076 2.96792209 2.97007305 2.97061666 2.9719758
 2.97251258 2.9728811  2.9729139  2.97294573 2.97327613 2.97345496
 2.97396955 2.97458868 2.97537462 2.97571206 2.97663759 2.9769009
 2.9771028  2.97816211 2.9783615  2.97924403 2.98101624 2.98210167
 2.98222679 2.98311798 2.98399323 2.98417324 2.98471358 2.98483906
 2.98485631 2.98737322 2.98759923 2.98905435 2.99246576 2.99326363
 2.9933963  2.99357196 2.9938929  2.99411429 2.994295   2.99586869
 2.99596264 3.0019137  3.0053788  3.00589409 3.00693285 3.00767464
 3.00982089 3.01145675 3.01711826 3.01921852 3.02110706 3.02205807
 3.02285448 3.02341546 3.02583965 3.02710782 3.02831983 3.02840337
 3.02917954 3.02938107 3.0302183  3.0315456  3.03235141 3.0330959
 3.0359247  3.0384471  3.04009258 3.04135157 3.04325937 3.04558993
 3.05763944 3.06046084 3.0625656  3.06356347 3.06360153 3.06895758
 3.06926631 3.06963974 3.07083585 3.07189158 3.07376632 3.0754002
 3.07571812 3.07649236 3.07870811 3.07945123 3.08034223 3.08058604
 3.08110363 3.08204851 3.08309237 3.08369239 3.08391163 3.08581096
 3.08704863 3.08809993 3.08992333 3.09027531 3.09082618 3.09184181
 3.09392162 3.0939715  3.09417905 3.09487673 3.09561932 3.0956471
 3.09579257 3.09629812 3.09737216 3.09877047 3.09964773 3.10047547
 3.10271219 3.10275686 3.10408903 3.10436158 3.10482695 3.10484235
 3.10514631 3.10534131 3.10537789 3.10564415 3.10677425 3.10721914
 3.10752796 3.1079192  3.10795012 3.10810739 3.10872597 3.10879367
 3.10894842 3.10928254 3.11002129 3.11009374 3.11020396 3.11065223
 3.11103624 3.11126426 3.11177478 3.11231659 3.11254307 3.1129794
 3.11300874 3.11316849 3.113687   3.11382138 3.11414039 3.11521648
 3.11548755 3.11575594 3.11593038 3.11632977 3.11750435 3.11784742
 3.11819716 3.11853591 3.11857795 3.11925667 3.1200918  3.12086585
 3.12118916 3.12129898 3.12217851 3.12309034 3.12394946 3.12451511
 3.1246281  3.12491671 3.12501768 3.12552592 3.12693239 3.12769091
 3.12798134 3.1282626  3.12871038 3.12910906 3.12931386 3.12951689
 3.12974919 3.13015204 3.13088477 3.13223538 3.13239798 3.13353744
 3.1339919  3.13412208 3.13425499 3.13636971 3.13669411 3.13684113
 3.13698703 3.13730448 3.13747493 3.13891274 3.13892413 3.13900371
 3.13982434 3.1398773  3.1400681  3.14051846 3.14086625 3.14163685
 3.14198271 3.14279225 3.14312536 3.1433054  3.14354832 3.14400871
 3.14403646 3.14494538 3.14542814 3.14559101 3.14566581 3.14573402
 3.14622671 3.14625611 3.14684239 3.14714802 3.14748675 3.14755076
 3.14787903 3.14796038 3.14848563 3.14857812 3.14883013 3.14906839
 3.1491291  3.14920916 3.14921719 3.14940939 3.14956667 3.14975482
 3.14981816 3.15038626 3.15077335 3.15123727 3.15142923 3.15175018
 3.15178373 3.15203194 3.15237109 3.15279703 3.15298819 3.15307562
 3.15315193 3.1531582  3.15322757 3.15347667 3.15382057 3.15389233
 3.15402337 3.15413167 3.15422231 3.15436243 3.15496839 3.15517403
 3.15524678 3.1554535  3.15586912 3.15593503 3.15633702 3.15668566
 3.15683765 3.15718025 3.15755818 3.15766723 3.15769607 3.15784801
 3.15796637 3.15797862 3.15817841 3.15834853 3.15865696 3.15897082
 3.15903049 3.15955493 3.15961622 3.1597414  3.15997253 3.16148826
 3.16152669 3.16154625 3.16174459 3.16175115 3.16183657 3.16201492
 3.16229961 3.16316077 3.16355278 3.16383657 3.16386484 3.16399454
 3.1640236  3.16408505 3.16412041 3.16419493 3.16434519 3.16438605
 3.16440256 3.16463417 3.16464332 3.16466057 3.16529346 3.16538084
 3.16538176 3.16545616 3.16587953 3.16594845 3.16600415 3.16609072
 3.16621404 3.16631953 3.16668619 3.16678926 3.16685885 3.16715545
 3.16792841 3.16807529 3.16812155 3.16868717 3.16911505 3.16916002
 3.16922246 3.16938817 3.16952964 3.16957705 3.16972159 3.16998923
 3.17007428 3.17009654 3.17010852 3.17015011 3.17032946 3.17054794
 3.1706491  3.17106825 3.17130592 3.17148648 3.17193077 3.17202809
 3.17214021 3.17224926 3.17228309 3.17328468 3.1733019  3.17371164
 3.17383574 3.17399618 3.17408439 3.17431595 3.17448717 3.17483409
 3.17489807 3.17501313 3.17529825 3.17555468 3.17566567 3.17572208
 3.17572574 3.17577798 3.1758462  3.1766154  3.17678375 3.17680669
 3.17681032 3.17685512 3.17699617 3.17706102 3.17714114 3.17734251
 3.17734834 3.17763211 3.17774695 3.17780281 3.17784712 3.17792965
 3.17847428 3.17905923 3.17920596 3.17925725 3.17970154 3.17988123
 3.17990293 3.17995428 3.18001373 3.18003588 3.18014355 3.18014689
 3.18084877 3.18088529 3.18106068 3.18119984 3.18126243 3.18165153
 3.18176781 3.18209036 3.18229954 3.18230451 3.18241078 3.18276121
 3.183253   3.18332355 3.18344202 3.18350635 3.18357946 3.18406018
 3.18408674 3.18480139 3.18592561 3.18628511 3.18637461 3.18673105
 3.18693901 3.18699741 3.18731649 3.18776893 3.18785127 3.18795523
 3.18826479 3.18828909 3.18863739 3.1889015  3.18905707 3.18923777
 3.18950796 3.19018753 3.19046428 3.19060979 3.19064106 3.19085117
 3.19089627 3.19172303 3.19188302 3.19208879 3.1922232  3.1925912
 3.1928916  3.19300605 3.19343006 3.19361428 3.19371742 3.19403399
 3.19459723 3.19465285 3.19470548 3.19506186 3.19510906 3.19525421
 3.19548789 3.19597431 3.19598269 3.19602975 3.19659019 3.19676338
 3.19743561 3.19758926 3.19768168 3.19872003 3.19882164 3.19887297
 3.20040701 3.20045627 3.20047428 3.20053676 3.2007395  3.20090988
 3.2009644  3.20119597 3.20126022 3.20171583 3.20188174 3.20202895
 3.20224357 3.20241708 3.2024871  3.20315356 3.20336723 3.2034001
 3.20344871 3.20363525 3.20381547 3.20411156 3.20424351 3.20426596
 3.20442481 3.20449989 3.2045932  3.20475964 3.20521359 3.20561168
 3.20624369 3.2072755  3.2073146  3.20795752 3.20799373 3.20808673
 3.20820463 3.20823881 3.20865122 3.20895352 3.2089879  3.20943347
 3.20948424 3.20999354 3.21007649 3.21034047 3.21094285 3.21121018
 3.21150701 3.21175793 3.21241352 3.21264715 3.21270244 3.2129466
 3.21356962 3.21367745 3.2136784  3.21399138 3.21412025 3.2146003
 3.21488254 3.21515884 3.21533652 3.21557524 3.21561246 3.21606204
 3.21631505 3.21633851 3.21640703 3.21647279 3.2167995  3.21845987
 3.21938167 3.21966275 3.21967286 3.21975558 3.22014426 3.22039259
 3.22073251 3.22110332 3.2213837  3.22167447 3.22242813 3.22269508
 3.22281062 3.22316481 3.22410802 3.2246196  3.22483513 3.22522971
 3.22556883 3.22622871 3.22628371 3.22651115 3.22654247 3.22685836
 3.22723629 3.22731734 3.22798688 3.22895052 3.23038176 3.23266416
 3.23374527 3.23386139 3.23396995 3.2342598  3.23434075 3.23534044
 3.23944896 3.24000586 3.24001271 3.24013903 3.2410751  3.24112422
 3.24126149 3.24129924 3.24292144 3.24418217 3.24571664 3.24630713
 3.24648909 3.24851186 3.24899277 3.2504768  3.25194937 3.25201272
 3.25264133 3.25453826 3.25486315 3.25738594 3.25752826 3.25776408
 3.25898457 3.25975354 3.2609423  3.26237828 3.26333435 3.2695281
 3.27054615 3.27077711 3.2718682  3.2734831  3.27391911 3.27420166
 3.27681799 3.27714583 3.27774826 3.27961439 3.28026344 3.28109463
 3.28173338 3.2817745  3.28276656 3.28326293 3.2834116  3.28398941
 3.28480862 3.28513943 3.28540808 3.28543693 3.28670077 3.28754509
 3.28860762 3.28872342 3.28963379 3.29169355 3.29241242 3.2933856
 3.29378448 3.29393123 3.29515358 3.29518912 3.29546071 3.2964158
 3.29989569 3.30285678 3.30299289 3.30405917 3.30523129 3.30526445
 3.30580626 3.30773816 3.31326164 3.31383052 3.31551772 3.31587724
 3.31758433 3.31926359 3.31990194 3.32025728 3.32027048 3.32068822
 3.32246275 3.32435686 3.32476256 3.32565385 3.32666225 3.32756646
 3.32932926 3.33071252 3.33412086 3.33528964 3.33812224 3.33863674
 3.34009782 3.34058299 3.34065073 3.34238231 3.34376627 3.35106386
 3.35273094 3.35281702 3.35449095 3.35647978 3.35672784 3.35835441
 3.35914375 3.35926995 3.36106114 3.3624628  3.36335143 3.3635668
 3.36659194 3.36659605 3.36916882 3.37012726 3.37033147 3.3714056
 3.3714247  3.37159475 3.37313557 3.37327192 3.37348487 3.37451277
 3.37486373 3.37584715 3.37741678 3.3782962  3.38005713 3.38042425
 3.38133771 3.38141544 3.38314916 3.38376002 3.38384671 3.38509409
 3.38531877 3.38545495 3.38719301 3.38789585 3.38811506 3.38850636
 3.38968062 3.38998799 3.39048596 3.39110766 3.39201531 3.39333366
 3.3944371  3.39497347 3.39509901 3.39535253 3.40057336 3.40081763
 3.40117545 3.40127458 3.40742471 3.40959364 3.41012944 3.4105503
 3.41056749 3.41144352 3.41446172 3.41568761 3.41854941 3.42685464
 3.42969909 3.43598335 3.44764203 3.46067454 3.4643273  3.47576119
 3.47636735 3.49713009 3.49847715 3.49955417 3.50082322 3.50087353
 3.50638885 3.50881417 3.51296724 3.52191631 3.52310592 3.52463496
 3.63910844 3.65819538 3.77778736 3.81649354 3.82194611 3.82259774
 3.82769232 3.842406   3.84441408 3.8517116  3.85317726 3.85801518
 3.85865975 3.87865611 3.88039819 3.89526393 3.9399283  3.94164818
 4.32216863 4.35824669 4.40897013 4.48601392 4.71957581 4.74515288
 4.75529624 4.79118482 4.79355391 4.79359516 4.7936555  4.79493359
 4.79500799 4.7970519  4.79781956 4.79872842 4.80179337 4.8033393
 4.8033752  4.80422537 4.80525811 4.81137111 4.81630446 4.81881991
 4.82547911 4.82705603 4.84068773 4.85414054 4.87292656 4.90800013
 4.92201708 4.92400461 4.92792896]

  warnings.warn(

2022-12-16 10:37:02,403:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.03953916 2.62884501 2.87222235 2.87898404 2.88680471 2.88967872
 2.91220353 2.92691191 2.93201496 2.93668603 2.9410296  2.94574148
 2.94719191 2.9484603  2.95060705 2.9518642  2.95188226 2.95263392
 2.95366633 2.95479428 2.95490168 2.95541911 2.95565308 2.95604345
 2.95647299 2.95800228 2.95887834 2.95895433 2.95996542 2.96146858
 2.96524612 2.96526272 2.9677841  2.96800508 2.96830334 2.96920372
 2.97029207 2.97179583 2.97300586 2.97343012 2.97414643 2.97429481
 2.9759789  2.97751294 2.98017299 2.98564985 2.98578781 2.98654347
 2.98893534 2.99040444 2.99331726 2.99539867 2.99635648 2.99673413
 2.9969856  2.99722836 2.998974   3.001286   3.00273478 3.00312702
 3.0041358  3.00471943 3.00508159 3.00526202 3.00626018 3.01011622
 3.01038835 3.01088848 3.01111927 3.01128613 3.01413366 3.01632905
 3.02089271 3.02136644 3.02218525 3.02511762 3.02581234 3.02696326
 3.02936912 3.02974609 3.03346071 3.0338246  3.03511425 3.03895482
 3.040954   3.04205086 3.04490335 3.04553572 3.04590809 3.04875834
 3.05045797 3.05319411 3.05470505 3.05538887 3.05785024 3.06042688
 3.06169329 3.06747784 3.06781032 3.06806823 3.06869938 3.07241178
 3.07324884 3.07671299 3.08109586 3.08201919 3.08372913 3.08496279
 3.08588006 3.0860498  3.09238187 3.09391551 3.09482251 3.09907905
 3.09971625 3.09990847 3.10004233 3.10165824 3.10464074 3.10472784
 3.10525668 3.10652495 3.10729842 3.10748327 3.10851736 3.10891953
 3.10911197 3.10915335 3.11111819 3.11251733 3.11276108 3.11318916
 3.11359821 3.11440376 3.11578249 3.11648608 3.11702865 3.11824426
 3.11962266 3.12181543 3.12346642 3.12419976 3.12432953 3.12513222
 3.12538965 3.12694336 3.12834898 3.12869454 3.12920971 3.13055429
 3.13066163 3.13107668 3.13160056 3.13175201 3.13210245 3.13222922
 3.132253   3.13291933 3.13300666 3.13438434 3.13470305 3.134956
 3.13506572 3.13507329 3.13609151 3.13625268 3.13652494 3.13666231
 3.13689656 3.13691108 3.13696182 3.13786202 3.13801557 3.13863352
 3.13912212 3.13930049 3.14034795 3.14047169 3.14076646 3.14076822
 3.14136518 3.14197551 3.14212419 3.14218179 3.14239511 3.14242498
 3.14246327 3.14258065 3.14259752 3.14267657 3.14268534 3.14299789
 3.14320304 3.14337757 3.14360922 3.14362347 3.14392309 3.14397204
 3.14423662 3.14437285 3.14451072 3.1449752  3.14506803 3.14540463
 3.14560685 3.14581895 3.14621749 3.14624265 3.14647348 3.14650821
 3.14661268 3.14661593 3.14694165 3.14720647 3.14730265 3.14734717
 3.1474359  3.14758061 3.14766408 3.14817727 3.14834356 3.14852324
 3.14861364 3.14903729 3.1495017  3.1496049  3.14965296 3.14988639
 3.15002337 3.15010713 3.15014841 3.15028705 3.15055013 3.15078032
 3.15083147 3.15113836 3.15126101 3.15129714 3.15206351 3.15223879
 3.15247843 3.15265661 3.15290248 3.15310856 3.15370777 3.15372627
 3.15386506 3.15392556 3.15393497 3.1540507  3.1542007  3.15450731
 3.15513748 3.15533387 3.15548409 3.1560078  3.15619763 3.15642562
 3.15675896 3.15712719 3.15717569 3.15728686 3.1573161  3.15767098
 3.1578813  3.1581441  3.15839181 3.15851536 3.15885105 3.15911596
 3.15920066 3.15940411 3.15960272 3.15972838 3.1599757  3.16000504
 3.16017509 3.16020578 3.16058683 3.16120822 3.16130367 3.16135947
 3.16149206 3.16151774 3.16170184 3.16183894 3.16227375 3.16312513
 3.16353706 3.16372819 3.16391414 3.16523814 3.16525637 3.16551206
 3.16561715 3.16631825 3.16631872 3.16639932 3.16657029 3.16672556
 3.16784345 3.16854911 3.16863074 3.16889264 3.1693599  3.16965484
 3.16969269 3.16989055 3.16989971 3.16993901 3.16999677 3.17152484
 3.17182059 3.1719542  3.17229902 3.17236075 3.17239349 3.17280784
 3.17291374 3.1729366  3.17300844 3.17306715 3.17338745 3.17366849
 3.17383218 3.17440305 3.17484958 3.17503866 3.1751303  3.17515052
 3.17551907 3.17563524 3.17637051 3.1764203  3.17656108 3.17674879
 3.1773885  3.17745952 3.17763586 3.17784525 3.17804635 3.17821488
 3.1789036  3.1790385  3.17922447 3.17930701 3.17931994 3.17946188
 3.17950615 3.17955599 3.17979708 3.18010305 3.18044405 3.18057029
 3.1807159  3.18075607 3.18089497 3.18098744 3.18113813 3.18116873
 3.18124882 3.18142842 3.1814732  3.18153522 3.18158062 3.18214763
 3.18223426 3.1822883  3.18277593 3.18298422 3.18308737 3.18309735
 3.18316808 3.1835153  3.1835807  3.1836554  3.18366081 3.1837697
 3.18392647 3.18420052 3.18427237 3.18438278 3.18448681 3.18456624
 3.18457636 3.18461581 3.1846472  3.18468724 3.18482173 3.18486423
 3.18500291 3.18510932 3.18540845 3.1854216  3.18578328 3.18615917
 3.18619466 3.18625278 3.18628202 3.18631413 3.18650495 3.18685108
 3.18705478 3.18715014 3.18744059 3.18809075 3.18819749 3.18834904
 3.18856305 3.18862928 3.18868706 3.18876451 3.18881439 3.18925644
 3.18978654 3.18981166 3.18991914 3.18997804 3.19118293 3.19129091
 3.19162117 3.19172014 3.19177777 3.19213379 3.19228626 3.19229475
 3.19231502 3.19240842 3.19241907 3.19251647 3.19254403 3.19257976
 3.19272526 3.19276664 3.19278101 3.19279716 3.19292982 3.19303289
 3.19330749 3.19341542 3.1938938  3.19397663 3.19408288 3.19419238
 3.19422353 3.19457002 3.19472942 3.19502078 3.19527384 3.19543725
 3.19554827 3.19573757 3.19578777 3.19591957 3.19622171 3.19659109
 3.19667648 3.19676703 3.19678959 3.19700027 3.19754415 3.19827061
 3.19848926 3.19849399 3.19852483 3.19861809 3.19887041 3.19897146
 3.19898784 3.19941749 3.199482   3.19978589 3.19979593 3.1998465
 3.20033275 3.20065876 3.20067987 3.20068389 3.20078126 3.20097647
 3.20102798 3.20107972 3.20114915 3.20124607 3.20188983 3.2019511
 3.20200544 3.20222947 3.20224042 3.2022946  3.20234408 3.20242678
 3.20252293 3.2025275  3.20300602 3.20316697 3.20338711 3.20363412
 3.20375799 3.20424923 3.20438366 3.2045174  3.20464681 3.20465045
 3.20480213 3.20532603 3.20553453 3.20556764 3.20602728 3.20628804
 3.20653989 3.20658203 3.20683782 3.2076638  3.20773076 3.20850544
 3.20868726 3.20871784 3.2087778  3.2089621  3.21021172 3.21051203
 3.21068792 3.21079337 3.21087153 3.21092632 3.21143064 3.21147453
 3.21202887 3.21209754 3.21242879 3.21258592 3.21292463 3.21319681
 3.2133949  3.213702   3.21383666 3.21383978 3.21389312 3.21546447
 3.21581716 3.2162959  3.21668714 3.21686906 3.21688043 3.2173226
 3.21838071 3.21844152 3.21861654 3.21923391 3.21960341 3.21998151
 3.22090373 3.22126684 3.22132656 3.22137298 3.22145202 3.22215406
 3.22252933 3.22282799 3.22289618 3.22347233 3.22359733 3.22362976
 3.2237912  3.22380587 3.22420444 3.22477504 3.22498141 3.22510675
 3.22522909 3.22552366 3.22581569 3.22601567 3.22613812 3.22718832
 3.22723102 3.22736318 3.22806449 3.22815705 3.22819483 3.22902656
 3.22925294 3.22933275 3.22941519 3.22953954 3.22965148 3.23068882
 3.2307245  3.2313035  3.23135093 3.23190225 3.23203633 3.2328263
 3.23286667 3.23377572 3.23441529 3.23449052 3.23469749 3.23533451
 3.23801391 3.2380292  3.23814804 3.23816614 3.23892944 3.23898244
 3.23955693 3.24000498 3.24017047 3.24088279 3.24198828 3.24301324
 3.24329014 3.243709   3.24432689 3.24455687 3.24525112 3.24570381
 3.24661507 3.24675364 3.24683689 3.24691067 3.24757635 3.24782299
 3.24790919 3.24826297 3.24923682 3.24936228 3.24939011 3.24976049
 3.2509402  3.25155953 3.25174075 3.25229457 3.25361445 3.25381739
 3.25428703 3.25466896 3.25466968 3.25478775 3.25500888 3.25726277
 3.25789885 3.25855993 3.25913534 3.25930906 3.25996333 3.26171593
 3.26192096 3.26443841 3.26532753 3.26536317 3.26543748 3.26699321
 3.26934309 3.26970662 3.27061661 3.27222053 3.2727872  3.27287318
 3.27302418 3.27358089 3.27597152 3.27625846 3.27832212 3.28077582
 3.28345576 3.28358475 3.28427855 3.28477401 3.28539079 3.28541878
 3.28577808 3.28618956 3.28733709 3.28807541 3.28860639 3.28867143
 3.28997455 3.29054103 3.29123309 3.29326502 3.29786365 3.29848604
 3.30111237 3.3015508  3.3018705  3.30291307 3.30393265 3.30719596
 3.3075184  3.30900946 3.3102071  3.31044436 3.31155115 3.31321598
 3.31392379 3.31520848 3.31818859 3.31868815 3.31945443 3.3224289
 3.32379969 3.32407258 3.32570444 3.3290863  3.33033014 3.33134088
 3.33180033 3.33287439 3.33302991 3.33445795 3.33464707 3.33542886
 3.33654346 3.3377486  3.34047088 3.34357399 3.34360018 3.34398868
 3.34411007 3.34498245 3.34830776 3.34896713 3.34909712 3.34934271
 3.35105928 3.35136127 3.35202968 3.35310162 3.35435275 3.35579852
 3.35625689 3.36009071 3.36017154 3.3606274  3.36128153 3.36213046
 3.36227197 3.36364626 3.36379454 3.36585471 3.36588926 3.36825154
 3.36830987 3.36994342 3.37157639 3.37258517 3.37411405 3.37538867
 3.37617725 3.37622275 3.37919529 3.37959579 3.38009735 3.3809433
 3.3813677  3.38168392 3.38239929 3.3834574  3.38480491 3.38500489
 3.3862984  3.38659067 3.38886422 3.38966458 3.39041666 3.390668
 3.39240283 3.39322165 3.39428543 3.39549084 3.39598711 3.39662415
 3.39697065 3.39814627 3.39894879 3.40159785 3.40180385 3.40383527
 3.40510744 3.40826152 3.40840859 3.41412202 3.4165306  3.42229825
 3.43309362 3.43395127 3.43759514 3.47185306 3.47657554 3.47751105
 3.480508   3.51177991 3.55008545 3.5911665  3.59178064 3.60572502
 3.60641899 3.60738382 3.6075838  3.6187354  3.62333684 3.64665313
 3.66459724 3.76538559 3.77122463 3.77661072 3.77792669 3.78711807
 3.79097378 3.79535551 3.80419326 3.80578972 3.81579495 4.13334987
 4.18183922 4.23257519 4.26699893 4.32150214 4.35479185 4.68254897
 4.68738328 4.6969955  4.69892636 4.74217176 4.74549137 4.74558096
 4.76057304 4.76138113 4.7634879  4.77057674 4.7730137  4.77418312
 4.77454719 4.77480885 4.7753075  4.77774168 4.77971721 4.77978783
 4.78196667 4.78352492 4.78611304 4.78708641 4.78738452 4.78801437
 4.79290002 4.79413567 4.79419132 4.79497135 4.79971705 4.80104913
 4.86057378 4.89661901 4.91535439 4.94999135]

  warnings.warn(

2022-12-16 10:37:02,408:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.71313581 1.71334218 2.02056489 2.04052989 2.06192458 2.06292628
 2.07566096 2.09239389 2.09744265 2.11205425 2.11418322 2.13416538
 2.16175564 2.30713136 2.69390688 2.78338308 2.78699407 2.80683668
 2.82142785 2.83130863 2.85230684 2.8558997  2.87825024 2.88451279
 2.88723309 2.88779711 2.91135066 2.91254399 2.91296533 2.91593015
 2.91793142 2.9220038  2.9226296  2.93424551 2.93433461 2.93502625
 2.93977318 2.94116238 2.94227468 2.94786762 2.94914796 2.95103234
 2.953427   2.95377942 2.95419642 2.95514527 2.95557366 2.95700425
 2.95721281 2.9584069  2.95934699 2.96105202 2.96199565 2.96569261
 2.96861129 2.96878613 2.97007696 2.97125882 2.97156645 2.97356302
 2.97450946 2.97600997 2.97714955 2.97772222 2.97792461 2.9779728
 2.97811166 2.97831973 2.97955505 2.97995536 2.979962   2.98016613
 2.98052608 2.98109669 2.9817253  2.98174367 2.98192031 2.98206625
 2.9829028  2.98345687 2.98373192 2.98377261 2.9840059  2.98430685
 2.98450638 2.98471705 2.98508318 2.98643421 2.98668029 2.98768646
 2.98773758 2.98850989 2.98884618 2.9899738  2.99150366 2.99176015
 2.9920169  2.99452307 2.99566246 2.99795989 2.9984779  2.99859349
 2.99937146 3.002828   3.0031099  3.00348139 3.00359012 3.00401786
 3.00452545 3.00460774 3.00625051 3.00632816 3.00740837 3.00747046
 3.00835747 3.00862702 3.00876791 3.01014679 3.01248852 3.01406322
 3.01410423 3.01502379 3.01563597 3.0159127  3.0168114  3.02108107
 3.02272391 3.02400035 3.02510846 3.02960505 3.03034537 3.0343756
 3.0469785  3.04756046 3.04887671 3.05002685 3.05086535 3.05414929
 3.05769492 3.06010636 3.06042086 3.06169106 3.06413588 3.06871653
 3.06978091 3.06991539 3.07750598 3.07924615 3.08192747 3.08193106
 3.08293136 3.08518092 3.09051752 3.09087966 3.09314214 3.09429902
 3.09463192 3.0949873  3.09540327 3.09609401 3.09774888 3.09832816
 3.09981369 3.10069434 3.10072761 3.10719256 3.10833499 3.10889667
 3.10927488 3.10953979 3.10962607 3.1098224  3.11006203 3.11039972
 3.11054289 3.1110172  3.1110459  3.11115143 3.11119626 3.1112102
 3.1119144  3.11261439 3.11274844 3.11282478 3.11288414 3.11300359
 3.11305027 3.11352722 3.11392425 3.11442551 3.11522977 3.11531364
 3.11564778 3.11571491 3.11645523 3.11650219 3.11924434 3.12005168
 3.12006697 3.12048572 3.12071806 3.12169118 3.12239071 3.122665
 3.12352309 3.12446514 3.12557855 3.12613233 3.12628436 3.12696742
 3.12892036 3.12934741 3.13029332 3.13100044 3.1315796  3.13183534
 3.13251118 3.13460959 3.13533905 3.13579087 3.13603007 3.1362886
 3.13669875 3.13676093 3.13680768 3.13681975 3.13687823 3.13690479
 3.13726096 3.13759957 3.13763846 3.13809989 3.13858661 3.13877244
 3.13878105 3.13883362 3.13913853 3.13929614 3.13957729 3.13961662
 3.13981614 3.13996618 3.140619   3.14157749 3.14180335 3.14234542
 3.14267313 3.14279695 3.14302933 3.14303008 3.14312698 3.14316059
 3.14394557 3.14419216 3.14630933 3.14664508 3.14676403 3.14783418
 3.14832116 3.14867081 3.1498882  3.15063349 3.15090253 3.15122857
 3.15131951 3.15139164 3.1521372  3.15231527 3.15275598 3.15294524
 3.15325018 3.15341401 3.15342898 3.15356075 3.15363239 3.15371968
 3.15378208 3.15386873 3.15395109 3.15398209 3.15406222 3.15417844
 3.15428847 3.1544497  3.15446732 3.15478634 3.15566496 3.1557476
 3.155781   3.1561062  3.15647947 3.15686926 3.15709495 3.15734477
 3.15745672 3.15767465 3.15783296 3.15840582 3.15899329 3.15901734
 3.15923492 3.15923567 3.15963895 3.16032118 3.16049284 3.16133788
 3.16185214 3.16216223 3.16226154 3.16259165 3.16263718 3.16339968
 3.16341201 3.1634306  3.1636219  3.16420451 3.16486877 3.16496739
 3.16545277 3.16560013 3.16569256 3.16587402 3.16616752 3.16623813
 3.16647583 3.16699525 3.16764715 3.16779471 3.16807998 3.16841539
 3.16885263 3.16951694 3.16976099 3.1702345  3.17053081 3.17157553
 3.17165827 3.17269943 3.17304158 3.1730955  3.17353313 3.17396414
 3.17400421 3.17432952 3.17447953 3.1753039  3.17548468 3.17556113
 3.17556501 3.17559005 3.17587258 3.17615982 3.17633164 3.17639606
 3.17700339 3.17703594 3.17709541 3.17756705 3.17757277 3.17770463
 3.17781651 3.17784032 3.17785744 3.17805268 3.17812597 3.17819599
 3.17819897 3.17841372 3.17853241 3.17887735 3.17909206 3.17939114
 3.17942426 3.17942973 3.17945766 3.17963344 3.1797063  3.17974887
 3.1798831  3.17996732 3.18052518 3.18068334 3.18100982 3.18108424
 3.18129292 3.18132214 3.18138808 3.18144737 3.18150734 3.18161714
 3.1817126  3.18187792 3.18195359 3.18200811 3.18201497 3.18230278
 3.18247724 3.18251067 3.18260792 3.18262257 3.18287358 3.18292988
 3.18299046 3.18306326 3.18311428 3.18359641 3.18396357 3.18404719
 3.1840885  3.18409292 3.18409829 3.18425422 3.18429616 3.18439336
 3.18465763 3.1847175  3.18479368 3.18487971 3.18490768 3.18572988
 3.18600971 3.18609452 3.18625124 3.1862729  3.18662721 3.18686335
 3.18722682 3.18725225 3.18725314 3.18776395 3.18778424 3.18799962
 3.18831752 3.18836809 3.18841415 3.18843831 3.18864637 3.18889709
 3.18891302 3.18954336 3.19027423 3.19042346 3.19056908 3.19062282
 3.19126259 3.19192866 3.19296867 3.1933333  3.1934222  3.19351892
 3.19383493 3.19405169 3.19425793 3.19474444 3.19486934 3.19515818
 3.19526619 3.19755098 3.19780371 3.19794556 3.19795264 3.19801358
 3.19838844 3.19867265 3.19945326 3.20010627 3.20030069 3.20071489
 3.20103852 3.20119322 3.20123224 3.20128484 3.20146939 3.20183165
 3.2020039  3.20212429 3.20270014 3.20311828 3.20328857 3.20344866
 3.2034707  3.20358269 3.20365143 3.20365582 3.20367871 3.20374778
 3.20379139 3.20385019 3.20390981 3.20394619 3.20420568 3.20423804
 3.20442061 3.20458353 3.20481764 3.20517218 3.20520044 3.20541101
 3.20563282 3.20583398 3.20584093 3.20611138 3.20611292 3.20634752
 3.20652949 3.20685031 3.20688855 3.20706543 3.20721665 3.20775066
 3.20792898 3.20818065 3.20855047 3.20860199 3.20868111 3.20878385
 3.20880152 3.20887331 3.20901162 3.20901817 3.20979161 3.2104393
 3.21081395 3.21094179 3.21131416 3.21141787 3.21151226 3.21155411
 3.21194215 3.2126704  3.21270088 3.21305669 3.21346249 3.21368586
 3.21430136 3.21459501 3.21505707 3.21512977 3.21518219 3.2152461
 3.2153293  3.21557012 3.21652311 3.21699526 3.21780022 3.21822833
 3.21825414 3.21826686 3.21869196 3.21876029 3.21910679 3.22123638
 3.22208884 3.22242685 3.22247969 3.22344074 3.22345122 3.22351902
 3.2236257  3.22363381 3.22394868 3.22476551 3.22478829 3.22493326
 3.22497098 3.22509571 3.22562316 3.22589934 3.22630198 3.22691172
 3.22789166 3.22794735 3.2281278  3.22829106 3.22829809 3.22838255
 3.2285161  3.22918406 3.2292621  3.22975455 3.22995298 3.22999122
 3.23005967 3.23029582 3.23051736 3.23067759 3.23108024 3.23121561
 3.23200921 3.2320116  3.23226119 3.23297387 3.23316931 3.23365967
 3.23502103 3.23536538 3.23625546 3.23683116 3.238039   3.23914788
 3.23960706 3.24030397 3.24267013 3.24440674 3.24490775 3.24509503
 3.24523833 3.24761312 3.24849372 3.24861158 3.24898021 3.24916531
 3.24942869 3.24994489 3.24999969 3.25010957 3.25011441 3.2507369
 3.25080392 3.25122047 3.25148563 3.25233669 3.25309144 3.25392623
 3.25623095 3.25751625 3.2577685  3.25796998 3.2585648  3.25857747
 3.259114   3.2591256  3.26123774 3.26245678 3.2627327  3.26307012
 3.26706914 3.27218658 3.27263685 3.27285809 3.27363263 3.27410393
 3.27721448 3.28222647 3.28232779 3.28313263 3.28460145 3.28594898
 3.28909365 3.28944239 3.29059906 3.2914445  3.29156992 3.29229866
 3.2927831  3.29309186 3.29365136 3.29427845 3.29588425 3.29634493
 3.29690533 3.29694676 3.29783349 3.29908291 3.29999955 3.30151843
 3.30221769 3.30547503 3.30636365 3.30637296 3.30704588 3.30713976
 3.30834333 3.31025936 3.31026191 3.31318585 3.31375362 3.3147048
 3.31484969 3.31502652 3.31572625 3.31597274 3.31826819 3.31861483
 3.31941236 3.31965958 3.32050823 3.32124556 3.32201352 3.32279447
 3.32338389 3.32585763 3.32717024 3.32748143 3.32933382 3.32978111
 3.33173331 3.33232035 3.33277009 3.33351406 3.33567822 3.33643147
 3.33701139 3.33778841 3.3382409  3.34028289 3.34064725 3.3419059
 3.34239807 3.34453275 3.34472055 3.34502357 3.34610474 3.346323
 3.34710037 3.34790802 3.34944055 3.35003501 3.35059336 3.35118881
 3.3540148  3.35423703 3.35499514 3.35686243 3.3575554  3.35800257
 3.35855398 3.35874241 3.35930297 3.35977662 3.3604659  3.36232598
 3.3624713  3.36386742 3.36675454 3.36738304 3.36834394 3.36998805
 3.37016825 3.37193338 3.3745289  3.37883078 3.37911939 3.3797748
 3.38019059 3.38364312 3.38538422 3.38736893 3.38748822 3.39015185
 3.39066362 3.39103413 3.39119419 3.39131993 3.392664   3.39520937
 3.39533953 3.39783919 3.39802225 3.39874564 3.40010525 3.4015695
 3.40193739 3.40307146 3.40317001 3.40329225 3.40333614 3.4049073
 3.40546477 3.4059141  3.40793503 3.41123435 3.4119454  3.41336135
 3.42330655 3.42449239 3.42873494 3.4287737  3.43647267 3.4371627
 3.43821037 3.46052691 3.4749492  3.48213335 3.48884093 3.51086829
 3.51411044 3.51466655 3.5155857  3.51847042 3.52354872 3.52963281
 3.53038846 3.5499753  3.55640656 3.56520409 3.57274383 3.58341329
 3.58930126 3.64700403 3.64840588 3.6683324  3.676687   3.67990377
 3.70331582 3.78584796 3.81347843 3.85307343 3.85380773 3.85952621
 3.87253346 3.87574186 3.88139859 3.88945263 3.96538318 3.9702444
 4.02754505 4.07193552 4.07473994 4.15987594 4.30191005 4.329498
 4.73168842 4.75560753 4.75887336 4.77094592 4.7727405  4.77725044
 4.77922525 4.78459779 4.78560955 4.78898149 4.79498298 4.79891152
 4.79977918 4.80067668 4.80240605 4.80328073 4.80446552 4.80542003
 4.80691069 4.80714975 4.8114535  4.81332518 4.81538355 4.82374069
 4.82797098 4.84090861 4.84655236 4.90844827 4.91156046 4.91390992
 4.92912368 4.93799178 4.95569779 5.01954529]

  warnings.warn(

2022-12-16 10:37:02,409:INFO:Calculating mean and std
2022-12-16 10:37:02,410:INFO:Creating metrics dataframe
2022-12-16 10:37:02,414:INFO:Uploading results into container
2022-12-16 10:37:02,415:INFO:Uploading model into container now
2022-12-16 10:37:02,415:INFO:master_model_container: 15
2022-12-16 10:37:02,415:INFO:display_container: 2
2022-12-16 10:37:02,416:INFO:BayesianRidge()
2022-12-16 10:37:02,416:INFO:create_model() successfully completed......................................
2022-12-16 10:37:02,566:WARNING:create_model() for BayesianRidge() raised an exception or returned all 0.0, trying without fit_kwargs:
2022-12-16 10:37:02,567:WARNING:Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 795, in compare_models
    assert (
AssertionError

2022-12-16 10:37:02,567:INFO:Initializing create_model()
2022-12-16 10:37:02,567:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002281239F8E0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022810EC8B20>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:37:02,567:INFO:Checking exceptions
2022-12-16 10:37:02,570:INFO:Importing libraries
2022-12-16 10:37:02,570:INFO:Copying training dataset
2022-12-16 10:37:02,576:INFO:Defining folds
2022-12-16 10:37:02,577:INFO:Declaring metric variables
2022-12-16 10:37:02,577:INFO:Importing untrained model
2022-12-16 10:37:02,577:INFO:Bayesian Ridge Imported successfully
2022-12-16 10:37:02,577:INFO:Starting cross validation
2022-12-16 10:37:02,579:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:37:04,584:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.69554868 1.70016723 1.7078496  1.91382892 1.95625996 1.97610903
 1.97853834 1.98243821 1.99135543 2.005331   2.02165768 2.20510007
 2.56828976 2.78252209 2.86346406 2.90072804 2.9048025  2.9147401
 2.92770079 2.94046497 2.94171419 2.94180193 2.94333382 2.94896163
 2.95532411 2.95643648 2.95739878 2.95910272 2.96006316 2.96197618
 2.96437536 2.96598277 2.96606786 2.96710729 2.96853452 2.97182417
 2.97251686 2.97283864 2.97474797 2.97519685 2.97633094 2.97765105
 2.9787463  2.98043642 2.98489974 2.98528975 2.98619627 2.98676605
 2.98730342 2.98884964 2.99008638 2.99034404 2.99149919 2.99182263
 2.9933293  2.99399377 2.99469472 2.99615058 2.99668499 2.99735599
 2.99787848 2.99881757 2.99909149 2.99925283 3.0000144  3.0001518
 3.0005897  3.00088076 3.00140817 3.0017161  3.00224199 3.00259793
 3.00377987 3.00398301 3.00469811 3.00497335 3.00497842 3.00611054
 3.00627871 3.00794867 3.00859827 3.00869297 3.01140206 3.01267962
 3.01272034 3.01380791 3.01385383 3.01469352 3.01475968 3.01564918
 3.01574764 3.01732064 3.01779044 3.01803235 3.01858327 3.01873499
 3.02063968 3.02134972 3.02144505 3.02287425 3.02788666 3.02893728
 3.02944782 3.02993669 3.03032064 3.03098617 3.03116001 3.03117335
 3.03282088 3.03285744 3.03315675 3.03338265 3.03344195 3.03511603
 3.03551555 3.03721956 3.03759717 3.03807772 3.03974736 3.04255774
 3.04393156 3.0446834  3.0464588  3.04690035 3.0469754  3.04793124
 3.04866055 3.05134416 3.05151842 3.05602256 3.0597744  3.06127723
 3.06351162 3.06578931 3.06762962 3.06993464 3.07087295 3.07239964
 3.07254208 3.07979672 3.08069674 3.08302237 3.08706977 3.08713525
 3.08837091 3.08854919 3.08931152 3.09163555 3.09386925 3.09496446
 3.09535585 3.09778336 3.09883992 3.09938249 3.09942708 3.10064856
 3.10073134 3.10138578 3.10277345 3.10407609 3.10501478 3.10556091
 3.10569182 3.10718122 3.10730643 3.10918018 3.10927488 3.11281153
 3.11340095 3.11371886 3.11442146 3.11498332 3.11574759 3.11587927
 3.11649675 3.11832506 3.11846366 3.11848657 3.11851581 3.11903112
 3.1196555  3.11982834 3.11994229 3.11995021 3.12016534 3.12086217
 3.12107698 3.12149644 3.12181299 3.12228434 3.12439907 3.1263721
 3.12659165 3.12726316 3.12748813 3.12793915 3.12882782 3.1304857
 3.1305466  3.13128918 3.13177264 3.13186192 3.13186262 3.13220429
 3.13271162 3.13293128 3.13316547 3.13366345 3.13519509 3.13519821
 3.13558979 3.13696512 3.13719238 3.13724027 3.13758245 3.13801012
 3.13846802 3.13944215 3.13987778 3.14111534 3.14128948 3.14197302
 3.14307649 3.14314751 3.14347878 3.1437969  3.14409574 3.14459733
 3.1449533  3.14524126 3.14527632 3.14557364 3.1457661  3.14579068
 3.14673576 3.14693375 3.14701055 3.1474245  3.14797579 3.14831435
 3.14832692 3.14848568 3.14852649 3.1493529  3.14936399 3.14980449
 3.14995495 3.15021785 3.15028309 3.1504154  3.15044602 3.15054125
 3.15055373 3.15112475 3.15151236 3.1525369  3.15258972 3.15280988
 3.15379462 3.15410042 3.15444631 3.15447886 3.15457072 3.15464431
 3.15467406 3.15474869 3.15505978 3.15510119 3.15545003 3.1557541
 3.15705812 3.15718947 3.15732388 3.15765361 3.15769249 3.15811781
 3.15816186 3.15840479 3.15849655 3.15853647 3.15898876 3.15965067
 3.15975537 3.16061346 3.16061423 3.16088311 3.16091635 3.16122833
 3.16125777 3.16126182 3.16129947 3.16206267 3.16228103 3.16275898
 3.16286908 3.16347871 3.16360852 3.1636346  3.16406215 3.16447475
 3.164634   3.16484564 3.16499314 3.16528887 3.16554874 3.16555061
 3.16555459 3.1656308  3.1657367  3.1658543  3.16601578 3.16624596
 3.16625844 3.16632905 3.1666903  3.16675953 3.16685841 3.16745985
 3.16790768 3.16799758 3.16811157 3.16815471 3.16831245 3.16835091
 3.16859153 3.16860907 3.16867845 3.16873775 3.16900607 3.16908784
 3.16909108 3.16935181 3.16962076 3.1706544  3.17120467 3.17124286
 3.17129741 3.17142088 3.17146966 3.17201509 3.17212085 3.17239059
 3.1727801  3.17297757 3.17359025 3.17398452 3.17427254 3.17434839
 3.17455507 3.17464359 3.17465011 3.17500771 3.17515624 3.1752936
 3.17538806 3.17638942 3.17646118 3.17655991 3.17660537 3.176815
 3.17689982 3.17743693 3.17754971 3.1775914  3.17781871 3.17798714
 3.17809779 3.17818553 3.17829107 3.17829705 3.1783876  3.17850255
 3.17885923 3.17887678 3.17911979 3.17944953 3.17962195 3.1797326
 3.18044812 3.18076159 3.18078353 3.18096312 3.18112008 3.18113256
 3.18117308 3.18119202 3.18147333 3.18172574 3.18195766 3.18204181
 3.18204377 3.18220575 3.18226937 3.18228009 3.1826888  3.18303282
 3.18321588 3.18338051 3.18364194 3.1841239  3.18433449 3.18434517
 3.1843734  3.18521571 3.1854631  3.18587243 3.1859025  3.18599701
 3.1864507  3.18668499 3.18672348 3.18683564 3.18690201 3.18691344
 3.18714505 3.18731248 3.18738188 3.18765418 3.18772936 3.18816374
 3.1882021  3.18900373 3.1891975  3.18972251 3.18990149 3.18990631
 3.18992973 3.19034176 3.19076504 3.19078527 3.19091467 3.19096783
 3.19155465 3.19162131 3.19164196 3.19173181 3.19180286 3.19187187
 3.19205018 3.19212769 3.19213609 3.19231485 3.19250939 3.19274356
 3.19275562 3.19308872 3.19341683 3.1937275  3.19373667 3.19376554
 3.19408724 3.19419484 3.19439067 3.19463424 3.19467586 3.19516013
 3.19535066 3.19590671 3.19648104 3.1964919  3.19659723 3.19698418
 3.19698766 3.19721644 3.19781027 3.19781347 3.19789678 3.19792999
 3.19838279 3.19839688 3.19848997 3.19868983 3.19877924 3.19882038
 3.19887419 3.19919275 3.1992175  3.2001999  3.20116867 3.20155356
 3.20184321 3.20186973 3.20192036 3.20199236 3.20206725 3.20232391
 3.20233564 3.2023562  3.20246387 3.2026405  3.20331543 3.20334974
 3.20348856 3.20377866 3.20391403 3.20417756 3.20517255 3.20532896
 3.20538637 3.20579642 3.20583005 3.20583617 3.20600907 3.20647463
 3.20656501 3.20662279 3.20698978 3.20763218 3.20773582 3.20785789
 3.20809029 3.20825971 3.20911549 3.20933632 3.20977908 3.21003776
 3.21009478 3.21009718 3.21016459 3.210305   3.21039138 3.21047707
 3.21070713 3.21076677 3.2111098  3.21126649 3.21146425 3.21161063
 3.21187011 3.21201364 3.2120722  3.21226869 3.21280397 3.21292882
 3.21303292 3.2146229  3.21530305 3.21547839 3.2155443  3.2156212
 3.21565483 3.21568784 3.21571158 3.2165459  3.21743812 3.21757543
 3.21849977 3.21890682 3.21922388 3.21927824 3.21934217 3.21971726
 3.22045678 3.22051997 3.22053615 3.22123964 3.22150642 3.22195272
 3.22215798 3.22219262 3.22231235 3.22238747 3.22255821 3.22275473
 3.22295415 3.22303421 3.22337523 3.22362205 3.22414084 3.2243848
 3.2246457  3.224654   3.22475907 3.22566834 3.22589938 3.22618091
 3.22675172 3.22676357 3.22734754 3.22759786 3.22843518 3.22883625
 3.22958673 3.22971586 3.22989537 3.22995624 3.23006999 3.23044026
 3.23073139 3.23171036 3.23209135 3.23224219 3.23254486 3.23366685
 3.23411231 3.23452202 3.23472494 3.23579272 3.23606744 3.23639293
 3.23661464 3.23799909 3.2381471  3.238245   3.23890226 3.23909015
 3.23943448 3.23972187 3.24008623 3.24048621 3.24048622 3.24174956
 3.24242498 3.24303187 3.24381596 3.2443246  3.24522802 3.24570294
 3.24660629 3.24723075 3.24757978 3.24761782 3.24785712 3.24820557
 3.24864551 3.2493623  3.24959381 3.24974193 3.25012458 3.25033347
 3.25215034 3.25242794 3.25331182 3.25375114 3.25486926 3.25537766
 3.25587088 3.25600465 3.2569424  3.25839155 3.25840227 3.25849871
 3.25851257 3.25866526 3.25903803 3.25908842 3.25996418 3.26066742
 3.26078228 3.26312278 3.26343499 3.26375584 3.26382359 3.26541693
 3.26568778 3.26780972 3.26788543 3.2685235  3.26859666 3.26876664
 3.26936868 3.26938041 3.27130106 3.27156647 3.27640507 3.27787279
 3.2781054  3.27892934 3.27929713 3.27964961 3.28208232 3.28355049
 3.28382622 3.28383011 3.2849186  3.28584714 3.2873406  3.28764831
 3.28802858 3.28865538 3.29058028 3.29110312 3.29212439 3.29386758
 3.29588152 3.29740452 3.29797894 3.30002487 3.30046185 3.30288254
 3.3029578  3.30299978 3.30366334 3.3057937  3.30588109 3.30613181
 3.3080735  3.30917265 3.30917285 3.3101603  3.31095825 3.31323494
 3.31437365 3.31498423 3.31688133 3.31723738 3.31744318 3.31909813
 3.32158556 3.32307024 3.32339534 3.32417619 3.32486051 3.32707622
 3.32895218 3.33113825 3.33360598 3.33691552 3.33715294 3.33807651
 3.33814843 3.33831829 3.33953404 3.34167955 3.3435168  3.34455597
 3.34582941 3.34604742 3.34667288 3.3484356  3.35037016 3.35456242
 3.35574336 3.35713797 3.35726386 3.35930021 3.35995247 3.36196656
 3.3621847  3.36240403 3.36246585 3.36363687 3.36435586 3.36445009
 3.36464218 3.36605499 3.36842387 3.37330437 3.37351256 3.3748795
 3.37583105 3.37646352 3.37730372 3.37758573 3.37782436 3.37850632
 3.3788119  3.37883123 3.37958458 3.37974789 3.38065446 3.38068629
 3.38106077 3.38158275 3.38162075 3.38207967 3.38367026 3.38461862
 3.38906041 3.38956248 3.39001435 3.39058182 3.39120677 3.39171349
 3.39188717 3.39300418 3.39324832 3.3935757  3.39362534 3.39563135
 3.3956489  3.40063134 3.40184366 3.4032743  3.40424558 3.40532712
 3.4057675  3.40599686 3.40731365 3.4129386  3.41433    3.41606371
 3.41731449 3.41810611 3.43494375 3.43764823 3.43937359 3.44840444
 3.44977433 3.45332995 3.46400661 3.46619169 3.46887616 3.47104646
 3.49592075 3.53361241 3.55069029 3.57808948 3.65276035 3.66754087
 3.75186106 3.79826716 3.80681565 3.80682146 3.80834287 3.81336947
 3.83417671 3.84799004 3.88358685 3.9403446  3.98152931 4.12092223
 4.1271373  4.14065091 4.50161678 4.53732247 4.75941827 4.77366203
 4.78830069 4.80044247 4.80464877 4.80677034 4.80830785 4.80916331
 4.81077326 4.81247153 4.81418309 4.81787663 4.81828627 4.81879552
 4.8207391  4.82103124 4.82294313 4.82822724 4.82844529 4.83905285
 4.84271061 4.8448199  4.86828185 4.87754468 4.88277862 4.91050332
 4.9275422  4.9368458  4.94055622 4.94241258 5.05206816]

  warnings.warn(

2022-12-16 10:37:04,695:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.72307187 1.92337644 1.96260522 1.97265793 2.12155281 2.18271353
 2.60633368 2.61745456 2.88234363 2.90647462 2.90871976 2.9123764
 2.92433271 2.94399865 2.94665062 2.95150849 2.95387004 2.95585661
 2.95697807 2.95703292 2.96179714 2.9623623  2.96446655 2.96597012
 2.96784041 2.97078174 2.9710683  2.97308594 2.9744938  2.97504237
 2.97585577 2.97597412 2.97703587 2.97929909 2.9810201  2.98108952
 2.98227837 2.98272007 2.98463164 2.98549143 2.9860479  2.98668006
 2.98749054 2.98992941 2.99074254 2.99110225 2.99142872 2.99175572
 2.992133   2.99214224 2.99257929 2.99292657 2.99447394 2.99589732
 2.99598379 2.9975029  2.99760501 2.99839331 2.99879903 2.99929549
 2.99935412 3.00185397 3.00226345 3.00304894 3.00517861 3.00578791
 3.00759701 3.0081203  3.00824476 3.00926394 3.00973393 3.01082189
 3.01115982 3.01187128 3.01311002 3.01335619 3.0138577  3.01453485
 3.01566402 3.01654818 3.01676715 3.01865406 3.0193914  3.01973176
 3.02022348 3.020671   3.0219743  3.02309304 3.02352413 3.02549398
 3.02550377 3.02553509 3.02683068 3.0278487  3.03266162 3.03545179
 3.04373569 3.04492875 3.04561843 3.0473355  3.0490227  3.05209093
 3.05464239 3.05485363 3.05725281 3.0576192  3.05880934 3.0620419
 3.06326354 3.06747177 3.07562189 3.07732808 3.07765997 3.07924089
 3.08150524 3.08648152 3.0878057  3.08910686 3.09098214 3.09150795
 3.09232799 3.09322321 3.09362352 3.09420366 3.09732751 3.09764569
 3.0985123  3.09918062 3.09929081 3.1002786  3.1036038  3.10586558
 3.10642449 3.10753895 3.10974332 3.11079798 3.11089829 3.11097786
 3.11173991 3.11232606 3.11257921 3.11282402 3.11293934 3.1134984
 3.11361855 3.11404848 3.11406092 3.11421287 3.11451289 3.11496869
 3.11822846 3.11876354 3.11883486 3.11909718 3.11970685 3.12059967
 3.12062552 3.12106495 3.12217217 3.12244862 3.12252878 3.12332209
 3.12384649 3.12402811 3.12412768 3.1249741  3.12532605 3.12571334
 3.12760296 3.12764738 3.12863621 3.12892068 3.12906118 3.12942677
 3.12956626 3.12958426 3.12961318 3.12962776 3.12983403 3.13006331
 3.13058354 3.13087362 3.13175294 3.13190119 3.1320126  3.13201496
 3.13244782 3.13246772 3.13309659 3.13348179 3.13369786 3.13402533
 3.13405233 3.13447458 3.13467258 3.13494156 3.1356957  3.13575505
 3.13577042 3.13589378 3.13631888 3.13655995 3.13665298 3.13674273
 3.13713984 3.13716191 3.13770838 3.1379599  3.13835911 3.13858848
 3.1386096  3.13880019 3.13907073 3.13928341 3.13929076 3.13935943
 3.13942084 3.13944602 3.13953055 3.13961956 3.13995994 3.14037097
 3.14051638 3.14085432 3.14110081 3.14129675 3.141329   3.1417461
 3.14186207 3.14262372 3.14312311 3.14313862 3.14377699 3.14404499
 3.14413857 3.14417533 3.14418802 3.14419163 3.14446719 3.14490612
 3.14499167 3.14534225 3.14558494 3.14601339 3.14682497 3.14720397
 3.14752961 3.14763727 3.14772849 3.14775427 3.14778955 3.14847319
 3.14890094 3.14934334 3.14960419 3.14964297 3.14982867 3.14995571
 3.15001251 3.1501354  3.15014408 3.15020123 3.1506921  3.15082233
 3.15101052 3.1510834  3.15156812 3.1518235  3.15230903 3.15236362
 3.15283234 3.15305356 3.15321382 3.1532828  3.15337655 3.15345649
 3.15401554 3.15491464 3.15495452 3.1553375  3.15542914 3.15585665
 3.155923   3.15605636 3.15637539 3.15641179 3.1572405  3.15735233
 3.15740753 3.15749636 3.15801451 3.15812251 3.15827079 3.15874248
 3.15916008 3.15924038 3.1593957  3.15945365 3.16032121 3.16056019
 3.16064522 3.1606616  3.16088785 3.16092337 3.16096743 3.16128696
 3.16151618 3.16161685 3.16167425 3.16171664 3.16182585 3.16210439
 3.16216732 3.16217509 3.1622436  3.16244958 3.16256895 3.16270116
 3.16285431 3.16288053 3.16296979 3.16299343 3.16322828 3.16376576
 3.16414355 3.1641529  3.16437922 3.16465003 3.16494712 3.16513677
 3.16530129 3.16545871 3.16549719 3.16557485 3.16560408 3.16575311
 3.1657665  3.16585915 3.16616495 3.16636967 3.16641617 3.16657284
 3.16693548 3.16708321 3.16712801 3.16756701 3.16765781 3.16769083
 3.16773375 3.16785987 3.1679072  3.16852615 3.16896141 3.16902662
 3.16908396 3.16938962 3.16943609 3.16957956 3.16966436 3.16976418
 3.17008212 3.17028905 3.17040332 3.17049086 3.17067113 3.17072877
 3.17084196 3.1711232  3.17133585 3.17149944 3.17158288 3.17165052
 3.17167082 3.17171052 3.17173883 3.17188184 3.17191574 3.17219272
 3.17305309 3.17306619 3.17306779 3.17308844 3.17309729 3.1732414
 3.17338323 3.17341465 3.17358944 3.17373428 3.17379778 3.17411947
 3.17414376 3.17441921 3.17449903 3.17477689 3.17490567 3.17514467
 3.17530474 3.17531262 3.17534256 3.17544316 3.17549556 3.17556798
 3.17574382 3.17587946 3.17602134 3.1760957  3.17620868 3.17629608
 3.17684207 3.17720806 3.1773296  3.1776461  3.17772622 3.17785924
 3.17789884 3.1781961  3.17822578 3.1783973  3.17849466 3.1791771
 3.17926353 3.17940122 3.17955676 3.17991026 3.1799287  3.18022992
 3.18080531 3.18086997 3.18087813 3.18134565 3.18134743 3.18143408
 3.18150159 3.18150513 3.18158704 3.18175269 3.18178059 3.18227323
 3.182507   3.1825968  3.18287087 3.18301481 3.18308852 3.18346556
 3.18373906 3.18380073 3.18395792 3.18425806 3.18435045 3.18446138
 3.18496736 3.18524369 3.18535173 3.18543478 3.18557963 3.18594358
 3.18605147 3.18611559 3.18673725 3.18746841 3.18808958 3.18819594
 3.1882124  3.18825166 3.18846729 3.18877658 3.18911519 3.18990742
 3.19018434 3.19021288 3.19029447 3.19178923 3.19195017 3.1922619
 3.19275951 3.1930771  3.19310434 3.19369588 3.19375466 3.1939503
 3.1945502  3.19467516 3.19475914 3.19493485 3.19531165 3.19537912
 3.19545283 3.19591694 3.19640253 3.19693842 3.19697151 3.1970018
 3.19714651 3.19721862 3.19747006 3.19763049 3.1977694  3.1982337
 3.19832282 3.1985377  3.19876525 3.19923685 3.19972896 3.20004125
 3.20010515 3.20029095 3.20031405 3.20095908 3.20104032 3.20113915
 3.20148634 3.20193797 3.20202291 3.20205767 3.20210563 3.20240237
 3.20244988 3.20285803 3.20295058 3.2035497  3.20386861 3.20387857
 3.20393926 3.20416788 3.20421162 3.20423716 3.20425398 3.20448203
 3.20531286 3.20534138 3.2053802  3.20544904 3.20548361 3.20603526
 3.20609621 3.20637853 3.20687657 3.20693253 3.20798236 3.20809244
 3.20819814 3.2084794  3.20873287 3.20880139 3.20897887 3.21008608
 3.21010378 3.21064898 3.21237079 3.2124959  3.21280879 3.21304936
 3.21373076 3.21406518 3.21467549 3.21509516 3.21557037 3.21608517
 3.21635389 3.21643176 3.21649464 3.21689331 3.21694111 3.21727118
 3.21771194 3.21784426 3.2181911  3.21871732 3.21891814 3.21895238
 3.21919384 3.2203396  3.22063049 3.22071773 3.22089908 3.22298845
 3.22371477 3.22396433 3.22410306 3.22411667 3.22423569 3.22577654
 3.22594478 3.22695171 3.22742059 3.22802524 3.22837572 3.22840644
 3.22998812 3.23087731 3.2309526  3.23133356 3.23160658 3.23168848
 3.23218599 3.23252477 3.23468006 3.23682817 3.23855068 3.23925387
 3.23938991 3.23985402 3.24133663 3.24148556 3.24151289 3.24168831
 3.2423997  3.24284261 3.24325152 3.24355856 3.24465547 3.2453665
 3.24547744 3.24571563 3.24631065 3.24657347 3.24761253 3.24874364
 3.24909658 3.25041036 3.25156297 3.25223141 3.25242206 3.25262116
 3.25283914 3.25358586 3.25411284 3.25454436 3.25459348 3.25511514
 3.25643472 3.25732795 3.25806385 3.25834501 3.25845165 3.25894607
 3.25902988 3.25909228 3.25917962 3.25927362 3.25967494 3.26108259
 3.26235354 3.262599   3.26555868 3.26583037 3.2658477  3.26605511
 3.26682323 3.26739591 3.26780538 3.26813989 3.2688039  3.26882367
 3.26922409 3.27156519 3.27300888 3.27430485 3.27498358 3.27518076
 3.27576336 3.27603415 3.27619016 3.27703353 3.2773222  3.27734734
 3.27809053 3.27862706 3.27871251 3.27898828 3.27928747 3.28078271
 3.2807889  3.28326624 3.28382    3.28397569 3.284725   3.28490192
 3.28512021 3.28558295 3.28665464 3.28665524 3.28737264 3.28855863
 3.28866956 3.28998602 3.29077609 3.29106301 3.29113606 3.29168796
 3.29234095 3.29337264 3.2935847  3.2944033  3.29637406 3.2967715
 3.29887731 3.30235808 3.30284002 3.3036528  3.30690887 3.30693662
 3.30701044 3.30842302 3.31213824 3.31259628 3.31522127 3.31539921
 3.31765176 3.3233016  3.32567    3.32733541 3.32880005 3.33308374
 3.33523284 3.33539906 3.33671174 3.33705111 3.33738503 3.33838555
 3.340025   3.3401796  3.34195964 3.34892479 3.35409626 3.35615963
 3.35751684 3.35777276 3.35880845 3.36451879 3.36595522 3.36599184
 3.36695673 3.36730449 3.36806819 3.37026689 3.37044093 3.37089161
 3.37188347 3.37276728 3.37385953 3.37414642 3.3742071  3.37690169
 3.37758169 3.37974081 3.38053973 3.38226034 3.38241896 3.3835295
 3.38673813 3.38778892 3.3877929  3.38851384 3.3887337  3.39079102
 3.39094808 3.39449788 3.39468937 3.40392535 3.40743549 3.41217027
 3.41354526 3.41648818 3.43533488 3.45058255 3.45460895 3.45648327
 3.4569562  3.46045369 3.46090927 3.46529862 3.4731854  3.47657412
 3.4778338  3.48303185 3.48495575 3.49252016 3.54772261 3.63524768
 3.63888004 3.64784429 3.65664103 3.66306786 3.68112151 3.68134593
 3.69214112 3.72984056 3.77042987 3.77788361 3.78523246 3.81525892
 3.81787641 3.81900789 3.8214455  3.8218695  3.82694857 3.83144778
 3.83256252 3.83588053 3.83869581 3.84159996 3.84264459 3.85307509
 3.85554067 3.85845583 3.9215509  3.93740203 3.93860606 3.96923428
 4.09708737 4.0977161  4.11854824 4.16674814 4.35405864 4.72256305
 4.73110053 4.73157807 4.75405895 4.77277303 4.77362001 4.77804416
 4.78075084 4.78156345 4.7874386  4.78963823 4.79019067 4.79043283
 4.79178967 4.79236439 4.79297923 4.7930016  4.79339208 4.79374558
 4.79390069 4.79402406 4.7969364  4.79766749 4.80596334 4.80684358
 4.8102186  4.81128811 4.81925686 4.82265251 4.82335423 4.82714791
 4.83178034 4.83480266 4.83945939 4.84462333 4.86296762 4.88303341
 4.88814221 4.89661229]

  warnings.warn(

2022-12-16 10:37:04,719:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.04575053 2.07805459 2.08071343 2.12206598 2.12210169 2.1961984
 2.73599822 2.80148421 2.83319181 2.85428888 2.85728937 2.86200521
 2.87241259 2.88718254 2.89716055 2.90372647 2.91458707 2.91628964
 2.92307131 2.92388243 2.925234   2.92695751 2.92718665 2.93096024
 2.93399101 2.9379467  2.93853138 2.94334538 2.94349252 2.94791307
 2.95160393 2.9561694  2.95991752 2.96370041 2.96494693 2.9653939
 2.96565394 2.96860599 2.96932912 2.97075401 2.97283135 2.97453704
 2.97551953 2.97583484 2.97692342 2.98064883 2.98097502 2.98225961
 2.98320756 2.98334981 2.98375132 2.98402912 2.98472481 2.98553458
 2.98810107 2.98872217 2.98915334 2.98925505 2.99134999 2.99375498
 2.99428727 2.99509186 2.99580325 2.99586004 2.99744914 2.9980227
 2.9987018  2.99881542 2.9988496  2.99913694 3.00342376 3.00352485
 3.00363107 3.00380062 3.00507082 3.00694769 3.00924546 3.01002356
 3.0114204  3.01255484 3.0127034  3.0129849  3.01493367 3.01493637
 3.01788365 3.01817776 3.01954649 3.0203651  3.02254199 3.02350409
 3.02469113 3.02565867 3.02705998 3.02822348 3.02880356 3.02937921
 3.03087233 3.03330172 3.03550824 3.03789769 3.03925129 3.03972802
 3.04023082 3.04266792 3.04336588 3.04346456 3.04392159 3.04407038
 3.04450747 3.04498969 3.04562839 3.04563892 3.04822488 3.04988282
 3.05004894 3.05141511 3.05233241 3.05531539 3.05536575 3.05578225
 3.05715141 3.05738914 3.05912863 3.06076157 3.06173066 3.06254817
 3.06298206 3.06565766 3.0658813  3.06881316 3.07026854 3.07179816
 3.07271413 3.07702398 3.07832934 3.08080383 3.0812794  3.08160273
 3.08287077 3.08329747 3.08366183 3.08409881 3.08446685 3.0847995
 3.08518654 3.08555593 3.08613745 3.08642596 3.08735696 3.08819708
 3.09248877 3.09287645 3.0930331  3.09731964 3.09888026 3.10026119
 3.10177198 3.10262096 3.10285856 3.10410388 3.10432347 3.10443479
 3.10476273 3.10648878 3.10783467 3.10957651 3.11152785 3.1117141
 3.11258479 3.11266655 3.11286797 3.11294767 3.11296237 3.11377471
 3.11397688 3.11475488 3.11486045 3.11541589 3.11560947 3.11572792
 3.11572835 3.11574831 3.11641701 3.11702573 3.11805727 3.11921956
 3.11935776 3.12013192 3.12036409 3.12052546 3.12084079 3.12187474
 3.12346362 3.12352157 3.12356579 3.12357327 3.12403773 3.12460167
 3.12466323 3.12480356 3.12482658 3.12490796 3.12535959 3.12538937
 3.12631745 3.12656762 3.12708297 3.12805003 3.12872479 3.12919911
 3.12929194 3.12947804 3.12986652 3.13030815 3.13066919 3.13159745
 3.13181765 3.13273165 3.13306397 3.13327903 3.13346548 3.13371861
 3.13375757 3.13405566 3.13406133 3.13488366 3.13541541 3.13571669
 3.13572229 3.13634606 3.13643766 3.13649001 3.13652189 3.13672799
 3.13700674 3.13770596 3.13811947 3.1384458  3.13888456 3.13918552
 3.1402528  3.14045379 3.14109183 3.14183682 3.14197557 3.14212312
 3.14286349 3.14291337 3.14384157 3.14394349 3.14435558 3.1445874
 3.14476605 3.14526129 3.1454878  3.14559968 3.14625364 3.14635
 3.14652681 3.1467257  3.14740484 3.14766496 3.14821155 3.14868495
 3.14989748 3.1500635  3.1503545  3.15051745 3.15226504 3.15292624
 3.15307225 3.15341893 3.15437718 3.15560128 3.15648603 3.15757512
 3.15776094 3.1579223  3.15830553 3.15854528 3.15873763 3.15937298
 3.15951391 3.15956724 3.15998442 3.16079685 3.16146484 3.16204252
 3.16242034 3.16309878 3.16325245 3.16334726 3.16389292 3.1639259
 3.16434265 3.16437965 3.16457355 3.16462202 3.16574604 3.16617824
 3.16644906 3.16650733 3.16681749 3.16693557 3.16697697 3.16702093
 3.16708559 3.16729959 3.16766504 3.16860439 3.16912483 3.16929705
 3.16939365 3.1697795  3.16988661 3.17027803 3.17054256 3.17054647
 3.17058629 3.17067236 3.17068435 3.1706881  3.17080582 3.17116907
 3.17149128 3.17157174 3.17207334 3.17208185 3.17214838 3.17220371
 3.1722887  3.1724853  3.17259685 3.17269039 3.17293985 3.17297146
 3.17325998 3.17338694 3.17360288 3.17365972 3.17366493 3.1736765
 3.17373847 3.17406122 3.17459096 3.17467954 3.17477747 3.17520412
 3.17539963 3.17567598 3.17595761 3.17598271 3.17602063 3.17602746
 3.17624655 3.17639393 3.17642008 3.17692426 3.17726464 3.17745942
 3.17748132 3.17751858 3.17757003 3.17793704 3.17794396 3.1780532
 3.17815865 3.1783718  3.17879796 3.17886496 3.17897341 3.17898447
 3.17899112 3.17934653 3.17970742 3.18002755 3.18047709 3.18099153
 3.18114929 3.18130253 3.18156246 3.1815748  3.18163306 3.18175878
 3.18181349 3.18184906 3.18189711 3.18196397 3.18200089 3.1820784
 3.18227718 3.18229861 3.18258163 3.18272658 3.18272899 3.18274888
 3.18289324 3.18300765 3.18305741 3.18318707 3.18404215 3.18441861
 3.18456555 3.18460525 3.18500796 3.18538918 3.18542191 3.18571394
 3.18579531 3.1857965  3.18580131 3.18585747 3.18611544 3.18613022
 3.18670991 3.18671821 3.18677836 3.18678423 3.18718241 3.18754247
 3.18763647 3.18835375 3.18869815 3.18891139 3.18915534 3.18955457
 3.18961572 3.18981288 3.18990753 3.19008817 3.19028594 3.19054301
 3.19056164 3.19112571 3.19209969 3.19246953 3.19276347 3.19310662
 3.19311541 3.19331772 3.19350966 3.19360259 3.19361661 3.1937136
 3.19408733 3.1941151  3.19441529 3.1946155  3.19472245 3.19478183
 3.19487677 3.19518761 3.19540486 3.19552958 3.19576258 3.19599318
 3.19635846 3.19656542 3.1970987  3.19746189 3.19764698 3.19778457
 3.19794865 3.19814596 3.19835581 3.1985871  3.1989146  3.19909591
 3.19927905 3.19940736 3.19960071 3.19976324 3.2006431  3.20108608
 3.20137063 3.20221904 3.20235292 3.20263251 3.2026392  3.20301921
 3.20317228 3.20343428 3.20353484 3.2035797  3.20398664 3.20409958
 3.20410243 3.20429552 3.20509536 3.20520728 3.20548642 3.20621683
 3.20650248 3.2069772  3.20763543 3.2079114  3.20798554 3.20811102
 3.20811901 3.20848767 3.20852003 3.20875036 3.20926083 3.20931052
 3.2096138  3.21006421 3.21048023 3.21052569 3.21068829 3.21134566
 3.21178715 3.21192786 3.21254891 3.21286318 3.21335292 3.21376687
 3.21378279 3.21417511 3.21465893 3.21499767 3.21530473 3.21558775
 3.21583487 3.21602228 3.21633775 3.21638907 3.21669884 3.21692126
 3.21695253 3.21706168 3.2172043  3.21724138 3.2175535  3.21755618
 3.21780084 3.21801135 3.21809904 3.21858651 3.21912902 3.21913232
 3.21917684 3.21970211 3.21977009 3.21986179 3.22018853 3.22065005
 3.22073142 3.22087971 3.22108169 3.22231901 3.22254996 3.22260869
 3.22284203 3.2230788  3.22311936 3.22346209 3.22496033 3.22555635
 3.22578309 3.2258747  3.22599622 3.22609125 3.22678888 3.22695745
 3.22704003 3.22712411 3.22753966 3.22760597 3.22784234 3.22818536
 3.22881445 3.22925592 3.22987929 3.22990092 3.23026257 3.23026755
 3.230786   3.23090411 3.23140187 3.23183786 3.23232369 3.2330298
 3.23303907 3.23353148 3.23377453 3.23392561 3.23411209 3.23420381
 3.23443956 3.23458733 3.23484507 3.23542395 3.23760321 3.23824054
 3.23841123 3.23863735 3.23937663 3.23939415 3.23942509 3.24132414
 3.2415164  3.24164427 3.24189202 3.24297068 3.24429737 3.24432303
 3.24436153 3.24623258 3.24652149 3.24876025 3.24945035 3.25000642
 3.25016672 3.25099065 3.25190126 3.25326607 3.25333044 3.25483763
 3.25503182 3.25580077 3.25607033 3.25734919 3.2594211  3.26015385
 3.26120571 3.26241005 3.26297244 3.26315135 3.26336312 3.26424407
 3.26592721 3.26609795 3.26612861 3.26623797 3.26635195 3.26641487
 3.26652783 3.26680506 3.26820505 3.26857666 3.27001994 3.27030918
 3.27056157 3.27106247 3.27110187 3.2720379  3.27276608 3.2732174
 3.27354418 3.27387312 3.27473082 3.27524044 3.2760089  3.27742833
 3.27832798 3.27966439 3.27966549 3.27982556 3.28001803 3.28014649
 3.28055503 3.28112199 3.28127716 3.28139977 3.28211051 3.28296821
 3.28373383 3.28419391 3.28477187 3.28503212 3.28553065 3.28589316
 3.28619859 3.28716399 3.28716783 3.28778481 3.28852897 3.29007934
 3.29205166 3.29229047 3.29378747 3.29410777 3.29541778 3.2966244
 3.30087123 3.30229656 3.30252131 3.30364781 3.30448325 3.30925729
 3.31286414 3.31360733 3.31416339 3.31518438 3.31542674 3.31557703
 3.31829376 3.32165571 3.32215141 3.32278476 3.32348748 3.32357143
 3.32517088 3.32564676 3.32609152 3.32835358 3.32934455 3.33082078
 3.33403002 3.33489681 3.33708017 3.33730664 3.34067914 3.34785786
 3.34931228 3.34989442 3.35132415 3.35509715 3.35777543 3.35957221
 3.36670317 3.36712246 3.36823066 3.37340195 3.37434664 3.37513351
 3.37624254 3.377185   3.37792202 3.38119935 3.38201507 3.38291625
 3.38352945 3.38364351 3.38735188 3.38819848 3.38821729 3.38898884
 3.38904704 3.3890811  3.38962707 3.39023336 3.39025384 3.39190932
 3.39306496 3.39350195 3.39418153 3.39459112 3.39608353 3.39722454
 3.39731849 3.39899568 3.39911655 3.39977138 3.40008528 3.40011697
 3.40055277 3.40076905 3.40247635 3.40444409 3.4057219  3.40745253
 3.40970793 3.4113184  3.41296337 3.41349837 3.41355945 3.41547166
 3.41705172 3.41797581 3.41868032 3.42371583 3.43041798 3.43059801
 3.436478   3.43761127 3.44040073 3.440871   3.44470313 3.45362492
 3.45457442 3.45608933 3.47227938 3.48315433 3.48982873 3.49560645
 3.50136509 3.50399694 3.51000057 3.5192016  3.59078176 3.59106597
 3.63878921 3.64485342 3.66201884 3.66478373 3.6657573  3.68343884
 3.76514781 3.77489895 3.78913829 3.79504962 3.79565686 3.81245954
 3.81814898 3.81861664 3.82550575 3.82894791 3.8302917  3.83393223
 3.84232281 3.84363252 3.84609352 3.84793249 3.8608745  3.86788884
 3.88065946 3.93514077 3.94783488 4.03765184 4.07652447 4.0926798
 4.17836865 4.31193956 4.34070508 4.75481913 4.76346173 4.76596413
 4.77164003 4.77660526 4.77917327 4.78309503 4.78578491 4.78623349
 4.79117653 4.79693721 4.79751755 4.79839291 4.8016956  4.80173766
 4.80546493 4.8063793  4.81139534 4.81457548 4.82486145 4.82654287
 4.83629378 4.83665076 4.84562325 4.85203302 4.85735079 4.86460809
 4.87588455 4.88820654 4.89211816 4.89852561 4.91303027 4.95299473]

  warnings.warn(

2022-12-16 10:37:04,723:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.81304626 2.03824123 2.07351931 2.07421897 2.09995333 2.10838352
 2.2836984  2.31598431 2.83786623 2.84437153 2.85647644 2.85695568
 2.89490756 2.89983935 2.92720937 2.94110921 2.94278374 2.95303581
 2.96352145 2.97142025 2.97314437 2.97369014 2.97524586 2.97658707
 2.97810228 2.98156098 2.98158417 2.98412717 2.98907167 2.99111404
 2.99490088 2.99784058 2.99807111 2.99826922 2.99866897 2.99946518
 3.00212681 3.00260468 3.00291119 3.00680838 3.00716071 3.00865699
 3.00922156 3.01164331 3.01258711 3.01331034 3.01368798 3.01473714
 3.01493708 3.01525555 3.01556311 3.0158648  3.01604408 3.01818905
 3.01919535 3.01977015 3.01978299 3.02069592 3.02137032 3.02195052
 3.02212547 3.02273122 3.02298314 3.02320207 3.02363557 3.02447394
 3.02488137 3.02580245 3.02671506 3.02673756 3.02748189 3.02904668
 3.02989337 3.03071288 3.03235102 3.03287833 3.03435609 3.03556099
 3.03610457 3.03640302 3.03768641 3.03956604 3.04129528 3.04131206
 3.04131976 3.042031   3.04210108 3.04228728 3.04251488 3.04339187
 3.04436175 3.04655948 3.04689855 3.0476452  3.04777125 3.04868302
 3.04971908 3.04997723 3.0504015  3.05059011 3.05064856 3.05287333
 3.05405863 3.05459749 3.05519588 3.05589376 3.05679442 3.05690438
 3.0570043  3.05732323 3.05734869 3.05788944 3.05791789 3.0583885
 3.05908316 3.05909394 3.06000919 3.0611211  3.06393357 3.06408773
 3.06439698 3.06462607 3.06718398 3.06793555 3.06892786 3.06928123
 3.06930976 3.06983367 3.07347246 3.07351807 3.07632857 3.07879362
 3.07915706 3.0791593  3.08186686 3.08226842 3.08658175 3.0869973
 3.08818923 3.08845711 3.08936596 3.08979721 3.09125572 3.09148456
 3.09279294 3.09367596 3.09433242 3.09458196 3.09460993 3.09557714
 3.09822443 3.09935634 3.10345025 3.1060558  3.10640552 3.10737559
 3.10813101 3.10835579 3.11038539 3.11039618 3.11070234 3.11425107
 3.11428876 3.11523502 3.11632734 3.11746153 3.1178705  3.11867478
 3.11899434 3.11914892 3.12002569 3.12180134 3.12188821 3.12189973
 3.12202781 3.12240874 3.12326728 3.12348803 3.12352864 3.12435274
 3.1245434  3.12504535 3.12533115 3.12553721 3.1264021  3.12690029
 3.12703464 3.12769866 3.12828737 3.12940141 3.12977934 3.13226811
 3.13245016 3.13358984 3.13401024 3.13452515 3.1350089  3.13538701
 3.13613907 3.13636781 3.13662894 3.13664605 3.1366693  3.13693586
 3.13759519 3.13801385 3.13833959 3.13887993 3.13933781 3.13957945
 3.14042919 3.14097229 3.1410327  3.14118718 3.14125778 3.14127895
 3.14187527 3.14215996 3.14229341 3.1425277  3.1429534  3.14296798
 3.14300013 3.14325846 3.14326176 3.1432636  3.14360071 3.14396991
 3.14416968 3.14434009 3.14566803 3.14569235 3.14612184 3.14644368
 3.14697412 3.14722091 3.14737055 3.14741731 3.14763461 3.14797208
 3.14822823 3.14823427 3.14849514 3.1487263  3.14874133 3.1496426
 3.15008679 3.15025178 3.15112572 3.15116584 3.15118502 3.15188669
 3.15199225 3.15208091 3.1521994  3.15262332 3.15264034 3.15304384
 3.15335118 3.15350861 3.1536125  3.15380592 3.15400085 3.15436206
 3.15444383 3.15445992 3.15471989 3.15501517 3.15504261 3.15506335
 3.15626599 3.15751786 3.15786092 3.15820145 3.15828916 3.15904865
 3.1590596  3.15913439 3.15933721 3.15946181 3.1598922  3.16037186
 3.16040916 3.16042264 3.16043686 3.16046361 3.16065428 3.16098537
 3.16111863 3.16201823 3.16210372 3.16244712 3.16290024 3.16306616
 3.16333795 3.16379146 3.16391626 3.16396859 3.16398082 3.16410912
 3.16430583 3.16435032 3.1644708  3.1645329  3.164887   3.16495121
 3.16577129 3.16597513 3.16611401 3.16641059 3.16649472 3.16658448
 3.16697643 3.16716303 3.16721824 3.16747832 3.16751448 3.16754732
 3.16786677 3.16789879 3.16817065 3.16831807 3.16832188 3.16832976
 3.16838892 3.16854276 3.16941991 3.1695836  3.16990265 3.17067919
 3.17072436 3.17077276 3.17096936 3.17111188 3.17120994 3.17191613
 3.17201845 3.17208181 3.17272833 3.17274301 3.17283244 3.17287388
 3.17298633 3.17302065 3.17314173 3.17318755 3.17343233 3.17347215
 3.17402772 3.17449934 3.17454128 3.17460047 3.17473523 3.17497482
 3.1753952  3.17549304 3.17586714 3.17596346 3.17598775 3.17671695
 3.1771331  3.17748573 3.17772069 3.17774311 3.17779691 3.17823694
 3.17864134 3.17864246 3.17885832 3.17890601 3.17903455 3.17928137
 3.17945922 3.17978062 3.17984897 3.18002839 3.18016138 3.18036623
 3.1804462  3.18088959 3.18124325 3.18158217 3.18162129 3.18184436
 3.18191157 3.18199895 3.18206809 3.18230367 3.18231051 3.18242949
 3.18274257 3.18285137 3.18310208 3.18324535 3.18331643 3.18345932
 3.18347633 3.18354964 3.18393929 3.18404141 3.18449137 3.18450397
 3.18481019 3.18487428 3.18493727 3.18502494 3.18509704 3.18615033
 3.18627219 3.18644604 3.18653626 3.18657887 3.18660859 3.18664195
 3.18724327 3.18751422 3.187535   3.18772033 3.18784508 3.18784787
 3.18798437 3.18805617 3.18843486 3.18884435 3.188872   3.1892996
 3.18962325 3.189637   3.18967969 3.18973372 3.19027339 3.19066488
 3.19073774 3.19087721 3.19090044 3.19090549 3.19128066 3.19150382
 3.19182304 3.19189617 3.19194671 3.19197364 3.19213782 3.19237625
 3.19318942 3.19326436 3.19343285 3.19364917 3.19379504 3.19383191
 3.19435039 3.19450659 3.19494316 3.19522966 3.19542139 3.19566704
 3.19583771 3.19596784 3.19605823 3.1961831  3.19626091 3.19651091
 3.19690584 3.19801899 3.1982839  3.19835691 3.19847531 3.19857493
 3.19859915 3.19907389 3.1991398  3.1993324  3.19935236 3.19950631
 3.19958847 3.20027252 3.20034803 3.20078941 3.20082342 3.20086326
 3.20096542 3.20107259 3.2014665  3.20151774 3.20158207 3.20197174
 3.20211032 3.20218641 3.20276587 3.20294429 3.20325472 3.20356331
 3.20375054 3.20376746 3.20430914 3.20436031 3.20453017 3.20454206
 3.20455622 3.20457385 3.20470783 3.2047403  3.20512741 3.20554424
 3.20578767 3.20587744 3.20591003 3.20621619 3.20627675 3.20637511
 3.20770377 3.20770498 3.20780546 3.20848028 3.20881791 3.20888976
 3.20889698 3.20901695 3.20926754 3.20927127 3.20992305 3.20996048
 3.21001513 3.2100208  3.21013339 3.21047589 3.21054957 3.21060109
 3.21060848 3.21095753 3.21115879 3.2116361  3.2121639  3.21219685
 3.21220341 3.21241098 3.21276273 3.21296037 3.21311227 3.21316822
 3.21330046 3.21334907 3.21385745 3.21392935 3.21411453 3.21440538
 3.21478031 3.21478255 3.21486502 3.21517926 3.21558541 3.21656667
 3.21669984 3.21681413 3.21692819 3.21698019 3.21709944 3.21711533
 3.21738468 3.21820011 3.21887324 3.21935012 3.2194211  3.21957534
 3.22000334 3.22017645 3.22144984 3.22171892 3.22211747 3.2223377
 3.22286508 3.2229567  3.22299988 3.22313482 3.22375588 3.22378848
 3.22435141 3.22446454 3.22458968 3.22495681 3.22525555 3.22561857
 3.2258621  3.22626442 3.22702276 3.22705849 3.22716952 3.22753715
 3.22774149 3.22841311 3.22861481 3.22937845 3.22975082 3.22983574
 3.23004568 3.23009932 3.23097632 3.23147438 3.23173303 3.23229636
 3.23256912 3.2329129  3.23293215 3.23319772 3.23337148 3.23471405
 3.23557709 3.23635666 3.23654424 3.23747595 3.2377748  3.23871503
 3.23986723 3.24018242 3.24082556 3.24088801 3.24301802 3.24315408
 3.24516331 3.24624334 3.24651625 3.24748076 3.24922464 3.24987696
 3.25049636 3.25084171 3.25260614 3.2531028  3.25593806 3.25871119
 3.25990874 3.26036966 3.2624174  3.26254033 3.26304993 3.26322988
 3.26464187 3.26523767 3.26744707 3.26826713 3.26841113 3.27011917
 3.27069844 3.27150895 3.27281608 3.27318941 3.27428836 3.27473391
 3.27639927 3.27734084 3.27786899 3.27921942 3.27961137 3.28092762
 3.28225049 3.28266183 3.28316311 3.28350297 3.28363919 3.28831835
 3.29052741 3.29300396 3.29497469 3.29511942 3.29566154 3.30034542
 3.30125935 3.30149546 3.30335442 3.30382226 3.30470945 3.3071792
 3.30756085 3.30801861 3.30835172 3.31132354 3.31494466 3.31506109
 3.3160665  3.31794833 3.32011652 3.32099904 3.32215866 3.32231539
 3.32267865 3.32276857 3.32415294 3.3256441  3.32710027 3.32767223
 3.32797129 3.33083477 3.33142389 3.33362007 3.33482874 3.33672692
 3.34176407 3.34289871 3.34726554 3.34736517 3.34801771 3.34915738
 3.34978455 3.35117054 3.35207649 3.35228774 3.35353101 3.35354639
 3.35406    3.35559649 3.35565123 3.35602812 3.35604553 3.3571164
 3.36030778 3.36035691 3.363746   3.36413412 3.36473728 3.36668728
 3.36838124 3.36838722 3.36952265 3.37063979 3.37224411 3.37291765
 3.37421896 3.37495371 3.37513979 3.37646435 3.37729196 3.38029355
 3.38151862 3.38165986 3.38212762 3.38314008 3.38322054 3.38329053
 3.38333542 3.38479644 3.38616037 3.38687772 3.38822222 3.38852712
 3.3885823  3.38897129 3.38929825 3.39080239 3.39361789 3.39615315
 3.39643944 3.3977781  3.39810369 3.39832761 3.39833854 3.39901954
 3.39962434 3.40069172 3.40296806 3.40328875 3.40344976 3.40424099
 3.40803527 3.40972356 3.4112319  3.41207946 3.41216512 3.41293994
 3.41685855 3.4216027  3.43171379 3.43388883 3.43661086 3.44307955
 3.45216056 3.45411187 3.4550073  3.45763326 3.46046271 3.52054108
 3.54499592 3.55468821 3.56919088 3.61969894 3.65448714 3.65615344
 3.66713934 3.6775458  3.68369492 3.68522782 3.69565485 3.71343191
 3.72773541 3.746622   3.79595109 3.79871548 3.8094265  3.8128339
 3.81514802 3.82151827 3.8228332  3.82602491 3.83204136 3.8357023
 3.84174951 3.84264155 3.84745922 3.85404834 3.86345275 3.87385171
 3.90406094 3.94720707 4.0900788  4.09612628 4.105773   4.13217636
 4.30927754 4.48857942 4.67123311 4.69968258 4.72184531 4.72514601
 4.75166784 4.75359222 4.75681025 4.76213673 4.7630316  4.7662041
 4.76631305 4.77106493 4.77345468 4.7806165  4.782495   4.78284472
 4.78512028 4.78716585 4.78975535 4.79538583 4.79821799 4.80067709
 4.8059223  4.80975386 4.81054192 4.81134376 4.81641388 4.8190344
 4.8212775  4.82771615 4.8309743  4.83903545 4.85815467 4.90899757
 4.90960161 4.91903117 4.92017044 5.01887496 5.12308096]

  warnings.warn(

2022-12-16 10:37:04,739:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.87932224 2.08771814 2.09534641 2.11179821 2.12332552 2.16177996
 2.16785655 2.18370794 2.18729637 2.2427499  2.34953431 2.80105311
 2.8030466  2.80931148 2.81983767 2.82270276 2.83269044 2.83937887
 2.86856379 2.92106945 2.92787964 2.93835519 2.95877759 2.96161442
 2.97377112 2.97497211 2.97535425 2.9772327  2.97857424 2.97933817
 2.97953885 2.98173941 2.98467481 2.9852759  2.9857309  2.98784028
 2.98874671 2.98917574 2.98942915 2.99134079 2.99167232 2.9931453
 2.99362448 2.99733298 2.99823891 2.99878483 2.99981221 2.99994607
 3.00220952 3.00322785 3.00425462 3.00465638 3.00700535 3.00744757
 3.00830112 3.00900953 3.01222669 3.01389862 3.01462602 3.01490794
 3.01506455 3.0151823  3.01686938 3.01696544 3.01844357 3.01899431
 3.01915221 3.02059766 3.02121943 3.02124953 3.02179581 3.02390028
 3.02427058 3.02506484 3.0251023  3.0262851  3.02784699 3.02871713
 3.02945954 3.02965503 3.02967281 3.03002431 3.03035443 3.03405754
 3.03420172 3.03439132 3.03456182 3.03474701 3.03549712 3.03674153
 3.03877304 3.03963226 3.04035181 3.04119123 3.04287932 3.043798
 3.04410814 3.0452689  3.05062031 3.05289067 3.0568263  3.05783464
 3.06107495 3.06650388 3.06763292 3.06910715 3.07183902 3.0725463
 3.07680592 3.08001396 3.08150634 3.08230155 3.08247988 3.08330287
 3.08523008 3.08642394 3.08744838 3.08890069 3.08946384 3.09264752
 3.09919183 3.09936701 3.10201067 3.10322868 3.10598981 3.10784291
 3.10906783 3.11079694 3.1118616  3.11194897 3.11321254 3.11349429
 3.11365895 3.11369028 3.11404146 3.11451906 3.11494846 3.11526614
 3.11564039 3.11607947 3.11785189 3.11800874 3.11821141 3.11924385
 3.11975324 3.12047207 3.12140809 3.12171501 3.12254706 3.1227191
 3.12303018 3.12324273 3.1237569  3.12470568 3.12515292 3.12526121
 3.12543355 3.12644791 3.1269469  3.12741804 3.12771691 3.12820902
 3.12832477 3.12881437 3.12910924 3.12917079 3.12918639 3.13002631
 3.13023785 3.13061033 3.13085377 3.13131387 3.1315128  3.13172376
 3.13203697 3.13228449 3.13229838 3.13241102 3.13350015 3.13454186
 3.13580871 3.13592379 3.13778644 3.13784147 3.13807699 3.13832194
 3.13833278 3.13833738 3.13836192 3.13879477 3.13882275 3.1391284
 3.1392819  3.13997603 3.1404164  3.14043908 3.14069461 3.14136664
 3.14144358 3.14146116 3.14200825 3.14206211 3.14209296 3.14216231
 3.14251579 3.14281898 3.14349491 3.14352921 3.14354805 3.14410916
 3.14425167 3.14444944 3.14455808 3.14485906 3.1448902  3.14532457
 3.14544304 3.14550982 3.14577715 3.14599446 3.14603385 3.14630063
 3.14661732 3.14681982 3.14693362 3.14695215 3.14714653 3.14756641
 3.1475684  3.14760711 3.14762891 3.14764976 3.14780446 3.14843717
 3.14851755 3.14865393 3.14879149 3.14925826 3.14930073 3.14953061
 3.15009115 3.15048501 3.15098576 3.15108172 3.15128115 3.15147285
 3.15160894 3.1518538  3.15206105 3.15258084 3.15269935 3.15316913
 3.15331301 3.1536209  3.15366    3.15380343 3.15413948 3.15440789
 3.15505743 3.15585174 3.15592127 3.15661436 3.15664102 3.15683428
 3.15730543 3.15741209 3.15745629 3.15762758 3.15762848 3.15788264
 3.1579898  3.15812345 3.15817683 3.15874856 3.15887012 3.15896861
 3.15946704 3.15949    3.15955104 3.15960916 3.15973065 3.15979164
 3.15982362 3.15992882 3.15999084 3.16059424 3.16083058 3.16095776
 3.16126843 3.16132355 3.16165524 3.16168869 3.16185631 3.1622473
 3.16264234 3.16283072 3.16312596 3.16317748 3.16337003 3.16353647
 3.16362292 3.16365192 3.1637278  3.16384637 3.16464828 3.16477845
 3.16489823 3.16496271 3.16498813 3.16522292 3.16534695 3.16555775
 3.16557461 3.16604864 3.16611199 3.16640927 3.16709437 3.16714123
 3.16721568 3.16734081 3.16758611 3.1679097  3.16793235 3.16798934
 3.16831918 3.16884487 3.16895607 3.16895619 3.16921471 3.16944654
 3.16945339 3.16971082 3.16997203 3.17010395 3.17031764 3.17033667
 3.17041891 3.17056888 3.17079496 3.17085155 3.1712212  3.17163338
 3.17176513 3.1721062  3.17253099 3.17265311 3.17291371 3.17319941
 3.17324357 3.17397618 3.17402226 3.17425069 3.17447238 3.1745506
 3.17471452 3.17527884 3.17541276 3.17563874 3.17596118 3.17597916
 3.17645757 3.17647195 3.1768424  3.17687899 3.17708416 3.1771036
 3.17715207 3.17717403 3.17730375 3.17731647 3.17759377 3.17780884
 3.17833203 3.17850507 3.17852382 3.17863667 3.17906283 3.1793404
 3.18029332 3.1803501  3.18060948 3.18105655 3.18149627 3.18242415
 3.18244873 3.18250587 3.18269864 3.1827742  3.18300421 3.18324734
 3.1833096  3.18335845 3.18389476 3.18408419 3.18477694 3.18498888
 3.18527467 3.18546595 3.18584325 3.1863306  3.18636532 3.18696054
 3.18709714 3.18763069 3.1879578  3.18844933 3.18884525 3.18884934
 3.18937063 3.18960605 3.18991737 3.19058278 3.19161602 3.1916222
 3.19189244 3.1925217  3.19256281 3.19258741 3.19269471 3.19288272
 3.19339183 3.19345621 3.19416823 3.1944431  3.19475759 3.19538081
 3.19626362 3.19647893 3.1965022  3.1966012  3.19748848 3.19756551
 3.19796162 3.19808494 3.19822186 3.19880955 3.1989563  3.19903367
 3.19907919 3.19915395 3.201892   3.20202846 3.20226319 3.20251447
 3.20292007 3.20324101 3.20335435 3.20371917 3.20418992 3.20449363
 3.20512735 3.20527628 3.20530426 3.20555516 3.2056683  3.20570054
 3.20577633 3.20581907 3.20588327 3.20653935 3.20656869 3.20671041
 3.20808757 3.208207   3.20959156 3.21003413 3.21018686 3.21041154
 3.21048185 3.21057465 3.21096125 3.21136634 3.21140239 3.21141815
 3.21144442 3.21153358 3.21156811 3.21161958 3.21221328 3.2138009
 3.21383399 3.21406264 3.2145102  3.21468698 3.21475484 3.21479672
 3.21509886 3.21598137 3.21599899 3.21625657 3.21626975 3.21628064
 3.21676719 3.21773551 3.2178197  3.21797489 3.21836135 3.21838513
 3.2185214  3.21877614 3.21878069 3.21880122 3.21901263 3.21921225
 3.21953971 3.2195784  3.2197164  3.22044107 3.22059166 3.22065397
 3.22065564 3.22077215 3.22164177 3.22192986 3.22265377 3.22285395
 3.22313057 3.22429719 3.22470763 3.22519058 3.22615188 3.22622235
 3.22675794 3.22684586 3.22687947 3.22757264 3.22787122 3.22839928
 3.22892766 3.22959998 3.229644   3.22973364 3.22984214 3.23005246
 3.23142876 3.23153685 3.23232215 3.23257626 3.23269258 3.232729
 3.23301867 3.2335438  3.23368824 3.23414073 3.23414948 3.23461373
 3.23588017 3.23591384 3.23609319 3.23643708 3.23655997 3.23678189
 3.23713897 3.23735916 3.23785563 3.23790753 3.23799082 3.23813893
 3.23820774 3.23835127 3.23836881 3.23841299 3.23870551 3.23937858
 3.23985753 3.24039555 3.24133542 3.24147053 3.24226458 3.24230439
 3.24375124 3.24387851 3.24485203 3.24517492 3.24538807 3.24595845
 3.24597966 3.24624811 3.24631926 3.24899212 3.24909559 3.24938394
 3.25001304 3.2500999  3.25030328 3.25111804 3.2516066  3.25168872
 3.25171936 3.25210273 3.25219124 3.25226924 3.25260914 3.2530153
 3.2539872  3.2544461  3.25464235 3.25521689 3.25572578 3.25596567
 3.25601508 3.25677701 3.2573239  3.25732519 3.2582988  3.25913345
 3.25953915 3.25976184 3.2606065  3.26218013 3.26255827 3.26298194
 3.26411363 3.2642327  3.2648487  3.26516877 3.26529901 3.26633553
 3.26834389 3.26856904 3.26915998 3.26940591 3.26953902 3.26980022
 3.27019164 3.27036545 3.27190755 3.27216305 3.27306127 3.2731145
 3.27396929 3.2741567  3.27508081 3.27534145 3.2756776  3.27793828
 3.27922941 3.27948917 3.28052904 3.28067709 3.2812274  3.28130087
 3.28245216 3.28333474 3.28334828 3.28700922 3.28814878 3.28822197
 3.28988115 3.29006448 3.29010501 3.29021205 3.29258992 3.29313165
 3.29355666 3.29401746 3.2941097  3.29460639 3.29716297 3.29934258
 3.30149931 3.3023116  3.30322333 3.3071964  3.30870089 3.31072166
 3.31080294 3.31146747 3.31163813 3.31236027 3.31328883 3.31338223
 3.31480582 3.31642038 3.31651334 3.31802952 3.31807106 3.31914865
 3.32170848 3.326807   3.32783081 3.32848348 3.32851763 3.32880914
 3.32959731 3.33216177 3.33464793 3.33771049 3.33818252 3.33953461
 3.34002829 3.34253653 3.34253956 3.34410503 3.34543893 3.351551
 3.35255146 3.35258619 3.35312066 3.35448483 3.35502826 3.35506364
 3.35651079 3.35688939 3.35745591 3.35965992 3.36091829 3.36119507
 3.36236321 3.36368932 3.36614401 3.36923746 3.36947567 3.36986383
 3.37016688 3.371722   3.37216801 3.37257536 3.37285719 3.37352981
 3.3738829  3.37596205 3.37649909 3.3774826  3.37748552 3.37791563
 3.37855917 3.37900339 3.37969672 3.38201237 3.38251666 3.38304214
 3.38403122 3.38438968 3.38462494 3.38594649 3.38656571 3.38671669
 3.38682235 3.38765682 3.38777543 3.38788833 3.38844226 3.38873604
 3.38885752 3.38909531 3.38955402 3.39112265 3.39161826 3.39272398
 3.39330893 3.39378232 3.39389512 3.39705352 3.3972448  3.40213536
 3.40510493 3.40540941 3.40744156 3.407696   3.41393316 3.41417848
 3.41712025 3.4241171  3.43055538 3.43104046 3.43641285 3.45311424
 3.45596043 3.46837904 3.47023536 3.47851875 3.48674624 3.48960975
 3.49398651 3.49432192 3.49621786 3.49744939 3.5016542  3.50299235
 3.50946479 3.51398366 3.51980814 3.52258927 3.52378589 3.52709964
 3.62373326 3.65119632 3.66933432 3.68511154 3.71824223 3.72259804
 3.72471714 3.77452278 3.81822936 3.82759566 3.84886402 3.86980063
 3.86994919 3.87174065 3.87633978 3.87769567 3.89727205 3.93768589
 3.94917781 3.96303854 3.96666408 3.96980959 3.97519947 4.06359027
 4.07295969 4.12740012 4.29031363 4.41469848 4.74364732 4.74929127
 4.74939383 4.75242898 4.75959235 4.76269659 4.76474803 4.76829911
 4.76902116 4.76950126 4.77360335 4.77378282 4.77572607 4.77943725
 4.7804555  4.78244768 4.78485105 4.78519134 4.7866658  4.78676022
 4.78848398 4.78963078 4.7899077  4.79107551 4.79284662 4.79429647
 4.79569583 4.79870127 4.79874014 4.80042707 4.80845519 4.8138419
 4.82552477 4.83201694 4.84530778 4.87721699 4.89823028 4.89967287
 4.90680877]

  warnings.warn(

2022-12-16 10:37:04,763:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.70060262 1.99214942 1.99794328 2.04933133 2.16740638 2.19606315
 2.73607067 2.82187796 2.84505187 2.85896924 2.88543852 2.90483659
 2.91615533 2.94117151 2.9424389  2.94541101 2.94697509 2.94728071
 2.94763775 2.95108722 2.95111023 2.9537791  2.9585677  2.96478999
 2.96621285 2.96739971 2.96955644 2.97099528 2.97196466 2.97290411
 2.97345043 2.9739405  2.97590395 2.97642778 2.97707238 2.97717362
 2.98078326 2.98146947 2.98349068 2.9848304  2.98526203 2.98783478
 2.98875849 2.98911749 2.99122531 2.99162929 2.9925839  2.99275506
 2.99521551 2.99548689 2.99647727 2.99703573 2.99824839 2.99991848
 3.00092453 3.00232291 3.00536165 3.00662794 3.00762697 3.00776565
 3.00790866 3.00848934 3.00954262 3.01048339 3.01336436 3.01827096
 3.01944325 3.02038423 3.02330341 3.0240764  3.02472266 3.02493006
 3.02553202 3.02637807 3.02644896 3.02704699 3.02758274 3.02841919
 3.02886933 3.02922023 3.03045616 3.03123692 3.03174687 3.0324147
 3.03320576 3.03483255 3.03548383 3.03843338 3.04168241 3.04544801
 3.04735763 3.04789043 3.04830636 3.05026141 3.05270337 3.05469005
 3.06183572 3.0622214  3.06264987 3.06505983 3.06664815 3.06730967
 3.06777191 3.06815115 3.0711041  3.07414332 3.07479506 3.07542623
 3.07656593 3.07672862 3.07711713 3.07954233 3.08035019 3.08082872
 3.08187224 3.08234895 3.08342423 3.08441297 3.08449501 3.0872832
 3.08750174 3.08822246 3.09052188 3.09360968 3.09378416 3.09392501
 3.09538117 3.09597315 3.09597714 3.09999204 3.1003395  3.10047535
 3.10052559 3.10164179 3.10192816 3.10393487 3.10398517 3.10473896
 3.10539595 3.10594739 3.10894278 3.10898315 3.10973832 3.1101166
 3.11014355 3.1108701  3.11172453 3.11240025 3.11247137 3.11264778
 3.11279098 3.11279643 3.11351098 3.11361089 3.11482058 3.11492807
 3.11537905 3.1156191  3.11637571 3.11678204 3.11753169 3.11842024
 3.11863484 3.11925092 3.12084577 3.12104621 3.12139341 3.12397211
 3.12500149 3.12558971 3.12696337 3.12740204 3.12740241 3.12741523
 3.12752262 3.12755657 3.12798953 3.12844246 3.12923765 3.12932417
 3.12944712 3.12953262 3.1296717  3.12985837 3.13015887 3.13094061
 3.13121301 3.13143967 3.13179236 3.13191611 3.13192294 3.13194905
 3.13218008 3.13388924 3.13411928 3.13441999 3.13460786 3.13505023
 3.13519966 3.13572513 3.13578533 3.13615774 3.13622111 3.13631078
 3.13657707 3.13689063 3.13689357 3.13703963 3.13723226 3.13771112
 3.13774291 3.13853416 3.13861282 3.13954973 3.13955061 3.13965517
 3.14023091 3.14055665 3.14055703 3.14186739 3.14195265 3.14204955
 3.14229711 3.14264101 3.14296709 3.14326795 3.14327538 3.14402851
 3.14625165 3.1466277  3.14718368 3.14720656 3.14743604 3.14749779
 3.14752511 3.14753517 3.14762011 3.14768503 3.14780936 3.14824346
 3.14850698 3.14872667 3.14901894 3.14910383 3.15028516 3.15099205
 3.15151532 3.15250794 3.15258882 3.15308436 3.15337573 3.15357948
 3.15396015 3.15429197 3.15447482 3.15452543 3.15497583 3.15539039
 3.15548769 3.15563312 3.15574508 3.15580253 3.1560492  3.15607175
 3.1562015  3.15684823 3.15703094 3.15707302 3.15720947 3.15731427
 3.15761791 3.15856511 3.15862481 3.15911024 3.15922719 3.15930318
 3.15935175 3.1601994  3.1603923  3.16074469 3.16074943 3.1613749
 3.16167481 3.16172664 3.16211968 3.16268812 3.16289184 3.16335668
 3.16448649 3.16463764 3.16528377 3.16581205 3.1660776  3.1666086
 3.16731289 3.16780026 3.16780091 3.16806088 3.16818619 3.16818998
 3.1683064  3.16832987 3.16838703 3.16910627 3.16913079 3.16978233
 3.16995605 3.17041971 3.17059658 3.17063124 3.17146459 3.17163523
 3.17177869 3.17179958 3.17190153 3.17211383 3.17212614 3.17252286
 3.17255731 3.17259893 3.1727332  3.17285341 3.17290638 3.17327858
 3.17348104 3.17388274 3.17395483 3.17404103 3.17409209 3.17440043
 3.17490306 3.17503276 3.17523669 3.17561723 3.1757595  3.17578511
 3.17601667 3.17623724 3.17630671 3.17650777 3.17656546 3.17663095
 3.17664547 3.17671425 3.17690893 3.17766288 3.17881817 3.1789138
 3.17898667 3.17905789 3.17931046 3.17932153 3.17950954 3.17974764
 3.17987561 3.1803721  3.18062613 3.18066077 3.18066419 3.18099466
 3.18135755 3.18146749 3.18196441 3.18207398 3.1825406  3.18282781
 3.18294273 3.18329997 3.18391164 3.18404024 3.18408952 3.18411886
 3.18435508 3.18440518 3.18451724 3.18461751 3.1846768  3.18473646
 3.18474982 3.18525581 3.18546439 3.18586203 3.18605114 3.18617192
 3.18633797 3.18684948 3.18737618 3.18743309 3.18760465 3.18765741
 3.18769619 3.18782881 3.1881434  3.18826361 3.18842583 3.18899291
 3.18946614 3.18947812 3.18978696 3.19011374 3.19023571 3.19031882
 3.19054576 3.1908662  3.19126296 3.19143306 3.19147205 3.1914793
 3.19165053 3.19179293 3.19181916 3.19236024 3.19246223 3.19255589
 3.19267455 3.19279153 3.19289345 3.19307352 3.19317324 3.19324168
 3.19356964 3.19360426 3.19368871 3.19385811 3.19424425 3.19425516
 3.19432955 3.19438389 3.19449027 3.19475265 3.19493272 3.1952547
 3.19529623 3.1957967  3.19594908 3.19630566 3.1963617  3.1963897
 3.19639859 3.19651837 3.19658671 3.19664726 3.19666059 3.19686187
 3.19730785 3.19732073 3.19794363 3.1982346  3.19898621 3.19907631
 3.19908021 3.19920838 3.19941747 3.19954896 3.19977699 3.19988629
 3.19997758 3.20024438 3.20039506 3.20055238 3.20056742 3.20068763
 3.20123347 3.20195427 3.20212585 3.20215934 3.20235908 3.20252473
 3.20260213 3.20345276 3.20379928 3.20389119 3.20414046 3.20424412
 3.20471726 3.20478669 3.20505559 3.20522224 3.20537305 3.20549326
 3.20557893 3.20636392 3.20646478 3.20671345 3.20673262 3.20673458
 3.20679106 3.20685069 3.20705289 3.20733927 3.2076783  3.20838556
 3.20842964 3.20850284 3.20888646 3.20899991 3.20920471 3.20954955
 3.20956843 3.20962902 3.20978554 3.2098562  3.21029842 3.21054388
 3.21094392 3.21094495 3.21099394 3.21100055 3.21111442 3.21134663
 3.21135452 3.21172097 3.21183857 3.21190688 3.21265575 3.21305162
 3.21313702 3.21342067 3.21379691 3.2140504  3.21419095 3.21453976
 3.21547994 3.2162123  3.2164351  3.21661504 3.21721995 3.21741576
 3.21747402 3.2175328  3.21763795 3.21819163 3.21826496 3.21833914
 3.21833951 3.218745   3.21932814 3.2195582  3.21987696 3.22087188
 3.22159753 3.22177841 3.22196314 3.22257931 3.22279892 3.22351083
 3.22419126 3.22483043 3.22513544 3.22550218 3.22579204 3.22638547
 3.22704524 3.22708371 3.22834087 3.22886879 3.22888916 3.22973461
 3.22981475 3.22981706 3.2302025  3.23093071 3.23096652 3.23101252
 3.23110225 3.23156422 3.23163724 3.23194006 3.23211941 3.23271317
 3.23281779 3.23294406 3.23329356 3.23362713 3.23384469 3.23435759
 3.23484565 3.23526609 3.23568068 3.23639981 3.23647482 3.23665953
 3.23667328 3.23787106 3.23844314 3.23845816 3.23962585 3.23984008
 3.2398442  3.24032843 3.24047563 3.24050683 3.24090728 3.24220249
 3.24225681 3.242333   3.24237908 3.24278246 3.24356659 3.24408132
 3.24466222 3.24473916 3.24687157 3.24695668 3.24788622 3.24862935
 3.24865869 3.24989606 3.25078126 3.25130802 3.25171246 3.25178591
 3.25216786 3.25220507 3.25230377 3.25255044 3.25376626 3.25392577
 3.25401249 3.25414048 3.25435867 3.25634523 3.25703475 3.25824723
 3.25912395 3.25914124 3.25923368 3.2608988  3.26141057 3.26370433
 3.26446455 3.26459011 3.26562158 3.26680001 3.26683725 3.26840016
 3.26965372 3.26991776 3.27003482 3.27142205 3.27233588 3.27297105
 3.27364827 3.27416934 3.27460714 3.274997   3.27734449 3.27756093
 3.28187641 3.28198065 3.28335135 3.28492819 3.28507915 3.28582537
 3.28707006 3.28735992 3.28739223 3.29072847 3.29098405 3.29110136
 3.29142339 3.29232434 3.29287965 3.29288479 3.29295479 3.29370301
 3.29477068 3.29531147 3.2958944  3.29642481 3.29695432 3.29728097
 3.2973152  3.29784105 3.29872893 3.29955799 3.30154865 3.30189083
 3.30194982 3.30468188 3.30506863 3.30756095 3.30871954 3.30873048
 3.30945639 3.30993635 3.31272033 3.31408249 3.3156827  3.31723358
 3.31808725 3.32139638 3.32165435 3.321702   3.32177186 3.32327191
 3.32359874 3.32499354 3.32599412 3.32679742 3.32745211 3.32965807
 3.33228528 3.33267992 3.33504185 3.33571434 3.34356417 3.34409629
 3.34493487 3.34615858 3.34620583 3.34919642 3.34968275 3.35040575
 3.35189455 3.35225318 3.35679479 3.3583742  3.35896715 3.36286717
 3.36298024 3.36372922 3.36411035 3.36418306 3.36519464 3.36637991
 3.36650196 3.36774741 3.36797321 3.36939467 3.37121648 3.37818452
 3.37830047 3.37832178 3.38165549 3.3817721  3.38251543 3.38267919
 3.38368701 3.38527488 3.38579438 3.38610439 3.38768908 3.3879713
 3.38844406 3.38890734 3.3923838  3.39700697 3.39943845 3.40097438
 3.40140941 3.40234492 3.40262653 3.40494822 3.40768236 3.40805482
 3.40942708 3.41039175 3.41073042 3.41197996 3.41329444 3.4145235
 3.41514082 3.42036388 3.42276573 3.42279271 3.42486828 3.42661971
 3.42976864 3.43017296 3.43281442 3.44015614 3.44554573 3.44758358
 3.45279764 3.45500153 3.45842378 3.46287492 3.46656393 3.46887733
 3.47142034 3.47161332 3.47173962 3.47242072 3.48995593 3.49309721
 3.49758515 3.4992043  3.50177759 3.51352256 3.52092681 3.52201602
 3.54506314 3.54789911 3.60157168 3.62760479 3.64631658 3.65667811
 3.67261874 3.68349547 3.73211037 3.74256373 3.77713714 3.81180217
 3.82369518 3.82778264 3.8324748  3.83457282 3.84831371 3.85430991
 3.86257073 3.86648778 3.87731051 3.8787747  3.93629878 4.00163495
 4.04678401 4.10420656 4.10997672 4.11531107 4.12498023 4.16170355
 4.17360061 4.33318186 4.35249888 4.41576196 4.62781814 4.69471009
 4.70855144 4.73910493 4.75645866 4.76640695 4.77458434 4.77785155
 4.77997661 4.78212047 4.78492643 4.78525681 4.78554275 4.79174249
 4.7951825  4.79939032 4.79948818 4.80198101 4.81040454 4.82077266
 4.82638753 4.83362792 4.84099219 4.84118538 4.85463197 4.85679208
 4.86192237 4.86944206 4.87380882 4.87709416 4.88246949 4.938501  ]

  warnings.warn(

2022-12-16 10:37:04,836:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.80299521 2.08618584 2.10367117 2.12401365 2.13317081 2.13998225
 2.14518695 2.14613732 2.16891692 2.18412542 2.28834535 2.33310057
 2.85785809 2.86608013 2.86742614 2.89195076 2.89305555 2.89957269
 2.90265042 2.90950548 2.90970207 2.91036307 2.91059672 2.91124847
 2.91149708 2.91173317 2.91231201 2.91256556 2.91434866 2.9146408
 2.9148755  2.91874385 2.91892027 2.92045312 2.92244612 2.92716132
 2.92864265 2.93618943 2.93755155 2.93875019 2.94508392 2.94551259
 2.9462143  2.94701586 2.94789541 2.94861317 2.95036686 2.95176629
 2.95206351 2.9522145  2.95278153 2.95411059 2.9575736  2.96072399
 2.96079822 2.96080316 2.96104454 2.9610553  2.96133961 2.96229831
 2.96405767 2.96417673 2.96528712 2.96549331 2.96562774 2.96657713
 2.96697105 2.96855162 2.96902873 2.97044344 2.97221515 2.9726963
 2.97319352 2.97380642 2.97444717 2.97577161 2.97849676 2.97891621
 2.97969246 2.97987891 2.98006492 2.9806149  2.9811757  2.98232319
 2.98353625 2.98735663 2.98852866 2.99344977 2.99514485 2.99706484
 2.99707947 2.99759193 3.00054988 3.0006551  3.00121869 3.00175337
 3.00412108 3.00715823 3.01200932 3.01361862 3.01433728 3.01473091
 3.01487213 3.01731797 3.01852385 3.02110188 3.03080132 3.03476267
 3.03790771 3.03809497 3.04770598 3.05007315 3.05031252 3.05508439
 3.06255583 3.07112575 3.0717357  3.07247095 3.08051386 3.08548496
 3.0856846  3.08780162 3.08838947 3.0892136  3.09369016 3.09513083
 3.09894238 3.09903205 3.10252058 3.10414417 3.10515081 3.10576524
 3.1060431  3.10697849 3.11063902 3.11134284 3.11202381 3.11331903
 3.11431419 3.11512887 3.11543551 3.11549039 3.11576629 3.11621649
 3.11822658 3.11941996 3.11980371 3.12014118 3.12019737 3.12089096
 3.1225474  3.12298596 3.12323152 3.12434371 3.12467061 3.12470058
 3.12482149 3.12484038 3.12506834 3.1252901  3.1256832  3.12662737
 3.12675055 3.12745494 3.12766072 3.12790587 3.12946715 3.12976894
 3.13081972 3.13128797 3.13163253 3.13227321 3.13279114 3.13364727
 3.1345452  3.13491821 3.13577495 3.1362829  3.13688983 3.1382287
 3.13831939 3.13868658 3.13875083 3.13904208 3.13947299 3.1396255
 3.13969174 3.13981414 3.140301   3.14053457 3.1408928  3.140949
 3.14189429 3.14199431 3.14232343 3.1426419  3.14328494 3.14351409
 3.14375067 3.14379517 3.14491294 3.1454063  3.14544189 3.14583654
 3.14604247 3.14627117 3.14652818 3.14671824 3.14720177 3.14831938
 3.14845799 3.14854929 3.14886028 3.14891416 3.1495175  3.14954137
 3.14984869 3.15033526 3.15054381 3.150557   3.1516178  3.15182577
 3.15248677 3.15321341 3.15323527 3.15346496 3.15389844 3.15477322
 3.15505269 3.15527304 3.1553809  3.15563113 3.1560162  3.15638405
 3.15644295 3.1567622  3.15706765 3.15725082 3.15798168 3.15808166
 3.1581476  3.15916088 3.15974338 3.15978985 3.15986546 3.15990019
 3.16003733 3.16012719 3.1601812  3.16031289 3.16086827 3.16155568
 3.16169118 3.16193643 3.16199638 3.16215165 3.16217414 3.16217764
 3.16235748 3.16258974 3.16259952 3.16297404 3.16320238 3.16326313
 3.1634359  3.1634976  3.16352049 3.16378405 3.164113   3.16419037
 3.16475519 3.16491346 3.16519068 3.16533362 3.16555401 3.16597109
 3.16605991 3.16611352 3.16622411 3.16627899 3.16630914 3.16680411
 3.16681807 3.16709352 3.16731375 3.16744246 3.16773598 3.16782791
 3.16799284 3.16817548 3.16822361 3.16843249 3.16866138 3.16905654
 3.16931458 3.17033614 3.17042789 3.17053847 3.17128341 3.17136638
 3.17152775 3.17153496 3.17195245 3.17199145 3.17208048 3.17236421
 3.17299    3.17321372 3.17332469 3.1734464  3.17349975 3.17374436
 3.17406379 3.17448788 3.17483534 3.17523598 3.17542802 3.1754615
 3.17599021 3.17635661 3.17653014 3.17678227 3.17693324 3.177264
 3.17739978 3.17746798 3.17773467 3.17820999 3.17824225 3.17906334
 3.17910896 3.17966819 3.17979229 3.17988872 3.18003586 3.18057421
 3.18086313 3.18106466 3.18112905 3.18116542 3.18122029 3.18123621
 3.18123956 3.18128041 3.18161146 3.18193361 3.18198987 3.18220512
 3.18224148 3.18230821 3.18236497 3.18264549 3.18269143 3.18281145
 3.18283824 3.18316452 3.18326904 3.18333601 3.18334052 3.18335243
 3.18341782 3.18343185 3.18381378 3.18436202 3.18454447 3.18465602
 3.18503712 3.1851822  3.18558886 3.18566822 3.18579463 3.18585999
 3.18590636 3.18601825 3.186109   3.18612798 3.18619456 3.18628606
 3.18639688 3.18661443 3.18672793 3.1867555  3.18684252 3.18686787
 3.18698112 3.18707291 3.18714076 3.18725468 3.18727189 3.18732562
 3.18738294 3.18744689 3.18745809 3.18762789 3.18768711 3.18800572
 3.18824081 3.18858439 3.18859125 3.18906632 3.1891133  3.18916484
 3.18955359 3.18956677 3.18957565 3.1899125  3.19025857 3.19056437
 3.19064353 3.19077941 3.19086209 3.19107312 3.19139449 3.19163604
 3.19206679 3.19215447 3.19248131 3.19302996 3.19314285 3.19351327
 3.19377606 3.19383074 3.19398747 3.19402424 3.19429553 3.19440712
 3.19453265 3.19458752 3.19473936 3.19526422 3.19601701 3.19615419
 3.19641953 3.19642127 3.19650771 3.19695694 3.1971866  3.19722518
 3.19726521 3.19741281 3.19751271 3.1976406  3.19799485 3.19829322
 3.19861715 3.19873999 3.19932861 3.19975907 3.19981627 3.19982408
 3.19990701 3.19991689 3.19994174 3.20055033 3.20109987 3.2011118
 3.20124017 3.20127955 3.20164624 3.2018743  3.20257325 3.20266404
 3.2028243  3.20309024 3.2033463  3.20334885 3.20336324 3.20336813
 3.20339836 3.20349982 3.20388578 3.20420259 3.20434398 3.20448613
 3.20451105 3.20469001 3.20487509 3.20515792 3.20522287 3.20539422
 3.20608777 3.20656072 3.20681423 3.20689942 3.20695659 3.20709187
 3.2071098  3.20725825 3.20726012 3.20767354 3.20777378 3.20809902
 3.20818331 3.20858599 3.20860641 3.20867265 3.20890461 3.20919394
 3.20944252 3.20947272 3.20950792 3.20970813 3.20994447 3.21036128
 3.21040517 3.21072707 3.21078837 3.21087014 3.21097295 3.21148669
 3.21156091 3.21157972 3.21213384 3.21230096 3.21233167 3.21284987
 3.21285446 3.21310082 3.21329034 3.21333281 3.21360965 3.2137942
 3.21380941 3.21383512 3.21393833 3.2139924  3.21436356 3.21462814
 3.21477564 3.21548304 3.21556044 3.21567852 3.2163196  3.21634578
 3.21642429 3.21659762 3.21723288 3.2178343  3.21803334 3.21848912
 3.21856817 3.21868706 3.21918739 3.21923561 3.21971185 3.21973468
 3.21977118 3.2200386  3.22011465 3.22038404 3.22063102 3.2207814
 3.22079659 3.22212761 3.22224227 3.22231231 3.22264737 3.22303005
 3.22354913 3.22365875 3.22382785 3.22385471 3.22395677 3.22401564
 3.22413657 3.22510698 3.22540273 3.22571117 3.22633727 3.22653171
 3.2265326  3.22700772 3.2270864  3.22711271 3.22725208 3.22727297
 3.22736842 3.23016831 3.23020433 3.23028301 3.2304147  3.2304928
 3.23057824 3.23106294 3.23115996 3.23150546 3.23184056 3.23355145
 3.23375392 3.23406849 3.23407447 3.23433648 3.23437819 3.23447019
 3.23494447 3.23570118 3.23571802 3.23586193 3.23587114 3.23640522
 3.23697982 3.23714401 3.2372765  3.23799087 3.23866448 3.23891924
 3.23896316 3.23961791 3.23972704 3.2399402  3.24014263 3.24112846
 3.24167628 3.24198156 3.2429749  3.24347038 3.24357277 3.24486314
 3.24531591 3.24536181 3.2455149  3.24570219 3.24613315 3.2462476
 3.24704375 3.24743184 3.2474513  3.2476172  3.24809904 3.2486828
 3.24943713 3.24950525 3.25028889 3.25153744 3.25228199 3.252322
 3.25261428 3.25328044 3.254604   3.2552851  3.25584269 3.25730351
 3.25797789 3.2593463  3.26217724 3.26311877 3.26711612 3.27089509
 3.27197577 3.27213469 3.27258199 3.27599973 3.2768656  3.276929
 3.27836275 3.27954334 3.28097229 3.28109425 3.28187838 3.28238501
 3.28252724 3.28312813 3.28569932 3.28743237 3.28747905 3.28768268
 3.28797175 3.29269357 3.29312629 3.29361437 3.29565112 3.29577212
 3.29751511 3.29922228 3.29932943 3.2996382  3.30189701 3.30244637
 3.30269174 3.30848189 3.30865945 3.30867222 3.30965851 3.31042297
 3.31172381 3.31443533 3.31882934 3.3190299  3.32140688 3.32351306
 3.3250125  3.32561104 3.32608557 3.32756746 3.32778621 3.3296915
 3.33175419 3.33194664 3.3376408  3.33960107 3.34406043 3.34602687
 3.34606024 3.34909493 3.35016117 3.35036579 3.35108264 3.35240745
 3.35482825 3.35586106 3.35630853 3.35637129 3.36084931 3.36341698
 3.3635271  3.36543023 3.36763284 3.36765365 3.36890321 3.37490491
 3.37881786 3.38244758 3.38336277 3.38340848 3.38407749 3.38419709
 3.38478352 3.38683072 3.38792525 3.38860509 3.38897598 3.39075391
 3.39378611 3.39389048 3.39416889 3.3947495  3.39672906 3.39727068
 3.39990832 3.40081501 3.4016583  3.40193652 3.40300689 3.40457459
 3.40483694 3.40489224 3.40653639 3.40816984 3.40819316 3.40880865
 3.41059179 3.41207303 3.41228088 3.4123011  3.41356305 3.41369297
 3.41636214 3.41665362 3.416814   3.41802869 3.41804623 3.41824923
 3.41947279 3.41950232 3.41994247 3.4200928  3.42038546 3.42094672
 3.4219532  3.42199943 3.42579731 3.42607875 3.42677982 3.43114717
 3.43218834 3.43386661 3.43753709 3.4376781  3.44131556 3.44369149
 3.44383347 3.46347553 3.48311521 3.48854788 3.49550449 3.52244451
 3.52666378 3.52940066 3.54838231 3.56396435 3.60576445 3.65987855
 3.68305642 3.68739876 3.68974845 3.6903626  3.72467903 3.72615487
 3.84938705 3.86391683 3.87073469 3.88287143 3.88425199 3.89065445
 3.89731819 3.89934505 3.9000972  3.91094122 3.91279495 3.91830517
 3.92401379 3.94431119 3.9886491  3.99348384 3.99374909 4.00664454
 4.05007735 4.08287083 4.16186042 4.28242095 4.29059047 4.32664398
 4.38778928 4.44401996 4.69492868 4.74309786 4.75816687 4.76414768
 4.76655213 4.77104373 4.77605876 4.77821193 4.77863253 4.78694545
 4.7877209  4.78796008 4.78875486 4.79012786 4.79411287 4.79837372
 4.79962529 4.79969724 4.80358735 4.80392941 4.80627635 4.80867785
 4.81095603 4.81628723 4.81982149 4.82396204 4.82644661 4.83186596
 4.83297878 4.84376855 4.84487999 4.86909949 4.89236716 4.89933847
 4.92110386]

  warnings.warn(

2022-12-16 10:37:04,846:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.04822606 2.07043377 2.09124741 2.10691535 2.11100979 2.19343128
 2.35428304 2.7209589  2.78861781 2.87332092 2.87971643 2.88899491
 2.89373235 2.90365148 2.9136811  2.91377624 2.91513765 2.91798984
 2.92483162 2.92725204 2.92973424 2.93178477 2.93227581 2.93230802
 2.93344768 2.93418744 2.93518993 2.93559337 2.93710153 2.94224437
 2.94273353 2.94406748 2.94561018 2.95012461 2.95034515 2.95171901
 2.95172664 2.95635857 2.95684541 2.95685662 2.95796715 2.95910385
 2.95924814 2.96174375 2.96176387 2.96188516 2.96537587 2.96540467
 2.96695795 2.96714076 2.96792209 2.97007305 2.97061666 2.9719758
 2.97251258 2.9728811  2.9729139  2.97294573 2.97327613 2.97345496
 2.97396955 2.97458868 2.97537462 2.97571206 2.97663759 2.9769009
 2.9771028  2.97816211 2.9783615  2.97924403 2.98101624 2.98210167
 2.98222679 2.98311798 2.98399323 2.98417324 2.98471358 2.98483906
 2.98485631 2.98737322 2.98759923 2.98905435 2.99246576 2.99326363
 2.9933963  2.99357196 2.9938929  2.99411429 2.994295   2.99586869
 2.99596264 3.0019137  3.0053788  3.00589409 3.00693285 3.00767464
 3.00982089 3.01145675 3.01711826 3.01921852 3.02110706 3.02205807
 3.02285448 3.02341546 3.02583965 3.02710782 3.02831983 3.02840337
 3.02917954 3.02938107 3.0302183  3.0315456  3.03235141 3.0330959
 3.0359247  3.0384471  3.04009258 3.04135157 3.04325937 3.04558993
 3.05763944 3.06046084 3.0625656  3.06356347 3.06360153 3.06895758
 3.06926631 3.06963974 3.07083585 3.07189158 3.07376632 3.0754002
 3.07571812 3.07649236 3.07870811 3.07945123 3.08034223 3.08058604
 3.08110363 3.08204851 3.08309237 3.08369239 3.08391163 3.08581096
 3.08704863 3.08809993 3.08992333 3.09027531 3.09082618 3.09184181
 3.09392162 3.0939715  3.09417905 3.09487673 3.09561932 3.0956471
 3.09579257 3.09629812 3.09737216 3.09877047 3.09964773 3.10047547
 3.10271219 3.10275686 3.10408903 3.10436158 3.10482695 3.10484235
 3.10514631 3.10534131 3.10537789 3.10564415 3.10677425 3.10721914
 3.10752796 3.1079192  3.10795012 3.10810739 3.10872597 3.10879367
 3.10894842 3.10928254 3.11002129 3.11009374 3.11020396 3.11065223
 3.11103624 3.11126426 3.11177478 3.11231659 3.11254307 3.1129794
 3.11300874 3.11316849 3.113687   3.11382138 3.11414039 3.11521648
 3.11548755 3.11575594 3.11593038 3.11632977 3.11750435 3.11784742
 3.11819716 3.11853591 3.11857795 3.11925667 3.1200918  3.12086585
 3.12118916 3.12129898 3.12217851 3.12309034 3.12394946 3.12451511
 3.1246281  3.12491671 3.12501768 3.12552592 3.12693239 3.12769091
 3.12798134 3.1282626  3.12871038 3.12910906 3.12931386 3.12951689
 3.12974919 3.13015204 3.13088477 3.13223538 3.13239798 3.13353744
 3.1339919  3.13412208 3.13425499 3.13636971 3.13669411 3.13684113
 3.13698703 3.13730448 3.13747493 3.13891274 3.13892413 3.13900371
 3.13982434 3.1398773  3.1400681  3.14051846 3.14086625 3.14163685
 3.14198271 3.14279225 3.14312536 3.1433054  3.14354832 3.14400871
 3.14403646 3.14494538 3.14542814 3.14559101 3.14566581 3.14573402
 3.14622671 3.14625611 3.14684239 3.14714802 3.14748675 3.14755076
 3.14787903 3.14796038 3.14848563 3.14857812 3.14883013 3.14906839
 3.1491291  3.14920916 3.14921719 3.14940939 3.14956667 3.14975482
 3.14981816 3.15038626 3.15077335 3.15123727 3.15142923 3.15175018
 3.15178373 3.15203194 3.15237109 3.15279703 3.15298819 3.15307562
 3.15315193 3.1531582  3.15322757 3.15347667 3.15382057 3.15389233
 3.15402337 3.15413167 3.15422231 3.15436243 3.15496839 3.15517403
 3.15524678 3.1554535  3.15586912 3.15593503 3.15633702 3.15668566
 3.15683765 3.15718025 3.15755818 3.15766723 3.15769607 3.15784801
 3.15796637 3.15797862 3.15817841 3.15834853 3.15865696 3.15897082
 3.15903049 3.15955493 3.15961622 3.1597414  3.15997253 3.16148826
 3.16152669 3.16154625 3.16174459 3.16175115 3.16183657 3.16201492
 3.16229961 3.16316077 3.16355278 3.16383657 3.16386484 3.16399454
 3.1640236  3.16408505 3.16412041 3.16419493 3.16434519 3.16438605
 3.16440256 3.16463417 3.16464332 3.16466057 3.16529346 3.16538084
 3.16538176 3.16545616 3.16587953 3.16594845 3.16600415 3.16609072
 3.16621404 3.16631953 3.16668619 3.16678926 3.16685885 3.16715545
 3.16792841 3.16807529 3.16812155 3.16868717 3.16911505 3.16916002
 3.16922246 3.16938817 3.16952964 3.16957705 3.16972159 3.16998923
 3.17007428 3.17009654 3.17010852 3.17015011 3.17032946 3.17054794
 3.1706491  3.17106825 3.17130592 3.17148648 3.17193077 3.17202809
 3.17214021 3.17224926 3.17228309 3.17328468 3.1733019  3.17371164
 3.17383574 3.17399618 3.17408439 3.17431595 3.17448717 3.17483409
 3.17489807 3.17501313 3.17529825 3.17555468 3.17566567 3.17572208
 3.17572574 3.17577798 3.1758462  3.1766154  3.17678375 3.17680669
 3.17681032 3.17685512 3.17699617 3.17706102 3.17714114 3.17734251
 3.17734834 3.17763211 3.17774695 3.17780281 3.17784712 3.17792965
 3.17847428 3.17905923 3.17920596 3.17925725 3.17970154 3.17988123
 3.17990293 3.17995428 3.18001373 3.18003588 3.18014355 3.18014689
 3.18084877 3.18088529 3.18106068 3.18119984 3.18126243 3.18165153
 3.18176781 3.18209036 3.18229954 3.18230451 3.18241078 3.18276121
 3.183253   3.18332355 3.18344202 3.18350635 3.18357946 3.18406018
 3.18408674 3.18480139 3.18592561 3.18628511 3.18637461 3.18673105
 3.18693901 3.18699741 3.18731649 3.18776893 3.18785127 3.18795523
 3.18826479 3.18828909 3.18863739 3.1889015  3.18905707 3.18923777
 3.18950796 3.19018753 3.19046428 3.19060979 3.19064106 3.19085117
 3.19089627 3.19172303 3.19188302 3.19208879 3.1922232  3.1925912
 3.1928916  3.19300605 3.19343006 3.19361428 3.19371742 3.19403399
 3.19459723 3.19465285 3.19470548 3.19506186 3.19510906 3.19525421
 3.19548789 3.19597431 3.19598269 3.19602975 3.19659019 3.19676338
 3.19743561 3.19758926 3.19768168 3.19872003 3.19882164 3.19887297
 3.20040701 3.20045627 3.20047428 3.20053676 3.2007395  3.20090988
 3.2009644  3.20119597 3.20126022 3.20171583 3.20188174 3.20202895
 3.20224357 3.20241708 3.2024871  3.20315356 3.20336723 3.2034001
 3.20344871 3.20363525 3.20381547 3.20411156 3.20424351 3.20426596
 3.20442481 3.20449989 3.2045932  3.20475964 3.20521359 3.20561168
 3.20624369 3.2072755  3.2073146  3.20795752 3.20799373 3.20808673
 3.20820463 3.20823881 3.20865122 3.20895352 3.2089879  3.20943347
 3.20948424 3.20999354 3.21007649 3.21034047 3.21094285 3.21121018
 3.21150701 3.21175793 3.21241352 3.21264715 3.21270244 3.2129466
 3.21356962 3.21367745 3.2136784  3.21399138 3.21412025 3.2146003
 3.21488254 3.21515884 3.21533652 3.21557524 3.21561246 3.21606204
 3.21631505 3.21633851 3.21640703 3.21647279 3.2167995  3.21845987
 3.21938167 3.21966275 3.21967286 3.21975558 3.22014426 3.22039259
 3.22073251 3.22110332 3.2213837  3.22167447 3.22242813 3.22269508
 3.22281062 3.22316481 3.22410802 3.2246196  3.22483513 3.22522971
 3.22556883 3.22622871 3.22628371 3.22651115 3.22654247 3.22685836
 3.22723629 3.22731734 3.22798688 3.22895052 3.23038176 3.23266416
 3.23374527 3.23386139 3.23396995 3.2342598  3.23434075 3.23534044
 3.23944896 3.24000586 3.24001271 3.24013903 3.2410751  3.24112422
 3.24126149 3.24129924 3.24292144 3.24418217 3.24571664 3.24630713
 3.24648909 3.24851186 3.24899277 3.2504768  3.25194937 3.25201272
 3.25264133 3.25453826 3.25486315 3.25738594 3.25752826 3.25776408
 3.25898457 3.25975354 3.2609423  3.26237828 3.26333435 3.2695281
 3.27054615 3.27077711 3.2718682  3.2734831  3.27391911 3.27420166
 3.27681799 3.27714583 3.27774826 3.27961439 3.28026344 3.28109463
 3.28173338 3.2817745  3.28276656 3.28326293 3.2834116  3.28398941
 3.28480862 3.28513943 3.28540808 3.28543693 3.28670077 3.28754509
 3.28860762 3.28872342 3.28963379 3.29169355 3.29241242 3.2933856
 3.29378448 3.29393123 3.29515358 3.29518912 3.29546071 3.2964158
 3.29989569 3.30285678 3.30299289 3.30405917 3.30523129 3.30526445
 3.30580626 3.30773816 3.31326164 3.31383052 3.31551772 3.31587724
 3.31758433 3.31926359 3.31990194 3.32025728 3.32027048 3.32068822
 3.32246275 3.32435686 3.32476256 3.32565385 3.32666225 3.32756646
 3.32932926 3.33071252 3.33412086 3.33528964 3.33812224 3.33863674
 3.34009782 3.34058299 3.34065073 3.34238231 3.34376627 3.35106386
 3.35273094 3.35281702 3.35449095 3.35647978 3.35672784 3.35835441
 3.35914375 3.35926995 3.36106114 3.3624628  3.36335143 3.3635668
 3.36659194 3.36659605 3.36916882 3.37012726 3.37033147 3.3714056
 3.3714247  3.37159475 3.37313557 3.37327192 3.37348487 3.37451277
 3.37486373 3.37584715 3.37741678 3.3782962  3.38005713 3.38042425
 3.38133771 3.38141544 3.38314916 3.38376002 3.38384671 3.38509409
 3.38531877 3.38545495 3.38719301 3.38789585 3.38811506 3.38850636
 3.38968062 3.38998799 3.39048596 3.39110766 3.39201531 3.39333366
 3.3944371  3.39497347 3.39509901 3.39535253 3.40057336 3.40081763
 3.40117545 3.40127458 3.40742471 3.40959364 3.41012944 3.4105503
 3.41056749 3.41144352 3.41446172 3.41568761 3.41854941 3.42685464
 3.42969909 3.43598335 3.44764203 3.46067454 3.4643273  3.47576119
 3.47636735 3.49713009 3.49847715 3.49955417 3.50082322 3.50087353
 3.50638885 3.50881417 3.51296724 3.52191631 3.52310592 3.52463496
 3.63910844 3.65819538 3.77778736 3.81649354 3.82194611 3.82259774
 3.82769232 3.842406   3.84441408 3.8517116  3.85317726 3.85801518
 3.85865975 3.87865611 3.88039819 3.89526393 3.9399283  3.94164818
 4.32216863 4.35824669 4.40897013 4.48601392 4.71957581 4.74515288
 4.75529624 4.79118482 4.79355391 4.79359516 4.7936555  4.79493359
 4.79500799 4.7970519  4.79781956 4.79872842 4.80179337 4.8033393
 4.8033752  4.80422537 4.80525811 4.81137111 4.81630446 4.81881991
 4.82547911 4.82705603 4.84068773 4.85414054 4.87292656 4.90800013
 4.92201708 4.92400461 4.92792896]

  warnings.warn(

2022-12-16 10:37:05,553:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.03953916 2.62884501 2.87222235 2.87898404 2.88680471 2.88967872
 2.91220353 2.92691191 2.93201496 2.93668603 2.9410296  2.94574148
 2.94719191 2.9484603  2.95060705 2.9518642  2.95188226 2.95263392
 2.95366633 2.95479428 2.95490168 2.95541911 2.95565308 2.95604345
 2.95647299 2.95800228 2.95887834 2.95895433 2.95996542 2.96146858
 2.96524612 2.96526272 2.9677841  2.96800508 2.96830334 2.96920372
 2.97029207 2.97179583 2.97300586 2.97343012 2.97414643 2.97429481
 2.9759789  2.97751294 2.98017299 2.98564985 2.98578781 2.98654347
 2.98893534 2.99040444 2.99331726 2.99539867 2.99635648 2.99673413
 2.9969856  2.99722836 2.998974   3.001286   3.00273478 3.00312702
 3.0041358  3.00471943 3.00508159 3.00526202 3.00626018 3.01011622
 3.01038835 3.01088848 3.01111927 3.01128613 3.01413366 3.01632905
 3.02089271 3.02136644 3.02218525 3.02511762 3.02581234 3.02696326
 3.02936912 3.02974609 3.03346071 3.0338246  3.03511425 3.03895482
 3.040954   3.04205086 3.04490335 3.04553572 3.04590809 3.04875834
 3.05045797 3.05319411 3.05470505 3.05538887 3.05785024 3.06042688
 3.06169329 3.06747784 3.06781032 3.06806823 3.06869938 3.07241178
 3.07324884 3.07671299 3.08109586 3.08201919 3.08372913 3.08496279
 3.08588006 3.0860498  3.09238187 3.09391551 3.09482251 3.09907905
 3.09971625 3.09990847 3.10004233 3.10165824 3.10464074 3.10472784
 3.10525668 3.10652495 3.10729842 3.10748327 3.10851736 3.10891953
 3.10911197 3.10915335 3.11111819 3.11251733 3.11276108 3.11318916
 3.11359821 3.11440376 3.11578249 3.11648608 3.11702865 3.11824426
 3.11962266 3.12181543 3.12346642 3.12419976 3.12432953 3.12513222
 3.12538965 3.12694336 3.12834898 3.12869454 3.12920971 3.13055429
 3.13066163 3.13107668 3.13160056 3.13175201 3.13210245 3.13222922
 3.132253   3.13291933 3.13300666 3.13438434 3.13470305 3.134956
 3.13506572 3.13507329 3.13609151 3.13625268 3.13652494 3.13666231
 3.13689656 3.13691108 3.13696182 3.13786202 3.13801557 3.13863352
 3.13912212 3.13930049 3.14034795 3.14047169 3.14076646 3.14076822
 3.14136518 3.14197551 3.14212419 3.14218179 3.14239511 3.14242498
 3.14246327 3.14258065 3.14259752 3.14267657 3.14268534 3.14299789
 3.14320304 3.14337757 3.14360922 3.14362347 3.14392309 3.14397204
 3.14423662 3.14437285 3.14451072 3.1449752  3.14506803 3.14540463
 3.14560685 3.14581895 3.14621749 3.14624265 3.14647348 3.14650821
 3.14661268 3.14661593 3.14694165 3.14720647 3.14730265 3.14734717
 3.1474359  3.14758061 3.14766408 3.14817727 3.14834356 3.14852324
 3.14861364 3.14903729 3.1495017  3.1496049  3.14965296 3.14988639
 3.15002337 3.15010713 3.15014841 3.15028705 3.15055013 3.15078032
 3.15083147 3.15113836 3.15126101 3.15129714 3.15206351 3.15223879
 3.15247843 3.15265661 3.15290248 3.15310856 3.15370777 3.15372627
 3.15386506 3.15392556 3.15393497 3.1540507  3.1542007  3.15450731
 3.15513748 3.15533387 3.15548409 3.1560078  3.15619763 3.15642562
 3.15675896 3.15712719 3.15717569 3.15728686 3.1573161  3.15767098
 3.1578813  3.1581441  3.15839181 3.15851536 3.15885105 3.15911596
 3.15920066 3.15940411 3.15960272 3.15972838 3.1599757  3.16000504
 3.16017509 3.16020578 3.16058683 3.16120822 3.16130367 3.16135947
 3.16149206 3.16151774 3.16170184 3.16183894 3.16227375 3.16312513
 3.16353706 3.16372819 3.16391414 3.16523814 3.16525637 3.16551206
 3.16561715 3.16631825 3.16631872 3.16639932 3.16657029 3.16672556
 3.16784345 3.16854911 3.16863074 3.16889264 3.1693599  3.16965484
 3.16969269 3.16989055 3.16989971 3.16993901 3.16999677 3.17152484
 3.17182059 3.1719542  3.17229902 3.17236075 3.17239349 3.17280784
 3.17291374 3.1729366  3.17300844 3.17306715 3.17338745 3.17366849
 3.17383218 3.17440305 3.17484958 3.17503866 3.1751303  3.17515052
 3.17551907 3.17563524 3.17637051 3.1764203  3.17656108 3.17674879
 3.1773885  3.17745952 3.17763586 3.17784525 3.17804635 3.17821488
 3.1789036  3.1790385  3.17922447 3.17930701 3.17931994 3.17946188
 3.17950615 3.17955599 3.17979708 3.18010305 3.18044405 3.18057029
 3.1807159  3.18075607 3.18089497 3.18098744 3.18113813 3.18116873
 3.18124882 3.18142842 3.1814732  3.18153522 3.18158062 3.18214763
 3.18223426 3.1822883  3.18277593 3.18298422 3.18308737 3.18309735
 3.18316808 3.1835153  3.1835807  3.1836554  3.18366081 3.1837697
 3.18392647 3.18420052 3.18427237 3.18438278 3.18448681 3.18456624
 3.18457636 3.18461581 3.1846472  3.18468724 3.18482173 3.18486423
 3.18500291 3.18510932 3.18540845 3.1854216  3.18578328 3.18615917
 3.18619466 3.18625278 3.18628202 3.18631413 3.18650495 3.18685108
 3.18705478 3.18715014 3.18744059 3.18809075 3.18819749 3.18834904
 3.18856305 3.18862928 3.18868706 3.18876451 3.18881439 3.18925644
 3.18978654 3.18981166 3.18991914 3.18997804 3.19118293 3.19129091
 3.19162117 3.19172014 3.19177777 3.19213379 3.19228626 3.19229475
 3.19231502 3.19240842 3.19241907 3.19251647 3.19254403 3.19257976
 3.19272526 3.19276664 3.19278101 3.19279716 3.19292982 3.19303289
 3.19330749 3.19341542 3.1938938  3.19397663 3.19408288 3.19419238
 3.19422353 3.19457002 3.19472942 3.19502078 3.19527384 3.19543725
 3.19554827 3.19573757 3.19578777 3.19591957 3.19622171 3.19659109
 3.19667648 3.19676703 3.19678959 3.19700027 3.19754415 3.19827061
 3.19848926 3.19849399 3.19852483 3.19861809 3.19887041 3.19897146
 3.19898784 3.19941749 3.199482   3.19978589 3.19979593 3.1998465
 3.20033275 3.20065876 3.20067987 3.20068389 3.20078126 3.20097647
 3.20102798 3.20107972 3.20114915 3.20124607 3.20188983 3.2019511
 3.20200544 3.20222947 3.20224042 3.2022946  3.20234408 3.20242678
 3.20252293 3.2025275  3.20300602 3.20316697 3.20338711 3.20363412
 3.20375799 3.20424923 3.20438366 3.2045174  3.20464681 3.20465045
 3.20480213 3.20532603 3.20553453 3.20556764 3.20602728 3.20628804
 3.20653989 3.20658203 3.20683782 3.2076638  3.20773076 3.20850544
 3.20868726 3.20871784 3.2087778  3.2089621  3.21021172 3.21051203
 3.21068792 3.21079337 3.21087153 3.21092632 3.21143064 3.21147453
 3.21202887 3.21209754 3.21242879 3.21258592 3.21292463 3.21319681
 3.2133949  3.213702   3.21383666 3.21383978 3.21389312 3.21546447
 3.21581716 3.2162959  3.21668714 3.21686906 3.21688043 3.2173226
 3.21838071 3.21844152 3.21861654 3.21923391 3.21960341 3.21998151
 3.22090373 3.22126684 3.22132656 3.22137298 3.22145202 3.22215406
 3.22252933 3.22282799 3.22289618 3.22347233 3.22359733 3.22362976
 3.2237912  3.22380587 3.22420444 3.22477504 3.22498141 3.22510675
 3.22522909 3.22552366 3.22581569 3.22601567 3.22613812 3.22718832
 3.22723102 3.22736318 3.22806449 3.22815705 3.22819483 3.22902656
 3.22925294 3.22933275 3.22941519 3.22953954 3.22965148 3.23068882
 3.2307245  3.2313035  3.23135093 3.23190225 3.23203633 3.2328263
 3.23286667 3.23377572 3.23441529 3.23449052 3.23469749 3.23533451
 3.23801391 3.2380292  3.23814804 3.23816614 3.23892944 3.23898244
 3.23955693 3.24000498 3.24017047 3.24088279 3.24198828 3.24301324
 3.24329014 3.243709   3.24432689 3.24455687 3.24525112 3.24570381
 3.24661507 3.24675364 3.24683689 3.24691067 3.24757635 3.24782299
 3.24790919 3.24826297 3.24923682 3.24936228 3.24939011 3.24976049
 3.2509402  3.25155953 3.25174075 3.25229457 3.25361445 3.25381739
 3.25428703 3.25466896 3.25466968 3.25478775 3.25500888 3.25726277
 3.25789885 3.25855993 3.25913534 3.25930906 3.25996333 3.26171593
 3.26192096 3.26443841 3.26532753 3.26536317 3.26543748 3.26699321
 3.26934309 3.26970662 3.27061661 3.27222053 3.2727872  3.27287318
 3.27302418 3.27358089 3.27597152 3.27625846 3.27832212 3.28077582
 3.28345576 3.28358475 3.28427855 3.28477401 3.28539079 3.28541878
 3.28577808 3.28618956 3.28733709 3.28807541 3.28860639 3.28867143
 3.28997455 3.29054103 3.29123309 3.29326502 3.29786365 3.29848604
 3.30111237 3.3015508  3.3018705  3.30291307 3.30393265 3.30719596
 3.3075184  3.30900946 3.3102071  3.31044436 3.31155115 3.31321598
 3.31392379 3.31520848 3.31818859 3.31868815 3.31945443 3.3224289
 3.32379969 3.32407258 3.32570444 3.3290863  3.33033014 3.33134088
 3.33180033 3.33287439 3.33302991 3.33445795 3.33464707 3.33542886
 3.33654346 3.3377486  3.34047088 3.34357399 3.34360018 3.34398868
 3.34411007 3.34498245 3.34830776 3.34896713 3.34909712 3.34934271
 3.35105928 3.35136127 3.35202968 3.35310162 3.35435275 3.35579852
 3.35625689 3.36009071 3.36017154 3.3606274  3.36128153 3.36213046
 3.36227197 3.36364626 3.36379454 3.36585471 3.36588926 3.36825154
 3.36830987 3.36994342 3.37157639 3.37258517 3.37411405 3.37538867
 3.37617725 3.37622275 3.37919529 3.37959579 3.38009735 3.3809433
 3.3813677  3.38168392 3.38239929 3.3834574  3.38480491 3.38500489
 3.3862984  3.38659067 3.38886422 3.38966458 3.39041666 3.390668
 3.39240283 3.39322165 3.39428543 3.39549084 3.39598711 3.39662415
 3.39697065 3.39814627 3.39894879 3.40159785 3.40180385 3.40383527
 3.40510744 3.40826152 3.40840859 3.41412202 3.4165306  3.42229825
 3.43309362 3.43395127 3.43759514 3.47185306 3.47657554 3.47751105
 3.480508   3.51177991 3.55008545 3.5911665  3.59178064 3.60572502
 3.60641899 3.60738382 3.6075838  3.6187354  3.62333684 3.64665313
 3.66459724 3.76538559 3.77122463 3.77661072 3.77792669 3.78711807
 3.79097378 3.79535551 3.80419326 3.80578972 3.81579495 4.13334987
 4.18183922 4.23257519 4.26699893 4.32150214 4.35479185 4.68254897
 4.68738328 4.6969955  4.69892636 4.74217176 4.74549137 4.74558096
 4.76057304 4.76138113 4.7634879  4.77057674 4.7730137  4.77418312
 4.77454719 4.77480885 4.7753075  4.77774168 4.77971721 4.77978783
 4.78196667 4.78352492 4.78611304 4.78708641 4.78738452 4.78801437
 4.79290002 4.79413567 4.79419132 4.79497135 4.79971705 4.80104913
 4.86057378 4.89661901 4.91535439 4.94999135]

  warnings.warn(

2022-12-16 10:37:05,592:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.71313581 1.71334218 2.02056489 2.04052989 2.06192458 2.06292628
 2.07566096 2.09239389 2.09744265 2.11205425 2.11418322 2.13416538
 2.16175564 2.30713136 2.69390688 2.78338308 2.78699407 2.80683668
 2.82142785 2.83130863 2.85230684 2.8558997  2.87825024 2.88451279
 2.88723309 2.88779711 2.91135066 2.91254399 2.91296533 2.91593015
 2.91793142 2.9220038  2.9226296  2.93424551 2.93433461 2.93502625
 2.93977318 2.94116238 2.94227468 2.94786762 2.94914796 2.95103234
 2.953427   2.95377942 2.95419642 2.95514527 2.95557366 2.95700425
 2.95721281 2.9584069  2.95934699 2.96105202 2.96199565 2.96569261
 2.96861129 2.96878613 2.97007696 2.97125882 2.97156645 2.97356302
 2.97450946 2.97600997 2.97714955 2.97772222 2.97792461 2.9779728
 2.97811166 2.97831973 2.97955505 2.97995536 2.979962   2.98016613
 2.98052608 2.98109669 2.9817253  2.98174367 2.98192031 2.98206625
 2.9829028  2.98345687 2.98373192 2.98377261 2.9840059  2.98430685
 2.98450638 2.98471705 2.98508318 2.98643421 2.98668029 2.98768646
 2.98773758 2.98850989 2.98884618 2.9899738  2.99150366 2.99176015
 2.9920169  2.99452307 2.99566246 2.99795989 2.9984779  2.99859349
 2.99937146 3.002828   3.0031099  3.00348139 3.00359012 3.00401786
 3.00452545 3.00460774 3.00625051 3.00632816 3.00740837 3.00747046
 3.00835747 3.00862702 3.00876791 3.01014679 3.01248852 3.01406322
 3.01410423 3.01502379 3.01563597 3.0159127  3.0168114  3.02108107
 3.02272391 3.02400035 3.02510846 3.02960505 3.03034537 3.0343756
 3.0469785  3.04756046 3.04887671 3.05002685 3.05086535 3.05414929
 3.05769492 3.06010636 3.06042086 3.06169106 3.06413588 3.06871653
 3.06978091 3.06991539 3.07750598 3.07924615 3.08192747 3.08193106
 3.08293136 3.08518092 3.09051752 3.09087966 3.09314214 3.09429902
 3.09463192 3.0949873  3.09540327 3.09609401 3.09774888 3.09832816
 3.09981369 3.10069434 3.10072761 3.10719256 3.10833499 3.10889667
 3.10927488 3.10953979 3.10962607 3.1098224  3.11006203 3.11039972
 3.11054289 3.1110172  3.1110459  3.11115143 3.11119626 3.1112102
 3.1119144  3.11261439 3.11274844 3.11282478 3.11288414 3.11300359
 3.11305027 3.11352722 3.11392425 3.11442551 3.11522977 3.11531364
 3.11564778 3.11571491 3.11645523 3.11650219 3.11924434 3.12005168
 3.12006697 3.12048572 3.12071806 3.12169118 3.12239071 3.122665
 3.12352309 3.12446514 3.12557855 3.12613233 3.12628436 3.12696742
 3.12892036 3.12934741 3.13029332 3.13100044 3.1315796  3.13183534
 3.13251118 3.13460959 3.13533905 3.13579087 3.13603007 3.1362886
 3.13669875 3.13676093 3.13680768 3.13681975 3.13687823 3.13690479
 3.13726096 3.13759957 3.13763846 3.13809989 3.13858661 3.13877244
 3.13878105 3.13883362 3.13913853 3.13929614 3.13957729 3.13961662
 3.13981614 3.13996618 3.140619   3.14157749 3.14180335 3.14234542
 3.14267313 3.14279695 3.14302933 3.14303008 3.14312698 3.14316059
 3.14394557 3.14419216 3.14630933 3.14664508 3.14676403 3.14783418
 3.14832116 3.14867081 3.1498882  3.15063349 3.15090253 3.15122857
 3.15131951 3.15139164 3.1521372  3.15231527 3.15275598 3.15294524
 3.15325018 3.15341401 3.15342898 3.15356075 3.15363239 3.15371968
 3.15378208 3.15386873 3.15395109 3.15398209 3.15406222 3.15417844
 3.15428847 3.1544497  3.15446732 3.15478634 3.15566496 3.1557476
 3.155781   3.1561062  3.15647947 3.15686926 3.15709495 3.15734477
 3.15745672 3.15767465 3.15783296 3.15840582 3.15899329 3.15901734
 3.15923492 3.15923567 3.15963895 3.16032118 3.16049284 3.16133788
 3.16185214 3.16216223 3.16226154 3.16259165 3.16263718 3.16339968
 3.16341201 3.1634306  3.1636219  3.16420451 3.16486877 3.16496739
 3.16545277 3.16560013 3.16569256 3.16587402 3.16616752 3.16623813
 3.16647583 3.16699525 3.16764715 3.16779471 3.16807998 3.16841539
 3.16885263 3.16951694 3.16976099 3.1702345  3.17053081 3.17157553
 3.17165827 3.17269943 3.17304158 3.1730955  3.17353313 3.17396414
 3.17400421 3.17432952 3.17447953 3.1753039  3.17548468 3.17556113
 3.17556501 3.17559005 3.17587258 3.17615982 3.17633164 3.17639606
 3.17700339 3.17703594 3.17709541 3.17756705 3.17757277 3.17770463
 3.17781651 3.17784032 3.17785744 3.17805268 3.17812597 3.17819599
 3.17819897 3.17841372 3.17853241 3.17887735 3.17909206 3.17939114
 3.17942426 3.17942973 3.17945766 3.17963344 3.1797063  3.17974887
 3.1798831  3.17996732 3.18052518 3.18068334 3.18100982 3.18108424
 3.18129292 3.18132214 3.18138808 3.18144737 3.18150734 3.18161714
 3.1817126  3.18187792 3.18195359 3.18200811 3.18201497 3.18230278
 3.18247724 3.18251067 3.18260792 3.18262257 3.18287358 3.18292988
 3.18299046 3.18306326 3.18311428 3.18359641 3.18396357 3.18404719
 3.1840885  3.18409292 3.18409829 3.18425422 3.18429616 3.18439336
 3.18465763 3.1847175  3.18479368 3.18487971 3.18490768 3.18572988
 3.18600971 3.18609452 3.18625124 3.1862729  3.18662721 3.18686335
 3.18722682 3.18725225 3.18725314 3.18776395 3.18778424 3.18799962
 3.18831752 3.18836809 3.18841415 3.18843831 3.18864637 3.18889709
 3.18891302 3.18954336 3.19027423 3.19042346 3.19056908 3.19062282
 3.19126259 3.19192866 3.19296867 3.1933333  3.1934222  3.19351892
 3.19383493 3.19405169 3.19425793 3.19474444 3.19486934 3.19515818
 3.19526619 3.19755098 3.19780371 3.19794556 3.19795264 3.19801358
 3.19838844 3.19867265 3.19945326 3.20010627 3.20030069 3.20071489
 3.20103852 3.20119322 3.20123224 3.20128484 3.20146939 3.20183165
 3.2020039  3.20212429 3.20270014 3.20311828 3.20328857 3.20344866
 3.2034707  3.20358269 3.20365143 3.20365582 3.20367871 3.20374778
 3.20379139 3.20385019 3.20390981 3.20394619 3.20420568 3.20423804
 3.20442061 3.20458353 3.20481764 3.20517218 3.20520044 3.20541101
 3.20563282 3.20583398 3.20584093 3.20611138 3.20611292 3.20634752
 3.20652949 3.20685031 3.20688855 3.20706543 3.20721665 3.20775066
 3.20792898 3.20818065 3.20855047 3.20860199 3.20868111 3.20878385
 3.20880152 3.20887331 3.20901162 3.20901817 3.20979161 3.2104393
 3.21081395 3.21094179 3.21131416 3.21141787 3.21151226 3.21155411
 3.21194215 3.2126704  3.21270088 3.21305669 3.21346249 3.21368586
 3.21430136 3.21459501 3.21505707 3.21512977 3.21518219 3.2152461
 3.2153293  3.21557012 3.21652311 3.21699526 3.21780022 3.21822833
 3.21825414 3.21826686 3.21869196 3.21876029 3.21910679 3.22123638
 3.22208884 3.22242685 3.22247969 3.22344074 3.22345122 3.22351902
 3.2236257  3.22363381 3.22394868 3.22476551 3.22478829 3.22493326
 3.22497098 3.22509571 3.22562316 3.22589934 3.22630198 3.22691172
 3.22789166 3.22794735 3.2281278  3.22829106 3.22829809 3.22838255
 3.2285161  3.22918406 3.2292621  3.22975455 3.22995298 3.22999122
 3.23005967 3.23029582 3.23051736 3.23067759 3.23108024 3.23121561
 3.23200921 3.2320116  3.23226119 3.23297387 3.23316931 3.23365967
 3.23502103 3.23536538 3.23625546 3.23683116 3.238039   3.23914788
 3.23960706 3.24030397 3.24267013 3.24440674 3.24490775 3.24509503
 3.24523833 3.24761312 3.24849372 3.24861158 3.24898021 3.24916531
 3.24942869 3.24994489 3.24999969 3.25010957 3.25011441 3.2507369
 3.25080392 3.25122047 3.25148563 3.25233669 3.25309144 3.25392623
 3.25623095 3.25751625 3.2577685  3.25796998 3.2585648  3.25857747
 3.259114   3.2591256  3.26123774 3.26245678 3.2627327  3.26307012
 3.26706914 3.27218658 3.27263685 3.27285809 3.27363263 3.27410393
 3.27721448 3.28222647 3.28232779 3.28313263 3.28460145 3.28594898
 3.28909365 3.28944239 3.29059906 3.2914445  3.29156992 3.29229866
 3.2927831  3.29309186 3.29365136 3.29427845 3.29588425 3.29634493
 3.29690533 3.29694676 3.29783349 3.29908291 3.29999955 3.30151843
 3.30221769 3.30547503 3.30636365 3.30637296 3.30704588 3.30713976
 3.30834333 3.31025936 3.31026191 3.31318585 3.31375362 3.3147048
 3.31484969 3.31502652 3.31572625 3.31597274 3.31826819 3.31861483
 3.31941236 3.31965958 3.32050823 3.32124556 3.32201352 3.32279447
 3.32338389 3.32585763 3.32717024 3.32748143 3.32933382 3.32978111
 3.33173331 3.33232035 3.33277009 3.33351406 3.33567822 3.33643147
 3.33701139 3.33778841 3.3382409  3.34028289 3.34064725 3.3419059
 3.34239807 3.34453275 3.34472055 3.34502357 3.34610474 3.346323
 3.34710037 3.34790802 3.34944055 3.35003501 3.35059336 3.35118881
 3.3540148  3.35423703 3.35499514 3.35686243 3.3575554  3.35800257
 3.35855398 3.35874241 3.35930297 3.35977662 3.3604659  3.36232598
 3.3624713  3.36386742 3.36675454 3.36738304 3.36834394 3.36998805
 3.37016825 3.37193338 3.3745289  3.37883078 3.37911939 3.3797748
 3.38019059 3.38364312 3.38538422 3.38736893 3.38748822 3.39015185
 3.39066362 3.39103413 3.39119419 3.39131993 3.392664   3.39520937
 3.39533953 3.39783919 3.39802225 3.39874564 3.40010525 3.4015695
 3.40193739 3.40307146 3.40317001 3.40329225 3.40333614 3.4049073
 3.40546477 3.4059141  3.40793503 3.41123435 3.4119454  3.41336135
 3.42330655 3.42449239 3.42873494 3.4287737  3.43647267 3.4371627
 3.43821037 3.46052691 3.4749492  3.48213335 3.48884093 3.51086829
 3.51411044 3.51466655 3.5155857  3.51847042 3.52354872 3.52963281
 3.53038846 3.5499753  3.55640656 3.56520409 3.57274383 3.58341329
 3.58930126 3.64700403 3.64840588 3.6683324  3.676687   3.67990377
 3.70331582 3.78584796 3.81347843 3.85307343 3.85380773 3.85952621
 3.87253346 3.87574186 3.88139859 3.88945263 3.96538318 3.9702444
 4.02754505 4.07193552 4.07473994 4.15987594 4.30191005 4.329498
 4.73168842 4.75560753 4.75887336 4.77094592 4.7727405  4.77725044
 4.77922525 4.78459779 4.78560955 4.78898149 4.79498298 4.79891152
 4.79977918 4.80067668 4.80240605 4.80328073 4.80446552 4.80542003
 4.80691069 4.80714975 4.8114535  4.81332518 4.81538355 4.82374069
 4.82797098 4.84090861 4.84655236 4.90844827 4.91156046 4.91390992
 4.92912368 4.93799178 4.95569779 5.01954529]

  warnings.warn(

2022-12-16 10:37:05,593:INFO:Calculating mean and std
2022-12-16 10:37:05,594:INFO:Creating metrics dataframe
2022-12-16 10:37:05,598:INFO:Uploading results into container
2022-12-16 10:37:05,599:INFO:Uploading model into container now
2022-12-16 10:37:05,599:INFO:master_model_container: 16
2022-12-16 10:37:05,600:INFO:display_container: 2
2022-12-16 10:37:05,600:INFO:BayesianRidge()
2022-12-16 10:37:05,600:INFO:create_model() successfully completed......................................
2022-12-16 10:37:05,747:ERROR:create_model() for BayesianRidge() raised an exception or returned all 0.0:
2022-12-16 10:37:05,747:ERROR:Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 795, in compare_models
    assert (
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 811, in compare_models
    assert (
AssertionError

2022-12-16 10:37:05,747:INFO:Initializing Passive Aggressive Regressor
2022-12-16 10:37:05,747:INFO:Total runtime is 1.1414836049079895 minutes
2022-12-16 10:37:05,748:INFO:SubProcess create_model() called ==================================
2022-12-16 10:37:05,748:INFO:Initializing create_model()
2022-12-16 10:37:05,748:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002281239F8E0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022810EC8B20>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:37:05,748:INFO:Checking exceptions
2022-12-16 10:37:05,752:INFO:Importing libraries
2022-12-16 10:37:05,752:INFO:Copying training dataset
2022-12-16 10:37:05,758:INFO:Defining folds
2022-12-16 10:37:05,758:INFO:Declaring metric variables
2022-12-16 10:37:05,758:INFO:Importing untrained model
2022-12-16 10:37:05,758:INFO:Passive Aggressive Regressor Imported successfully
2022-12-16 10:37:05,759:INFO:Starting cross validation
2022-12-16 10:37:05,760:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:37:07,730:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.98507991 2.16322598 2.22836875 2.26090784 2.3182499  2.41506702
 2.49949468 2.50391175 2.52960998 2.56066551 2.740705   2.81812024
 3.07278153 3.18305662 3.35920663 3.40965138 3.42340731 3.43868825
 3.44208541 3.4759595  3.47812023 3.4810882  3.48283818 3.48299071
 3.48313044 3.49418367 3.49425995 3.49790987 3.50156081 3.50454574
 3.50537417 3.51278542 3.51715841 3.51822717 3.5193148  3.51946655
 3.51974583 3.52045282 3.52315202 3.52330389 3.52665276 3.53034517
 3.53047887 3.53057282 3.53122144 3.53154217 3.53210604 3.53288439
 3.53313428 3.53331062 3.53348478 3.53436271 3.53614467 3.53667428
 3.53843319 3.54078061 3.54126137 3.54565533 3.54583325 3.54636365
 3.54674669 3.5477744  3.54789685 3.54907787 3.55028139 3.55216354
 3.55333066 3.55348192 3.55393942 3.55439362 3.55490533 3.55676981
 3.55758123 3.55845206 3.55982935 3.55983674 3.56225431 3.56388182
 3.56400684 3.56470123 3.56483631 3.56508804 3.56554861 3.56579884
 3.567263   3.56735254 3.57046293 3.57348875 3.57468294 3.57489703
 3.57531423 3.57622767 3.57747792 3.57774613 3.57923248 3.57970691
 3.57982504 3.57984489 3.58035125 3.58044229 3.58071717 3.58126129
 3.58159862 3.58308904 3.58370769 3.58453935 3.58477509 3.58506736
 3.585186   3.58588867 3.5860468  3.58867869 3.58924688 3.59095489
 3.59333209 3.59434246 3.59486325 3.59517859 3.5953696  3.5954177
 3.59727044 3.59768117 3.59817884 3.5981853  3.60003772 3.60006015
 3.60041776 3.6004234  3.60052305 3.60063793 3.60090424 3.60134216
 3.60247345 3.60266543 3.60360607 3.6037148  3.60385412 3.60399076
 3.60575528 3.60579242 3.60718727 3.60728849 3.60743246 3.60779325
 3.60806685 3.60812159 3.60858349 3.6095272  3.60958263 3.60959573
 3.60990784 3.61329971 3.61331036 3.61363748 3.6140793  3.61507817
 3.61510924 3.61571072 3.61585468 3.61644857 3.61708082 3.61719123
 3.61799632 3.62026995 3.62144006 3.62223894 3.62345965 3.62348804
 3.62408983 3.62441967 3.62497673 3.62551788 3.62641854 3.6281178
 3.62862348 3.63162149 3.63210213 3.63539399 3.6369186  3.63760098
 3.63915049 3.63979125 3.64063684 3.64082393 3.64082721 3.64125243
 3.64297691 3.64486565 3.64521007 3.64678018 3.64796997 3.64937428
 3.65048346 3.65074703 3.6544655  3.6553562  3.6560659  3.65633521
 3.65806859 3.65869709 3.65892161 3.66015078 3.66258917 3.66298141
 3.66317092 3.66455361 3.66494872 3.66542908 3.66837832 3.66942683
 3.67362179 3.67387081 3.67408675 3.67628124 3.67749337 3.67858374
 3.68054398 3.68074578 3.68172163 3.68311158 3.68417776 3.68759273
 3.690022   3.69023387 3.69251851 3.69700656 3.70316913 3.70571884
 3.70654058 3.70724528 3.70803469 3.70811592 3.71107529 3.71170677
 3.71284703 3.7203831  3.72150282 3.72601624 3.72613186 3.72765303
 3.72773675 3.73000043 3.73108177 3.73280046 3.73688261 3.73719283
 3.73914434 3.73941649 3.74005269 3.74029351 3.74101807 3.74316867
 3.7436502  3.74553012 3.74870165 3.75086388 3.75134456 3.75248729
 3.75291312 3.75356668 3.75713463 3.75915426 3.76015827 3.76439456
 3.76509178 3.76537515 3.76670974 3.7668951  3.76817694 3.76862593
 3.7690318  3.77026323 3.77049147 3.77079125 3.77342665 3.77368288
 3.77412301 3.77457565 3.77477882 3.77701006 3.77782494 3.77958481
 3.77979224 3.78168811 3.78285635 3.7842568  3.78663786 3.78731201
 3.78733268 3.78916507 3.78952911 3.78994343 3.79177836 3.79319719
 3.79342466 3.79443332 3.79445079 3.79526648 3.79569045 3.7963578
 3.79667223 3.79678577 3.79751975 3.79873629 3.79920171 3.80129327
 3.8016923  3.80200628 3.80311846 3.8034285  3.80392435 3.8068362
 3.80800266 3.80994764 3.81156571 3.81216901 3.81451375 3.81589852
 3.81668078 3.81836072 3.81961714 3.8208668  3.82131407 3.82146932
 3.82259557 3.82285814 3.82485378 3.82497656 3.82521827 3.82573284
 3.82657755 3.82673519 3.82690543 3.8270362  3.82759437 3.82906644
 3.82927331 3.83244351 3.83434498 3.83484589 3.83663486 3.83831351
 3.83854401 3.84104969 3.84105359 3.84108549 3.8423027  3.84267889
 3.84329257 3.84539287 3.84549344 3.84613029 3.8461812  3.8464243
 3.84653062 3.84665265 3.84682251 3.84754313 3.84755826 3.84763183
 3.84802993 3.84815771 3.84857486 3.84964429 3.85064773 3.85076457
 3.85163056 3.85226151 3.85314607 3.85344598 3.8538376  3.85517771
 3.85785955 3.85865564 3.8591433  3.8591966  3.85926499 3.85943483
 3.86099449 3.86134347 3.86187197 3.86312088 3.86332406 3.86354484
 3.86514642 3.86626658 3.86666234 3.8682536  3.86855328 3.87027111
 3.87070061 3.8711198  3.87139038 3.87261072 3.87270674 3.87274659
 3.87275429 3.87285914 3.87451678 3.87461439 3.87537769 3.87600069
 3.87663422 3.87684546 3.87733585 3.87776086 3.87793676 3.87832239
 3.87877544 3.87934767 3.87977134 3.8801263  3.88058467 3.88135802
 3.88188846 3.88287084 3.883098   3.88429019 3.88437826 3.88441728
 3.88451831 3.88489262 3.88609084 3.88708161 3.88714741 3.88728112
 3.88733092 3.88761434 3.88773233 3.88859353 3.88920924 3.89126288
 3.89170596 3.89217492 3.89338692 3.89356723 3.89411105 3.89491713
 3.89501917 3.89618088 3.8962261  3.89624194 3.89713349 3.89756542
 3.89782007 3.89805831 3.89814405 3.89825099 3.89834332 3.89839547
 3.89863014 3.89866863 3.8997316  3.8998026  3.89994912 3.90001364
 3.90004844 3.90106314 3.90139675 3.90220908 3.90249241 3.90269796
 3.9035734  3.90380489 3.90422944 3.90461009 3.90503306 3.90597094
 3.90624875 3.90637592 3.90656184 3.90666223 3.90693945 3.90695087
 3.90744433 3.90769487 3.90783013 3.90789917 3.90797432 3.90805155
 3.90820574 3.90858518 3.90860437 3.90876055 3.90958916 3.90973352
 3.90989983 3.9099227  3.91092901 3.91107152 3.91150187 3.91218951
 3.91227108 3.91306803 3.91341089 3.91342954 3.91358261 3.91366158
 3.91370078 3.91378218 3.91380716 3.91401516 3.9140772  3.9173996
 3.91755587 3.91799465 3.91807019 3.91815734 3.91840131 3.91840131
 3.91904167 3.91905936 3.919188   3.92038088 3.92047197 3.92101006
 3.92123535 3.92141395 3.92220273 3.92417863 3.92428951 3.92429652
 3.92504636 3.92524263 3.92578801 3.92579174 3.92594702 3.92621664
 3.92650123 3.92653248 3.92669301 3.92678031 3.92680555 3.92764111
 3.92881097 3.92958077 3.92970154 3.92985826 3.93077222 3.93105112
 3.93106332 3.93139744 3.93153569 3.9317002  3.93263411 3.93305343
 3.93320137 3.93430982 3.93438804 3.93448102 3.93454876 3.934641
 3.93479586 3.93486806 3.9348813  3.93552563 3.9359719  3.93620583
 3.9363292  3.93752662 3.93801971 3.93806458 3.93877427 3.93966439
 3.94024328 3.94032998 3.94038007 3.94039299 3.94064983 3.94068015
 3.94069094 3.94075424 3.94214438 3.94226135 3.94239201 3.94267872
 3.94327439 3.94413156 3.94445149 3.94486029 3.94488448 3.94601281
 3.94644716 3.94799818 3.94832951 3.94939904 3.94959608 3.95067765
 3.95081775 3.95122649 3.95126162 3.9531143  3.95325027 3.95394352
 3.95409437 3.95415094 3.95498351 3.95527772 3.95557908 3.95577953
 3.95636705 3.9569087  3.95717883 3.95782908 3.95868808 3.95906934
 3.96118372 3.96250264 3.96252457 3.96256214 3.96310295 3.96381589
 3.96436232 3.96495563 3.96503027 3.96577544 3.96713929 3.96918895
 3.96929919 3.96965702 3.96996027 3.97048565 3.97130991 3.97150361
 3.97247334 3.97353783 3.97360965 3.9749901  3.9790426  3.98103496
 3.98125435 3.98319113 3.98678375 3.98683412 3.98923218 3.98929133
 3.99450392 3.99528032 3.99686061 4.00065808 4.00290369 4.00441573
 4.00442886 4.00478455 4.00479124 4.00631212 4.0068346  4.01111257
 4.01230721 4.01294907 4.01952956 4.01974866 4.02018076 4.02301235
 4.02444917 4.02657168 4.02941442 4.03102527 4.03186211 4.03476131
 4.03579868 4.04334105 4.0449171  4.04665029 4.05908796 4.05919197
 4.06020538 4.06324053 4.06453888 4.06776327 4.06811435 4.07538813
 4.07740998 4.07791189 4.07913449 4.07978025 4.08026815 4.08104593
 4.08115052 4.08296022 4.08578898 4.08936162 4.09143979 4.09217039
 4.09251981 4.09364967 4.09439693 4.09501927 4.09629785 4.09661107
 4.10107936 4.10138402 4.10367363 4.10408157 4.10540382 4.10801261
 4.11038184 4.11100635 4.11113836 4.11268654 4.11528689 4.11742271
 4.11784849 4.11930969 4.12075896 4.12343633 4.1242358  4.1243998
 4.12474904 4.1248176  4.12560257 4.1302048  4.13531074 4.13698779
 4.13738812 4.13839869 4.13859231 4.14022954 4.14364851 4.14458648
 4.15302497 4.15396925 4.15756749 4.1581012  4.15909777 4.1624165
 4.16363568 4.16416421 4.16505863 4.16929593 4.17055012 4.17301665
 4.17325382 4.17651108 4.177311   4.18333417 4.18536862 4.1855605
 4.18747148 4.18785839 4.1879174  4.1886418  4.19037487 4.19169825
 4.19193167 4.193362   4.19837665 4.19860011 4.20284903 4.20427763
 4.2054561  4.20717858 4.20747969 4.2079612  4.20815924 4.20995916
 4.21092805 4.21246671 4.2135838  4.21678654 4.22025781 4.22266914
 4.22351487 4.22595564 4.22728936 4.23145136 4.23160172 4.23584573
 4.23717628 4.23781905 4.23844849 4.23933824 4.24019791 4.24140063
 4.24174999 4.24328837 4.24341979 4.24642786 4.24719589 4.24730123
 4.24774852 4.24987872 4.25363882 4.25407631 4.25416738 4.25624385
 4.25650014 4.25732486 4.26077348 4.26119925 4.26592752 4.26898826
 4.26923481 4.27021278 4.27457555 4.28865583 4.30099963 4.30240255
 4.30330865 4.31867035 4.32647793 4.33341448 4.37156497 4.38217622
 4.38420145 4.38472393 4.38540348 4.38731517 4.38870791 4.3918471
 4.40064261 4.41037523 4.4120784  4.4176827  4.46445901 4.46941718
 4.47346196 4.48017209 4.52481236 4.65336385 4.72186755 4.72197699
 4.72501793 4.74108802 4.75263162 5.22546787 5.24411493 5.27675983
 5.28413429 5.29778242 5.32209819 5.33377671 5.34254069 5.34562094
 5.35539645 5.36704722 5.42805494 5.43225376 5.44605504 5.44829117
 5.56248464 5.58803408 5.58910423 5.59414197 5.59559321 5.60101055
 5.6035129  5.60832223 5.61593968 5.63737814 5.6501138  5.71950194
 5.8511679  5.86596909 5.89344858 5.89648899 5.91179052 5.92189991]

  warnings.warn(

2022-12-16 10:37:07,764:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.34254971 2.72315389 2.74834277 2.75122438 2.7920761  2.87581132
 3.02518132 3.34938479 3.39510751 3.41819158 3.44294834 3.4612655
 3.46524327 3.46643821 3.46748346 3.46824873 3.47510662 3.48373516
 3.48425774 3.48495898 3.48634639 3.48901918 3.49097061 3.49177194
 3.49328904 3.49361657 3.4940412  3.49498492 3.495291   3.49536949
 3.49569242 3.49583022 3.51520458 3.51851203 3.51869063 3.52167286
 3.52330018 3.52452285 3.52504057 3.52820127 3.53109052 3.5315169
 3.53163479 3.53195492 3.53200824 3.53323869 3.53332145 3.53401323
 3.53439581 3.5344758  3.53588788 3.53635812 3.53642764 3.53682898
 3.5380027  3.5380421  3.53813594 3.53997336 3.54524087 3.55135778
 3.55486599 3.55542448 3.55654172 3.55665328 3.5661211  3.56752474
 3.56759245 3.56885459 3.56954538 3.57178736 3.57241085 3.57264163
 3.57276622 3.57794779 3.57887543 3.57888271 3.58048647 3.58062371
 3.5841185  3.58522376 3.59009857 3.59096204 3.59275442 3.59368001
 3.59398048 3.59641566 3.59695524 3.59768418 3.59859842 3.5986375
 3.60060155 3.60267282 3.60938961 3.61140689 3.62168334 3.62355069
 3.62476075 3.62802742 3.62916514 3.63416267 3.6361152  3.6410749
 3.64390523 3.65559182 3.6557246  3.65583192 3.65631048 3.65639039
 3.65675089 3.65890381 3.66315648 3.66605476 3.66729385 3.66933684
 3.66969816 3.6721371  3.67965342 3.67985855 3.68032315 3.68175104
 3.68311007 3.68465307 3.68479832 3.68672826 3.68808296 3.69191865
 3.69192017 3.69455225 3.70026318 3.7010874  3.70179495 3.70356813
 3.7055278  3.70612033 3.70774053 3.71007588 3.71074757 3.71303815
 3.71311417 3.71377042 3.71596002 3.71716416 3.71831445 3.71879119
 3.720216   3.72333253 3.72340291 3.72459328 3.72485408 3.72511867
 3.7256737  3.72568098 3.72582563 3.72611247 3.72641819 3.72736341
 3.72767683 3.7285351  3.73124933 3.73139609 3.7314581  3.73205765
 3.73280843 3.733885   3.7343948  3.73544292 3.73598833 3.73629966
 3.73738033 3.737387   3.73852747 3.73866373 3.7387784  3.73936737
 3.74035248 3.74102911 3.74118192 3.7431934  3.7460075  3.74606888
 3.74618399 3.74634024 3.74657028 3.74769301 3.74789069 3.74870953
 3.74917656 3.74920403 3.74969325 3.74997223 3.75061064 3.75102468
 3.75127596 3.7517346  3.75227164 3.75386665 3.75400799 3.75741537
 3.75771322 3.75787383 3.75877122 3.7589307  3.75944347 3.75966354
 3.76010807 3.76038763 3.7604729  3.76083011 3.76168795 3.76189983
 3.76223619 3.7626854  3.76308511 3.76418125 3.76511621 3.76518371
 3.76535779 3.76557188 3.76587021 3.76768741 3.76862218 3.7687495
 3.76904507 3.76954015 3.77457317 3.77557928 3.7767875  3.77685005
 3.77740314 3.77840992 3.77880957 3.77886489 3.77943394 3.77951915
 3.78492629 3.78509414 3.78531749 3.78562809 3.78595413 3.78612424
 3.78619822 3.78727609 3.78782089 3.78785007 3.78798768 3.78874738
 3.78988294 3.79000327 3.79043404 3.79052831 3.79062663 3.79160718
 3.79323617 3.79411875 3.79596745 3.79616342 3.79645162 3.79706109
 3.7971334  3.79747576 3.79801294 3.79812407 3.79879443 3.79958834
 3.79971595 3.80048828 3.80240822 3.80313726 3.80376754 3.80429326
 3.80485842 3.80490646 3.80583126 3.80609635 3.80618654 3.80630987
 3.80634086 3.80659367 3.80680038 3.80828834 3.81181044 3.81182975
 3.81240279 3.81248581 3.81467765 3.81471455 3.81477132 3.81605814
 3.8161763  3.81640287 3.81646663 3.81646886 3.81657062 3.81749422
 3.81757449 3.81774616 3.81796279 3.81948191 3.82061339 3.82110485
 3.82152352 3.82233886 3.82267722 3.82354809 3.82413155 3.82515093
 3.82680298 3.82779105 3.82855722 3.82865156 3.82991927 3.831228
 3.83286387 3.83316183 3.83341797 3.83378449 3.83393038 3.83467264
 3.83472866 3.83732975 3.83752944 3.83898617 3.83904419 3.83918856
 3.83998702 3.84113286 3.84119619 3.84159356 3.84179607 3.84195
 3.84357512 3.84387648 3.84496137 3.84585538 3.84592521 3.84666788
 3.84755682 3.84759144 3.84791693 3.84968843 3.84991001 3.84991729
 3.85072101 3.85077432 3.85131495 3.85241205 3.85257323 3.85270909
 3.85291579 3.8536448  3.85429361 3.85474746 3.85545483 3.85577371
 3.85636686 3.85650992 3.8578528  3.85892655 3.85957684 3.8603729
 3.86041515 3.86136224 3.86225812 3.86281346 3.8633374  3.86423435
 3.86471078 3.8657903  3.86634994 3.86796255 3.86826537 3.87028756
 3.87047844 3.87077329 3.87130446 3.87170275 3.87299366 3.87408012
 3.87470019 3.87504419 3.87602997 3.87760632 3.87786572 3.87938399
 3.88004644 3.88039039 3.88054084 3.8811012  3.88317265 3.88328102
 3.88446351 3.88584343 3.88769549 3.88800475 3.88899587 3.8905047
 3.89062595 3.89108814 3.89124683 3.89131173 3.89154605 3.89240766
 3.89485106 3.89679186 3.89751731 3.89759506 3.89980924 3.90043812
 3.90078816 3.90216243 3.90235337 3.90246518 3.9036182  3.90431087
 3.90441963 3.90481837 3.90490449 3.90492082 3.90515408 3.90537508
 3.90575474 3.90587187 3.90611011 3.90621146 3.90658894 3.90667444
 3.90673019 3.90694889 3.9074481  3.90769788 3.90867517 3.90898605
 3.91066144 3.91072966 3.9112798  3.91225083 3.91316432 3.91328183
 3.9142819  3.91431156 3.91473073 3.9147594  3.91503558 3.91505794
 3.91528219 3.91534462 3.91571163 3.91636658 3.9173386  3.91755353
 3.9177003  3.91837706 3.91904359 3.91914732 3.92042818 3.92073025
 3.92087707 3.92114115 3.92121317 3.92131634 3.92291011 3.92340803
 3.92489962 3.92663136 3.92739728 3.92750035 3.92779735 3.92786842
 3.93019973 3.93248598 3.93301678 3.93306324 3.93326673 3.93470745
 3.93595323 3.93688122 3.93730417 3.93733532 3.93811431 3.94037055
 3.94196767 3.9427916  3.9428724  3.94338129 3.94385916 3.94451203
 3.94535774 3.94783923 3.94833849 3.94874604 3.95050454 3.95133863
 3.9514029  3.95223208 3.95265615 3.95266456 3.95273491 3.95318284
 3.95423118 3.95424748 3.95466032 3.95581288 3.95584849 3.95605274
 3.95673082 3.95785525 3.95820167 3.95841657 3.95956811 3.95998243
 3.96089381 3.96093402 3.96289896 3.96295228 3.96319822 3.96376482
 3.96410278 3.96499254 3.96524339 3.96531048 3.96566551 3.9658001
 3.96631703 3.966441   3.96649724 3.96686768 3.96789205 3.96947408
 3.96950371 3.96998071 3.97009523 3.97082488 3.97190444 3.9721728
 3.97257887 3.97435265 3.97455211 3.97498839 3.97658046 3.97670297
 3.97730362 3.97763124 3.97970239 3.98036438 3.98038875 3.98060086
 3.98122224 3.98139879 3.98156173 3.98164617 3.98266777 3.98441349
 3.98486113 3.98587611 3.98761616 3.98783453 3.98784798 3.98810004
 3.98826423 3.98840388 3.98883553 3.99028869 3.99232751 3.99254072
 3.9937191  3.99499865 3.99711397 3.99728897 3.99736395 3.9982768
 3.99919211 4.00172274 4.00375775 4.00447588 4.00731341 4.00777803
 4.00787493 4.00796955 4.00824445 4.00825351 4.00892174 4.00909751
 4.01072753 4.01114189 4.01507887 4.01526576 4.01648635 4.01724959
 4.01963234 4.01966929 4.01972722 4.01977572 4.02008625 4.02061394
 4.02101819 4.0212345  4.02270436 4.02353983 4.0236091  4.02410501
 4.02644666 4.02721908 4.02726064 4.02759675 4.02769192 4.02813516
 4.02935671 4.0295691  4.03008682 4.03291705 4.03388918 4.034045
 4.0348316  4.03525617 4.03529754 4.03558102 4.03576226 4.03855177
 4.03990996 4.04070565 4.04092062 4.0418055  4.04219942 4.04296084
 4.04342818 4.04806919 4.04988531 4.05063579 4.05131919 4.05173878
 4.0522326  4.0558779  4.05686801 4.05692289 4.06013163 4.06189971
 4.06487809 4.06537922 4.06807603 4.06995595 4.07102627 4.07193923
 4.07217395 4.0723958  4.07329537 4.07608555 4.07695944 4.07772141
 4.07798179 4.08128446 4.08276657 4.08388427 4.08394203 4.08512348
 4.08661021 4.08769163 4.08866597 4.08913914 4.0918761  4.09349834
 4.09371025 4.09856698 4.09945643 4.10310409 4.10371581 4.10417554
 4.10601026 4.10713145 4.1082636  4.1087353  4.11290964 4.11310992
 4.11572398 4.11604426 4.11620166 4.11642347 4.1167284  4.11692714
 4.11908385 4.12032845 4.1221692  4.12228989 4.12297637 4.12459994
 4.12562206 4.12672169 4.1301488  4.13040223 4.13077586 4.13093775
 4.13196888 4.13227971 4.13231456 4.13276017 4.13357252 4.13387765
 4.13393305 4.13446287 4.13478081 4.1354335  4.13724945 4.13740564
 4.13987635 4.14140083 4.14455003 4.14459209 4.14499359 4.14710936
 4.14950993 4.15109949 4.15388412 4.15584934 4.15632995 4.15791616
 4.15989244 4.16112307 4.16181161 4.1620711  4.16343514 4.16363921
 4.16512338 4.16749185 4.16817076 4.16958999 4.17129192 4.17134908
 4.17220615 4.17251397 4.17677757 4.1790063  4.18041045 4.18061085
 4.18235401 4.1836693  4.18483426 4.18705761 4.18707095 4.18885184
 4.18999363 4.19292854 4.19372376 4.1946284  4.19590279 4.19689608
 4.19709562 4.19973644 4.2022322  4.20311404 4.20825825 4.21445578
 4.21623962 4.21667354 4.21699269 4.21869862 4.22250905 4.22757742
 4.22825979 4.22906109 4.22969865 4.23004059 4.230384   4.23129425
 4.23270376 4.23301545 4.23370481 4.23537442 4.23870311 4.24359309
 4.2511539  4.251554   4.2542228  4.25470283 4.2555458  4.26360031
 4.26567239 4.26640912 4.27057111 4.27196252 4.28428799 4.28473293
 4.30036608 4.30534525 4.31400307 4.34664336 4.37772208 4.38841665
 4.39347178 4.39635233 4.41910719 4.42596595 4.44017355 4.44096534
 4.4525469  4.45866274 4.45926052 4.48610939 4.51676082 4.51759366
 4.52307159 4.5632417  4.58825216 4.61051497 4.62232676 4.62870649
 4.63590917 4.63687942 4.64203499 4.66018438 4.66962994 4.73723887
 4.75565334 4.75868138 4.8047142  4.82379809 4.8420453  4.85473154
 4.8894519  4.90793495 4.93134653 4.95930145 4.97680267 4.97686119
 5.0282509  5.04798304 5.16289722 5.25530558 5.35076515 5.4989711
 5.51659    5.51978564 5.52488671 5.53302313 5.53533997 5.54046232
 5.54505587 5.55013    5.55675588 5.60636109 5.69505165 5.69651233
 5.70605728 5.70989382 5.7129112  5.71349792 5.72324049 5.73103071
 5.73259981 5.74571418 5.76791987 5.76999438 5.78107594 5.86315408
 5.91480291 5.9386625  5.95424252 5.96455076 5.96665277 6.02344501]

  warnings.warn(

2022-12-16 10:37:07,841:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.48090666 2.61276769 2.62745673 2.65145473 2.70904417 2.875184
 2.89851222 3.01693722 3.32118605 3.47994066 3.48410428 3.48507279
 3.49035038 3.57333359 3.57440166 3.57912563 3.58031419 3.58549445
 3.58596634 3.58786282 3.59072472 3.59404461 3.59554304 3.60166386
 3.61198275 3.61826235 3.61991053 3.62036208 3.62118582 3.62152156
 3.62470473 3.6259823  3.62945231 3.62974313 3.63085472 3.63236813
 3.63249322 3.63312351 3.63600862 3.63648921 3.63649605 3.63835522
 3.63862418 3.63907387 3.63920744 3.64041721 3.64052641 3.65705734
 3.65779779 3.66405554 3.66501752 3.66510204 3.6692889  3.67320036
 3.6746609  3.68115665 3.68466233 3.68520771 3.68945487 3.68996058
 3.69094599 3.6917427  3.6926053  3.69262268 3.69425676 3.69435134
 3.69665972 3.69763755 3.69833551 3.7014416  3.7051346  3.70661611
 3.70734011 3.71288224 3.72087834 3.72395305 3.72895615 3.72921588
 3.73402543 3.73563769 3.73688668 3.73745328 3.73770473 3.73829861
 3.73853679 3.74060286 3.74239449 3.7441113  3.74517756 3.74561871
 3.74882175 3.74915285 3.74977142 3.74999396 3.75175352 3.75317278
 3.75586651 3.75727877 3.77010567 3.7726417  3.77327715 3.77444726
 3.77694485 3.77921613 3.77992528 3.78181985 3.78311729 3.79119274
 3.79225493 3.79227474 3.79523959 3.79742721 3.79917858 3.80066673
 3.80067986 3.80081383 3.80135135 3.80186408 3.80382145 3.80391582
 3.80406875 3.80511384 3.80603725 3.80710447 3.80753278 3.80761663
 3.80801604 3.8080325  3.80911675 3.80933647 3.8094771  3.81053605
 3.81135207 3.81333757 3.81523859 3.81955034 3.82000617 3.82092919
 3.8211351  3.82175115 3.82219583 3.82230044 3.82322889 3.8233214
 3.82396418 3.82460429 3.82562259 3.82584277 3.82595565 3.82670804
 3.82823655 3.82842358 3.83050109 3.83197789 3.83280844 3.83326365
 3.83441965 3.83453032 3.83531711 3.83765788 3.83909903 3.83964349
 3.83977821 3.84135388 3.84211215 3.8421299  3.84258943 3.84294247
 3.84311308 3.84331231 3.84340798 3.84497252 3.84517389 3.84525187
 3.84529132 3.84576257 3.84581809 3.84622414 3.84625715 3.84630423
 3.84630941 3.84648194 3.84661666 3.84679191 3.84682536 3.84696813
 3.84754273 3.84780128 3.84863839 3.84916673 3.84981573 3.84992794
 3.85041909 3.85073056 3.85136892 3.851624   3.85170012 3.85219354
 3.85251397 3.85297298 3.85314358 3.85330742 3.85443776 3.85483257
 3.85506914 3.85508907 3.85538498 3.85566475 3.85659404 3.85667002
 3.85707221 3.85723824 3.85767765 3.85820614 3.85821463 3.85832715
 3.85832884 3.85909738 3.85950645 3.85957443 3.86011518 3.86022676
 3.8606922  3.86087295 3.8613843  3.86179444 3.86236827 3.86242387
 3.86292068 3.86326078 3.86340461 3.86346961 3.86348104 3.86369794
 3.86388709 3.86412008 3.86440622 3.86445486 3.86462152 3.86508763
 3.86539311 3.86539505 3.86575186 3.8657836  3.8658631  3.8661083
 3.8680385  3.86838692 3.86878412 3.86976278 3.87029981 3.87139206
 3.87180578 3.87183179 3.8727837  3.87300338 3.87329683 3.87347261
 3.87366155 3.87431834 3.87455774 3.87469907 3.87502049 3.87593637
 3.87601399 3.87617738 3.87630823 3.87705426 3.87804976 3.87858938
 3.87894194 3.87900011 3.87928033 3.87950975 3.87952417 3.87973234
 3.87986781 3.88062569 3.88114796 3.88130282 3.88139593 3.88141459
 3.88236233 3.88260336 3.88296389 3.8834425  3.88372541 3.88429153
 3.8849367  3.88651103 3.8865649  3.88692815 3.88701017 3.88710638
 3.88712808 3.88733238 3.88753131 3.88783941 3.88805488 3.88855406
 3.88887038 3.88890976 3.88892188 3.88897497 3.88976895 3.8897865
 3.88999689 3.89000019 3.89030733 3.89075119 3.89079475 3.8908188
 3.89123718 3.89135227 3.89189253 3.893902   3.89463746 3.89467938
 3.89471587 3.89577483 3.89579801 3.89596865 3.896014   3.89649994
 3.89688312 3.89720684 3.8973654  3.89869508 3.89963053 3.90039377
 3.90081134 3.90093749 3.90096292 3.90128321 3.90136595 3.90221234
 3.90237492 3.90240814 3.90244818 3.90258713 3.90343748 3.90489002
 3.90539485 3.90561543 3.90566767 3.90578335 3.90609829 3.90610884
 3.90614944 3.90630889 3.90671035 3.90726857 3.90727372 3.9077212
 3.9078117  3.90842763 3.9088322  3.9089321  3.90942186 3.91063083
 3.91066406 3.91105338 3.91136301 3.9128114  3.91291706 3.9131674
 3.91372187 3.91408753 3.9148446  3.91516523 3.91558488 3.91660772
 3.91762503 3.9195024  3.92048955 3.92080768 3.92136425 3.92200861
 3.92218857 3.92257638 3.92374395 3.92403118 3.92416498 3.92560977
 3.92709657 3.92747767 3.92751283 3.92789404 3.92824567 3.92874824
 3.92878968 3.92886891 3.92919101 3.9293371  3.92935512 3.92953707
 3.92975963 3.93005311 3.9316241  3.93189526 3.93252488 3.93260358
 3.93342338 3.93362075 3.9349877  3.93837839 3.93869392 3.94024863
 3.94059834 3.9423965  3.94286247 3.94338623 3.94475254 3.9474066
 3.94878631 3.94945756 3.95099377 3.95172365 3.95196641 3.95261649
 3.95362247 3.95396732 3.95442781 3.95501268 3.95518605 3.95572792
 3.95589344 3.95622752 3.95702084 3.95703747 3.95760901 3.95779474
 3.95780297 3.9584352  3.96085789 3.96157618 3.96197186 3.96421497
 3.96423881 3.96634209 3.96710321 3.9692917  3.9723669  3.97335018
 3.97431732 3.9746643  3.97551437 3.9756307  3.97602734 3.97671403
 3.97718138 3.97902075 3.98131753 3.98202805 3.98256642 3.98330083
 3.98369591 3.98586362 3.98644754 3.9869724  3.98727336 3.98733218
 3.98787611 3.98902363 3.98927163 3.9894035  3.99223492 3.99547262
 3.99649051 3.99670142 3.9975757  3.99916109 3.99932326 3.99946443
 4.0020721  4.00534236 4.00715162 4.00884655 4.00977423 4.01019141
 4.01131833 4.0114829  4.01214542 4.01335618 4.0152645  4.01543355
 4.0157259  4.01685094 4.01915389 4.02267108 4.02268007 4.02404941
 4.02504234 4.02724279 4.02727935 4.027687   4.02836918 4.02853164
 4.02911378 4.03100476 4.03402269 4.03455901 4.03512422 4.03956298
 4.03969954 4.04135351 4.04213971 4.04366498 4.04607065 4.04681065
 4.04691315 4.04810183 4.04942691 4.052315   4.05237522 4.05268238
 4.05273718 4.05323731 4.05390342 4.0539616  4.05488214 4.055173
 4.05596559 4.0566122  4.05824264 4.05911032 4.06085179 4.06322614
 4.06608373 4.06630147 4.06715808 4.06767222 4.0735892  4.07400723
 4.07479961 4.07748082 4.07806485 4.07941636 4.08074035 4.08208514
 4.08302081 4.08497203 4.08518399 4.08529387 4.08636466 4.08710304
 4.08877792 4.08961442 4.08974221 4.09052018 4.09067306 4.09101054
 4.0912936  4.0921131  4.09230465 4.09273644 4.09443088 4.09505646
 4.09508797 4.09640733 4.09674135 4.09814373 4.09879528 4.09912405
 4.10058933 4.10074736 4.10091191 4.10107787 4.10201659 4.10427976
 4.10432366 4.10433348 4.10436468 4.10525106 4.10531348 4.10569162
 4.10610767 4.10620837 4.10664554 4.10683468 4.10694592 4.10723025
 4.10769267 4.10840862 4.10888359 4.10953044 4.10979278 4.11031621
 4.11039648 4.11100108 4.11118894 4.11166807 4.11188585 4.11271667
 4.11272785 4.11409321 4.11425084 4.11472303 4.1150086  4.11541844
 4.11575224 4.11605352 4.1164509  4.11758735 4.11789951 4.11888474
 4.11945229 4.11980698 4.12043238 4.12126095 4.12143826 4.1214438
 4.12148213 4.12160552 4.12314939 4.12377482 4.12554263 4.12577657
 4.12633824 4.12711987 4.12725863 4.12778487 4.12803954 4.12824224
 4.12864112 4.12890767 4.12892617 4.12893783 4.12912756 4.12992199
 4.13050563 4.13075458 4.13102509 4.13119471 4.13184426 4.13234069
 4.13274766 4.13282315 4.13306442 4.13319946 4.13428565 4.13465596
 4.13479091 4.13665576 4.13709002 4.13815218 4.13944064 4.13972501
 4.14000858 4.14051727 4.1442138  4.14478106 4.14516464 4.14636253
 4.14702669 4.14727751 4.14729315 4.14835456 4.14843836 4.15039983
 4.15046681 4.15079357 4.15146738 4.15152334 4.15202942 4.15226151
 4.15244502 4.15290585 4.15433592 4.154559   4.15531762 4.15539363
 4.15581125 4.15694705 4.15884263 4.16190022 4.16206806 4.16262991
 4.16355495 4.16514678 4.16749844 4.16842201 4.1700014  4.17222596
 4.17230418 4.17273152 4.17425258 4.17441628 4.17590279 4.1767646
 4.17801094 4.17829318 4.18054444 4.1811962  4.18242672 4.18316961
 4.18352738 4.18420028 4.18606702 4.18761379 4.18774908 4.18778556
 4.18855323 4.18921343 4.19109063 4.19326055 4.1941733  4.19579973
 4.19905631 4.20107879 4.20162212 4.20372722 4.20375094 4.20616205
 4.20768713 4.20797077 4.20824757 4.20913129 4.20959042 4.21135625
 4.21289093 4.21532065 4.21672558 4.21739928 4.22017683 4.22172797
 4.22316074 4.22678218 4.2267999  4.23271607 4.23454128 4.24047134
 4.24377487 4.24677899 4.25270595 4.25498503 4.25772353 4.27404586
 4.27528544 4.27892298 4.28233314 4.2849271  4.28567818 4.28678569
 4.29105404 4.29800128 4.30007143 4.30229673 4.30270909 4.30889681
 4.3137325  4.32067145 4.32300058 4.33442245 4.33560683 4.34255359
 4.34904012 4.35312019 4.35429514 4.35827842 4.36378943 4.36574231
 4.3666264  4.36698305 4.3674797  4.37090675 4.37375422 4.37431034
 4.37435922 4.37779578 4.3847497  4.38793149 4.39580351 4.40343904
 4.40790616 4.41265201 4.42320614 4.42573814 4.43385945 4.43422823
 4.45282125 4.47086093 4.47280432 4.48164367 4.59025933 4.59097256
 4.59736297 4.61557885 4.62226069 4.65759441 4.66321396 4.66453761
 4.66995986 4.67002549 4.67103121 4.67348729 4.67417778 4.67844878
 4.67991498 4.68055984 4.69000526 4.70649547 4.7179261  4.73158398
 4.73248897 4.74191431 4.75438098 4.78339559 4.89295687 4.91375601
 4.91458161 4.93988061 4.94677699 4.95769436 5.08282398 5.09167458
 5.09856277 5.13817053 5.28000721 5.3942126  5.39690957 5.49898703
 5.50587708 5.50606187 5.50786477 5.51235951 5.51373175 5.51416065
 5.51821733 5.51970118 5.5232002  5.52723895 5.52897261 5.52905425
 5.53156153 5.53556833 5.54397944 5.56232313 5.57740747 5.57892303
 5.58059289 5.58513603 5.58582799 5.63084354 5.63084636 5.64257404
 5.67362599 5.73831992 5.76917705 5.7773195  5.7781235  5.81238867
 5.83977416 5.8717514  5.88443681 5.88662983 5.91462855]

  warnings.warn(

2022-12-16 10:37:07,890:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.33012542 2.67219882 2.73124072 2.82486884 2.85644203 3.03964886
 3.08794337 3.08946563 3.14260423 3.19244795 3.40996794 3.52003791
 3.56292316 3.64717076 3.66689907 3.66699531 3.67410003 3.67622464
 3.67815443 3.68015733 3.68522134 3.68957985 3.69019767 3.69126635
 3.69291245 3.69946225 3.701694   3.70445421 3.70962863 3.71153616
 3.71248919 3.71505726 3.71669406 3.72040989 3.73819658 3.74371969
 3.74666221 3.75313779 3.76621495 3.76752994 3.79032476 3.791946
 3.80913689 3.82186889 3.84537652 3.84936631 3.87399865 3.89964236
 3.90199586 3.91412862 3.91436103 3.91787625 3.9190812  3.92127065
 3.92679409 3.9272453  3.93528757 3.94067153 3.94156442 3.94241768
 3.94283101 3.94494363 3.9450705  3.94541535 3.94547143 3.94588725
 3.94599505 3.94616105 3.94672694 3.94681319 3.94771055 3.9477256
 3.94908747 3.94943854 3.94952539 3.94972376 3.95103993 3.95109862
 3.95137502 3.95467581 3.96395112 3.96536483 3.97038071 3.97088057
 3.97288709 3.97307165 3.97387599 3.97401443 3.97625488 3.97931585
 3.97982461 3.98205783 3.98225572 3.98270315 3.98332672 3.98374734
 3.98397143 3.98508655 3.98525367 3.98536086 3.98545746 3.98565461
 3.9857618  3.98664214 3.98740789 3.98764274 3.98812769 3.98822427
 3.98824518 3.98908547 3.98913802 3.99056169 3.99106859 3.99182003
 3.99190478 3.99343963 3.99349179 3.99418931 3.99646376 3.99763086
 3.99794979 3.99894721 3.9994685  4.00023876 4.00073189 4.00146261
 4.00177783 4.00208217 4.00243047 4.00245151 4.00254811 4.00347897
 4.00411216 4.0054604  4.00559521 4.0064325  4.00725634 4.00796158
 4.00805914 4.00910822 4.00941528 4.01010847 4.01019141 4.01032576
 4.01051841 4.01125941 4.01440982 4.01462472 4.01492888 4.0149323
 4.01541775 4.01641833 4.0174111  4.0174903  4.01766053 4.01792382
 4.02076474 4.02275209 4.02289781 4.02414951 4.02515112 4.02619218
 4.0314101  4.03441006 4.03466495 4.03583174 4.03615098 4.03762212
 4.0424613  4.04296712 4.04335759 4.04358983 4.04547318 4.04709788
 4.04971351 4.05135026 4.0520758  4.05455951 4.0634413  4.07384871
 4.07505357 4.07768853 4.0813902  4.08939493 4.08998715 4.09278196
 4.09289456 4.09421134 4.09682448 4.1027801  4.10472627 4.10501085
 4.1052745  4.10830156 4.11527334 4.11527979 4.11532893 4.11607401
 4.12246329 4.12292453 4.1235482  4.12357037 4.12597593 4.12805224
 4.12931013 4.13050133 4.13130053 4.13393025 4.13457971 4.13512242
 4.1355217  4.13697421 4.14030487 4.14062786 4.14171334 4.14224372
 4.1425518  4.14298026 4.1453164  4.14646135 4.14784082 4.14824974
 4.14869341 4.14896    4.14928462 4.14986666 4.15295023 4.15315432
 4.15394111 4.15660994 4.15705973 4.15714598 4.15721715 4.15839267
 4.16091103 4.16313291 4.1635669  4.16416005 4.16531407 4.16595043
 4.16671064 4.17011662 4.17247066 4.17303797 4.17305469 4.17402916
 4.17430639 4.17550118 4.17699142 4.17717984 4.17923255 4.18074462
 4.18107339 4.18258178 4.1831883  4.18420387 4.18548066 4.18823508
 4.18837661 4.1884287  4.18991877 4.19225097 4.1930351  4.19338144
 4.19355571 4.19464445 4.19572208 4.19573694 4.1966914  4.19728816
 4.19732859 4.1983953  4.20003077 4.20049327 4.20055501 4.20149382
 4.20294342 4.20320758 4.20598208 4.20626931 4.20729102 4.20808505
 4.20825783 4.20877589 4.2088069  4.21001242 4.21251156 4.21318179
 4.2175865  4.22142839 4.22423777 4.22478791 4.22564494 4.22656905
 4.23084572 4.23185097 4.23247934 4.23258859 4.23330294 4.23361772
 4.23365805 4.23470308 4.2348503  4.2349412  4.23713969 4.23790689
 4.2388441  4.23947623 4.23960646 4.23982398 4.2400036  4.24108274
 4.24292282 4.24418649 4.24452349 4.24498776 4.24518631 4.24605378
 4.24652808 4.24729237 4.24791847 4.24795468 4.24860775 4.24935006
 4.24942535 4.25011511 4.2514263  4.25241081 4.25461849 4.25488068
 4.25716598 4.25799987 4.26038414 4.26091615 4.26297161 4.26479844
 4.26495357 4.26739061 4.26891202 4.27027578 4.27108326 4.27161053
 4.27307283 4.2757363  4.27594082 4.27690882 4.27724625 4.27915614
 4.27930722 4.28068382 4.28417055 4.28468622 4.28986099 4.2899317
 4.2903154  4.29089066 4.29170425 4.29180143 4.29369029 4.29481448
 4.29514117 4.29525687 4.29527659 4.29862135 4.29950272 4.2996579
 4.30018289 4.30238416 4.30250895 4.30289241 4.30408365 4.30783333
 4.30792412 4.31025589 4.31043504 4.31075529 4.31145325 4.31192696
 4.31205119 4.31239409 4.31334927 4.31840071 4.31894695 4.3207442
 4.32115501 4.32309939 4.32338173 4.32423676 4.32442102 4.32495076
 4.32707574 4.33176275 4.33462817 4.33547813 4.33573427 4.34513097
 4.34655698 4.35329741 4.35567949 4.35653734 4.35663162 4.35863749
 4.35936366 4.36202678 4.36322315 4.36987483 4.37258946 4.3732382
 4.37410821 4.37575961 4.3817245  4.38198023 4.38323458 4.38523926
 4.38545868 4.38664618 4.38710189 4.38880241 4.38989163 4.39009377
 4.39010234 4.39421133 4.39548508 4.39620207 4.39653139 4.39712716
 4.3977401  4.39823073 4.39832444 4.39925484 4.3994256  4.39980005
 4.40071782 4.40073261 4.4010337  4.40132252 4.40155748 4.40163572
 4.40248938 4.40448111 4.40450927 4.40505327 4.40585565 4.40589617
 4.40601251 4.40777439 4.40796276 4.41041803 4.41158678 4.41209523
 4.41256552 4.41302155 4.41332306 4.41649715 4.41808586 4.41823808
 4.41840123 4.41919209 4.4192117  4.41998942 4.42034938 4.42111443
 4.42161054 4.42241162 4.4229084  4.42377467 4.424065   4.42470294
 4.4251894  4.42581613 4.42584564 4.42604285 4.42627338 4.42769302
 4.42893333 4.42940017 4.4308756  4.4312009  4.43160442 4.43257476
 4.43511869 4.43527105 4.43532325 4.43779232 4.43975728 4.44082119
 4.44110987 4.44135853 4.4418501  4.44189953 4.44208523 4.44212522
 4.44260947 4.44289938 4.44327353 4.44355541 4.44408173 4.44435565
 4.4444953  4.44459286 4.44468704 4.44513217 4.44522296 4.44557965
 4.44652733 4.44691014 4.44698331 4.44843656 4.44863342 4.44891761
 4.44974222 4.45061695 4.45117769 4.45128873 4.45322244 4.45371656
 4.45443851 4.45489489 4.45554069 4.45699664 4.45717702 4.45736436
 4.45783636 4.4587042  4.46363749 4.46383284 4.46400559 4.46508193
 4.46580116 4.46724831 4.46769411 4.4686593  4.46900575 4.47043632
 4.47085072 4.47252915 4.47261983 4.47297613 4.47360844 4.4763049
 4.47757426 4.47816742 4.47902092 4.47975004 4.48000999 4.48030362
 4.48041405 4.48099865 4.48120141 4.48181906 4.4825857  4.48277461
 4.48299554 4.48306122 4.48445782 4.48618946 4.48700645 4.48846755
 4.48933239 4.49136817 4.49221211 4.49567057 4.49650094 4.4966169
 4.4966318  4.49675378 4.49709564 4.4972252  4.49741318 4.49779859
 4.49832095 4.49903084 4.49940463 4.49962859 4.50048632 4.50073225
 4.5015662  4.50429902 4.50480088 4.50649927 4.50718293 4.50751152
 4.50821413 4.50952304 4.51019433 4.51049449 4.51097672 4.51101029
 4.51202233 4.51208007 4.51347739 4.51388082 4.51426653 4.52013458
 4.52481133 4.52545288 4.52592992 4.52939735 4.53008091 4.5317519
 4.53335144 4.53384495 4.53424073 4.53511991 4.53540707 4.53693513
 4.53752938 4.5404737  4.54086086 4.54200651 4.54234403 4.5442775
 4.54734599 4.5477266  4.54812574 4.5492818  4.55021094 4.55060144
 4.55071493 4.55136099 4.55164384 4.55204044 4.55480489 4.55533197
 4.55612435 4.55708245 4.55837331 4.56025703 4.56077891 4.56104761
 4.56152868 4.56382317 4.56431553 4.56586956 4.56681121 4.56837276
 4.57126819 4.57215347 4.5732813  4.57406514 4.57747814 4.58202464
 4.58480445 4.58689108 4.58986001 4.58996215 4.59307619 4.59318296
 4.59362412 4.59815199 4.59856467 4.60265385 4.60326666 4.60491281
 4.61001809 4.61358917 4.61482376 4.61787583 4.61856559 4.61952031
 4.62228304 4.62271142 4.62352438 4.62723589 4.63005996 4.63104502
 4.63871715 4.64453687 4.64602655 4.64623771 4.64695557 4.64847367
 4.6500561  4.65013777 4.65060809 4.65137764 4.65213236 4.65257627
 4.65377785 4.65533937 4.65539975 4.65730667 4.65744114 4.65805237
 4.65835671 4.65947705 4.66136978 4.66323147 4.66582828 4.66901924
 4.66964849 4.67037449 4.67404103 4.67667402 4.679815   4.68088605
 4.69612477 4.69619321 4.6975741  4.69860124 4.69903249 4.69904484
 4.69933683 4.70018387 4.70023107 4.70039161 4.70164823 4.70170073
 4.70213431 4.70230813 4.70287715 4.70349315 4.70403323 4.70417897
 4.70517665 4.70649126 4.70745797 4.71001347 4.71036135 4.71056257
 4.71085112 4.71094961 4.71208195 4.71240469 4.71307432 4.71419847
 4.71478007 4.71796669 4.71932575 4.71988324 4.7215224  4.72217994
 4.72258583 4.72409031 4.7244468  4.72461377 4.72609283 4.72759553
 4.73196738 4.73204341 4.73227253 4.73392627 4.73447091 4.7349356
 4.73558276 4.73590297 4.7419674  4.74395497 4.74507044 4.74759005
 4.74851297 4.75082959 4.75119715 4.75304558 4.75331003 4.75939304
 4.76369912 4.76484128 4.76811666 4.76901807 4.76965738 4.77096283
 4.78361235 4.78582817 4.78901042 4.79285413 4.79290159 4.79592818
 4.79637776 4.79932406 4.80035006 4.80275411 4.80759476 4.81013446
 4.8144694  4.81604091 4.81874278 4.82307543 4.82454732 4.83336458
 4.83681101 4.84361291 4.84570425 4.84999282 4.86464559 4.8791058
 4.9005164  4.90516311 4.90600791 4.91716509 4.93644683 4.94753261
 4.94976414 4.94997117 4.95042818 4.9545745  4.95629142 5.00863586
 5.03394757 5.03888708 5.04015574 5.04236553 5.04293917 5.04543322
 5.07692581 5.0972051  5.10575235 5.13530106 5.19307081 5.19454194
 5.22269168 5.22576614 5.24534064 5.25147405 5.25647186 5.25984595
 5.26027706 5.33796946 5.3794821  5.46622322 5.48510854 5.50046407
 5.59457496 5.6244865  5.62674996 5.6289379  5.62894953 5.63172562
 5.73632231 5.78728645 5.79841809 5.85481874 5.86168831 5.87842061
 5.88225476 5.89564051 5.90472105 5.95229603 5.95928743 5.96785021
 6.04103811 6.04174505 6.04750934 6.0543305  6.0702838  6.09720541
 6.09980004 6.10149866 6.18129738 6.18607775 6.19079499 6.19117621
 6.19987422 6.24223472 6.32434696 6.32499962 6.3341878  6.34636342
 6.36874421]

  warnings.warn(

2022-12-16 10:37:07,897:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.47495189 2.54489976 2.58403795 2.66881475 2.73689247 2.74405004
 2.89494894 2.92040201 2.96559759 3.11003416 3.15125052 3.45336901
 3.45476009 3.45554193 3.45640407 3.50510719 3.6574191  3.70202129
 3.70541771 3.70944411 3.71049421 3.72190947 3.72751987 3.73078755
 3.73185933 3.7321589  3.73389822 3.73601674 3.74027615 3.74149155
 3.74562955 3.74852368 3.75088573 3.7509395  3.75100765 3.75638887
 3.75680895 3.76315215 3.76783514 3.77071616 3.77593233 3.77972539
 3.78020874 3.78258767 3.78267123 3.78350684 3.78790337 3.79007058
 3.79047363 3.79143265 3.79144715 3.79268133 3.7935916  3.79372152
 3.79381322 3.79525612 3.79595404 3.79685133 3.79764994 3.79779807
 3.7990904  3.79967493 3.80075856 3.80105152 3.80202211 3.80226847
 3.80229438 3.80236577 3.80443565 3.80450911 3.80497214 3.80502754
 3.80777078 3.81000062 3.81148322 3.81192716 3.81209836 3.81220878
 3.81249725 3.81312075 3.81319287 3.81327758 3.81346759 3.81449135
 3.81454243 3.81473963 3.81475634 3.81497843 3.8154961  3.81550805
 3.8156727  3.81570604 3.81714793 3.81944197 3.82054132 3.82059995
 3.82124377 3.82469054 3.82585678 3.82609198 3.82737385 3.82739347
 3.82741974 3.82761119 3.82826345 3.8286317  3.82881714 3.82945599
 3.83026788 3.83052977 3.83103226 3.83127166 3.83146372 3.83220758
 3.83277363 3.83351252 3.8335567  3.83440679 3.83440792 3.83462739
 3.83470646 3.83474603 3.83479807 3.83515494 3.8354012  3.83542561
 3.83592115 3.8361064  3.83736226 3.83747685 3.83755307 3.83864138
 3.83881108 3.84072155 3.8409318  3.84121197 3.8412696  3.84209253
 3.84372443 3.84443305 3.8481441  3.85225886 3.85268543 3.85573249
 3.85577155 3.85585979 3.85826265 3.86003905 3.86195271 3.86221366
 3.86260839 3.86298518 3.86389662 3.86547489 3.86552734 3.86564807
 3.86619881 3.86637663 3.86908297 3.87046235 3.87142527 3.87377437
 3.87408699 3.87558377 3.87710006 3.87839599 3.87841952 3.87851747
 3.87880308 3.88144123 3.88177306 3.88209307 3.88228308 3.8826962
 3.88275395 3.88428556 3.8845056  3.88465726 3.88473685 3.88496793
 3.88579493 3.8880361  3.88943476 3.88958218 3.88961731 3.8900496
 3.89039995 3.89137206 3.89208422 3.89395005 3.89541718 3.89749404
 3.90109547 3.90239567 3.9031746  3.90342915 3.90818061 3.90859615
 3.9103049  3.91056452 3.91139214 3.91192234 3.91300071 3.91348134
 3.91371368 3.91457419 3.91762143 3.9183205  3.91893954 3.91977175
 3.92030698 3.92185672 3.92213892 3.92247964 3.92329963 3.9252129
 3.92687053 3.93069131 3.93400401 3.93416576 3.93581279 3.93674102
 3.93681762 3.93748705 3.93972377 3.93976991 3.94973662 3.94997114
 3.95028215 3.95175893 3.95197763 3.95954575 3.96473766 3.96582348
 3.96615901 3.96658238 3.96748181 3.9678525  3.96794525 3.9681797
 3.97188369 3.97295184 3.97300959 3.97384565 3.97556083 3.9785726
 3.98908672 3.99763114 4.00293446 4.00419308 4.00693939 4.00793395
 4.00939247 4.0094378  4.01101717 4.01424101 4.01549305 4.01564342
 4.01752791 4.01782661 4.01864498 4.02237762 4.024357   4.0245964
 4.02488721 4.02629513 4.02767662 4.0284899  4.02952873 4.03167369
 4.03223735 4.03266037 4.03350594 4.03523037 4.03542864 4.0364089
 4.03826463 4.03832158 4.03904972 4.03957877 4.04388083 4.0453015
 4.04608414 4.04647542 4.04666543 4.0485631  4.04869556 4.04934176
 4.0501894  4.05074984 4.05140305 4.05166676 4.0517779  4.05187639
 4.05217872 4.05368216 4.0545119  4.05475142 4.05492848 4.05504051
 4.05505348 4.05587325 4.05590132 4.05700157 4.0576047  4.05762912
 4.05906864 4.05916573 4.05970452 4.06186172 4.06256436 4.06258519
 4.064163   4.06663229 4.06711428 4.06827589 4.06829656 4.06877657
 4.06947636 4.07044193 4.07268355 4.07272319 4.07335671 4.07536162
 4.07561689 4.07810008 4.07833333 4.07871833 4.07946861 4.07957596
 4.08097368 4.08140675 4.08216478 4.08421981 4.08434603 4.0851381
 4.08876273 4.08989488 4.09248488 4.09390268 4.09413444 4.09424129
 4.09516714 4.09599625 4.09652462 4.09693774 4.09729522 4.09771929
 4.09777562 4.09837967 4.09875539 4.10053254 4.10185039 4.10266814
 4.10314424 4.10435554 4.10451237 4.10522812 4.10636387 4.1089149
 4.11143624 4.11147079 4.11150103 4.11289167 4.11793061 4.11807624
 4.11938749 4.11950945 4.12156098 4.12205006 4.12205257 4.12205745
 4.12222843 4.12355765 4.12454486 4.1247224  4.12491675 4.12558599
 4.12565159 4.12587656 4.12687233 4.12751321 4.12864401 4.12964825
 4.12999786 4.13023068 4.13114822 4.13145478 4.13164707 4.13214882
 4.13226214 4.13262156 4.13310947 4.13359912 4.13401052 4.13507171
 4.13537536 4.13541248 4.1356489  4.13570157 4.13662233 4.13797831
 4.13811057 4.13952457 4.14037891 4.14083208 4.14175117 4.14233438
 4.1428207  4.14353581 4.14573844 4.14685516 4.14777454 4.14922432
 4.14962075 4.14978853 4.150123   4.15347898 4.15364971 4.15413591
 4.15516236 4.15531191 4.15551601 4.15676035 4.15740123 4.15740145
 4.15937105 4.16030412 4.16040165 4.16062986 4.16078669 4.16134507
 4.16153826 4.16206105 4.16231592 4.16256294 4.16268276 4.16275295
 4.16314068 4.16318182 4.16321515 4.16359739 4.16469447 4.16522669
 4.16543758 4.1654874  4.16600567 4.1664546  4.16751435 4.16768933
 4.16832611 4.16856381 4.16978921 4.17025178 4.17270614 4.17455507
 4.17604849 4.1771884  4.17743963 4.17744173 4.17753958 4.17782475
 4.17832478 4.18018032 4.18093408 4.1812653  4.18138102 4.18215035
 4.18243944 4.18296179 4.18366491 4.18372266 4.18420872 4.18424198
 4.1843249  4.18500363 4.18527774 4.18567963 4.18568198 4.18577519
 4.18597335 4.1861505  4.18753512 4.18777835 4.18803576 4.19128006
 4.19378446 4.19483313 4.19526603 4.19798927 4.19822342 4.19852423
 4.1993167  4.19967733 4.20034373 4.20051534 4.20098334 4.20184002
 4.2020085  4.20293955 4.20439369 4.20582803 4.20683111 4.20688146
 4.20789885 4.20875034 4.20908519 4.21154319 4.2120613  4.21422179
 4.21474855 4.21507893 4.21628486 4.21636445 4.21804467 4.21812099
 4.21823547 4.21845031 4.21866498 4.21879319 4.2194731  4.21950517
 4.21950993 4.2203127  4.22093657 4.22121598 4.22182644 4.22242971
 4.22253055 4.22263377 4.2226907  4.22295787 4.22330084 4.22367488
 4.22433694 4.22438399 4.22462868 4.22485692 4.22527828 4.22534167
 4.22608568 4.22612022 4.22665256 4.22713799 4.22738525 4.22856187
 4.2292109  4.22950387 4.22960218 4.22979219 4.23003112 4.23024304
 4.23145739 4.23200954 4.23216637 4.23224596 4.23235638 4.2327695
 4.2330339  4.23375983 4.23418647 4.23427062 4.23467305 4.23624476
 4.236317   4.23636725 4.23768372 4.23953503 4.23971922 4.23987242
 4.24002803 4.24025841 4.24054642 4.2406189  4.2411017  4.24159648
 4.24196194 4.24199527 4.24200883 4.24220027 4.24233197 4.24297117
 4.24322691 4.24364644 4.24390622 4.24393626 4.2442921  4.24438681
 4.24482225 4.24567011 4.24889573 4.24914497 4.25226082 4.2525348
 4.25266149 4.25315996 4.25442    4.25459301 4.2553126  4.25592651
 4.25640009 4.25998159 4.26015822 4.26193959 4.26238085 4.26767841
 4.26902587 4.26954646 4.26980367 4.27036618 4.27197182 4.27236299
 4.27364316 4.27421497 4.27448688 4.27820339 4.27854172 4.27955655
 4.27999833 4.28031025 4.28236919 4.2831113  4.28372276 4.28419494
 4.28495869 4.28578643 4.28766799 4.28775023 4.2906901  4.29153945
 4.29215758 4.29302636 4.29536979 4.29679163 4.30071091 4.30755332
 4.30959437 4.31028653 4.31207297 4.31435489 4.31447031 4.31720349
 4.31826172 4.31860258 4.31957071 4.32190561 4.32263444 4.32280127
 4.32374924 4.3246053  4.32488264 4.32964216 4.32991418 4.33029755
 4.33119037 4.33471448 4.33883953 4.33936678 4.34062292 4.34124965
 4.34236202 4.34570933 4.35012489 4.35208152 4.35238829 4.35255767
 4.35470448 4.35645328 4.35904045 4.36315125 4.36361111 4.36488638
 4.36504875 4.36823762 4.36926918 4.37117329 4.37118014 4.37143936
 4.37195522 4.37257289 4.37264992 4.37408346 4.37974657 4.38021733
 4.38061492 4.38410587 4.38687709 4.38688371 4.38750592 4.38796256
 4.38815003 4.38875754 4.38896898 4.38955914 4.3921808  4.39306668
 4.39367533 4.39414121 4.39632813 4.39779239 4.39794188 4.398718
 4.40083953 4.40089197 4.40101319 4.40210856 4.40304847 4.40401898
 4.40443081 4.40482472 4.40577193 4.40698082 4.40711047 4.41006264
 4.4101794  4.41288709 4.41480668 4.41612871 4.41622172 4.41800082
 4.42121437 4.42208229 4.42341428 4.42484045 4.42954771 4.4312624
 4.43374654 4.437618   4.4414118  4.44149565 4.4433466  4.44351328
 4.44377212 4.44379284 4.44407193 4.44786852 4.44804461 4.44829137
 4.45088275 4.45104454 4.4518314  4.45847629 4.46348166 4.46658442
 4.46953623 4.47144006 4.47641567 4.47649625 4.48492621 4.48690808
 4.48760526 4.48982643 4.49363983 4.49768063 4.49844665 4.49942758
 4.5004513  4.50228214 4.50412122 4.50414379 4.50511171 4.5057749
 4.5066338  4.51079295 4.52311813 4.52317521 4.52444546 4.53297559
 4.54009057 4.54393205 4.54401122 4.55331184 4.55762708 4.56020246
 4.57545158 4.58151982 4.58487779 4.59187474 4.60640366 4.61503933
 4.62843932 4.63653432 4.65503635 4.66461518 4.67382942 4.67782232
 4.7175653  4.73458184 4.74066771 4.75583021 4.7583873  4.77673451
 4.7816355  4.78464356 4.79964171 4.80984393 4.85564899 4.86404856
 4.88370389 4.89733308 4.90407622 4.90757588 4.91063972 4.91193586
 4.99869363 5.04605043 5.08802585 5.15792523 5.18463701 5.19088922
 5.20706992 5.26329577 5.30592345 5.30665519 5.31057058 5.31084719
 5.31169288 5.32424072 5.34063186 5.36653931 5.41287728 5.43322299
 5.4340091  5.43994311 5.44233401 5.44282149 5.45094314 5.47176274
 5.51047446 5.51583668 5.52607846 5.53554614 5.58229344 5.60792736
 5.61942    5.64887041 5.65392965 5.65446093 5.65526857 5.65579211
 5.65657329 5.66710753 5.6796847  5.70470981 5.70723577 5.73077021
 5.7426806  5.76092822 5.86170731 5.8695872  5.8700914  5.88550881
 5.9198579 ]

  warnings.warn(

2022-12-16 10:37:07,936:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.58152519 2.93511516 2.99825521 3.00670019 3.2314585  3.28386434
 3.48889349 3.50360835 3.58485103 3.59367991 3.62131556 3.6364485
 3.67037942 3.67423336 3.67601304 3.68552573 3.68568975 3.6891648
 3.6906749  3.69334275 3.69389909 3.70147904 3.70302053 3.70329935
 3.70880057 3.7116503  3.71201827 3.71531344 3.71675175 3.71782823
 3.72225978 3.72424242 3.72521421 3.7278079  3.73196003 3.73196506
 3.73211244 3.74006142 3.7839296  3.78795943 3.79693408 3.80580663
 3.8099646  3.81280823 3.81509231 3.82070779 3.82429712 3.83136108
 3.83336144 3.83746906 3.83798271 3.8385834  3.84390347 3.84720957
 3.85155038 3.85410716 3.85449889 3.85560472 3.8559039  3.85628942
 3.85699976 3.85775513 3.86196165 3.86197266 3.86280081 3.86339518
 3.86414999 3.86574436 3.86657541 3.86966624 3.87229167 3.87242771
 3.87335644 3.87336575 3.87594149 3.88195744 3.88199099 3.8847423
 3.8851281  3.88664817 3.88720831 3.88992487 3.89072717 3.89242315
 3.89331462 3.89344137 3.89523536 3.89644972 3.89678727 3.89774792
 3.89811731 3.89902919 3.89919284 3.89976205 3.90021779 3.90032869
 3.90055661 3.90155718 3.90158476 3.9019652  3.90203601 3.90230444
 3.90265581 3.90277954 3.90299963 3.90371623 3.90497081 3.90614374
 3.90617444 3.90683746 3.90688401 3.90701543 3.90750903 3.90762621
 3.90771292 3.90806501 3.90839304 3.90881639 3.90888462 3.90905862
 3.90932315 3.90954657 3.9097475  3.91117209 3.91121282 3.91128373
 3.91137302 3.91150591 3.91179316 3.91183316 3.91203409 3.91217476
 3.91401475 3.91463359 3.91497716 3.91563755 3.91602349 3.91645393
 3.91687804 3.91775    3.9196034  3.92404393 3.92880209 3.93018024
 3.93501792 3.93545256 3.93640065 3.93800547 3.94207594 3.94490264
 3.94637292 3.94641176 3.94672024 3.94675219 3.94713001 3.94821502
 3.9522196  3.95243253 3.95406855 3.95436164 3.95458713 3.9550162
 3.95632732 3.95647363 3.95682224 3.95787743 3.95788097 3.95947241
 3.95948182 3.959632   3.96252619 3.96429963 3.96715704 3.96939404
 3.97174653 3.97496631 3.97981281 3.97995724 3.98559078 3.98616597
 3.99424913 3.99716953 3.9981721  3.99825212 4.00146176 4.00345852
 4.00682046 4.0083083  4.01049847 4.01232392 4.01635078 4.01681951
 4.01802642 4.02125642 4.02451347 4.02454939 4.0274728  4.02828716
 4.0296342  4.03098808 4.04085143 4.04113881 4.04197231 4.04594082
 4.04665907 4.04990746 4.05216744 4.05263593 4.05402106 4.0545551
 4.05460027 4.05509529 4.05537563 4.05720971 4.05728465 4.05851134
 4.06097983 4.06281857 4.06577853 4.06593596 4.06687328 4.0686898
 4.06968979 4.07016091 4.07352145 4.07414286 4.07537135 4.07642254
 4.07714504 4.07718572 4.07803314 4.08011814 4.08080401 4.08213029
 4.08248008 4.08609066 4.0882518  4.08912878 4.09111415 4.09192974
 4.09379571 4.09406722 4.09440377 4.0961871  4.09757447 4.10387511
 4.1042741  4.10452538 4.10547639 4.10929785 4.10992597 4.10999848
 4.11564013 4.11643818 4.11654435 4.11767295 4.11806001 4.11998824
 4.12020473 4.12106501 4.12226695 4.12247988 4.12265637 4.12281658
 4.12348797 4.12365612 4.12416077 4.12447089 4.12592202 4.13232801
 4.13359209 4.13376992 4.1343744  4.13495176 4.13538149 4.13642306
 4.13693159 4.13729998 4.13821795 4.13851925 4.13910574 4.13973429
 4.14371142 4.14593134 4.14630044 4.14674749 4.14789122 4.14889097
 4.1502122  4.15032189 4.1515961  4.15307061 4.15500548 4.15973341
 4.16256056 4.16300062 4.1650143  4.16535003 4.16720977 4.16969412
 4.16983953 4.16984891 4.17045201 4.17202803 4.17287528 4.17331101
 4.17639114 4.17751071 4.18035125 4.18323296 4.18350661 4.19250726
 4.19362941 4.19408162 4.1946579  4.19522107 4.19558128 4.19676341
 4.19737724 4.20163437 4.20183975 4.20237711 4.20290985 4.20329018
 4.20390106 4.2060026  4.20627903 4.20707184 4.20780398 4.20796612
 4.21476372 4.2154421  4.21558137 4.21662238 4.2171142  4.21731908
 4.21791284 4.21901232 4.22079394 4.22097638 4.22291029 4.22384805
 4.2238744  4.22434955 4.22545244 4.22657759 4.22823384 4.23250203
 4.23342765 4.23392473 4.23395843 4.23419394 4.23503726 4.23732095
 4.23798204 4.2385749  4.23882324 4.23888157 4.23991202 4.24000952
 4.24036944 4.24066144 4.24082165 4.24092361 4.24120888 4.24131901
 4.24168187 4.24221049 4.24487645 4.24503891 4.24972743 4.250397
 4.25147791 4.25150101 4.25392193 4.25547704 4.25673018 4.25920877
 4.2641567  4.26740664 4.27029479 4.27110444 4.27173274 4.27377039
 4.2744397  4.27453053 4.27517909 4.27716356 4.27814097 4.2784122
 4.27908105 4.28008371 4.2801617  4.28026547 4.28028464 4.28057755
 4.28088535 4.28104781 4.28163381 4.28167454 4.28193424 4.28243546
 4.28284992 4.2844675  4.28482023 4.28520351 4.28554364 4.28584193
 4.28678939 4.28702473 4.28711354 4.28723781 4.28886202 4.29008592
 4.29328716 4.2932904  4.29552698 4.29606383 4.29792922 4.29952297
 4.3020657  4.30309422 4.30381466 4.30462103 4.30528303 4.30616119
 4.30791983 4.30994974 4.31075724 4.31253785 4.31318896 4.31326424
 4.31452685 4.31593426 4.31715624 4.31716224 4.31719787 4.31797765
 4.31825298 4.31875485 4.32028397 4.32174014 4.32174651 4.32248204
 4.32306028 4.32376985 4.32382534 4.32384326 4.32483771 4.32530258
 4.32606846 4.32622866 4.32708007 4.32733021 4.32735386 4.32780761
 4.3291832  4.32931699 4.32982104 4.33084502 4.33087397 4.33107489
 4.3315538  4.33159004 4.33242407 4.332625   4.3326592  4.33330749
 4.33384038 4.33455928 4.33489828 4.33643988 4.33689985 4.33701319
 4.33725745 4.33744274 4.33745867 4.33947359 4.33963727 4.3397999
 4.34074334 4.34109893 4.34136291 4.34294156 4.34338394 4.34338419
 4.34475023 4.34481365 4.34692209 4.3475922  4.34824384 4.34849469
 4.35128922 4.35142628 4.35174752 4.35505718 4.35697048 4.35734642
 4.35919516 4.35954746 4.35975167 4.36058501 4.36121174 4.36184633
 4.36270481 4.36297306 4.36309385 4.36474965 4.36541945 4.36556483
 4.3661867  4.36628751 4.3690924  4.36924809 4.36952    4.36995831
 4.37192148 4.37214786 4.37387561 4.37433355 4.37435859 4.37552145
 4.37711405 4.37995327 4.3813762  4.38262887 4.38303277 4.38379219
 4.38465291 4.38538104 4.38716627 4.38821182 4.3885406  4.39041918
 4.39069837 4.39089931 4.39110024 4.39642006 4.39815285 4.3985692
 4.40185719 4.40580492 4.40599519 4.40607193 4.40757463 4.40797559
 4.41070538 4.41198608 4.41477691 4.41642382 4.41945432 4.42047595
 4.42324311 4.42416062 4.42548357 4.42597065 4.42731983 4.42852285
 4.42863602 4.43296455 4.43344367 4.43482501 4.43591401 4.43602447
 4.43713751 4.43878596 4.43968134 4.44150274 4.4417136  4.44394019
 4.44649257 4.44794872 4.44879217 4.45155971 4.45786446 4.4579392
 4.45862713 4.46021566 4.46051588 4.46090654 4.46097549 4.46132119
 4.46399472 4.46403176 4.46766157 4.4682749  4.4694715  4.46976225
 4.47493446 4.47607184 4.47689365 4.47697757 4.4802897  4.4803724
 4.48075786 4.48100469 4.48101814 4.48115755 4.48708367 4.48710609
 4.4902103  4.49320364 4.4935569  4.49398183 4.49492455 4.49644965
 4.49678471 4.50150439 4.50435883 4.5066467  4.5088982  4.50931135
 4.50968547 4.51061371 4.51359012 4.51582772 4.5165664  4.51822743
 4.51942199 4.52066049 4.52416513 4.5245823  4.52568341 4.52645182
 4.52697807 4.52799103 4.52882298 4.53084495 4.53137088 4.53577421
 4.53659471 4.53772288 4.53962901 4.53971604 4.53974248 4.54072863
 4.54180524 4.54349162 4.54353231 4.54456386 4.5446521  4.54508241
 4.54643672 4.54728426 4.54892197 4.54964043 4.54981277 4.54988282
 4.55168654 4.55229638 4.55246913 4.55342458 4.55512647 4.55578445
 4.55680618 4.5568213  4.55798692 4.55800058 4.56018398 4.56022859
 4.56203663 4.56226123 4.56376608 4.5644658  4.56505988 4.56901534
 4.57001776 4.57058459 4.57091718 4.57361547 4.57416798 4.57491322
 4.57519689 4.57698199 4.57766642 4.58387167 4.59158687 4.59182139
 4.59253232 4.59352844 4.59488485 4.59575615 4.60813738 4.60879104
 4.61042316 4.61132499 4.61251273 4.61645783 4.61857582 4.61938989
 4.61968715 4.62166823 4.62209589 4.62311563 4.62372719 4.6240705
 4.62511553 4.62797156 4.63191346 4.63300051 4.6331511  4.63368658
 4.63411622 4.6352446  4.63856538 4.64352265 4.64368285 4.64437279
 4.64720818 4.65603412 4.65742348 4.65764842 4.65986647 4.66057604
 4.66061875 4.66114192 4.66195453 4.66813584 4.66904749 4.66962802
 4.67049794 4.67448416 4.67678846 4.68187842 4.6822223  4.69138148
 4.699791   4.70515966 4.70619424 4.7086555  4.71345825 4.71464508
 4.71592896 4.71600613 4.72296047 4.72440633 4.72677147 4.72843879
 4.72916325 4.73146935 4.73393635 4.73437525 4.73506238 4.73797564
 4.74018648 4.74053044 4.74191225 4.74570224 4.74698995 4.74940074
 4.75238724 4.75553513 4.75598779 4.7562447  4.75678994 4.75745589
 4.75761293 4.76077055 4.76095269 4.76205115 4.7648438  4.76730483
 4.76776547 4.76786628 4.77378392 4.77520531 4.77985791 4.7828653
 4.78480384 4.78973016 4.78994999 4.79147281 4.79437337 4.79558034
 4.79743855 4.80145872 4.80208997 4.80235182 4.8046048  4.80610073
 4.81002639 4.81053292 4.81309387 4.82385249 4.82593404 4.83092895
 4.83107061 4.83175336 4.8326411  4.83273634 4.83576142 4.83855715
 4.84179997 4.84313398 4.84438356 4.84453498 4.84467404 4.85945881
 4.86206625 4.86211088 4.86469655 4.86753125 4.87053412 4.87868718
 4.88277316 4.88467896 4.89027771 4.91453155 4.97452476 4.97749405
 4.98107026 4.98730845 5.00821311 5.02148572 5.03086052 5.03719157
 5.0376277  5.04277367 5.20575313 5.27715537 5.32224562 5.33842049
 5.3415159  5.34632735 5.34700839 5.3489941  5.35802709 5.36122372
 5.36385527 5.36412777 5.36625167 5.37059516 5.38240623 5.459556
 5.47543508 5.49632133 5.50424937 5.52634792 5.53086765 5.60767175
 5.62614929 5.63335963 5.67250743 5.67407647 5.73224081 5.74048238
 5.75640904 5.75833508 5.76820992 5.77933165 5.79947058 5.82676139
 5.84352553 5.946362   5.95966519 5.98346345 6.0313624  6.25481803]

  warnings.warn(

2022-12-16 10:37:07,937:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.30926653 2.52267765 2.58986392 2.59047786 2.79663118 2.94100916
 3.37181617 3.53062987 3.55147712 3.63130219 3.66870762 3.72635672
 3.73619386 3.74346903 3.75936076 3.76609244 3.76794593 3.7759996
 3.77667049 3.77979788 3.78295335 3.78465123 3.78652254 3.78749993
 3.78978586 3.79194783 3.79246309 3.79696194 3.80571273 3.81284693
 3.81790876 3.8193572  3.81959003 3.82031048 3.82063689 3.82102985
 3.82264496 3.82268821 3.83000723 3.83124798 3.83371844 3.83456978
 3.83457324 3.83554977 3.83612196 3.83649354 3.83763919 3.83827374
 3.84131607 3.84409057 3.84682614 3.84689363 3.85834466 3.86123078
 3.86407283 3.86632301 3.86694048 3.86778302 3.86836848 3.87076549
 3.87164521 3.87240131 3.87308076 3.87672565 3.88180087 3.88213292
 3.88238195 3.88274048 3.88326168 3.8834893  3.88407866 3.88445967
 3.88522278 3.88534909 3.8855626  3.88646203 3.88686156 3.88826585
 3.88968585 3.8927322  3.89337665 3.89342453 3.89401012 3.89928694
 3.90051245 3.90085916 3.90130177 3.90149169 3.90199416 3.90252595
 3.90502949 3.90649938 3.90764868 3.90768874 3.90901281 3.91007155
 3.91158307 3.91190812 3.91209764 3.91407974 3.91445629 3.91558356
 3.91639196 3.91777242 3.91863629 3.91886702 3.91890359 3.9195261
 3.91955977 3.9197301  3.91979011 3.92009835 3.92020671 3.92034707
 3.92053888 3.92135165 3.92155693 3.92159576 3.92163862 3.92216743
 3.92289127 3.92345166 3.9241557  3.92462941 3.9248939  3.9249447
 3.9250519  3.92536165 3.92549092 3.92554738 3.92559777 3.92578547
 3.92593123 3.92614816 3.92632074 3.92678416 3.92678894 3.92697866
 3.92701911 3.92709966 3.92791119 3.92838297 3.92851858 3.92916997
 3.92949412 3.92949435 3.9349366  3.93496893 3.93651271 3.93954978
 3.93993808 3.94103256 3.94135201 3.94174883 3.94231783 3.94259374
 3.94316108 3.9432548  3.94486693 3.94544402 3.94763463 3.94836709
 3.94841521 3.94874052 3.94894316 3.95027978 3.95051497 3.9528149
 3.95294099 3.95309102 3.95384402 3.95533294 3.95571139 3.95608737
 3.95773021 3.95817514 3.95864864 3.95948803 3.95963695 3.96115355
 3.96141876 3.9619813  3.96296597 3.96354088 3.96376187 3.96395119
 3.96410276 3.96411884 3.96417659 3.96450173 3.96473981 3.96613085
 3.96652206 3.96699051 3.96748342 3.96766669 3.96780494 3.96820787
 3.96824009 3.96868204 3.96882253 3.96890184 3.97010959 3.97015307
 3.97056532 3.97056851 3.97074049 3.97125462 3.9714877  3.97232303
 3.97256019 3.9729361  3.97388925 3.97398285 3.97458444 3.97462154
 3.97534329 3.97632642 3.97637644 3.97649794 3.97673638 3.97708536
 3.97778896 3.97809945 3.97818193 3.97831197 3.97849856 3.97869426
 3.97881757 3.97901314 3.97907628 3.98004467 3.98017357 3.98039978
 3.98064838 3.98072126 3.98075438 3.98100486 3.98118767 3.98170163
 3.98245929 3.9830105  3.98323838 3.98358149 3.98412103 3.98433808
 3.98510463 3.98599369 3.98632616 3.98679131 3.98708155 3.9880309
 3.98855993 3.98960737 3.98965581 3.99023813 3.99051283 3.99081603
 3.99183478 3.99291108 3.99322874 3.99333406 3.99555414 3.99592513
 3.99619375 3.99801445 3.99939986 3.9996613  4.00010582 4.00015098
 4.0008765  4.00194101 4.005078   4.00520571 4.00529914 4.00532484
 4.00546771 4.0073782  4.0079397  4.00947504 4.01176983 4.01262369
 4.01370061 4.01401522 4.01444231 4.01451126 4.01457764 4.01476877
 4.01498374 4.01503827 4.01529599 4.01535266 4.01690242 4.01691749
 4.01797197 4.01826757 4.01839548 4.01844452 4.01914019 4.01933498
 4.01963033 4.02027086 4.02027955 4.02054693 4.02087292 4.0209509
 4.0217612  4.02182608 4.0219823  4.02216295 4.02230408 4.02308847
 4.02320821 4.02348479 4.02443115 4.02551907 4.02699834 4.02857615
 4.02871725 4.02998767 4.03019528 4.0322907  4.032676   4.03365533
 4.03370323 4.03517148 4.03546776 4.03558739 4.03613049 4.03620148
 4.03675629 4.03728047 4.03813578 4.03850709 4.03897899 4.03902844
 4.03916483 4.03934765 4.03947163 4.03958216 4.03958884 4.03978856
 4.0402623  4.04065408 4.04077884 4.0410242  4.04104412 4.04157036
 4.04214728 4.04349262 4.04363547 4.04378699 4.0443567  4.04524825
 4.04589445 4.04590839 4.04599592 4.046753   4.04704933 4.04737705
 4.04766199 4.04921747 4.04932506 4.049664   4.04980553 4.04997912
 4.05033022 4.05082381 4.05153012 4.05167866 4.05218501 4.05246885
 4.05292148 4.0530465  4.05331445 4.05369789 4.05369822 4.05370396
 4.05372146 4.05385017 4.05402341 4.05415662 4.05441827 4.05467953
 4.0547635  4.05481123 4.05491705 4.05494445 4.05573596 4.05593497
 4.05597946 4.05599294 4.05606942 4.05612199 4.056461   4.05672655
 4.05707588 4.05709325 4.0571664  4.05760585 4.05783597 4.05825068
 4.05878677 4.05962527 4.05999336 4.06011764 4.06196979 4.0621228
 4.06274002 4.06330281 4.06340705 4.06358123 4.06369122 4.06436858
 4.0648933  4.06514806 4.06573835 4.06675579 4.06718167 4.06753821
 4.06929091 4.06944611 4.0703679  4.07133881 4.07191003 4.07559672
 4.07564165 4.07567325 4.07775905 4.08009517 4.08100832 4.08107454
 4.08214731 4.08261986 4.08408822 4.08469489 4.08509399 4.08537789
 4.08564628 4.08577286 4.08670005 4.08670619 4.08674073 4.08685543
 4.08701977 4.08708671 4.08710453 4.08715218 4.08730304 4.08772302
 4.08775837 4.08917489 4.08939785 4.08974871 4.08978539 4.09053173
 4.09062501 4.09107173 4.09110571 4.09119092 4.0920529  4.09259951
 4.0926447  4.09273362 4.09302618 4.09305514 4.09370172 4.09370829
 4.0939332  4.09396228 4.09407948 4.09452349 4.09477132 4.09543081
 4.09567229 4.096052   4.09638797 4.09693625 4.09749869 4.09788338
 4.09794914 4.09843205 4.098583   4.09860495 4.09898055 4.09922969
 4.09942958 4.09946178 4.09968435 4.10012897 4.10052217 4.10078783
 4.10197115 4.10224514 4.10252923 4.10255205 4.10336336 4.10345702
 4.10415202 4.1043543  4.10601013 4.10703727 4.10740891 4.1081231
 4.10815032 4.10986343 4.11051914 4.11212638 4.11337891 4.11499361
 4.11520692 4.11669121 4.11718403 4.11745668 4.11746002 4.11748379
 4.118722   4.11911006 4.12010542 4.12085479 4.12165538 4.12170156
 4.1223775  4.1237115  4.12643051 4.12722737 4.1282966  4.12850474
 4.12882083 4.12980192 4.13014213 4.13049148 4.13065335 4.13090985
 4.1312     4.13167659 4.13315451 4.13339353 4.1354642  4.13584548
 4.13604475 4.13688634 4.13728889 4.13765724 4.13826255 4.13876218
 4.13914511 4.13992676 4.13997455 4.14000247 4.14024273 4.14247746
 4.14358472 4.14403478 4.14479968 4.14591048 4.14677605 4.1479607
 4.15062477 4.15273965 4.15282727 4.15598262 4.15702973 4.15798657
 4.15819406 4.1586389  4.15871136 4.15908967 4.15952973 4.15964416
 4.16022289 4.16031941 4.16050902 4.16061217 4.1608571  4.16116987
 4.16146753 4.16217318 4.16245807 4.16261599 4.16307627 4.1638851
 4.16413216 4.16461759 4.16483402 4.16493315 4.16513793 4.16534882
 4.16653497 4.16710235 4.16716932 4.16731566 4.16824159 4.17050738
 4.17212272 4.17306037 4.17350284 4.17453836 4.17542844 4.17639867
 4.17700917 4.17740213 4.17877529 4.17902288 4.17909196 4.18125863
 4.18182865 4.1819068  4.18406726 4.18500912 4.18652495 4.18745728
 4.18833742 4.19024722 4.19061259 4.19258536 4.19347145 4.1935579
 4.19364997 4.19518464 4.19525061 4.19869468 4.19876791 4.19891098
 4.19930709 4.20017351 4.20270814 4.20383262 4.20445003 4.20692976
 4.20697351 4.21101901 4.21196913 4.21228565 4.21230258 4.21352698
 4.21358908 4.21526029 4.21531424 4.21592264 4.21728311 4.21732042
 4.21773256 4.21808232 4.21811132 4.21818269 4.21904618 4.2198917
 4.22031853 4.22108624 4.22206329 4.22487272 4.22602364 4.22830338
 4.22831154 4.22948163 4.2338345  4.23528743 4.23721242 4.2375475
 4.23796731 4.23861845 4.23924498 4.23996902 4.24005828 4.24068164
 4.24804984 4.24898547 4.24901545 4.24912523 4.24985099 4.2550775
 4.26058159 4.260791   4.26088561 4.26184614 4.26385428 4.26483654
 4.2689706  4.27147285 4.27156934 4.27592452 4.27629618 4.27760423
 4.28154033 4.28272961 4.28338635 4.28377572 4.2844264  4.28678807
 4.29289294 4.29469959 4.29571702 4.29636791 4.29682971 4.29690831
 4.29859148 4.29895577 4.29947399 4.30131178 4.30133319 4.30212953
 4.30219991 4.30227916 4.30329324 4.30692914 4.30735101 4.30989502
 4.31063765 4.31122513 4.31234945 4.31264163 4.31272246 4.31522159
 4.31698527 4.31724076 4.3182315  4.3196545  4.32425564 4.32537227
 4.32838837 4.33179335 4.33275978 4.33642173 4.34010718 4.34236441
 4.34369876 4.34376737 4.34658739 4.34879003 4.35395024 4.35569633
 4.35707237 4.35731758 4.36121264 4.36162704 4.37843896 4.38277172
 4.38332623 4.38633433 4.39218127 4.3938423  4.39831366 4.40890981
 4.41284232 4.414673   4.4156422  4.41759561 4.41969563 4.42268305
 4.42597435 4.42853311 4.42871455 4.43127522 4.43127776 4.43260013
 4.44300322 4.44367136 4.44566119 4.46584483 4.47083432 4.47280259
 4.48964637 4.49103367 4.49609629 4.50066489 4.50447574 4.51326612
 4.51488057 4.52830823 4.53681629 4.55333723 4.55653801 4.56330638
 4.59191448 4.61052466 4.64529375 4.65700758 4.65706258 4.6679425
 4.68413515 4.68952702 4.76089403 4.76974859 4.77164283 4.77906262
 4.79882487 4.80194596 4.81539003 4.82391581 4.82789758 4.82964057
 4.84086735 4.85326293 4.88583384 4.88584702 4.88671375 4.88933987
 4.90074392 4.91434476 4.91472642 4.91604119 4.92314346 4.96042865
 4.96276378 4.9928975  5.00414946 5.0282201  5.03074803 5.03564678
 5.04690369 5.04796812 5.06113255 5.11710358 5.11975347 5.70942109
 5.71133606 5.71983851 5.74109693 5.74143559 5.74674293 5.74951373
 5.7520689  5.76149346 5.76165124 5.7617119  5.76186378 5.76264772
 5.76518035 5.76591839 5.7736295  5.77364651 5.79861737 5.83198208
 5.83259258 5.83279663 5.83338506 5.83635952 5.83685514 5.8434015
 5.86942608 5.87298945 5.87324396 5.88033728 5.8839833  5.88526564
 5.90478301 5.90621799 5.95351211 5.95518097 5.96347653 5.97360459
 6.08851046 6.10544866]

  warnings.warn(

2022-12-16 10:37:07,984:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.52692103 2.56058114 2.56574633 2.79830847 3.08864864 3.20647595
 3.38408035 3.39310423 3.60825268 3.6174844  3.61885855 3.61953722
 3.62252387 3.62415474 3.62831295 3.63529217 3.63941393 3.64307693
 3.6434118  3.6549141  3.66382414 3.66758498 3.66915558 3.67021952
 3.67075104 3.67294393 3.67375947 3.68363022 3.68438345 3.68593998
 3.68703877 3.6908322  3.69120825 3.6933853  3.6952709  3.69730572
 3.69856801 3.7012186  3.70549398 3.70560719 3.70597875 3.71014662
 3.71534907 3.71847928 3.72330837 3.72400204 3.73101692 3.73249253
 3.7348237  3.73777787 3.74049944 3.740997   3.74144795 3.74459058
 3.74590709 3.74688228 3.74817394 3.74897787 3.74992498 3.75119976
 3.75161624 3.75274022 3.75307045 3.75339156 3.75443676 3.75499773
 3.75504697 3.75509367 3.75569089 3.75572996 3.75597595 3.75828272
 3.76049075 3.76056858 3.76060198 3.76321552 3.76488037 3.76511473
 3.76926994 3.77063346 3.77196233 3.77412325 3.77431299 3.77520587
 3.7752144  3.77674155 3.77770648 3.7780145  3.78071748 3.78463525
 3.78594596 3.78707957 3.78757233 3.79038427 3.79203454 3.79221797
 3.79256346 3.79301196 3.79391897 3.79444912 3.79489449 3.79555289
 3.79589077 3.79669149 3.796821   3.79682153 3.79708757 3.79717932
 3.79769858 3.79941799 3.79959966 3.79974277 3.80132097 3.80155965
 3.80160662 3.80190472 3.8019891  3.80280471 3.8028121  3.80284698
 3.80307542 3.80341026 3.80360943 3.80390569 3.80471251 3.80492529
 3.80494559 3.80556854 3.80572218 3.80594467 3.80594531 3.80607715
 3.80639826 3.80655821 3.80689335 3.80721217 3.80738802 3.80778686
 3.80834009 3.80909881 3.81064913 3.81110928 3.81139409 3.81145745
 3.81161689 3.81230482 3.81237832 3.81249671 3.81261365 3.81341377
 3.81406241 3.81445616 3.8149032  3.81587031 3.81631273 3.81781808
 3.81796873 3.81858476 3.81906305 3.81994278 3.82019402 3.82161223
 3.82299283 3.82312183 3.8251942  3.82762203 3.83232748 3.83273515
 3.83375691 3.83413409 3.83559113 3.83586976 3.8365849  3.83776378
 3.83875156 3.8413435  3.84198427 3.84235121 3.84238933 3.84255353
 3.84388041 3.84395407 3.84404462 3.84484296 3.84635024 3.84666918
 3.84681323 3.84685785 3.84714452 3.84815446 3.8484416  3.84954482
 3.85486575 3.85761007 3.86117867 3.86365483 3.86409524 3.87051143
 3.87057063 3.87197949 3.87337025 3.87367257 3.87550387 3.87561662
 3.87661503 3.87973487 3.88034196 3.88109556 3.88861685 3.88900666
 3.89325764 3.89403408 3.89707402 3.89890755 3.89964656 3.9067795
 3.90834366 3.90927061 3.91059778 3.9144273  3.91457037 3.91485641
 3.91935529 3.92140096 3.92820556 3.92852681 3.9295791  3.93313322
 3.93360527 3.93907785 3.93985813 3.94065364 3.94387622 3.94536672
 3.94737826 3.9473984  3.94762264 3.94867575 3.94989179 3.95081548
 3.95432586 3.95478009 3.95488872 3.95542929 3.95609961 3.95681516
 3.9583746  3.95947428 3.96083037 3.96127611 3.96256142 3.96434853
 3.96758804 3.96964702 3.97009665 3.97038378 3.97472297 3.97542826
 3.97647616 3.97711268 3.97939342 3.98253207 3.98492551 3.98602737
 3.98723399 3.98832651 3.98920089 3.98985348 3.98988959 3.99190201
 3.99209454 3.99214286 3.99284091 3.9932532  3.99329499 3.99447995
 3.99552896 3.9955439  3.99604713 3.99635725 3.99644163 3.99652189
 3.99671049 3.99764845 3.99793271 4.00043272 4.00060491 4.00242582
 4.00275731 4.00302953 4.00385384 4.00895681 4.01081035 4.01237446
 4.01564949 4.01625206 4.01656501 4.01721897 4.0181747  4.02016918
 4.02145262 4.02153042 4.02256159 4.02273467 4.02437035 4.02472024
 4.02568686 4.02637096 4.02640458 4.02681334 4.02891661 4.0292106
 4.02997283 4.03072364 4.03125555 4.03209622 4.03265078 4.03296599
 4.03364305 4.03644475 4.03667081 4.0374808  4.03774604 4.03775478
 4.03823527 4.04026094 4.04049756 4.04099971 4.04136091 4.04186416
 4.04198193 4.04386739 4.04471104 4.04484007 4.04769684 4.04833558
 4.04912981 4.05056102 4.0508803  4.05140545 4.05154707 4.05191882
 4.05213144 4.05225766 4.05268014 4.0535348  4.05449645 4.05469458
 4.0579997  4.0593465  4.0595294  4.05994418 4.06019494 4.06135069
 4.06174284 4.06230801 4.06277026 4.06379307 4.06478372 4.06659205
 4.06744885 4.06832182 4.06862559 4.06884722 4.06889284 4.06915213
 4.07060977 4.07121699 4.07173359 4.07192219 4.07250348 4.07254054
 4.07288316 4.07288888 4.07320811 4.07321236 4.07342386 4.07356913
 4.07405389 4.07420441 4.07427919 4.07477139 4.07530063 4.07540263
 4.07675272 4.07686734 4.07688763 4.0773244  4.0773914  4.07739524
 4.07739735 4.07759441 4.0778003  4.07791552 4.0785252  4.07901073
 4.07982918 4.0806245  4.08071166 4.0813797  4.08166634 4.08226882
 4.08294586 4.08320333 4.08332603 4.0833655  4.08387414 4.08444024
 4.08452924 4.08471697 4.08479587 4.08507229 4.08544715 4.08574574
 4.08585068 4.08586823 4.08596552 4.08677652 4.08681171 4.08691415
 4.08721677 4.08728998 4.08757412 4.08762726 4.08801179 4.08834287
 4.08855135 4.08928928 4.08936422 4.08952853 4.08965126 4.09024834
 4.09027218 4.09065798 4.09079284 4.09166747 4.09203885 4.09254224
 4.09295215 4.09365314 4.09483182 4.09548072 4.09566694 4.09585569
 4.09706284 4.09713441 4.09737142 4.09814005 4.09833398 4.09924759
 4.09962452 4.10015025 4.10125334 4.1025005  4.10356849 4.10384764
 4.10425937 4.10498885 4.10815638 4.10910843 4.10924976 4.11083868
 4.11184766 4.11253598 4.11257178 4.11364395 4.11401723 4.11420333
 4.11530637 4.11536572 4.1153888  4.11630707 4.11737876 4.11780604
 4.11799464 4.11850436 4.11885368 4.11896208 4.11972658 4.1207111
 4.12098749 4.12104819 4.12140257 4.12148177 4.12172262 4.12192241
 4.12219429 4.12219737 4.12258562 4.12390487 4.12425469 4.12429345
 4.12649098 4.12659716 4.12830758 4.12907923 4.13020877 4.13091392
 4.13363013 4.13444648 4.13802862 4.13938144 4.14149734 4.14388913
 4.14394522 4.14538478 4.14601173 4.14605961 4.14710804 4.1507371
 4.15103841 4.15124826 4.15602352 4.15665621 4.15716087 4.15941407
 4.16009341 4.16137068 4.16610146 4.16699496 4.16701544 4.16703017
 4.16744494 4.1692591  4.169399   4.16990755 4.17124883 4.17163056
 4.17362984 4.17615162 4.17720782 4.17823955 4.17924944 4.18194223
 4.18488736 4.18766256 4.18907724 4.18999936 4.19261744 4.19653081
 4.19931244 4.20271795 4.20475331 4.20548802 4.20678326 4.2071112
 4.20930619 4.21503674 4.21504286 4.21526458 4.21557323 4.21803396
 4.22042377 4.22232244 4.22246666 4.22370269 4.22389317 4.22779006
 4.22894531 4.22911702 4.23799135 4.23904713 4.24042001 4.24541335
 4.24568205 4.24576126 4.24587342 4.24666273 4.24700612 4.24716823
 4.24959974 4.25036459 4.25256335 4.25262712 4.25357103 4.25377693
 4.25444226 4.25481392 4.25569482 4.2587345  4.25933112 4.26032953
 4.26146684 4.26200763 4.26203123 4.26206827 4.26255866 4.26297136
 4.26483801 4.26522814 4.26643676 4.26660196 4.26968758 4.2698701
 4.27002258 4.27021306 4.2709425  4.27161437 4.27175815 4.27208189
 4.27213586 4.27312137 4.27338378 4.27351806 4.27371952 4.27374391
 4.27396177 4.27412946 4.2751184  4.27518898 4.27573843 4.27673191
 4.27720111 4.27726632 4.27799789 4.27837135 4.27923175 4.27933921
 4.28110722 4.28257731 4.28259081 4.28265514 4.28368496 4.28541368
 4.28545238 4.28622389 4.28625067 4.28770025 4.28824465 4.28922281
 4.28972465 4.29009131 4.29157255 4.29393727 4.29573208 4.29648892
 4.29838869 4.29862611 4.29920784 4.3011237  4.30162817 4.30715408
 4.30778234 4.30862742 4.31118634 4.31237924 4.31280561 4.31690014
 4.31994027 4.32029736 4.32186039 4.32473243 4.32515356 4.32917105
 4.33116972 4.33138001 4.33509993 4.33557971 4.3358689  4.33876192
 4.34006408 4.34006981 4.34452254 4.34791032 4.34833784 4.35053579
 4.3509409  4.35187338 4.35364499 4.35467508 4.35770446 4.35808187
 4.35872196 4.35879907 4.35884639 4.35893118 4.35906747 4.3590862
 4.35919173 4.36058597 4.36101383 4.36116315 4.36125991 4.36214548
 4.36253238 4.36305282 4.36414298 4.36540551 4.36652715 4.36660993
 4.36795074 4.36877438 4.36883193 4.3691329  4.36946348 4.37169132
 4.3723108  4.37233905 4.37452144 4.37771224 4.37804063 4.37824247
 4.37967402 4.38031767 4.38262628 4.3861337  4.38701864 4.3878625
 4.3942265  4.39838352 4.3992157  4.39978092 4.39984959 4.40179417
 4.40369082 4.40388795 4.40595835 4.40612458 4.40880853 4.41027949
 4.41052327 4.41128378 4.4125413  4.41449012 4.41498116 4.41774894
 4.42048533 4.42435549 4.42612388 4.427743   4.43303093 4.43391112
 4.43907065 4.44302656 4.4460074  4.45467583 4.45839181 4.46491997
 4.46713299 4.46891116 4.46951797 4.47148268 4.47298761 4.47851474
 4.48345139 4.48348851 4.48709306 4.48951502 4.49038389 4.49151026
 4.49194822 4.49310011 4.49889342 4.49895539 4.49901301 4.51528927
 4.51722336 4.52053014 4.52283677 4.52312769 4.52412502 4.52853112
 4.53053685 4.5322322  4.54115451 4.54483366 4.54636943 4.54688066
 4.54812029 4.54969429 4.55129514 4.55187258 4.55194754 4.55205645
 4.55222103 4.55313034 4.5593785  4.56265056 4.56880288 4.56943337
 4.56953803 4.57343963 4.57429466 4.57836098 4.57878392 4.58018624
 4.61133842 4.61260558 4.61534802 4.62553646 4.63936828 4.6579967
 4.67077212 4.67091966 4.67177453 4.67261765 4.67293084 4.67360124
 4.6747708  4.68489839 4.68627015 4.68983777 4.69303255 4.695076
 4.70921135 4.71327534 4.72041851 4.74171057 4.74221496 4.75569123
 4.76332532 4.7645971  4.76464183 4.78264638 4.80262943 4.82460312
 4.86724891 4.86824241 4.89005599 4.89005809 4.91408017 4.92436696
 5.01488362 5.29785818 5.29865403 5.33012141 5.36060391 5.38539686
 5.39891293 5.40054933 5.41923743 5.4210986  5.42634091 5.43624927
 5.43626919 5.44538029 5.58892395 5.58957444 5.63168789 5.68780707
 5.69104061 5.692402   5.70027537 5.70056668 5.70113953 5.78609978
 5.79863432 5.85628913 5.88668323 5.91333671 5.96668205 5.96863437
 6.01652512 6.08730269 6.18537015]

  warnings.warn(

2022-12-16 10:37:08,725:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [-0.65140698 -0.41270178 -0.40102324 -0.35194191 -0.34374567 -0.23863523
 -0.191643   -0.16583193 -0.16040158 -0.12778218 -0.05408449 -0.01889222
  0.05994701  0.17154839  0.2715551   0.46412658  0.54386083  0.55797063
  0.55926334  0.5633303   0.56404705  0.57050972  0.57445013  0.57508275
  0.57639464  0.57785127  0.5804067   0.58887256  0.59299063  0.59536004
  0.5967599   0.59811542  0.59927634  0.59951746  0.60517465  0.6131402
  0.61412745  0.61443562  0.61538189  0.61699144  0.61909974  0.62749612
  0.63253255  0.64421706  0.64545583  0.65432478  0.65691858  0.66250648
  0.66976329  0.6710776   0.69536464  0.70559599  0.7128152   0.72103982
  0.7347991   0.74505107  0.75193383  0.75574849  0.76547726  0.76633832
  0.77184318  0.77869011  0.78993591  0.79112365  0.79117002  0.79571877
  0.79770769  0.80105419  0.8050488   0.80562537  0.80875324  0.80950258
  0.81277123  0.81414878  0.81944896  0.8252347   0.82569188  0.83088741
  0.83576843  0.83612006  0.84149531  0.84704427  0.84742265  0.85437631
  0.85632417  0.86626628  0.87682448  0.87722697  0.88871806  0.89061027
  0.89098137  0.89110954  0.89228643  0.89261592  0.89449432  0.90371921
  0.90526998  0.90912445  0.91896599  0.92036151  0.92359372  0.92702342
  0.92955653  0.93130058  0.93333361  0.93525866  0.93675073  0.93844236
  0.93867873  0.93952514  0.94031331  0.9438082   0.94620664  0.94790189
  0.94799505  0.95039702  0.95077176  0.95127232  0.95146533  0.95149066
  0.95275857  0.95377254  0.95544207  0.95624298  0.95799653  0.95962311
  0.96355317  0.96401101  0.96927742  0.96946815  0.9719217   0.97201542
  0.97257032  0.97266782  0.97674321  0.97784676  0.98721199  0.98915221
  0.9895175   0.99945679  0.99975846  1.0001795   1.00056614  1.00076865
  1.00139037  1.00229119  1.00351055  1.0042975   1.00747158  1.01113631
  1.01259638  1.01369308  1.0144922   1.01456691  1.01636799  1.01653566
  1.01933776  1.02043447  1.02136902  1.0239672   1.02820708  1.02823245
  1.03189398  1.03419329  1.03454847  1.03584389  1.03606272  1.03726426
  1.03812136  1.03846756  1.03881576  1.03919947  1.04189175  1.04270245
  1.04438985  1.04459202  1.04559111  1.04643193  1.04769462  1.04800031
  1.04830715  1.04835967  1.04947973  1.04987197  1.05128184  1.05296221
  1.0535375   1.05357518  1.0541414   1.05487229  1.0556082   1.05619604
  1.05660839  1.05750718  1.05795904  1.05967136  1.06007276  1.06017278
  1.0602743   1.06070188  1.06149313  1.06198482  1.06214597  1.06272724
  1.06302967  1.06481796  1.06512436  1.06526546  1.06616382  1.06726663
  1.06730024  1.06797923  1.0680483   1.06805516  1.06811024  1.06827667
  1.06838446  1.07261321  1.0730363   1.07399793  1.07449811  1.07467109
  1.07622457  1.07651791  1.07757478  1.07781333  1.07905167  1.08025227
  1.08283811  1.08334997  1.08836735  1.08918642  1.0909271   1.09104783
  1.09192021  1.09261969  1.09433399  1.09535753  1.09608815  1.09704465
  1.09711152  1.09865329  1.09994701  1.10013873  1.10043952  1.10046635
  1.10111678  1.10147411  1.1026015   1.10260188  1.1028941   1.10302156
  1.10405502  1.10527426  1.10683646  1.10779321  1.11033831  1.11120051
  1.11355591  1.11386375  1.11534067  1.11720571  1.11739661  1.11802196
  1.120849    1.12142546  1.12185387  1.12254791  1.12278666  1.12505577
  1.12533076  1.1271387   1.12810158  1.12836131  1.12975618  1.13577
  1.13933526  1.14164238  1.14352067  1.14681422  1.14687422  1.14886535
  1.15257797  1.15491356  1.1557982   1.15988174  1.16167444  1.16537574
  1.16559512  1.16571419  1.16726996  1.16762491  1.1683175   1.1690163
  1.17264243  1.17317795  1.17349946  1.17361232  1.17475823  1.17481573
  1.17498808  1.17767025  1.17823954  1.17879793  1.1791358   1.18106694
  1.18313548  1.18468439  1.184811    1.1855385   1.18594262  1.18721587
  1.1872966   1.18915692  1.19138928  1.19228594  1.19683591  1.19708771
  1.19776843  1.19843374  1.20172706  1.20277622  1.20495645  1.21018267
  1.212022    1.21288954  1.21532901  1.21572713  1.21631955  1.21805099
  1.21986229  1.22066195  1.22194513  1.22379303  1.2238786   1.22528937
  1.22620281  1.22645989  1.22668436  1.22724237  1.22880257  1.22944942
  1.2299603   1.23292043  1.23364244  1.2345268   1.23585078  1.23945827
  1.24105575  1.24108002  1.24243908  1.24459519  1.24508391  1.24534868
  1.24537054  1.24537264  1.24597191  1.24628582  1.24695805  1.24797696
  1.24807784  1.2483614   1.24896187  1.24902063  1.24905624  1.25035246
  1.25059782  1.25183012  1.25238028  1.25287936  1.25496438  1.25568391
  1.25577651  1.25581277  1.25678505  1.25847654  1.26111332  1.26196863
  1.26248858  1.26290092  1.26324465  1.26345548  1.26346228  1.26482839
  1.26509854  1.26559076  1.26571736  1.26707942  1.26793281  1.26961823
  1.26986971  1.26987316  1.27003109  1.27087     1.27106054  1.27312202
  1.27489658  1.27508611  1.27619941  1.2776062   1.27828603  1.2793771
  1.2795607   1.27993495  1.28015207  1.28279452  1.28281652  1.28292454
  1.28345049  1.28428346  1.28478382  1.28482     1.28550028  1.28595345
  1.28725038  1.28746599  1.28806534  1.28845985  1.28875576  1.28934846
  1.29049179  1.29132243  1.29136155  1.29262791  1.29384382  1.29396271
  1.29559416  1.29585937  1.29630618  1.29761198  1.29799582  1.29917976
  1.30198727  1.30221141  1.3023268   1.30268147  1.30381662  1.30755166
  1.30788139  1.30801966  1.30856362  1.3085819   1.30977987  1.30995385
  1.31087191  1.31192478  1.31409728  1.314513    1.31515284  1.31556525
  1.31702663  1.32071182  1.321468    1.32208686  1.32400731  1.32440821
  1.32509675  1.32589044  1.32601604  1.3277755   1.32879382  1.32907881
  1.32951559  1.32967284  1.3304205   1.33073375  1.3308781   1.33183774
  1.33256752  1.3328989   1.33903411  1.34066767  1.34183258  1.34283223
  1.34704596  1.34860057  1.3487062   1.34900579  1.34972813  1.34993639
  1.35095237  1.35154577  1.35203738  1.35210219  1.35418542  1.35426156
  1.35597793  1.35609995  1.35618993  1.35619072  1.35625841  1.35634237
  1.35742218  1.35743791  1.35892366  1.36084245  1.36175594  1.36183145
  1.36197461  1.36237914  1.36278178  1.36345077  1.3646327   1.36493339
  1.36729978  1.36781431  1.36794363  1.36797841  1.36857607  1.36930392
  1.36980846  1.37046738  1.37383365  1.37449439  1.37461859  1.37600247
  1.3783915   1.37965634  1.38079189  1.38095396  1.38197614  1.38231388
  1.38352263  1.38380226  1.38388776  1.38496021  1.3850595   1.38625835
  1.387218    1.3874021   1.3880312   1.38834508  1.39026408  1.39143012
  1.39201626  1.39206339  1.3924908   1.39260763  1.39295293  1.39336953
  1.39413003  1.39450296  1.39471787  1.39505112  1.39567985  1.39588357
  1.39591126  1.39598445  1.39714537  1.39721857  1.39725576  1.39835475
  1.39864676  1.39886948  1.39907906  1.40134902  1.40265908  1.40277238
  1.40324078  1.40386495  1.40393514  1.40509806  1.40532868  1.40555603
  1.40616441  1.40644671  1.40818511  1.40967878  1.40969094  1.41026495
  1.41055271  1.41063348  1.41161353  1.41233155  1.41445998  1.41597311
  1.41621166  1.41636545  1.41688408  1.41706685  1.41749753  1.41854832
  1.41877658  1.41886354  1.41886615  1.42014709  1.42034218  1.42080578
  1.4208326   1.42118928  1.42145933  1.42188065  1.42197548  1.42224922
  1.42241426  1.42300381  1.42314336  1.42390234  1.42408302  1.42412957
  1.42554707  1.42572297  1.42635959  1.42677282  1.42737046  1.42755481
  1.42756209  1.42795942  1.42806966  1.42891651  1.42991045  1.43034907
  1.4309297   1.43124067  1.43241473  1.43244162  1.43258127  1.43315744
  1.43364809  1.43377652  1.43397906  1.43409348  1.43416733  1.43417891
  1.4342072   1.43523811  1.43524199  1.43576053  1.43796453  1.43881054
  1.43918593  1.43918801  1.43948971  1.44027171  1.44045318  1.44111835
  1.44141965  1.44511281  1.44521645  1.44603546  1.44705538  1.44707088
  1.4474748   1.44841726  1.44875208  1.44930389  1.44969514  1.45033028
  1.45082019  1.45094128  1.45103304  1.45129633  1.45309258  1.45384664
  1.45404297  1.45694321  1.45705325  1.45787574  1.45796953  1.4591093
  1.46221981  1.46281772  1.46453112  1.46484313  1.4666739   1.46985977
  1.47004098  1.47215785  1.47277944  1.47396241  1.47578286  1.47664803
  1.47682954  1.47856661  1.48045165  1.48095905  1.48110859  1.48434848
  1.48516044  1.48851969  1.48885878  1.48967318  1.49071605  1.49165
  1.49219916  1.49351714  1.49485465  1.49504932  1.50359781  1.5042569
  1.50703307  1.50751775  1.50803812  1.51237733  1.51458646  1.51624362
  1.51811336  1.52119504  1.53414364  1.53536404  1.53678873  1.54525224
  1.54707568  1.55168356  1.55589775  1.55737657  1.55973709  1.55980039
  1.56114011  1.57119275  1.57145481  1.57233018  1.5736193   1.57717373
  1.57783486  1.57991749  1.58114481  1.58196244  1.58276966  1.58311406
  1.58324661  1.584755    1.58518009  1.58591797  1.59105079  1.59460642
  1.59528574  1.59632387  1.59662153  1.59804702  1.59957599  1.6043821
  1.60646624  1.60709941  1.60718597  1.60887788  1.61004171  1.61077008
  1.61295849  1.6134179   1.61364507  1.61420157  1.61741027  1.61787732
  1.61916142  1.61926801  1.61983183  1.62148025  1.62342286  1.62368622
  1.62370746  1.62392063  1.62493063  1.62863353  1.62999671  1.63068072
  1.63495403  1.63568942  1.6357092   1.63593484  1.63688999  1.63694361
  1.64113381  1.64115927  1.64189582  1.64406089  1.64782762  1.65086832
  1.65087712  1.6525617   1.65319588  1.65590036  1.65656643  1.65735678
  1.65786065  1.65816675  1.65913943  1.66280365  1.66462875  1.66864473
  1.66936587  1.6723593   1.67256502  1.67274423  1.67461242  1.67984465
  1.68261262  1.68970106  1.69261801  1.70176302  1.70648911  1.7079789
  1.71703538  1.72177751  1.72631094  1.73600957  1.74067775  1.76061995
  1.76279315  1.76996284  1.79128255  1.81519116  1.81766144  1.82752602
  1.83396501  1.84094091  1.84418654  1.85095356  1.86954206  1.89535183
  1.91404297  1.93629163  1.9681892   1.97013153  1.98118569  1.99213019
  2.06088922  2.06390198  2.08640231  2.13461893  2.21494579  2.31197117
  2.32833161  2.34047976  2.36400333  2.36850816  2.37313813  2.37317229
  2.37669282  2.37905614  2.37966253  2.38028197  2.41209444  2.50531803
  2.54622007  2.59266196  2.6052657   2.6056113   2.61060357  2.6444026
  2.64481742  2.65409408  2.6696787   2.69469486  2.70158852  2.71924336
  2.72402091  2.72987638  2.77292723  2.80119025  2.95346394  2.96664931
  2.97479412  2.99240829  3.03704235  3.05021691]

  warnings.warn(

2022-12-16 10:37:08,735:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [-0.56062877  0.34155607  0.37666628  0.38352543  0.39237855  0.41218041
  0.41269606  0.41673122  0.420602    0.42912851  0.43929381  0.44313034
  0.44376797  0.45117905  0.45686169  0.46345274  0.46534182  0.46636471
  0.46764467  0.47017317  0.47032037  0.47729077  0.47739991  0.48268966
  0.48380695  0.49040613  0.49441056  0.49780839  0.4984292   0.50486005
  0.50834306  0.51389346  0.5169655   0.52197745  0.5241769   0.53118498
  0.53339951  0.53847254  0.54324053  0.54947778  0.56646189  0.62649561
  0.63751642  0.64795843  0.65000024  0.65341221  0.65842876  0.65849085
  0.66743774  0.67545679  0.67754331  0.68371646  0.69093691  0.6973587
  0.70654493  0.71312443  0.71625897  0.72015801  0.72250296  0.72335084
  0.73976478  0.74698029  0.74735615  0.74813742  0.74824011  0.75179334
  0.75219856  0.7550196   0.7552641   0.75611935  0.76620304  0.76774497
  0.76789173  0.77337774  0.77347694  0.77355182  0.77726408  0.77948673
  0.78045766  0.78461106  0.78597834  0.79095529  0.79106008  0.79798112
  0.79854267  0.79893345  0.79973285  0.79994338  0.80876897  0.8144209
  0.81493548  0.81777009  0.82874679  0.83527462  0.8360927   0.83896147
  0.8503775   0.85103437  0.85189471  0.85553289  0.86490211  0.87691267
  0.89066091  0.9084174   0.91045421  0.91847612  0.92571919  0.92907989
  0.93063299  0.93891968  0.94225071  0.94578965  0.94834664  0.94843249
  0.9485018   0.95117908  0.95262297  0.95273473  0.95598185  0.96617584
  0.96636177  0.96684458  0.96804111  0.96827862  0.96865175  0.96894809
  0.97052562  0.97094078  0.97102585  0.97108516  0.97182004  0.9730669
  0.97451011  0.97520305  0.97731055  0.97801604  0.979404    0.98192387
  0.98252367  0.98511794  0.98527113  0.98558786  0.98629501  0.98679684
  0.98712562  0.99043061  0.99074671  0.99151856  0.99152968  0.99309554
  0.99340442  0.99412289  0.9953304   0.99565845  0.99601057  0.99654041
  0.99737434  0.9974539   0.99771467  0.997822    0.99849074  0.99866124
  0.9993156   0.99962387  0.99998558  1.00080087  1.00085859  1.00092686
  1.00118113  1.00151479  1.0016724   1.00189257  1.00216297  1.00250079
  1.00374916  1.00553423  1.00626436  1.00660919  1.00690037  1.00840243
  1.0085273   1.00909757  1.00920239  1.0099421   1.01106214  1.01111763
  1.0127031   1.01405909  1.01431816  1.01467423  1.01481741  1.01519148
  1.01520486  1.01583737  1.01601257  1.01655349  1.0167727   1.01692231
  1.01710893  1.01730579  1.01738723  1.01743995  1.01746638  1.01788187
  1.01942499  1.01966301  1.01978173  1.02025564  1.0210798   1.02398147
  1.02456278  1.02492096  1.02492559  1.02696311  1.02697649  1.03053938
  1.03259345  1.03491978  1.03502891  1.03654738  1.03708194  1.03887353
  1.03899152  1.03900889  1.04013658  1.040451    1.04126306  1.04142772
  1.04175083  1.04225238  1.04271005  1.04359352  1.04368414  1.04377348
  1.04402646  1.04458487  1.04586791  1.0459513   1.04632864  1.04646789
  1.04652704  1.04765824  1.04769042  1.04937441  1.04976829  1.05070948
  1.0507346   1.05119112  1.05143095  1.05166336  1.05320829  1.05340966
  1.05367951  1.0541082   1.05471829  1.05497537  1.05569672  1.05586758
  1.05671516  1.0571782   1.05814635  1.05863014  1.06026914  1.06034209
  1.06074105  1.06101326  1.06206324  1.06288808  1.06302407  1.0633436
  1.06344962  1.06402241  1.06403283  1.06442127  1.06579362  1.06631985
  1.06657361  1.06692558  1.06707948  1.06767475  1.0680018   1.07141114
  1.07149713  1.07203687  1.07209899  1.07249038  1.07281832  1.07373316
  1.0823494   1.08526643  1.08544106  1.08560497  1.08615873  1.08664144
  1.08736023  1.0896791   1.09187179  1.09202342  1.09228469  1.09311393
  1.09586358  1.09738965  1.0979657   1.09822771  1.09881971  1.10240578
  1.10252754  1.10394436  1.10578597  1.10592201  1.10894728  1.10920306
  1.10954977  1.1173126   1.12161541  1.12360835  1.12683194  1.12812518
  1.12843737  1.13103917  1.13143938  1.13496782  1.13860401  1.13886347
  1.13906188  1.14050633  1.14297351  1.14455776  1.15090196  1.15103861
  1.15286658  1.15415161  1.15436442  1.15510897  1.15754041  1.15790209
  1.1623479   1.16271727  1.16548216  1.16701483  1.16807396  1.16830129
  1.16926614  1.17251146  1.1729287   1.17312007  1.17364547  1.17378842
  1.17519006  1.17636838  1.17744327  1.18072704  1.1808158   1.18095472
  1.18162563  1.18406153  1.18714778  1.18882015  1.18941968  1.19099324
  1.19193699  1.19250115  1.19437989  1.19835998  1.19849883  1.20000248
  1.20063829  1.20124006  1.20212507  1.20382516  1.20559069  1.20567885
  1.20578909  1.20614606  1.20731184  1.2082355   1.20890506  1.20933473
  1.20940768  1.20950472  1.21139067  1.21146393  1.21175974  1.21262771
  1.21295056  1.21419721  1.21446857  1.21528265  1.21575765  1.21595251
  1.21628733  1.21767223  1.21900159  1.22120978  1.22158697  1.22363795
  1.22797908  1.2297868   1.23036875  1.23226051  1.23388714  1.23615057
  1.23662782  1.23870814  1.23929794  1.23948129  1.24198958  1.24288
  1.24770181  1.24814165  1.2494769   1.24968724  1.2502038   1.25087156
  1.25126099  1.25174554  1.25426105  1.2575219   1.25806523  1.25841348
  1.25865267  1.261818    1.26296633  1.26446124  1.2652553   1.26787773
  1.26810175  1.2694225   1.2703327   1.27046076  1.27193885  1.27617919
  1.27681526  1.27752289  1.27878236  1.27957526  1.27967464  1.28065259
  1.28239085  1.28328504  1.28455211  1.28488616  1.28538976  1.28646634
  1.28689313  1.28756427  1.2879204   1.28803246  1.28826939  1.28837743
  1.28847996  1.28856536  1.29057944  1.29177649  1.29224389  1.29334245
  1.29352954  1.2937479   1.29403879  1.2940722   1.29435566  1.29441599
  1.29444836  1.29590531  1.29634792  1.29700414  1.29743152  1.29858071
  1.29866851  1.29920222  1.30067711  1.30102186  1.30102898  1.30130916
  1.30214227  1.30275595  1.30331184  1.30338787  1.30463973  1.30522819
  1.30549383  1.30692616  1.30735454  1.30816744  1.30922927  1.30987931
  1.31008307  1.31123888  1.31129105  1.31130249  1.31309797  1.31315772
  1.31392968  1.31396308  1.31423056  1.31495875  1.31625061  1.31678773
  1.31684925  1.31719823  1.31788222  1.31797653  1.31873372  1.32068227
  1.32116212  1.32119265  1.32141041  1.32200653  1.32220657  1.32223654
  1.32229851  1.32249641  1.32298398  1.32303104  1.32317324  1.32370066
  1.32383191  1.32445353  1.32497719  1.32506579  1.32538077  1.32718999
  1.32811581  1.32812576  1.32826507  1.32856315  1.32888137  1.32910986
  1.32911386  1.32952517  1.32959331  1.33013836  1.33075971  1.330884
  1.33149894  1.33171556  1.33220398  1.33247479  1.33283012  1.33292685
  1.33315579  1.33324036  1.33569168  1.3358371   1.33584639  1.33629178
  1.33711122  1.33721164  1.33733728  1.3374812   1.33767683  1.337841
  1.33797412  1.33846355  1.33889347  1.3390382   1.33937457  1.33980946
  1.33982566  1.34071     1.34080761  1.34118767  1.34127972  1.34224545
  1.34251605  1.34270243  1.3429222   1.34326089  1.34360953  1.34380073
  1.34415853  1.34449424  1.34450999  1.34455086  1.34598097  1.3462361
  1.34762414  1.34825612  1.34849894  1.34890229  1.34925483  1.34955375
  1.34999801  1.35089074  1.35137389  1.35184511  1.35254162  1.35254836
  1.35452533  1.3547464   1.35549683  1.35593503  1.35609498  1.35656147
  1.35670993  1.35674032  1.3578075   1.35822406  1.35824514  1.35827707
  1.35831637  1.35897821  1.35897981  1.35968897  1.35989189  1.3602704
  1.3612147   1.36148157  1.3623917   1.36579801  1.36649288  1.36684987
  1.36838485  1.36840278  1.36900922  1.36921905  1.3702407   1.37089756
  1.37120259  1.37178196  1.3722201   1.37287546  1.37341902  1.37382174
  1.37400858  1.37480492  1.37556718  1.37577007  1.37602371  1.37647868
  1.37763008  1.3779119   1.37828151  1.37834709  1.37941662  1.37960238
  1.38283621  1.3867953   1.38716352  1.38773126  1.38833046  1.38874193
  1.38923148  1.39189955  1.39261063  1.39275732  1.39282705  1.39564906
  1.39746308  1.39769646  1.39913172  1.39970427  1.40105638  1.40466992
  1.40799559  1.4102745   1.41318034  1.41391041  1.41569406  1.41817396
  1.41853643  1.41952445  1.42264792  1.42276349  1.42352365  1.42567785
  1.42665763  1.42724942  1.43032435  1.43595218  1.43673604  1.43849247
  1.43877544  1.44170154  1.44172653  1.4433562   1.44538158  1.44689931
  1.44813947  1.4495      1.44966032  1.45101376  1.45154666  1.45297625
  1.4586248   1.46294142  1.46475878  1.46636578  1.46947579  1.47065231
  1.4743316   1.4769124   1.47802156  1.47882259  1.48166964  1.49281519
  1.49453766  1.50002903  1.50252251  1.51089717  1.51190927  1.51288057
  1.51301848  1.51545566  1.51690013  1.52063843  1.5212292   1.52402757
  1.52516651  1.52678404  1.52696566  1.52823907  1.53011802  1.53032875
  1.5319365   1.53356036  1.53404186  1.53505558  1.53508735  1.53575347
  1.53781155  1.53890434  1.54052104  1.54232135  1.54269891  1.54636243
  1.546841    1.54899591  1.55004122  1.55065814  1.55100036  1.55433322
  1.55492583  1.5598864   1.56791572  1.57133564  1.57191015  1.57460801
  1.57712599  1.57832286  1.57942841  1.57985616  1.58104792  1.58331742
  1.58404226  1.58406119  1.58588075  1.59011399  1.59036071  1.59153483
  1.59849799  1.60294884  1.60510565  1.61044323  1.61246681  1.61657367
  1.6187582   1.62067972  1.62270203  1.62531214  1.62882988  1.63068202
  1.63314437  1.63435666  1.63593905  1.63600624  1.63675355  1.63700312
  1.63813086  1.64076029  1.64248625  1.64457368  1.64568971  1.64579207
  1.65095814  1.65782893  1.66276251  1.66306308  1.66507656  1.66518102
  1.66755201  1.67947607  1.68337823  1.68348467  1.68381487  1.68393159
  1.68460847  1.68540464  1.68565726  1.69028816  1.69214019  1.69547546
  1.69769451  1.69991356  1.70104379  1.70357634  1.70481973  1.7049114
  1.71215482  1.71250832  1.71773141  1.72067413  1.72603641  1.75072515
  1.75877349  1.77838288  1.77890807  1.78765039  1.81790315  1.83850651
  1.84023632  1.94966365  1.96018197  1.96154407  1.96287268  2.00791643
  2.08281791  2.08505229  2.14395754  2.17274047  2.29386617  2.3034024
  2.32432423  2.39481423  2.41679054  2.41968096  2.42493495  2.42559994
  2.42843849  2.43867813  2.46154494  2.46596531  2.4713731   2.47373082
  2.4738712   2.47390337  2.47416953  2.55255486  2.56909431  2.61060919
  2.6219201   2.65514264  2.72229696  2.72911734  2.7397632   2.74321496
  2.74550399  2.75069201  2.75128113  2.75249122  2.77783623  2.83257346
  2.8390659   3.05457135  3.12139905  3.16638687]

  warnings.warn(

2022-12-16 10:37:08,736:INFO:Calculating mean and std
2022-12-16 10:37:08,737:INFO:Creating metrics dataframe
2022-12-16 10:37:08,742:INFO:Uploading results into container
2022-12-16 10:37:08,742:INFO:Uploading model into container now
2022-12-16 10:37:08,743:INFO:master_model_container: 17
2022-12-16 10:37:08,743:INFO:display_container: 2
2022-12-16 10:37:08,743:INFO:PassiveAggressiveRegressor(random_state=5099)
2022-12-16 10:37:08,743:INFO:create_model() successfully completed......................................
2022-12-16 10:37:08,888:WARNING:create_model() for PassiveAggressiveRegressor(random_state=5099) raised an exception or returned all 0.0, trying without fit_kwargs:
2022-12-16 10:37:08,889:WARNING:Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 795, in compare_models
    assert (
AssertionError

2022-12-16 10:37:08,889:INFO:Initializing create_model()
2022-12-16 10:37:08,889:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002281239F8E0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022810EC8B20>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:37:08,889:INFO:Checking exceptions
2022-12-16 10:37:08,892:INFO:Importing libraries
2022-12-16 10:37:08,892:INFO:Copying training dataset
2022-12-16 10:37:08,897:INFO:Defining folds
2022-12-16 10:37:08,897:INFO:Declaring metric variables
2022-12-16 10:37:08,897:INFO:Importing untrained model
2022-12-16 10:37:08,897:INFO:Passive Aggressive Regressor Imported successfully
2022-12-16 10:37:08,897:INFO:Starting cross validation
2022-12-16 10:37:08,899:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:37:10,854:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.98507991 2.16322598 2.22836875 2.26090784 2.3182499  2.41506702
 2.49949468 2.50391175 2.52960998 2.56066551 2.740705   2.81812024
 3.07278153 3.18305662 3.35920663 3.40965138 3.42340731 3.43868825
 3.44208541 3.4759595  3.47812023 3.4810882  3.48283818 3.48299071
 3.48313044 3.49418367 3.49425995 3.49790987 3.50156081 3.50454574
 3.50537417 3.51278542 3.51715841 3.51822717 3.5193148  3.51946655
 3.51974583 3.52045282 3.52315202 3.52330389 3.52665276 3.53034517
 3.53047887 3.53057282 3.53122144 3.53154217 3.53210604 3.53288439
 3.53313428 3.53331062 3.53348478 3.53436271 3.53614467 3.53667428
 3.53843319 3.54078061 3.54126137 3.54565533 3.54583325 3.54636365
 3.54674669 3.5477744  3.54789685 3.54907787 3.55028139 3.55216354
 3.55333066 3.55348192 3.55393942 3.55439362 3.55490533 3.55676981
 3.55758123 3.55845206 3.55982935 3.55983674 3.56225431 3.56388182
 3.56400684 3.56470123 3.56483631 3.56508804 3.56554861 3.56579884
 3.567263   3.56735254 3.57046293 3.57348875 3.57468294 3.57489703
 3.57531423 3.57622767 3.57747792 3.57774613 3.57923248 3.57970691
 3.57982504 3.57984489 3.58035125 3.58044229 3.58071717 3.58126129
 3.58159862 3.58308904 3.58370769 3.58453935 3.58477509 3.58506736
 3.585186   3.58588867 3.5860468  3.58867869 3.58924688 3.59095489
 3.59333209 3.59434246 3.59486325 3.59517859 3.5953696  3.5954177
 3.59727044 3.59768117 3.59817884 3.5981853  3.60003772 3.60006015
 3.60041776 3.6004234  3.60052305 3.60063793 3.60090424 3.60134216
 3.60247345 3.60266543 3.60360607 3.6037148  3.60385412 3.60399076
 3.60575528 3.60579242 3.60718727 3.60728849 3.60743246 3.60779325
 3.60806685 3.60812159 3.60858349 3.6095272  3.60958263 3.60959573
 3.60990784 3.61329971 3.61331036 3.61363748 3.6140793  3.61507817
 3.61510924 3.61571072 3.61585468 3.61644857 3.61708082 3.61719123
 3.61799632 3.62026995 3.62144006 3.62223894 3.62345965 3.62348804
 3.62408983 3.62441967 3.62497673 3.62551788 3.62641854 3.6281178
 3.62862348 3.63162149 3.63210213 3.63539399 3.6369186  3.63760098
 3.63915049 3.63979125 3.64063684 3.64082393 3.64082721 3.64125243
 3.64297691 3.64486565 3.64521007 3.64678018 3.64796997 3.64937428
 3.65048346 3.65074703 3.6544655  3.6553562  3.6560659  3.65633521
 3.65806859 3.65869709 3.65892161 3.66015078 3.66258917 3.66298141
 3.66317092 3.66455361 3.66494872 3.66542908 3.66837832 3.66942683
 3.67362179 3.67387081 3.67408675 3.67628124 3.67749337 3.67858374
 3.68054398 3.68074578 3.68172163 3.68311158 3.68417776 3.68759273
 3.690022   3.69023387 3.69251851 3.69700656 3.70316913 3.70571884
 3.70654058 3.70724528 3.70803469 3.70811592 3.71107529 3.71170677
 3.71284703 3.7203831  3.72150282 3.72601624 3.72613186 3.72765303
 3.72773675 3.73000043 3.73108177 3.73280046 3.73688261 3.73719283
 3.73914434 3.73941649 3.74005269 3.74029351 3.74101807 3.74316867
 3.7436502  3.74553012 3.74870165 3.75086388 3.75134456 3.75248729
 3.75291312 3.75356668 3.75713463 3.75915426 3.76015827 3.76439456
 3.76509178 3.76537515 3.76670974 3.7668951  3.76817694 3.76862593
 3.7690318  3.77026323 3.77049147 3.77079125 3.77342665 3.77368288
 3.77412301 3.77457565 3.77477882 3.77701006 3.77782494 3.77958481
 3.77979224 3.78168811 3.78285635 3.7842568  3.78663786 3.78731201
 3.78733268 3.78916507 3.78952911 3.78994343 3.79177836 3.79319719
 3.79342466 3.79443332 3.79445079 3.79526648 3.79569045 3.7963578
 3.79667223 3.79678577 3.79751975 3.79873629 3.79920171 3.80129327
 3.8016923  3.80200628 3.80311846 3.8034285  3.80392435 3.8068362
 3.80800266 3.80994764 3.81156571 3.81216901 3.81451375 3.81589852
 3.81668078 3.81836072 3.81961714 3.8208668  3.82131407 3.82146932
 3.82259557 3.82285814 3.82485378 3.82497656 3.82521827 3.82573284
 3.82657755 3.82673519 3.82690543 3.8270362  3.82759437 3.82906644
 3.82927331 3.83244351 3.83434498 3.83484589 3.83663486 3.83831351
 3.83854401 3.84104969 3.84105359 3.84108549 3.8423027  3.84267889
 3.84329257 3.84539287 3.84549344 3.84613029 3.8461812  3.8464243
 3.84653062 3.84665265 3.84682251 3.84754313 3.84755826 3.84763183
 3.84802993 3.84815771 3.84857486 3.84964429 3.85064773 3.85076457
 3.85163056 3.85226151 3.85314607 3.85344598 3.8538376  3.85517771
 3.85785955 3.85865564 3.8591433  3.8591966  3.85926499 3.85943483
 3.86099449 3.86134347 3.86187197 3.86312088 3.86332406 3.86354484
 3.86514642 3.86626658 3.86666234 3.8682536  3.86855328 3.87027111
 3.87070061 3.8711198  3.87139038 3.87261072 3.87270674 3.87274659
 3.87275429 3.87285914 3.87451678 3.87461439 3.87537769 3.87600069
 3.87663422 3.87684546 3.87733585 3.87776086 3.87793676 3.87832239
 3.87877544 3.87934767 3.87977134 3.8801263  3.88058467 3.88135802
 3.88188846 3.88287084 3.883098   3.88429019 3.88437826 3.88441728
 3.88451831 3.88489262 3.88609084 3.88708161 3.88714741 3.88728112
 3.88733092 3.88761434 3.88773233 3.88859353 3.88920924 3.89126288
 3.89170596 3.89217492 3.89338692 3.89356723 3.89411105 3.89491713
 3.89501917 3.89618088 3.8962261  3.89624194 3.89713349 3.89756542
 3.89782007 3.89805831 3.89814405 3.89825099 3.89834332 3.89839547
 3.89863014 3.89866863 3.8997316  3.8998026  3.89994912 3.90001364
 3.90004844 3.90106314 3.90139675 3.90220908 3.90249241 3.90269796
 3.9035734  3.90380489 3.90422944 3.90461009 3.90503306 3.90597094
 3.90624875 3.90637592 3.90656184 3.90666223 3.90693945 3.90695087
 3.90744433 3.90769487 3.90783013 3.90789917 3.90797432 3.90805155
 3.90820574 3.90858518 3.90860437 3.90876055 3.90958916 3.90973352
 3.90989983 3.9099227  3.91092901 3.91107152 3.91150187 3.91218951
 3.91227108 3.91306803 3.91341089 3.91342954 3.91358261 3.91366158
 3.91370078 3.91378218 3.91380716 3.91401516 3.9140772  3.9173996
 3.91755587 3.91799465 3.91807019 3.91815734 3.91840131 3.91840131
 3.91904167 3.91905936 3.919188   3.92038088 3.92047197 3.92101006
 3.92123535 3.92141395 3.92220273 3.92417863 3.92428951 3.92429652
 3.92504636 3.92524263 3.92578801 3.92579174 3.92594702 3.92621664
 3.92650123 3.92653248 3.92669301 3.92678031 3.92680555 3.92764111
 3.92881097 3.92958077 3.92970154 3.92985826 3.93077222 3.93105112
 3.93106332 3.93139744 3.93153569 3.9317002  3.93263411 3.93305343
 3.93320137 3.93430982 3.93438804 3.93448102 3.93454876 3.934641
 3.93479586 3.93486806 3.9348813  3.93552563 3.9359719  3.93620583
 3.9363292  3.93752662 3.93801971 3.93806458 3.93877427 3.93966439
 3.94024328 3.94032998 3.94038007 3.94039299 3.94064983 3.94068015
 3.94069094 3.94075424 3.94214438 3.94226135 3.94239201 3.94267872
 3.94327439 3.94413156 3.94445149 3.94486029 3.94488448 3.94601281
 3.94644716 3.94799818 3.94832951 3.94939904 3.94959608 3.95067765
 3.95081775 3.95122649 3.95126162 3.9531143  3.95325027 3.95394352
 3.95409437 3.95415094 3.95498351 3.95527772 3.95557908 3.95577953
 3.95636705 3.9569087  3.95717883 3.95782908 3.95868808 3.95906934
 3.96118372 3.96250264 3.96252457 3.96256214 3.96310295 3.96381589
 3.96436232 3.96495563 3.96503027 3.96577544 3.96713929 3.96918895
 3.96929919 3.96965702 3.96996027 3.97048565 3.97130991 3.97150361
 3.97247334 3.97353783 3.97360965 3.9749901  3.9790426  3.98103496
 3.98125435 3.98319113 3.98678375 3.98683412 3.98923218 3.98929133
 3.99450392 3.99528032 3.99686061 4.00065808 4.00290369 4.00441573
 4.00442886 4.00478455 4.00479124 4.00631212 4.0068346  4.01111257
 4.01230721 4.01294907 4.01952956 4.01974866 4.02018076 4.02301235
 4.02444917 4.02657168 4.02941442 4.03102527 4.03186211 4.03476131
 4.03579868 4.04334105 4.0449171  4.04665029 4.05908796 4.05919197
 4.06020538 4.06324053 4.06453888 4.06776327 4.06811435 4.07538813
 4.07740998 4.07791189 4.07913449 4.07978025 4.08026815 4.08104593
 4.08115052 4.08296022 4.08578898 4.08936162 4.09143979 4.09217039
 4.09251981 4.09364967 4.09439693 4.09501927 4.09629785 4.09661107
 4.10107936 4.10138402 4.10367363 4.10408157 4.10540382 4.10801261
 4.11038184 4.11100635 4.11113836 4.11268654 4.11528689 4.11742271
 4.11784849 4.11930969 4.12075896 4.12343633 4.1242358  4.1243998
 4.12474904 4.1248176  4.12560257 4.1302048  4.13531074 4.13698779
 4.13738812 4.13839869 4.13859231 4.14022954 4.14364851 4.14458648
 4.15302497 4.15396925 4.15756749 4.1581012  4.15909777 4.1624165
 4.16363568 4.16416421 4.16505863 4.16929593 4.17055012 4.17301665
 4.17325382 4.17651108 4.177311   4.18333417 4.18536862 4.1855605
 4.18747148 4.18785839 4.1879174  4.1886418  4.19037487 4.19169825
 4.19193167 4.193362   4.19837665 4.19860011 4.20284903 4.20427763
 4.2054561  4.20717858 4.20747969 4.2079612  4.20815924 4.20995916
 4.21092805 4.21246671 4.2135838  4.21678654 4.22025781 4.22266914
 4.22351487 4.22595564 4.22728936 4.23145136 4.23160172 4.23584573
 4.23717628 4.23781905 4.23844849 4.23933824 4.24019791 4.24140063
 4.24174999 4.24328837 4.24341979 4.24642786 4.24719589 4.24730123
 4.24774852 4.24987872 4.25363882 4.25407631 4.25416738 4.25624385
 4.25650014 4.25732486 4.26077348 4.26119925 4.26592752 4.26898826
 4.26923481 4.27021278 4.27457555 4.28865583 4.30099963 4.30240255
 4.30330865 4.31867035 4.32647793 4.33341448 4.37156497 4.38217622
 4.38420145 4.38472393 4.38540348 4.38731517 4.38870791 4.3918471
 4.40064261 4.41037523 4.4120784  4.4176827  4.46445901 4.46941718
 4.47346196 4.48017209 4.52481236 4.65336385 4.72186755 4.72197699
 4.72501793 4.74108802 4.75263162 5.22546787 5.24411493 5.27675983
 5.28413429 5.29778242 5.32209819 5.33377671 5.34254069 5.34562094
 5.35539645 5.36704722 5.42805494 5.43225376 5.44605504 5.44829117
 5.56248464 5.58803408 5.58910423 5.59414197 5.59559321 5.60101055
 5.6035129  5.60832223 5.61593968 5.63737814 5.6501138  5.71950194
 5.8511679  5.86596909 5.89344858 5.89648899 5.91179052 5.92189991]

  warnings.warn(

2022-12-16 10:37:10,920:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.48090666 2.61276769 2.62745673 2.65145473 2.70904417 2.875184
 2.89851222 3.01693722 3.32118605 3.47994066 3.48410428 3.48507279
 3.49035038 3.57333359 3.57440166 3.57912563 3.58031419 3.58549445
 3.58596634 3.58786282 3.59072472 3.59404461 3.59554304 3.60166386
 3.61198275 3.61826235 3.61991053 3.62036208 3.62118582 3.62152156
 3.62470473 3.6259823  3.62945231 3.62974313 3.63085472 3.63236813
 3.63249322 3.63312351 3.63600862 3.63648921 3.63649605 3.63835522
 3.63862418 3.63907387 3.63920744 3.64041721 3.64052641 3.65705734
 3.65779779 3.66405554 3.66501752 3.66510204 3.6692889  3.67320036
 3.6746609  3.68115665 3.68466233 3.68520771 3.68945487 3.68996058
 3.69094599 3.6917427  3.6926053  3.69262268 3.69425676 3.69435134
 3.69665972 3.69763755 3.69833551 3.7014416  3.7051346  3.70661611
 3.70734011 3.71288224 3.72087834 3.72395305 3.72895615 3.72921588
 3.73402543 3.73563769 3.73688668 3.73745328 3.73770473 3.73829861
 3.73853679 3.74060286 3.74239449 3.7441113  3.74517756 3.74561871
 3.74882175 3.74915285 3.74977142 3.74999396 3.75175352 3.75317278
 3.75586651 3.75727877 3.77010567 3.7726417  3.77327715 3.77444726
 3.77694485 3.77921613 3.77992528 3.78181985 3.78311729 3.79119274
 3.79225493 3.79227474 3.79523959 3.79742721 3.79917858 3.80066673
 3.80067986 3.80081383 3.80135135 3.80186408 3.80382145 3.80391582
 3.80406875 3.80511384 3.80603725 3.80710447 3.80753278 3.80761663
 3.80801604 3.8080325  3.80911675 3.80933647 3.8094771  3.81053605
 3.81135207 3.81333757 3.81523859 3.81955034 3.82000617 3.82092919
 3.8211351  3.82175115 3.82219583 3.82230044 3.82322889 3.8233214
 3.82396418 3.82460429 3.82562259 3.82584277 3.82595565 3.82670804
 3.82823655 3.82842358 3.83050109 3.83197789 3.83280844 3.83326365
 3.83441965 3.83453032 3.83531711 3.83765788 3.83909903 3.83964349
 3.83977821 3.84135388 3.84211215 3.8421299  3.84258943 3.84294247
 3.84311308 3.84331231 3.84340798 3.84497252 3.84517389 3.84525187
 3.84529132 3.84576257 3.84581809 3.84622414 3.84625715 3.84630423
 3.84630941 3.84648194 3.84661666 3.84679191 3.84682536 3.84696813
 3.84754273 3.84780128 3.84863839 3.84916673 3.84981573 3.84992794
 3.85041909 3.85073056 3.85136892 3.851624   3.85170012 3.85219354
 3.85251397 3.85297298 3.85314358 3.85330742 3.85443776 3.85483257
 3.85506914 3.85508907 3.85538498 3.85566475 3.85659404 3.85667002
 3.85707221 3.85723824 3.85767765 3.85820614 3.85821463 3.85832715
 3.85832884 3.85909738 3.85950645 3.85957443 3.86011518 3.86022676
 3.8606922  3.86087295 3.8613843  3.86179444 3.86236827 3.86242387
 3.86292068 3.86326078 3.86340461 3.86346961 3.86348104 3.86369794
 3.86388709 3.86412008 3.86440622 3.86445486 3.86462152 3.86508763
 3.86539311 3.86539505 3.86575186 3.8657836  3.8658631  3.8661083
 3.8680385  3.86838692 3.86878412 3.86976278 3.87029981 3.87139206
 3.87180578 3.87183179 3.8727837  3.87300338 3.87329683 3.87347261
 3.87366155 3.87431834 3.87455774 3.87469907 3.87502049 3.87593637
 3.87601399 3.87617738 3.87630823 3.87705426 3.87804976 3.87858938
 3.87894194 3.87900011 3.87928033 3.87950975 3.87952417 3.87973234
 3.87986781 3.88062569 3.88114796 3.88130282 3.88139593 3.88141459
 3.88236233 3.88260336 3.88296389 3.8834425  3.88372541 3.88429153
 3.8849367  3.88651103 3.8865649  3.88692815 3.88701017 3.88710638
 3.88712808 3.88733238 3.88753131 3.88783941 3.88805488 3.88855406
 3.88887038 3.88890976 3.88892188 3.88897497 3.88976895 3.8897865
 3.88999689 3.89000019 3.89030733 3.89075119 3.89079475 3.8908188
 3.89123718 3.89135227 3.89189253 3.893902   3.89463746 3.89467938
 3.89471587 3.89577483 3.89579801 3.89596865 3.896014   3.89649994
 3.89688312 3.89720684 3.8973654  3.89869508 3.89963053 3.90039377
 3.90081134 3.90093749 3.90096292 3.90128321 3.90136595 3.90221234
 3.90237492 3.90240814 3.90244818 3.90258713 3.90343748 3.90489002
 3.90539485 3.90561543 3.90566767 3.90578335 3.90609829 3.90610884
 3.90614944 3.90630889 3.90671035 3.90726857 3.90727372 3.9077212
 3.9078117  3.90842763 3.9088322  3.9089321  3.90942186 3.91063083
 3.91066406 3.91105338 3.91136301 3.9128114  3.91291706 3.9131674
 3.91372187 3.91408753 3.9148446  3.91516523 3.91558488 3.91660772
 3.91762503 3.9195024  3.92048955 3.92080768 3.92136425 3.92200861
 3.92218857 3.92257638 3.92374395 3.92403118 3.92416498 3.92560977
 3.92709657 3.92747767 3.92751283 3.92789404 3.92824567 3.92874824
 3.92878968 3.92886891 3.92919101 3.9293371  3.92935512 3.92953707
 3.92975963 3.93005311 3.9316241  3.93189526 3.93252488 3.93260358
 3.93342338 3.93362075 3.9349877  3.93837839 3.93869392 3.94024863
 3.94059834 3.9423965  3.94286247 3.94338623 3.94475254 3.9474066
 3.94878631 3.94945756 3.95099377 3.95172365 3.95196641 3.95261649
 3.95362247 3.95396732 3.95442781 3.95501268 3.95518605 3.95572792
 3.95589344 3.95622752 3.95702084 3.95703747 3.95760901 3.95779474
 3.95780297 3.9584352  3.96085789 3.96157618 3.96197186 3.96421497
 3.96423881 3.96634209 3.96710321 3.9692917  3.9723669  3.97335018
 3.97431732 3.9746643  3.97551437 3.9756307  3.97602734 3.97671403
 3.97718138 3.97902075 3.98131753 3.98202805 3.98256642 3.98330083
 3.98369591 3.98586362 3.98644754 3.9869724  3.98727336 3.98733218
 3.98787611 3.98902363 3.98927163 3.9894035  3.99223492 3.99547262
 3.99649051 3.99670142 3.9975757  3.99916109 3.99932326 3.99946443
 4.0020721  4.00534236 4.00715162 4.00884655 4.00977423 4.01019141
 4.01131833 4.0114829  4.01214542 4.01335618 4.0152645  4.01543355
 4.0157259  4.01685094 4.01915389 4.02267108 4.02268007 4.02404941
 4.02504234 4.02724279 4.02727935 4.027687   4.02836918 4.02853164
 4.02911378 4.03100476 4.03402269 4.03455901 4.03512422 4.03956298
 4.03969954 4.04135351 4.04213971 4.04366498 4.04607065 4.04681065
 4.04691315 4.04810183 4.04942691 4.052315   4.05237522 4.05268238
 4.05273718 4.05323731 4.05390342 4.0539616  4.05488214 4.055173
 4.05596559 4.0566122  4.05824264 4.05911032 4.06085179 4.06322614
 4.06608373 4.06630147 4.06715808 4.06767222 4.0735892  4.07400723
 4.07479961 4.07748082 4.07806485 4.07941636 4.08074035 4.08208514
 4.08302081 4.08497203 4.08518399 4.08529387 4.08636466 4.08710304
 4.08877792 4.08961442 4.08974221 4.09052018 4.09067306 4.09101054
 4.0912936  4.0921131  4.09230465 4.09273644 4.09443088 4.09505646
 4.09508797 4.09640733 4.09674135 4.09814373 4.09879528 4.09912405
 4.10058933 4.10074736 4.10091191 4.10107787 4.10201659 4.10427976
 4.10432366 4.10433348 4.10436468 4.10525106 4.10531348 4.10569162
 4.10610767 4.10620837 4.10664554 4.10683468 4.10694592 4.10723025
 4.10769267 4.10840862 4.10888359 4.10953044 4.10979278 4.11031621
 4.11039648 4.11100108 4.11118894 4.11166807 4.11188585 4.11271667
 4.11272785 4.11409321 4.11425084 4.11472303 4.1150086  4.11541844
 4.11575224 4.11605352 4.1164509  4.11758735 4.11789951 4.11888474
 4.11945229 4.11980698 4.12043238 4.12126095 4.12143826 4.1214438
 4.12148213 4.12160552 4.12314939 4.12377482 4.12554263 4.12577657
 4.12633824 4.12711987 4.12725863 4.12778487 4.12803954 4.12824224
 4.12864112 4.12890767 4.12892617 4.12893783 4.12912756 4.12992199
 4.13050563 4.13075458 4.13102509 4.13119471 4.13184426 4.13234069
 4.13274766 4.13282315 4.13306442 4.13319946 4.13428565 4.13465596
 4.13479091 4.13665576 4.13709002 4.13815218 4.13944064 4.13972501
 4.14000858 4.14051727 4.1442138  4.14478106 4.14516464 4.14636253
 4.14702669 4.14727751 4.14729315 4.14835456 4.14843836 4.15039983
 4.15046681 4.15079357 4.15146738 4.15152334 4.15202942 4.15226151
 4.15244502 4.15290585 4.15433592 4.154559   4.15531762 4.15539363
 4.15581125 4.15694705 4.15884263 4.16190022 4.16206806 4.16262991
 4.16355495 4.16514678 4.16749844 4.16842201 4.1700014  4.17222596
 4.17230418 4.17273152 4.17425258 4.17441628 4.17590279 4.1767646
 4.17801094 4.17829318 4.18054444 4.1811962  4.18242672 4.18316961
 4.18352738 4.18420028 4.18606702 4.18761379 4.18774908 4.18778556
 4.18855323 4.18921343 4.19109063 4.19326055 4.1941733  4.19579973
 4.19905631 4.20107879 4.20162212 4.20372722 4.20375094 4.20616205
 4.20768713 4.20797077 4.20824757 4.20913129 4.20959042 4.21135625
 4.21289093 4.21532065 4.21672558 4.21739928 4.22017683 4.22172797
 4.22316074 4.22678218 4.2267999  4.23271607 4.23454128 4.24047134
 4.24377487 4.24677899 4.25270595 4.25498503 4.25772353 4.27404586
 4.27528544 4.27892298 4.28233314 4.2849271  4.28567818 4.28678569
 4.29105404 4.29800128 4.30007143 4.30229673 4.30270909 4.30889681
 4.3137325  4.32067145 4.32300058 4.33442245 4.33560683 4.34255359
 4.34904012 4.35312019 4.35429514 4.35827842 4.36378943 4.36574231
 4.3666264  4.36698305 4.3674797  4.37090675 4.37375422 4.37431034
 4.37435922 4.37779578 4.3847497  4.38793149 4.39580351 4.40343904
 4.40790616 4.41265201 4.42320614 4.42573814 4.43385945 4.43422823
 4.45282125 4.47086093 4.47280432 4.48164367 4.59025933 4.59097256
 4.59736297 4.61557885 4.62226069 4.65759441 4.66321396 4.66453761
 4.66995986 4.67002549 4.67103121 4.67348729 4.67417778 4.67844878
 4.67991498 4.68055984 4.69000526 4.70649547 4.7179261  4.73158398
 4.73248897 4.74191431 4.75438098 4.78339559 4.89295687 4.91375601
 4.91458161 4.93988061 4.94677699 4.95769436 5.08282398 5.09167458
 5.09856277 5.13817053 5.28000721 5.3942126  5.39690957 5.49898703
 5.50587708 5.50606187 5.50786477 5.51235951 5.51373175 5.51416065
 5.51821733 5.51970118 5.5232002  5.52723895 5.52897261 5.52905425
 5.53156153 5.53556833 5.54397944 5.56232313 5.57740747 5.57892303
 5.58059289 5.58513603 5.58582799 5.63084354 5.63084636 5.64257404
 5.67362599 5.73831992 5.76917705 5.7773195  5.7781235  5.81238867
 5.83977416 5.8717514  5.88443681 5.88662983 5.91462855]

  warnings.warn(

2022-12-16 10:37:10,923:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.58152519 2.93511516 2.99825521 3.00670019 3.2314585  3.28386434
 3.48889349 3.50360835 3.58485103 3.59367991 3.62131556 3.6364485
 3.67037942 3.67423336 3.67601304 3.68552573 3.68568975 3.6891648
 3.6906749  3.69334275 3.69389909 3.70147904 3.70302053 3.70329935
 3.70880057 3.7116503  3.71201827 3.71531344 3.71675175 3.71782823
 3.72225978 3.72424242 3.72521421 3.7278079  3.73196003 3.73196506
 3.73211244 3.74006142 3.7839296  3.78795943 3.79693408 3.80580663
 3.8099646  3.81280823 3.81509231 3.82070779 3.82429712 3.83136108
 3.83336144 3.83746906 3.83798271 3.8385834  3.84390347 3.84720957
 3.85155038 3.85410716 3.85449889 3.85560472 3.8559039  3.85628942
 3.85699976 3.85775513 3.86196165 3.86197266 3.86280081 3.86339518
 3.86414999 3.86574436 3.86657541 3.86966624 3.87229167 3.87242771
 3.87335644 3.87336575 3.87594149 3.88195744 3.88199099 3.8847423
 3.8851281  3.88664817 3.88720831 3.88992487 3.89072717 3.89242315
 3.89331462 3.89344137 3.89523536 3.89644972 3.89678727 3.89774792
 3.89811731 3.89902919 3.89919284 3.89976205 3.90021779 3.90032869
 3.90055661 3.90155718 3.90158476 3.9019652  3.90203601 3.90230444
 3.90265581 3.90277954 3.90299963 3.90371623 3.90497081 3.90614374
 3.90617444 3.90683746 3.90688401 3.90701543 3.90750903 3.90762621
 3.90771292 3.90806501 3.90839304 3.90881639 3.90888462 3.90905862
 3.90932315 3.90954657 3.9097475  3.91117209 3.91121282 3.91128373
 3.91137302 3.91150591 3.91179316 3.91183316 3.91203409 3.91217476
 3.91401475 3.91463359 3.91497716 3.91563755 3.91602349 3.91645393
 3.91687804 3.91775    3.9196034  3.92404393 3.92880209 3.93018024
 3.93501792 3.93545256 3.93640065 3.93800547 3.94207594 3.94490264
 3.94637292 3.94641176 3.94672024 3.94675219 3.94713001 3.94821502
 3.9522196  3.95243253 3.95406855 3.95436164 3.95458713 3.9550162
 3.95632732 3.95647363 3.95682224 3.95787743 3.95788097 3.95947241
 3.95948182 3.959632   3.96252619 3.96429963 3.96715704 3.96939404
 3.97174653 3.97496631 3.97981281 3.97995724 3.98559078 3.98616597
 3.99424913 3.99716953 3.9981721  3.99825212 4.00146176 4.00345852
 4.00682046 4.0083083  4.01049847 4.01232392 4.01635078 4.01681951
 4.01802642 4.02125642 4.02451347 4.02454939 4.0274728  4.02828716
 4.0296342  4.03098808 4.04085143 4.04113881 4.04197231 4.04594082
 4.04665907 4.04990746 4.05216744 4.05263593 4.05402106 4.0545551
 4.05460027 4.05509529 4.05537563 4.05720971 4.05728465 4.05851134
 4.06097983 4.06281857 4.06577853 4.06593596 4.06687328 4.0686898
 4.06968979 4.07016091 4.07352145 4.07414286 4.07537135 4.07642254
 4.07714504 4.07718572 4.07803314 4.08011814 4.08080401 4.08213029
 4.08248008 4.08609066 4.0882518  4.08912878 4.09111415 4.09192974
 4.09379571 4.09406722 4.09440377 4.0961871  4.09757447 4.10387511
 4.1042741  4.10452538 4.10547639 4.10929785 4.10992597 4.10999848
 4.11564013 4.11643818 4.11654435 4.11767295 4.11806001 4.11998824
 4.12020473 4.12106501 4.12226695 4.12247988 4.12265637 4.12281658
 4.12348797 4.12365612 4.12416077 4.12447089 4.12592202 4.13232801
 4.13359209 4.13376992 4.1343744  4.13495176 4.13538149 4.13642306
 4.13693159 4.13729998 4.13821795 4.13851925 4.13910574 4.13973429
 4.14371142 4.14593134 4.14630044 4.14674749 4.14789122 4.14889097
 4.1502122  4.15032189 4.1515961  4.15307061 4.15500548 4.15973341
 4.16256056 4.16300062 4.1650143  4.16535003 4.16720977 4.16969412
 4.16983953 4.16984891 4.17045201 4.17202803 4.17287528 4.17331101
 4.17639114 4.17751071 4.18035125 4.18323296 4.18350661 4.19250726
 4.19362941 4.19408162 4.1946579  4.19522107 4.19558128 4.19676341
 4.19737724 4.20163437 4.20183975 4.20237711 4.20290985 4.20329018
 4.20390106 4.2060026  4.20627903 4.20707184 4.20780398 4.20796612
 4.21476372 4.2154421  4.21558137 4.21662238 4.2171142  4.21731908
 4.21791284 4.21901232 4.22079394 4.22097638 4.22291029 4.22384805
 4.2238744  4.22434955 4.22545244 4.22657759 4.22823384 4.23250203
 4.23342765 4.23392473 4.23395843 4.23419394 4.23503726 4.23732095
 4.23798204 4.2385749  4.23882324 4.23888157 4.23991202 4.24000952
 4.24036944 4.24066144 4.24082165 4.24092361 4.24120888 4.24131901
 4.24168187 4.24221049 4.24487645 4.24503891 4.24972743 4.250397
 4.25147791 4.25150101 4.25392193 4.25547704 4.25673018 4.25920877
 4.2641567  4.26740664 4.27029479 4.27110444 4.27173274 4.27377039
 4.2744397  4.27453053 4.27517909 4.27716356 4.27814097 4.2784122
 4.27908105 4.28008371 4.2801617  4.28026547 4.28028464 4.28057755
 4.28088535 4.28104781 4.28163381 4.28167454 4.28193424 4.28243546
 4.28284992 4.2844675  4.28482023 4.28520351 4.28554364 4.28584193
 4.28678939 4.28702473 4.28711354 4.28723781 4.28886202 4.29008592
 4.29328716 4.2932904  4.29552698 4.29606383 4.29792922 4.29952297
 4.3020657  4.30309422 4.30381466 4.30462103 4.30528303 4.30616119
 4.30791983 4.30994974 4.31075724 4.31253785 4.31318896 4.31326424
 4.31452685 4.31593426 4.31715624 4.31716224 4.31719787 4.31797765
 4.31825298 4.31875485 4.32028397 4.32174014 4.32174651 4.32248204
 4.32306028 4.32376985 4.32382534 4.32384326 4.32483771 4.32530258
 4.32606846 4.32622866 4.32708007 4.32733021 4.32735386 4.32780761
 4.3291832  4.32931699 4.32982104 4.33084502 4.33087397 4.33107489
 4.3315538  4.33159004 4.33242407 4.332625   4.3326592  4.33330749
 4.33384038 4.33455928 4.33489828 4.33643988 4.33689985 4.33701319
 4.33725745 4.33744274 4.33745867 4.33947359 4.33963727 4.3397999
 4.34074334 4.34109893 4.34136291 4.34294156 4.34338394 4.34338419
 4.34475023 4.34481365 4.34692209 4.3475922  4.34824384 4.34849469
 4.35128922 4.35142628 4.35174752 4.35505718 4.35697048 4.35734642
 4.35919516 4.35954746 4.35975167 4.36058501 4.36121174 4.36184633
 4.36270481 4.36297306 4.36309385 4.36474965 4.36541945 4.36556483
 4.3661867  4.36628751 4.3690924  4.36924809 4.36952    4.36995831
 4.37192148 4.37214786 4.37387561 4.37433355 4.37435859 4.37552145
 4.37711405 4.37995327 4.3813762  4.38262887 4.38303277 4.38379219
 4.38465291 4.38538104 4.38716627 4.38821182 4.3885406  4.39041918
 4.39069837 4.39089931 4.39110024 4.39642006 4.39815285 4.3985692
 4.40185719 4.40580492 4.40599519 4.40607193 4.40757463 4.40797559
 4.41070538 4.41198608 4.41477691 4.41642382 4.41945432 4.42047595
 4.42324311 4.42416062 4.42548357 4.42597065 4.42731983 4.42852285
 4.42863602 4.43296455 4.43344367 4.43482501 4.43591401 4.43602447
 4.43713751 4.43878596 4.43968134 4.44150274 4.4417136  4.44394019
 4.44649257 4.44794872 4.44879217 4.45155971 4.45786446 4.4579392
 4.45862713 4.46021566 4.46051588 4.46090654 4.46097549 4.46132119
 4.46399472 4.46403176 4.46766157 4.4682749  4.4694715  4.46976225
 4.47493446 4.47607184 4.47689365 4.47697757 4.4802897  4.4803724
 4.48075786 4.48100469 4.48101814 4.48115755 4.48708367 4.48710609
 4.4902103  4.49320364 4.4935569  4.49398183 4.49492455 4.49644965
 4.49678471 4.50150439 4.50435883 4.5066467  4.5088982  4.50931135
 4.50968547 4.51061371 4.51359012 4.51582772 4.5165664  4.51822743
 4.51942199 4.52066049 4.52416513 4.5245823  4.52568341 4.52645182
 4.52697807 4.52799103 4.52882298 4.53084495 4.53137088 4.53577421
 4.53659471 4.53772288 4.53962901 4.53971604 4.53974248 4.54072863
 4.54180524 4.54349162 4.54353231 4.54456386 4.5446521  4.54508241
 4.54643672 4.54728426 4.54892197 4.54964043 4.54981277 4.54988282
 4.55168654 4.55229638 4.55246913 4.55342458 4.55512647 4.55578445
 4.55680618 4.5568213  4.55798692 4.55800058 4.56018398 4.56022859
 4.56203663 4.56226123 4.56376608 4.5644658  4.56505988 4.56901534
 4.57001776 4.57058459 4.57091718 4.57361547 4.57416798 4.57491322
 4.57519689 4.57698199 4.57766642 4.58387167 4.59158687 4.59182139
 4.59253232 4.59352844 4.59488485 4.59575615 4.60813738 4.60879104
 4.61042316 4.61132499 4.61251273 4.61645783 4.61857582 4.61938989
 4.61968715 4.62166823 4.62209589 4.62311563 4.62372719 4.6240705
 4.62511553 4.62797156 4.63191346 4.63300051 4.6331511  4.63368658
 4.63411622 4.6352446  4.63856538 4.64352265 4.64368285 4.64437279
 4.64720818 4.65603412 4.65742348 4.65764842 4.65986647 4.66057604
 4.66061875 4.66114192 4.66195453 4.66813584 4.66904749 4.66962802
 4.67049794 4.67448416 4.67678846 4.68187842 4.6822223  4.69138148
 4.699791   4.70515966 4.70619424 4.7086555  4.71345825 4.71464508
 4.71592896 4.71600613 4.72296047 4.72440633 4.72677147 4.72843879
 4.72916325 4.73146935 4.73393635 4.73437525 4.73506238 4.73797564
 4.74018648 4.74053044 4.74191225 4.74570224 4.74698995 4.74940074
 4.75238724 4.75553513 4.75598779 4.7562447  4.75678994 4.75745589
 4.75761293 4.76077055 4.76095269 4.76205115 4.7648438  4.76730483
 4.76776547 4.76786628 4.77378392 4.77520531 4.77985791 4.7828653
 4.78480384 4.78973016 4.78994999 4.79147281 4.79437337 4.79558034
 4.79743855 4.80145872 4.80208997 4.80235182 4.8046048  4.80610073
 4.81002639 4.81053292 4.81309387 4.82385249 4.82593404 4.83092895
 4.83107061 4.83175336 4.8326411  4.83273634 4.83576142 4.83855715
 4.84179997 4.84313398 4.84438356 4.84453498 4.84467404 4.85945881
 4.86206625 4.86211088 4.86469655 4.86753125 4.87053412 4.87868718
 4.88277316 4.88467896 4.89027771 4.91453155 4.97452476 4.97749405
 4.98107026 4.98730845 5.00821311 5.02148572 5.03086052 5.03719157
 5.0376277  5.04277367 5.20575313 5.27715537 5.32224562 5.33842049
 5.3415159  5.34632735 5.34700839 5.3489941  5.35802709 5.36122372
 5.36385527 5.36412777 5.36625167 5.37059516 5.38240623 5.459556
 5.47543508 5.49632133 5.50424937 5.52634792 5.53086765 5.60767175
 5.62614929 5.63335963 5.67250743 5.67407647 5.73224081 5.74048238
 5.75640904 5.75833508 5.76820992 5.77933165 5.79947058 5.82676139
 5.84352553 5.946362   5.95966519 5.98346345 6.0313624  6.25481803]

  warnings.warn(

2022-12-16 10:37:10,927:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.30926653 2.52267765 2.58986392 2.59047786 2.79663118 2.94100916
 3.37181617 3.53062987 3.55147712 3.63130219 3.66870762 3.72635672
 3.73619386 3.74346903 3.75936076 3.76609244 3.76794593 3.7759996
 3.77667049 3.77979788 3.78295335 3.78465123 3.78652254 3.78749993
 3.78978586 3.79194783 3.79246309 3.79696194 3.80571273 3.81284693
 3.81790876 3.8193572  3.81959003 3.82031048 3.82063689 3.82102985
 3.82264496 3.82268821 3.83000723 3.83124798 3.83371844 3.83456978
 3.83457324 3.83554977 3.83612196 3.83649354 3.83763919 3.83827374
 3.84131607 3.84409057 3.84682614 3.84689363 3.85834466 3.86123078
 3.86407283 3.86632301 3.86694048 3.86778302 3.86836848 3.87076549
 3.87164521 3.87240131 3.87308076 3.87672565 3.88180087 3.88213292
 3.88238195 3.88274048 3.88326168 3.8834893  3.88407866 3.88445967
 3.88522278 3.88534909 3.8855626  3.88646203 3.88686156 3.88826585
 3.88968585 3.8927322  3.89337665 3.89342453 3.89401012 3.89928694
 3.90051245 3.90085916 3.90130177 3.90149169 3.90199416 3.90252595
 3.90502949 3.90649938 3.90764868 3.90768874 3.90901281 3.91007155
 3.91158307 3.91190812 3.91209764 3.91407974 3.91445629 3.91558356
 3.91639196 3.91777242 3.91863629 3.91886702 3.91890359 3.9195261
 3.91955977 3.9197301  3.91979011 3.92009835 3.92020671 3.92034707
 3.92053888 3.92135165 3.92155693 3.92159576 3.92163862 3.92216743
 3.92289127 3.92345166 3.9241557  3.92462941 3.9248939  3.9249447
 3.9250519  3.92536165 3.92549092 3.92554738 3.92559777 3.92578547
 3.92593123 3.92614816 3.92632074 3.92678416 3.92678894 3.92697866
 3.92701911 3.92709966 3.92791119 3.92838297 3.92851858 3.92916997
 3.92949412 3.92949435 3.9349366  3.93496893 3.93651271 3.93954978
 3.93993808 3.94103256 3.94135201 3.94174883 3.94231783 3.94259374
 3.94316108 3.9432548  3.94486693 3.94544402 3.94763463 3.94836709
 3.94841521 3.94874052 3.94894316 3.95027978 3.95051497 3.9528149
 3.95294099 3.95309102 3.95384402 3.95533294 3.95571139 3.95608737
 3.95773021 3.95817514 3.95864864 3.95948803 3.95963695 3.96115355
 3.96141876 3.9619813  3.96296597 3.96354088 3.96376187 3.96395119
 3.96410276 3.96411884 3.96417659 3.96450173 3.96473981 3.96613085
 3.96652206 3.96699051 3.96748342 3.96766669 3.96780494 3.96820787
 3.96824009 3.96868204 3.96882253 3.96890184 3.97010959 3.97015307
 3.97056532 3.97056851 3.97074049 3.97125462 3.9714877  3.97232303
 3.97256019 3.9729361  3.97388925 3.97398285 3.97458444 3.97462154
 3.97534329 3.97632642 3.97637644 3.97649794 3.97673638 3.97708536
 3.97778896 3.97809945 3.97818193 3.97831197 3.97849856 3.97869426
 3.97881757 3.97901314 3.97907628 3.98004467 3.98017357 3.98039978
 3.98064838 3.98072126 3.98075438 3.98100486 3.98118767 3.98170163
 3.98245929 3.9830105  3.98323838 3.98358149 3.98412103 3.98433808
 3.98510463 3.98599369 3.98632616 3.98679131 3.98708155 3.9880309
 3.98855993 3.98960737 3.98965581 3.99023813 3.99051283 3.99081603
 3.99183478 3.99291108 3.99322874 3.99333406 3.99555414 3.99592513
 3.99619375 3.99801445 3.99939986 3.9996613  4.00010582 4.00015098
 4.0008765  4.00194101 4.005078   4.00520571 4.00529914 4.00532484
 4.00546771 4.0073782  4.0079397  4.00947504 4.01176983 4.01262369
 4.01370061 4.01401522 4.01444231 4.01451126 4.01457764 4.01476877
 4.01498374 4.01503827 4.01529599 4.01535266 4.01690242 4.01691749
 4.01797197 4.01826757 4.01839548 4.01844452 4.01914019 4.01933498
 4.01963033 4.02027086 4.02027955 4.02054693 4.02087292 4.0209509
 4.0217612  4.02182608 4.0219823  4.02216295 4.02230408 4.02308847
 4.02320821 4.02348479 4.02443115 4.02551907 4.02699834 4.02857615
 4.02871725 4.02998767 4.03019528 4.0322907  4.032676   4.03365533
 4.03370323 4.03517148 4.03546776 4.03558739 4.03613049 4.03620148
 4.03675629 4.03728047 4.03813578 4.03850709 4.03897899 4.03902844
 4.03916483 4.03934765 4.03947163 4.03958216 4.03958884 4.03978856
 4.0402623  4.04065408 4.04077884 4.0410242  4.04104412 4.04157036
 4.04214728 4.04349262 4.04363547 4.04378699 4.0443567  4.04524825
 4.04589445 4.04590839 4.04599592 4.046753   4.04704933 4.04737705
 4.04766199 4.04921747 4.04932506 4.049664   4.04980553 4.04997912
 4.05033022 4.05082381 4.05153012 4.05167866 4.05218501 4.05246885
 4.05292148 4.0530465  4.05331445 4.05369789 4.05369822 4.05370396
 4.05372146 4.05385017 4.05402341 4.05415662 4.05441827 4.05467953
 4.0547635  4.05481123 4.05491705 4.05494445 4.05573596 4.05593497
 4.05597946 4.05599294 4.05606942 4.05612199 4.056461   4.05672655
 4.05707588 4.05709325 4.0571664  4.05760585 4.05783597 4.05825068
 4.05878677 4.05962527 4.05999336 4.06011764 4.06196979 4.0621228
 4.06274002 4.06330281 4.06340705 4.06358123 4.06369122 4.06436858
 4.0648933  4.06514806 4.06573835 4.06675579 4.06718167 4.06753821
 4.06929091 4.06944611 4.0703679  4.07133881 4.07191003 4.07559672
 4.07564165 4.07567325 4.07775905 4.08009517 4.08100832 4.08107454
 4.08214731 4.08261986 4.08408822 4.08469489 4.08509399 4.08537789
 4.08564628 4.08577286 4.08670005 4.08670619 4.08674073 4.08685543
 4.08701977 4.08708671 4.08710453 4.08715218 4.08730304 4.08772302
 4.08775837 4.08917489 4.08939785 4.08974871 4.08978539 4.09053173
 4.09062501 4.09107173 4.09110571 4.09119092 4.0920529  4.09259951
 4.0926447  4.09273362 4.09302618 4.09305514 4.09370172 4.09370829
 4.0939332  4.09396228 4.09407948 4.09452349 4.09477132 4.09543081
 4.09567229 4.096052   4.09638797 4.09693625 4.09749869 4.09788338
 4.09794914 4.09843205 4.098583   4.09860495 4.09898055 4.09922969
 4.09942958 4.09946178 4.09968435 4.10012897 4.10052217 4.10078783
 4.10197115 4.10224514 4.10252923 4.10255205 4.10336336 4.10345702
 4.10415202 4.1043543  4.10601013 4.10703727 4.10740891 4.1081231
 4.10815032 4.10986343 4.11051914 4.11212638 4.11337891 4.11499361
 4.11520692 4.11669121 4.11718403 4.11745668 4.11746002 4.11748379
 4.118722   4.11911006 4.12010542 4.12085479 4.12165538 4.12170156
 4.1223775  4.1237115  4.12643051 4.12722737 4.1282966  4.12850474
 4.12882083 4.12980192 4.13014213 4.13049148 4.13065335 4.13090985
 4.1312     4.13167659 4.13315451 4.13339353 4.1354642  4.13584548
 4.13604475 4.13688634 4.13728889 4.13765724 4.13826255 4.13876218
 4.13914511 4.13992676 4.13997455 4.14000247 4.14024273 4.14247746
 4.14358472 4.14403478 4.14479968 4.14591048 4.14677605 4.1479607
 4.15062477 4.15273965 4.15282727 4.15598262 4.15702973 4.15798657
 4.15819406 4.1586389  4.15871136 4.15908967 4.15952973 4.15964416
 4.16022289 4.16031941 4.16050902 4.16061217 4.1608571  4.16116987
 4.16146753 4.16217318 4.16245807 4.16261599 4.16307627 4.1638851
 4.16413216 4.16461759 4.16483402 4.16493315 4.16513793 4.16534882
 4.16653497 4.16710235 4.16716932 4.16731566 4.16824159 4.17050738
 4.17212272 4.17306037 4.17350284 4.17453836 4.17542844 4.17639867
 4.17700917 4.17740213 4.17877529 4.17902288 4.17909196 4.18125863
 4.18182865 4.1819068  4.18406726 4.18500912 4.18652495 4.18745728
 4.18833742 4.19024722 4.19061259 4.19258536 4.19347145 4.1935579
 4.19364997 4.19518464 4.19525061 4.19869468 4.19876791 4.19891098
 4.19930709 4.20017351 4.20270814 4.20383262 4.20445003 4.20692976
 4.20697351 4.21101901 4.21196913 4.21228565 4.21230258 4.21352698
 4.21358908 4.21526029 4.21531424 4.21592264 4.21728311 4.21732042
 4.21773256 4.21808232 4.21811132 4.21818269 4.21904618 4.2198917
 4.22031853 4.22108624 4.22206329 4.22487272 4.22602364 4.22830338
 4.22831154 4.22948163 4.2338345  4.23528743 4.23721242 4.2375475
 4.23796731 4.23861845 4.23924498 4.23996902 4.24005828 4.24068164
 4.24804984 4.24898547 4.24901545 4.24912523 4.24985099 4.2550775
 4.26058159 4.260791   4.26088561 4.26184614 4.26385428 4.26483654
 4.2689706  4.27147285 4.27156934 4.27592452 4.27629618 4.27760423
 4.28154033 4.28272961 4.28338635 4.28377572 4.2844264  4.28678807
 4.29289294 4.29469959 4.29571702 4.29636791 4.29682971 4.29690831
 4.29859148 4.29895577 4.29947399 4.30131178 4.30133319 4.30212953
 4.30219991 4.30227916 4.30329324 4.30692914 4.30735101 4.30989502
 4.31063765 4.31122513 4.31234945 4.31264163 4.31272246 4.31522159
 4.31698527 4.31724076 4.3182315  4.3196545  4.32425564 4.32537227
 4.32838837 4.33179335 4.33275978 4.33642173 4.34010718 4.34236441
 4.34369876 4.34376737 4.34658739 4.34879003 4.35395024 4.35569633
 4.35707237 4.35731758 4.36121264 4.36162704 4.37843896 4.38277172
 4.38332623 4.38633433 4.39218127 4.3938423  4.39831366 4.40890981
 4.41284232 4.414673   4.4156422  4.41759561 4.41969563 4.42268305
 4.42597435 4.42853311 4.42871455 4.43127522 4.43127776 4.43260013
 4.44300322 4.44367136 4.44566119 4.46584483 4.47083432 4.47280259
 4.48964637 4.49103367 4.49609629 4.50066489 4.50447574 4.51326612
 4.51488057 4.52830823 4.53681629 4.55333723 4.55653801 4.56330638
 4.59191448 4.61052466 4.64529375 4.65700758 4.65706258 4.6679425
 4.68413515 4.68952702 4.76089403 4.76974859 4.77164283 4.77906262
 4.79882487 4.80194596 4.81539003 4.82391581 4.82789758 4.82964057
 4.84086735 4.85326293 4.88583384 4.88584702 4.88671375 4.88933987
 4.90074392 4.91434476 4.91472642 4.91604119 4.92314346 4.96042865
 4.96276378 4.9928975  5.00414946 5.0282201  5.03074803 5.03564678
 5.04690369 5.04796812 5.06113255 5.11710358 5.11975347 5.70942109
 5.71133606 5.71983851 5.74109693 5.74143559 5.74674293 5.74951373
 5.7520689  5.76149346 5.76165124 5.7617119  5.76186378 5.76264772
 5.76518035 5.76591839 5.7736295  5.77364651 5.79861737 5.83198208
 5.83259258 5.83279663 5.83338506 5.83635952 5.83685514 5.8434015
 5.86942608 5.87298945 5.87324396 5.88033728 5.8839833  5.88526564
 5.90478301 5.90621799 5.95351211 5.95518097 5.96347653 5.97360459
 6.08851046 6.10544866]

  warnings.warn(

2022-12-16 10:37:10,992:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.34254971 2.72315389 2.74834277 2.75122438 2.7920761  2.87581132
 3.02518132 3.34938479 3.39510751 3.41819158 3.44294834 3.4612655
 3.46524327 3.46643821 3.46748346 3.46824873 3.47510662 3.48373516
 3.48425774 3.48495898 3.48634639 3.48901918 3.49097061 3.49177194
 3.49328904 3.49361657 3.4940412  3.49498492 3.495291   3.49536949
 3.49569242 3.49583022 3.51520458 3.51851203 3.51869063 3.52167286
 3.52330018 3.52452285 3.52504057 3.52820127 3.53109052 3.5315169
 3.53163479 3.53195492 3.53200824 3.53323869 3.53332145 3.53401323
 3.53439581 3.5344758  3.53588788 3.53635812 3.53642764 3.53682898
 3.5380027  3.5380421  3.53813594 3.53997336 3.54524087 3.55135778
 3.55486599 3.55542448 3.55654172 3.55665328 3.5661211  3.56752474
 3.56759245 3.56885459 3.56954538 3.57178736 3.57241085 3.57264163
 3.57276622 3.57794779 3.57887543 3.57888271 3.58048647 3.58062371
 3.5841185  3.58522376 3.59009857 3.59096204 3.59275442 3.59368001
 3.59398048 3.59641566 3.59695524 3.59768418 3.59859842 3.5986375
 3.60060155 3.60267282 3.60938961 3.61140689 3.62168334 3.62355069
 3.62476075 3.62802742 3.62916514 3.63416267 3.6361152  3.6410749
 3.64390523 3.65559182 3.6557246  3.65583192 3.65631048 3.65639039
 3.65675089 3.65890381 3.66315648 3.66605476 3.66729385 3.66933684
 3.66969816 3.6721371  3.67965342 3.67985855 3.68032315 3.68175104
 3.68311007 3.68465307 3.68479832 3.68672826 3.68808296 3.69191865
 3.69192017 3.69455225 3.70026318 3.7010874  3.70179495 3.70356813
 3.7055278  3.70612033 3.70774053 3.71007588 3.71074757 3.71303815
 3.71311417 3.71377042 3.71596002 3.71716416 3.71831445 3.71879119
 3.720216   3.72333253 3.72340291 3.72459328 3.72485408 3.72511867
 3.7256737  3.72568098 3.72582563 3.72611247 3.72641819 3.72736341
 3.72767683 3.7285351  3.73124933 3.73139609 3.7314581  3.73205765
 3.73280843 3.733885   3.7343948  3.73544292 3.73598833 3.73629966
 3.73738033 3.737387   3.73852747 3.73866373 3.7387784  3.73936737
 3.74035248 3.74102911 3.74118192 3.7431934  3.7460075  3.74606888
 3.74618399 3.74634024 3.74657028 3.74769301 3.74789069 3.74870953
 3.74917656 3.74920403 3.74969325 3.74997223 3.75061064 3.75102468
 3.75127596 3.7517346  3.75227164 3.75386665 3.75400799 3.75741537
 3.75771322 3.75787383 3.75877122 3.7589307  3.75944347 3.75966354
 3.76010807 3.76038763 3.7604729  3.76083011 3.76168795 3.76189983
 3.76223619 3.7626854  3.76308511 3.76418125 3.76511621 3.76518371
 3.76535779 3.76557188 3.76587021 3.76768741 3.76862218 3.7687495
 3.76904507 3.76954015 3.77457317 3.77557928 3.7767875  3.77685005
 3.77740314 3.77840992 3.77880957 3.77886489 3.77943394 3.77951915
 3.78492629 3.78509414 3.78531749 3.78562809 3.78595413 3.78612424
 3.78619822 3.78727609 3.78782089 3.78785007 3.78798768 3.78874738
 3.78988294 3.79000327 3.79043404 3.79052831 3.79062663 3.79160718
 3.79323617 3.79411875 3.79596745 3.79616342 3.79645162 3.79706109
 3.7971334  3.79747576 3.79801294 3.79812407 3.79879443 3.79958834
 3.79971595 3.80048828 3.80240822 3.80313726 3.80376754 3.80429326
 3.80485842 3.80490646 3.80583126 3.80609635 3.80618654 3.80630987
 3.80634086 3.80659367 3.80680038 3.80828834 3.81181044 3.81182975
 3.81240279 3.81248581 3.81467765 3.81471455 3.81477132 3.81605814
 3.8161763  3.81640287 3.81646663 3.81646886 3.81657062 3.81749422
 3.81757449 3.81774616 3.81796279 3.81948191 3.82061339 3.82110485
 3.82152352 3.82233886 3.82267722 3.82354809 3.82413155 3.82515093
 3.82680298 3.82779105 3.82855722 3.82865156 3.82991927 3.831228
 3.83286387 3.83316183 3.83341797 3.83378449 3.83393038 3.83467264
 3.83472866 3.83732975 3.83752944 3.83898617 3.83904419 3.83918856
 3.83998702 3.84113286 3.84119619 3.84159356 3.84179607 3.84195
 3.84357512 3.84387648 3.84496137 3.84585538 3.84592521 3.84666788
 3.84755682 3.84759144 3.84791693 3.84968843 3.84991001 3.84991729
 3.85072101 3.85077432 3.85131495 3.85241205 3.85257323 3.85270909
 3.85291579 3.8536448  3.85429361 3.85474746 3.85545483 3.85577371
 3.85636686 3.85650992 3.8578528  3.85892655 3.85957684 3.8603729
 3.86041515 3.86136224 3.86225812 3.86281346 3.8633374  3.86423435
 3.86471078 3.8657903  3.86634994 3.86796255 3.86826537 3.87028756
 3.87047844 3.87077329 3.87130446 3.87170275 3.87299366 3.87408012
 3.87470019 3.87504419 3.87602997 3.87760632 3.87786572 3.87938399
 3.88004644 3.88039039 3.88054084 3.8811012  3.88317265 3.88328102
 3.88446351 3.88584343 3.88769549 3.88800475 3.88899587 3.8905047
 3.89062595 3.89108814 3.89124683 3.89131173 3.89154605 3.89240766
 3.89485106 3.89679186 3.89751731 3.89759506 3.89980924 3.90043812
 3.90078816 3.90216243 3.90235337 3.90246518 3.9036182  3.90431087
 3.90441963 3.90481837 3.90490449 3.90492082 3.90515408 3.90537508
 3.90575474 3.90587187 3.90611011 3.90621146 3.90658894 3.90667444
 3.90673019 3.90694889 3.9074481  3.90769788 3.90867517 3.90898605
 3.91066144 3.91072966 3.9112798  3.91225083 3.91316432 3.91328183
 3.9142819  3.91431156 3.91473073 3.9147594  3.91503558 3.91505794
 3.91528219 3.91534462 3.91571163 3.91636658 3.9173386  3.91755353
 3.9177003  3.91837706 3.91904359 3.91914732 3.92042818 3.92073025
 3.92087707 3.92114115 3.92121317 3.92131634 3.92291011 3.92340803
 3.92489962 3.92663136 3.92739728 3.92750035 3.92779735 3.92786842
 3.93019973 3.93248598 3.93301678 3.93306324 3.93326673 3.93470745
 3.93595323 3.93688122 3.93730417 3.93733532 3.93811431 3.94037055
 3.94196767 3.9427916  3.9428724  3.94338129 3.94385916 3.94451203
 3.94535774 3.94783923 3.94833849 3.94874604 3.95050454 3.95133863
 3.9514029  3.95223208 3.95265615 3.95266456 3.95273491 3.95318284
 3.95423118 3.95424748 3.95466032 3.95581288 3.95584849 3.95605274
 3.95673082 3.95785525 3.95820167 3.95841657 3.95956811 3.95998243
 3.96089381 3.96093402 3.96289896 3.96295228 3.96319822 3.96376482
 3.96410278 3.96499254 3.96524339 3.96531048 3.96566551 3.9658001
 3.96631703 3.966441   3.96649724 3.96686768 3.96789205 3.96947408
 3.96950371 3.96998071 3.97009523 3.97082488 3.97190444 3.9721728
 3.97257887 3.97435265 3.97455211 3.97498839 3.97658046 3.97670297
 3.97730362 3.97763124 3.97970239 3.98036438 3.98038875 3.98060086
 3.98122224 3.98139879 3.98156173 3.98164617 3.98266777 3.98441349
 3.98486113 3.98587611 3.98761616 3.98783453 3.98784798 3.98810004
 3.98826423 3.98840388 3.98883553 3.99028869 3.99232751 3.99254072
 3.9937191  3.99499865 3.99711397 3.99728897 3.99736395 3.9982768
 3.99919211 4.00172274 4.00375775 4.00447588 4.00731341 4.00777803
 4.00787493 4.00796955 4.00824445 4.00825351 4.00892174 4.00909751
 4.01072753 4.01114189 4.01507887 4.01526576 4.01648635 4.01724959
 4.01963234 4.01966929 4.01972722 4.01977572 4.02008625 4.02061394
 4.02101819 4.0212345  4.02270436 4.02353983 4.0236091  4.02410501
 4.02644666 4.02721908 4.02726064 4.02759675 4.02769192 4.02813516
 4.02935671 4.0295691  4.03008682 4.03291705 4.03388918 4.034045
 4.0348316  4.03525617 4.03529754 4.03558102 4.03576226 4.03855177
 4.03990996 4.04070565 4.04092062 4.0418055  4.04219942 4.04296084
 4.04342818 4.04806919 4.04988531 4.05063579 4.05131919 4.05173878
 4.0522326  4.0558779  4.05686801 4.05692289 4.06013163 4.06189971
 4.06487809 4.06537922 4.06807603 4.06995595 4.07102627 4.07193923
 4.07217395 4.0723958  4.07329537 4.07608555 4.07695944 4.07772141
 4.07798179 4.08128446 4.08276657 4.08388427 4.08394203 4.08512348
 4.08661021 4.08769163 4.08866597 4.08913914 4.0918761  4.09349834
 4.09371025 4.09856698 4.09945643 4.10310409 4.10371581 4.10417554
 4.10601026 4.10713145 4.1082636  4.1087353  4.11290964 4.11310992
 4.11572398 4.11604426 4.11620166 4.11642347 4.1167284  4.11692714
 4.11908385 4.12032845 4.1221692  4.12228989 4.12297637 4.12459994
 4.12562206 4.12672169 4.1301488  4.13040223 4.13077586 4.13093775
 4.13196888 4.13227971 4.13231456 4.13276017 4.13357252 4.13387765
 4.13393305 4.13446287 4.13478081 4.1354335  4.13724945 4.13740564
 4.13987635 4.14140083 4.14455003 4.14459209 4.14499359 4.14710936
 4.14950993 4.15109949 4.15388412 4.15584934 4.15632995 4.15791616
 4.15989244 4.16112307 4.16181161 4.1620711  4.16343514 4.16363921
 4.16512338 4.16749185 4.16817076 4.16958999 4.17129192 4.17134908
 4.17220615 4.17251397 4.17677757 4.1790063  4.18041045 4.18061085
 4.18235401 4.1836693  4.18483426 4.18705761 4.18707095 4.18885184
 4.18999363 4.19292854 4.19372376 4.1946284  4.19590279 4.19689608
 4.19709562 4.19973644 4.2022322  4.20311404 4.20825825 4.21445578
 4.21623962 4.21667354 4.21699269 4.21869862 4.22250905 4.22757742
 4.22825979 4.22906109 4.22969865 4.23004059 4.230384   4.23129425
 4.23270376 4.23301545 4.23370481 4.23537442 4.23870311 4.24359309
 4.2511539  4.251554   4.2542228  4.25470283 4.2555458  4.26360031
 4.26567239 4.26640912 4.27057111 4.27196252 4.28428799 4.28473293
 4.30036608 4.30534525 4.31400307 4.34664336 4.37772208 4.38841665
 4.39347178 4.39635233 4.41910719 4.42596595 4.44017355 4.44096534
 4.4525469  4.45866274 4.45926052 4.48610939 4.51676082 4.51759366
 4.52307159 4.5632417  4.58825216 4.61051497 4.62232676 4.62870649
 4.63590917 4.63687942 4.64203499 4.66018438 4.66962994 4.73723887
 4.75565334 4.75868138 4.8047142  4.82379809 4.8420453  4.85473154
 4.8894519  4.90793495 4.93134653 4.95930145 4.97680267 4.97686119
 5.0282509  5.04798304 5.16289722 5.25530558 5.35076515 5.4989711
 5.51659    5.51978564 5.52488671 5.53302313 5.53533997 5.54046232
 5.54505587 5.55013    5.55675588 5.60636109 5.69505165 5.69651233
 5.70605728 5.70989382 5.7129112  5.71349792 5.72324049 5.73103071
 5.73259981 5.74571418 5.76791987 5.76999438 5.78107594 5.86315408
 5.91480291 5.9386625  5.95424252 5.96455076 5.96665277 6.02344501]

  warnings.warn(

2022-12-16 10:37:11,021:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.47495189 2.54489976 2.58403795 2.66881475 2.73689247 2.74405004
 2.89494894 2.92040201 2.96559759 3.11003416 3.15125052 3.45336901
 3.45476009 3.45554193 3.45640407 3.50510719 3.6574191  3.70202129
 3.70541771 3.70944411 3.71049421 3.72190947 3.72751987 3.73078755
 3.73185933 3.7321589  3.73389822 3.73601674 3.74027615 3.74149155
 3.74562955 3.74852368 3.75088573 3.7509395  3.75100765 3.75638887
 3.75680895 3.76315215 3.76783514 3.77071616 3.77593233 3.77972539
 3.78020874 3.78258767 3.78267123 3.78350684 3.78790337 3.79007058
 3.79047363 3.79143265 3.79144715 3.79268133 3.7935916  3.79372152
 3.79381322 3.79525612 3.79595404 3.79685133 3.79764994 3.79779807
 3.7990904  3.79967493 3.80075856 3.80105152 3.80202211 3.80226847
 3.80229438 3.80236577 3.80443565 3.80450911 3.80497214 3.80502754
 3.80777078 3.81000062 3.81148322 3.81192716 3.81209836 3.81220878
 3.81249725 3.81312075 3.81319287 3.81327758 3.81346759 3.81449135
 3.81454243 3.81473963 3.81475634 3.81497843 3.8154961  3.81550805
 3.8156727  3.81570604 3.81714793 3.81944197 3.82054132 3.82059995
 3.82124377 3.82469054 3.82585678 3.82609198 3.82737385 3.82739347
 3.82741974 3.82761119 3.82826345 3.8286317  3.82881714 3.82945599
 3.83026788 3.83052977 3.83103226 3.83127166 3.83146372 3.83220758
 3.83277363 3.83351252 3.8335567  3.83440679 3.83440792 3.83462739
 3.83470646 3.83474603 3.83479807 3.83515494 3.8354012  3.83542561
 3.83592115 3.8361064  3.83736226 3.83747685 3.83755307 3.83864138
 3.83881108 3.84072155 3.8409318  3.84121197 3.8412696  3.84209253
 3.84372443 3.84443305 3.8481441  3.85225886 3.85268543 3.85573249
 3.85577155 3.85585979 3.85826265 3.86003905 3.86195271 3.86221366
 3.86260839 3.86298518 3.86389662 3.86547489 3.86552734 3.86564807
 3.86619881 3.86637663 3.86908297 3.87046235 3.87142527 3.87377437
 3.87408699 3.87558377 3.87710006 3.87839599 3.87841952 3.87851747
 3.87880308 3.88144123 3.88177306 3.88209307 3.88228308 3.8826962
 3.88275395 3.88428556 3.8845056  3.88465726 3.88473685 3.88496793
 3.88579493 3.8880361  3.88943476 3.88958218 3.88961731 3.8900496
 3.89039995 3.89137206 3.89208422 3.89395005 3.89541718 3.89749404
 3.90109547 3.90239567 3.9031746  3.90342915 3.90818061 3.90859615
 3.9103049  3.91056452 3.91139214 3.91192234 3.91300071 3.91348134
 3.91371368 3.91457419 3.91762143 3.9183205  3.91893954 3.91977175
 3.92030698 3.92185672 3.92213892 3.92247964 3.92329963 3.9252129
 3.92687053 3.93069131 3.93400401 3.93416576 3.93581279 3.93674102
 3.93681762 3.93748705 3.93972377 3.93976991 3.94973662 3.94997114
 3.95028215 3.95175893 3.95197763 3.95954575 3.96473766 3.96582348
 3.96615901 3.96658238 3.96748181 3.9678525  3.96794525 3.9681797
 3.97188369 3.97295184 3.97300959 3.97384565 3.97556083 3.9785726
 3.98908672 3.99763114 4.00293446 4.00419308 4.00693939 4.00793395
 4.00939247 4.0094378  4.01101717 4.01424101 4.01549305 4.01564342
 4.01752791 4.01782661 4.01864498 4.02237762 4.024357   4.0245964
 4.02488721 4.02629513 4.02767662 4.0284899  4.02952873 4.03167369
 4.03223735 4.03266037 4.03350594 4.03523037 4.03542864 4.0364089
 4.03826463 4.03832158 4.03904972 4.03957877 4.04388083 4.0453015
 4.04608414 4.04647542 4.04666543 4.0485631  4.04869556 4.04934176
 4.0501894  4.05074984 4.05140305 4.05166676 4.0517779  4.05187639
 4.05217872 4.05368216 4.0545119  4.05475142 4.05492848 4.05504051
 4.05505348 4.05587325 4.05590132 4.05700157 4.0576047  4.05762912
 4.05906864 4.05916573 4.05970452 4.06186172 4.06256436 4.06258519
 4.064163   4.06663229 4.06711428 4.06827589 4.06829656 4.06877657
 4.06947636 4.07044193 4.07268355 4.07272319 4.07335671 4.07536162
 4.07561689 4.07810008 4.07833333 4.07871833 4.07946861 4.07957596
 4.08097368 4.08140675 4.08216478 4.08421981 4.08434603 4.0851381
 4.08876273 4.08989488 4.09248488 4.09390268 4.09413444 4.09424129
 4.09516714 4.09599625 4.09652462 4.09693774 4.09729522 4.09771929
 4.09777562 4.09837967 4.09875539 4.10053254 4.10185039 4.10266814
 4.10314424 4.10435554 4.10451237 4.10522812 4.10636387 4.1089149
 4.11143624 4.11147079 4.11150103 4.11289167 4.11793061 4.11807624
 4.11938749 4.11950945 4.12156098 4.12205006 4.12205257 4.12205745
 4.12222843 4.12355765 4.12454486 4.1247224  4.12491675 4.12558599
 4.12565159 4.12587656 4.12687233 4.12751321 4.12864401 4.12964825
 4.12999786 4.13023068 4.13114822 4.13145478 4.13164707 4.13214882
 4.13226214 4.13262156 4.13310947 4.13359912 4.13401052 4.13507171
 4.13537536 4.13541248 4.1356489  4.13570157 4.13662233 4.13797831
 4.13811057 4.13952457 4.14037891 4.14083208 4.14175117 4.14233438
 4.1428207  4.14353581 4.14573844 4.14685516 4.14777454 4.14922432
 4.14962075 4.14978853 4.150123   4.15347898 4.15364971 4.15413591
 4.15516236 4.15531191 4.15551601 4.15676035 4.15740123 4.15740145
 4.15937105 4.16030412 4.16040165 4.16062986 4.16078669 4.16134507
 4.16153826 4.16206105 4.16231592 4.16256294 4.16268276 4.16275295
 4.16314068 4.16318182 4.16321515 4.16359739 4.16469447 4.16522669
 4.16543758 4.1654874  4.16600567 4.1664546  4.16751435 4.16768933
 4.16832611 4.16856381 4.16978921 4.17025178 4.17270614 4.17455507
 4.17604849 4.1771884  4.17743963 4.17744173 4.17753958 4.17782475
 4.17832478 4.18018032 4.18093408 4.1812653  4.18138102 4.18215035
 4.18243944 4.18296179 4.18366491 4.18372266 4.18420872 4.18424198
 4.1843249  4.18500363 4.18527774 4.18567963 4.18568198 4.18577519
 4.18597335 4.1861505  4.18753512 4.18777835 4.18803576 4.19128006
 4.19378446 4.19483313 4.19526603 4.19798927 4.19822342 4.19852423
 4.1993167  4.19967733 4.20034373 4.20051534 4.20098334 4.20184002
 4.2020085  4.20293955 4.20439369 4.20582803 4.20683111 4.20688146
 4.20789885 4.20875034 4.20908519 4.21154319 4.2120613  4.21422179
 4.21474855 4.21507893 4.21628486 4.21636445 4.21804467 4.21812099
 4.21823547 4.21845031 4.21866498 4.21879319 4.2194731  4.21950517
 4.21950993 4.2203127  4.22093657 4.22121598 4.22182644 4.22242971
 4.22253055 4.22263377 4.2226907  4.22295787 4.22330084 4.22367488
 4.22433694 4.22438399 4.22462868 4.22485692 4.22527828 4.22534167
 4.22608568 4.22612022 4.22665256 4.22713799 4.22738525 4.22856187
 4.2292109  4.22950387 4.22960218 4.22979219 4.23003112 4.23024304
 4.23145739 4.23200954 4.23216637 4.23224596 4.23235638 4.2327695
 4.2330339  4.23375983 4.23418647 4.23427062 4.23467305 4.23624476
 4.236317   4.23636725 4.23768372 4.23953503 4.23971922 4.23987242
 4.24002803 4.24025841 4.24054642 4.2406189  4.2411017  4.24159648
 4.24196194 4.24199527 4.24200883 4.24220027 4.24233197 4.24297117
 4.24322691 4.24364644 4.24390622 4.24393626 4.2442921  4.24438681
 4.24482225 4.24567011 4.24889573 4.24914497 4.25226082 4.2525348
 4.25266149 4.25315996 4.25442    4.25459301 4.2553126  4.25592651
 4.25640009 4.25998159 4.26015822 4.26193959 4.26238085 4.26767841
 4.26902587 4.26954646 4.26980367 4.27036618 4.27197182 4.27236299
 4.27364316 4.27421497 4.27448688 4.27820339 4.27854172 4.27955655
 4.27999833 4.28031025 4.28236919 4.2831113  4.28372276 4.28419494
 4.28495869 4.28578643 4.28766799 4.28775023 4.2906901  4.29153945
 4.29215758 4.29302636 4.29536979 4.29679163 4.30071091 4.30755332
 4.30959437 4.31028653 4.31207297 4.31435489 4.31447031 4.31720349
 4.31826172 4.31860258 4.31957071 4.32190561 4.32263444 4.32280127
 4.32374924 4.3246053  4.32488264 4.32964216 4.32991418 4.33029755
 4.33119037 4.33471448 4.33883953 4.33936678 4.34062292 4.34124965
 4.34236202 4.34570933 4.35012489 4.35208152 4.35238829 4.35255767
 4.35470448 4.35645328 4.35904045 4.36315125 4.36361111 4.36488638
 4.36504875 4.36823762 4.36926918 4.37117329 4.37118014 4.37143936
 4.37195522 4.37257289 4.37264992 4.37408346 4.37974657 4.38021733
 4.38061492 4.38410587 4.38687709 4.38688371 4.38750592 4.38796256
 4.38815003 4.38875754 4.38896898 4.38955914 4.3921808  4.39306668
 4.39367533 4.39414121 4.39632813 4.39779239 4.39794188 4.398718
 4.40083953 4.40089197 4.40101319 4.40210856 4.40304847 4.40401898
 4.40443081 4.40482472 4.40577193 4.40698082 4.40711047 4.41006264
 4.4101794  4.41288709 4.41480668 4.41612871 4.41622172 4.41800082
 4.42121437 4.42208229 4.42341428 4.42484045 4.42954771 4.4312624
 4.43374654 4.437618   4.4414118  4.44149565 4.4433466  4.44351328
 4.44377212 4.44379284 4.44407193 4.44786852 4.44804461 4.44829137
 4.45088275 4.45104454 4.4518314  4.45847629 4.46348166 4.46658442
 4.46953623 4.47144006 4.47641567 4.47649625 4.48492621 4.48690808
 4.48760526 4.48982643 4.49363983 4.49768063 4.49844665 4.49942758
 4.5004513  4.50228214 4.50412122 4.50414379 4.50511171 4.5057749
 4.5066338  4.51079295 4.52311813 4.52317521 4.52444546 4.53297559
 4.54009057 4.54393205 4.54401122 4.55331184 4.55762708 4.56020246
 4.57545158 4.58151982 4.58487779 4.59187474 4.60640366 4.61503933
 4.62843932 4.63653432 4.65503635 4.66461518 4.67382942 4.67782232
 4.7175653  4.73458184 4.74066771 4.75583021 4.7583873  4.77673451
 4.7816355  4.78464356 4.79964171 4.80984393 4.85564899 4.86404856
 4.88370389 4.89733308 4.90407622 4.90757588 4.91063972 4.91193586
 4.99869363 5.04605043 5.08802585 5.15792523 5.18463701 5.19088922
 5.20706992 5.26329577 5.30592345 5.30665519 5.31057058 5.31084719
 5.31169288 5.32424072 5.34063186 5.36653931 5.41287728 5.43322299
 5.4340091  5.43994311 5.44233401 5.44282149 5.45094314 5.47176274
 5.51047446 5.51583668 5.52607846 5.53554614 5.58229344 5.60792736
 5.61942    5.64887041 5.65392965 5.65446093 5.65526857 5.65579211
 5.65657329 5.66710753 5.6796847  5.70470981 5.70723577 5.73077021
 5.7426806  5.76092822 5.86170731 5.8695872  5.8700914  5.88550881
 5.9198579 ]

  warnings.warn(

2022-12-16 10:37:11,033:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.52692103 2.56058114 2.56574633 2.79830847 3.08864864 3.20647595
 3.38408035 3.39310423 3.60825268 3.6174844  3.61885855 3.61953722
 3.62252387 3.62415474 3.62831295 3.63529217 3.63941393 3.64307693
 3.6434118  3.6549141  3.66382414 3.66758498 3.66915558 3.67021952
 3.67075104 3.67294393 3.67375947 3.68363022 3.68438345 3.68593998
 3.68703877 3.6908322  3.69120825 3.6933853  3.6952709  3.69730572
 3.69856801 3.7012186  3.70549398 3.70560719 3.70597875 3.71014662
 3.71534907 3.71847928 3.72330837 3.72400204 3.73101692 3.73249253
 3.7348237  3.73777787 3.74049944 3.740997   3.74144795 3.74459058
 3.74590709 3.74688228 3.74817394 3.74897787 3.74992498 3.75119976
 3.75161624 3.75274022 3.75307045 3.75339156 3.75443676 3.75499773
 3.75504697 3.75509367 3.75569089 3.75572996 3.75597595 3.75828272
 3.76049075 3.76056858 3.76060198 3.76321552 3.76488037 3.76511473
 3.76926994 3.77063346 3.77196233 3.77412325 3.77431299 3.77520587
 3.7752144  3.77674155 3.77770648 3.7780145  3.78071748 3.78463525
 3.78594596 3.78707957 3.78757233 3.79038427 3.79203454 3.79221797
 3.79256346 3.79301196 3.79391897 3.79444912 3.79489449 3.79555289
 3.79589077 3.79669149 3.796821   3.79682153 3.79708757 3.79717932
 3.79769858 3.79941799 3.79959966 3.79974277 3.80132097 3.80155965
 3.80160662 3.80190472 3.8019891  3.80280471 3.8028121  3.80284698
 3.80307542 3.80341026 3.80360943 3.80390569 3.80471251 3.80492529
 3.80494559 3.80556854 3.80572218 3.80594467 3.80594531 3.80607715
 3.80639826 3.80655821 3.80689335 3.80721217 3.80738802 3.80778686
 3.80834009 3.80909881 3.81064913 3.81110928 3.81139409 3.81145745
 3.81161689 3.81230482 3.81237832 3.81249671 3.81261365 3.81341377
 3.81406241 3.81445616 3.8149032  3.81587031 3.81631273 3.81781808
 3.81796873 3.81858476 3.81906305 3.81994278 3.82019402 3.82161223
 3.82299283 3.82312183 3.8251942  3.82762203 3.83232748 3.83273515
 3.83375691 3.83413409 3.83559113 3.83586976 3.8365849  3.83776378
 3.83875156 3.8413435  3.84198427 3.84235121 3.84238933 3.84255353
 3.84388041 3.84395407 3.84404462 3.84484296 3.84635024 3.84666918
 3.84681323 3.84685785 3.84714452 3.84815446 3.8484416  3.84954482
 3.85486575 3.85761007 3.86117867 3.86365483 3.86409524 3.87051143
 3.87057063 3.87197949 3.87337025 3.87367257 3.87550387 3.87561662
 3.87661503 3.87973487 3.88034196 3.88109556 3.88861685 3.88900666
 3.89325764 3.89403408 3.89707402 3.89890755 3.89964656 3.9067795
 3.90834366 3.90927061 3.91059778 3.9144273  3.91457037 3.91485641
 3.91935529 3.92140096 3.92820556 3.92852681 3.9295791  3.93313322
 3.93360527 3.93907785 3.93985813 3.94065364 3.94387622 3.94536672
 3.94737826 3.9473984  3.94762264 3.94867575 3.94989179 3.95081548
 3.95432586 3.95478009 3.95488872 3.95542929 3.95609961 3.95681516
 3.9583746  3.95947428 3.96083037 3.96127611 3.96256142 3.96434853
 3.96758804 3.96964702 3.97009665 3.97038378 3.97472297 3.97542826
 3.97647616 3.97711268 3.97939342 3.98253207 3.98492551 3.98602737
 3.98723399 3.98832651 3.98920089 3.98985348 3.98988959 3.99190201
 3.99209454 3.99214286 3.99284091 3.9932532  3.99329499 3.99447995
 3.99552896 3.9955439  3.99604713 3.99635725 3.99644163 3.99652189
 3.99671049 3.99764845 3.99793271 4.00043272 4.00060491 4.00242582
 4.00275731 4.00302953 4.00385384 4.00895681 4.01081035 4.01237446
 4.01564949 4.01625206 4.01656501 4.01721897 4.0181747  4.02016918
 4.02145262 4.02153042 4.02256159 4.02273467 4.02437035 4.02472024
 4.02568686 4.02637096 4.02640458 4.02681334 4.02891661 4.0292106
 4.02997283 4.03072364 4.03125555 4.03209622 4.03265078 4.03296599
 4.03364305 4.03644475 4.03667081 4.0374808  4.03774604 4.03775478
 4.03823527 4.04026094 4.04049756 4.04099971 4.04136091 4.04186416
 4.04198193 4.04386739 4.04471104 4.04484007 4.04769684 4.04833558
 4.04912981 4.05056102 4.0508803  4.05140545 4.05154707 4.05191882
 4.05213144 4.05225766 4.05268014 4.0535348  4.05449645 4.05469458
 4.0579997  4.0593465  4.0595294  4.05994418 4.06019494 4.06135069
 4.06174284 4.06230801 4.06277026 4.06379307 4.06478372 4.06659205
 4.06744885 4.06832182 4.06862559 4.06884722 4.06889284 4.06915213
 4.07060977 4.07121699 4.07173359 4.07192219 4.07250348 4.07254054
 4.07288316 4.07288888 4.07320811 4.07321236 4.07342386 4.07356913
 4.07405389 4.07420441 4.07427919 4.07477139 4.07530063 4.07540263
 4.07675272 4.07686734 4.07688763 4.0773244  4.0773914  4.07739524
 4.07739735 4.07759441 4.0778003  4.07791552 4.0785252  4.07901073
 4.07982918 4.0806245  4.08071166 4.0813797  4.08166634 4.08226882
 4.08294586 4.08320333 4.08332603 4.0833655  4.08387414 4.08444024
 4.08452924 4.08471697 4.08479587 4.08507229 4.08544715 4.08574574
 4.08585068 4.08586823 4.08596552 4.08677652 4.08681171 4.08691415
 4.08721677 4.08728998 4.08757412 4.08762726 4.08801179 4.08834287
 4.08855135 4.08928928 4.08936422 4.08952853 4.08965126 4.09024834
 4.09027218 4.09065798 4.09079284 4.09166747 4.09203885 4.09254224
 4.09295215 4.09365314 4.09483182 4.09548072 4.09566694 4.09585569
 4.09706284 4.09713441 4.09737142 4.09814005 4.09833398 4.09924759
 4.09962452 4.10015025 4.10125334 4.1025005  4.10356849 4.10384764
 4.10425937 4.10498885 4.10815638 4.10910843 4.10924976 4.11083868
 4.11184766 4.11253598 4.11257178 4.11364395 4.11401723 4.11420333
 4.11530637 4.11536572 4.1153888  4.11630707 4.11737876 4.11780604
 4.11799464 4.11850436 4.11885368 4.11896208 4.11972658 4.1207111
 4.12098749 4.12104819 4.12140257 4.12148177 4.12172262 4.12192241
 4.12219429 4.12219737 4.12258562 4.12390487 4.12425469 4.12429345
 4.12649098 4.12659716 4.12830758 4.12907923 4.13020877 4.13091392
 4.13363013 4.13444648 4.13802862 4.13938144 4.14149734 4.14388913
 4.14394522 4.14538478 4.14601173 4.14605961 4.14710804 4.1507371
 4.15103841 4.15124826 4.15602352 4.15665621 4.15716087 4.15941407
 4.16009341 4.16137068 4.16610146 4.16699496 4.16701544 4.16703017
 4.16744494 4.1692591  4.169399   4.16990755 4.17124883 4.17163056
 4.17362984 4.17615162 4.17720782 4.17823955 4.17924944 4.18194223
 4.18488736 4.18766256 4.18907724 4.18999936 4.19261744 4.19653081
 4.19931244 4.20271795 4.20475331 4.20548802 4.20678326 4.2071112
 4.20930619 4.21503674 4.21504286 4.21526458 4.21557323 4.21803396
 4.22042377 4.22232244 4.22246666 4.22370269 4.22389317 4.22779006
 4.22894531 4.22911702 4.23799135 4.23904713 4.24042001 4.24541335
 4.24568205 4.24576126 4.24587342 4.24666273 4.24700612 4.24716823
 4.24959974 4.25036459 4.25256335 4.25262712 4.25357103 4.25377693
 4.25444226 4.25481392 4.25569482 4.2587345  4.25933112 4.26032953
 4.26146684 4.26200763 4.26203123 4.26206827 4.26255866 4.26297136
 4.26483801 4.26522814 4.26643676 4.26660196 4.26968758 4.2698701
 4.27002258 4.27021306 4.2709425  4.27161437 4.27175815 4.27208189
 4.27213586 4.27312137 4.27338378 4.27351806 4.27371952 4.27374391
 4.27396177 4.27412946 4.2751184  4.27518898 4.27573843 4.27673191
 4.27720111 4.27726632 4.27799789 4.27837135 4.27923175 4.27933921
 4.28110722 4.28257731 4.28259081 4.28265514 4.28368496 4.28541368
 4.28545238 4.28622389 4.28625067 4.28770025 4.28824465 4.28922281
 4.28972465 4.29009131 4.29157255 4.29393727 4.29573208 4.29648892
 4.29838869 4.29862611 4.29920784 4.3011237  4.30162817 4.30715408
 4.30778234 4.30862742 4.31118634 4.31237924 4.31280561 4.31690014
 4.31994027 4.32029736 4.32186039 4.32473243 4.32515356 4.32917105
 4.33116972 4.33138001 4.33509993 4.33557971 4.3358689  4.33876192
 4.34006408 4.34006981 4.34452254 4.34791032 4.34833784 4.35053579
 4.3509409  4.35187338 4.35364499 4.35467508 4.35770446 4.35808187
 4.35872196 4.35879907 4.35884639 4.35893118 4.35906747 4.3590862
 4.35919173 4.36058597 4.36101383 4.36116315 4.36125991 4.36214548
 4.36253238 4.36305282 4.36414298 4.36540551 4.36652715 4.36660993
 4.36795074 4.36877438 4.36883193 4.3691329  4.36946348 4.37169132
 4.3723108  4.37233905 4.37452144 4.37771224 4.37804063 4.37824247
 4.37967402 4.38031767 4.38262628 4.3861337  4.38701864 4.3878625
 4.3942265  4.39838352 4.3992157  4.39978092 4.39984959 4.40179417
 4.40369082 4.40388795 4.40595835 4.40612458 4.40880853 4.41027949
 4.41052327 4.41128378 4.4125413  4.41449012 4.41498116 4.41774894
 4.42048533 4.42435549 4.42612388 4.427743   4.43303093 4.43391112
 4.43907065 4.44302656 4.4460074  4.45467583 4.45839181 4.46491997
 4.46713299 4.46891116 4.46951797 4.47148268 4.47298761 4.47851474
 4.48345139 4.48348851 4.48709306 4.48951502 4.49038389 4.49151026
 4.49194822 4.49310011 4.49889342 4.49895539 4.49901301 4.51528927
 4.51722336 4.52053014 4.52283677 4.52312769 4.52412502 4.52853112
 4.53053685 4.5322322  4.54115451 4.54483366 4.54636943 4.54688066
 4.54812029 4.54969429 4.55129514 4.55187258 4.55194754 4.55205645
 4.55222103 4.55313034 4.5593785  4.56265056 4.56880288 4.56943337
 4.56953803 4.57343963 4.57429466 4.57836098 4.57878392 4.58018624
 4.61133842 4.61260558 4.61534802 4.62553646 4.63936828 4.6579967
 4.67077212 4.67091966 4.67177453 4.67261765 4.67293084 4.67360124
 4.6747708  4.68489839 4.68627015 4.68983777 4.69303255 4.695076
 4.70921135 4.71327534 4.72041851 4.74171057 4.74221496 4.75569123
 4.76332532 4.7645971  4.76464183 4.78264638 4.80262943 4.82460312
 4.86724891 4.86824241 4.89005599 4.89005809 4.91408017 4.92436696
 5.01488362 5.29785818 5.29865403 5.33012141 5.36060391 5.38539686
 5.39891293 5.40054933 5.41923743 5.4210986  5.42634091 5.43624927
 5.43626919 5.44538029 5.58892395 5.58957444 5.63168789 5.68780707
 5.69104061 5.692402   5.70027537 5.70056668 5.70113953 5.78609978
 5.79863432 5.85628913 5.88668323 5.91333671 5.96668205 5.96863437
 6.01652512 6.08730269 6.18537015]

  warnings.warn(

2022-12-16 10:37:11,057:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.33012542 2.67219882 2.73124072 2.82486884 2.85644203 3.03964886
 3.08794337 3.08946563 3.14260423 3.19244795 3.40996794 3.52003791
 3.56292316 3.64717076 3.66689907 3.66699531 3.67410003 3.67622464
 3.67815443 3.68015733 3.68522134 3.68957985 3.69019767 3.69126635
 3.69291245 3.69946225 3.701694   3.70445421 3.70962863 3.71153616
 3.71248919 3.71505726 3.71669406 3.72040989 3.73819658 3.74371969
 3.74666221 3.75313779 3.76621495 3.76752994 3.79032476 3.791946
 3.80913689 3.82186889 3.84537652 3.84936631 3.87399865 3.89964236
 3.90199586 3.91412862 3.91436103 3.91787625 3.9190812  3.92127065
 3.92679409 3.9272453  3.93528757 3.94067153 3.94156442 3.94241768
 3.94283101 3.94494363 3.9450705  3.94541535 3.94547143 3.94588725
 3.94599505 3.94616105 3.94672694 3.94681319 3.94771055 3.9477256
 3.94908747 3.94943854 3.94952539 3.94972376 3.95103993 3.95109862
 3.95137502 3.95467581 3.96395112 3.96536483 3.97038071 3.97088057
 3.97288709 3.97307165 3.97387599 3.97401443 3.97625488 3.97931585
 3.97982461 3.98205783 3.98225572 3.98270315 3.98332672 3.98374734
 3.98397143 3.98508655 3.98525367 3.98536086 3.98545746 3.98565461
 3.9857618  3.98664214 3.98740789 3.98764274 3.98812769 3.98822427
 3.98824518 3.98908547 3.98913802 3.99056169 3.99106859 3.99182003
 3.99190478 3.99343963 3.99349179 3.99418931 3.99646376 3.99763086
 3.99794979 3.99894721 3.9994685  4.00023876 4.00073189 4.00146261
 4.00177783 4.00208217 4.00243047 4.00245151 4.00254811 4.00347897
 4.00411216 4.0054604  4.00559521 4.0064325  4.00725634 4.00796158
 4.00805914 4.00910822 4.00941528 4.01010847 4.01019141 4.01032576
 4.01051841 4.01125941 4.01440982 4.01462472 4.01492888 4.0149323
 4.01541775 4.01641833 4.0174111  4.0174903  4.01766053 4.01792382
 4.02076474 4.02275209 4.02289781 4.02414951 4.02515112 4.02619218
 4.0314101  4.03441006 4.03466495 4.03583174 4.03615098 4.03762212
 4.0424613  4.04296712 4.04335759 4.04358983 4.04547318 4.04709788
 4.04971351 4.05135026 4.0520758  4.05455951 4.0634413  4.07384871
 4.07505357 4.07768853 4.0813902  4.08939493 4.08998715 4.09278196
 4.09289456 4.09421134 4.09682448 4.1027801  4.10472627 4.10501085
 4.1052745  4.10830156 4.11527334 4.11527979 4.11532893 4.11607401
 4.12246329 4.12292453 4.1235482  4.12357037 4.12597593 4.12805224
 4.12931013 4.13050133 4.13130053 4.13393025 4.13457971 4.13512242
 4.1355217  4.13697421 4.14030487 4.14062786 4.14171334 4.14224372
 4.1425518  4.14298026 4.1453164  4.14646135 4.14784082 4.14824974
 4.14869341 4.14896    4.14928462 4.14986666 4.15295023 4.15315432
 4.15394111 4.15660994 4.15705973 4.15714598 4.15721715 4.15839267
 4.16091103 4.16313291 4.1635669  4.16416005 4.16531407 4.16595043
 4.16671064 4.17011662 4.17247066 4.17303797 4.17305469 4.17402916
 4.17430639 4.17550118 4.17699142 4.17717984 4.17923255 4.18074462
 4.18107339 4.18258178 4.1831883  4.18420387 4.18548066 4.18823508
 4.18837661 4.1884287  4.18991877 4.19225097 4.1930351  4.19338144
 4.19355571 4.19464445 4.19572208 4.19573694 4.1966914  4.19728816
 4.19732859 4.1983953  4.20003077 4.20049327 4.20055501 4.20149382
 4.20294342 4.20320758 4.20598208 4.20626931 4.20729102 4.20808505
 4.20825783 4.20877589 4.2088069  4.21001242 4.21251156 4.21318179
 4.2175865  4.22142839 4.22423777 4.22478791 4.22564494 4.22656905
 4.23084572 4.23185097 4.23247934 4.23258859 4.23330294 4.23361772
 4.23365805 4.23470308 4.2348503  4.2349412  4.23713969 4.23790689
 4.2388441  4.23947623 4.23960646 4.23982398 4.2400036  4.24108274
 4.24292282 4.24418649 4.24452349 4.24498776 4.24518631 4.24605378
 4.24652808 4.24729237 4.24791847 4.24795468 4.24860775 4.24935006
 4.24942535 4.25011511 4.2514263  4.25241081 4.25461849 4.25488068
 4.25716598 4.25799987 4.26038414 4.26091615 4.26297161 4.26479844
 4.26495357 4.26739061 4.26891202 4.27027578 4.27108326 4.27161053
 4.27307283 4.2757363  4.27594082 4.27690882 4.27724625 4.27915614
 4.27930722 4.28068382 4.28417055 4.28468622 4.28986099 4.2899317
 4.2903154  4.29089066 4.29170425 4.29180143 4.29369029 4.29481448
 4.29514117 4.29525687 4.29527659 4.29862135 4.29950272 4.2996579
 4.30018289 4.30238416 4.30250895 4.30289241 4.30408365 4.30783333
 4.30792412 4.31025589 4.31043504 4.31075529 4.31145325 4.31192696
 4.31205119 4.31239409 4.31334927 4.31840071 4.31894695 4.3207442
 4.32115501 4.32309939 4.32338173 4.32423676 4.32442102 4.32495076
 4.32707574 4.33176275 4.33462817 4.33547813 4.33573427 4.34513097
 4.34655698 4.35329741 4.35567949 4.35653734 4.35663162 4.35863749
 4.35936366 4.36202678 4.36322315 4.36987483 4.37258946 4.3732382
 4.37410821 4.37575961 4.3817245  4.38198023 4.38323458 4.38523926
 4.38545868 4.38664618 4.38710189 4.38880241 4.38989163 4.39009377
 4.39010234 4.39421133 4.39548508 4.39620207 4.39653139 4.39712716
 4.3977401  4.39823073 4.39832444 4.39925484 4.3994256  4.39980005
 4.40071782 4.40073261 4.4010337  4.40132252 4.40155748 4.40163572
 4.40248938 4.40448111 4.40450927 4.40505327 4.40585565 4.40589617
 4.40601251 4.40777439 4.40796276 4.41041803 4.41158678 4.41209523
 4.41256552 4.41302155 4.41332306 4.41649715 4.41808586 4.41823808
 4.41840123 4.41919209 4.4192117  4.41998942 4.42034938 4.42111443
 4.42161054 4.42241162 4.4229084  4.42377467 4.424065   4.42470294
 4.4251894  4.42581613 4.42584564 4.42604285 4.42627338 4.42769302
 4.42893333 4.42940017 4.4308756  4.4312009  4.43160442 4.43257476
 4.43511869 4.43527105 4.43532325 4.43779232 4.43975728 4.44082119
 4.44110987 4.44135853 4.4418501  4.44189953 4.44208523 4.44212522
 4.44260947 4.44289938 4.44327353 4.44355541 4.44408173 4.44435565
 4.4444953  4.44459286 4.44468704 4.44513217 4.44522296 4.44557965
 4.44652733 4.44691014 4.44698331 4.44843656 4.44863342 4.44891761
 4.44974222 4.45061695 4.45117769 4.45128873 4.45322244 4.45371656
 4.45443851 4.45489489 4.45554069 4.45699664 4.45717702 4.45736436
 4.45783636 4.4587042  4.46363749 4.46383284 4.46400559 4.46508193
 4.46580116 4.46724831 4.46769411 4.4686593  4.46900575 4.47043632
 4.47085072 4.47252915 4.47261983 4.47297613 4.47360844 4.4763049
 4.47757426 4.47816742 4.47902092 4.47975004 4.48000999 4.48030362
 4.48041405 4.48099865 4.48120141 4.48181906 4.4825857  4.48277461
 4.48299554 4.48306122 4.48445782 4.48618946 4.48700645 4.48846755
 4.48933239 4.49136817 4.49221211 4.49567057 4.49650094 4.4966169
 4.4966318  4.49675378 4.49709564 4.4972252  4.49741318 4.49779859
 4.49832095 4.49903084 4.49940463 4.49962859 4.50048632 4.50073225
 4.5015662  4.50429902 4.50480088 4.50649927 4.50718293 4.50751152
 4.50821413 4.50952304 4.51019433 4.51049449 4.51097672 4.51101029
 4.51202233 4.51208007 4.51347739 4.51388082 4.51426653 4.52013458
 4.52481133 4.52545288 4.52592992 4.52939735 4.53008091 4.5317519
 4.53335144 4.53384495 4.53424073 4.53511991 4.53540707 4.53693513
 4.53752938 4.5404737  4.54086086 4.54200651 4.54234403 4.5442775
 4.54734599 4.5477266  4.54812574 4.5492818  4.55021094 4.55060144
 4.55071493 4.55136099 4.55164384 4.55204044 4.55480489 4.55533197
 4.55612435 4.55708245 4.55837331 4.56025703 4.56077891 4.56104761
 4.56152868 4.56382317 4.56431553 4.56586956 4.56681121 4.56837276
 4.57126819 4.57215347 4.5732813  4.57406514 4.57747814 4.58202464
 4.58480445 4.58689108 4.58986001 4.58996215 4.59307619 4.59318296
 4.59362412 4.59815199 4.59856467 4.60265385 4.60326666 4.60491281
 4.61001809 4.61358917 4.61482376 4.61787583 4.61856559 4.61952031
 4.62228304 4.62271142 4.62352438 4.62723589 4.63005996 4.63104502
 4.63871715 4.64453687 4.64602655 4.64623771 4.64695557 4.64847367
 4.6500561  4.65013777 4.65060809 4.65137764 4.65213236 4.65257627
 4.65377785 4.65533937 4.65539975 4.65730667 4.65744114 4.65805237
 4.65835671 4.65947705 4.66136978 4.66323147 4.66582828 4.66901924
 4.66964849 4.67037449 4.67404103 4.67667402 4.679815   4.68088605
 4.69612477 4.69619321 4.6975741  4.69860124 4.69903249 4.69904484
 4.69933683 4.70018387 4.70023107 4.70039161 4.70164823 4.70170073
 4.70213431 4.70230813 4.70287715 4.70349315 4.70403323 4.70417897
 4.70517665 4.70649126 4.70745797 4.71001347 4.71036135 4.71056257
 4.71085112 4.71094961 4.71208195 4.71240469 4.71307432 4.71419847
 4.71478007 4.71796669 4.71932575 4.71988324 4.7215224  4.72217994
 4.72258583 4.72409031 4.7244468  4.72461377 4.72609283 4.72759553
 4.73196738 4.73204341 4.73227253 4.73392627 4.73447091 4.7349356
 4.73558276 4.73590297 4.7419674  4.74395497 4.74507044 4.74759005
 4.74851297 4.75082959 4.75119715 4.75304558 4.75331003 4.75939304
 4.76369912 4.76484128 4.76811666 4.76901807 4.76965738 4.77096283
 4.78361235 4.78582817 4.78901042 4.79285413 4.79290159 4.79592818
 4.79637776 4.79932406 4.80035006 4.80275411 4.80759476 4.81013446
 4.8144694  4.81604091 4.81874278 4.82307543 4.82454732 4.83336458
 4.83681101 4.84361291 4.84570425 4.84999282 4.86464559 4.8791058
 4.9005164  4.90516311 4.90600791 4.91716509 4.93644683 4.94753261
 4.94976414 4.94997117 4.95042818 4.9545745  4.95629142 5.00863586
 5.03394757 5.03888708 5.04015574 5.04236553 5.04293917 5.04543322
 5.07692581 5.0972051  5.10575235 5.13530106 5.19307081 5.19454194
 5.22269168 5.22576614 5.24534064 5.25147405 5.25647186 5.25984595
 5.26027706 5.33796946 5.3794821  5.46622322 5.48510854 5.50046407
 5.59457496 5.6244865  5.62674996 5.6289379  5.62894953 5.63172562
 5.73632231 5.78728645 5.79841809 5.85481874 5.86168831 5.87842061
 5.88225476 5.89564051 5.90472105 5.95229603 5.95928743 5.96785021
 6.04103811 6.04174505 6.04750934 6.0543305  6.0702838  6.09720541
 6.09980004 6.10149866 6.18129738 6.18607775 6.19079499 6.19117621
 6.19987422 6.24223472 6.32434696 6.32499962 6.3341878  6.34636342
 6.36874421]

  warnings.warn(

2022-12-16 10:37:11,776:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [-0.56062877  0.34155607  0.37666628  0.38352543  0.39237855  0.41218041
  0.41269606  0.41673122  0.420602    0.42912851  0.43929381  0.44313034
  0.44376797  0.45117905  0.45686169  0.46345274  0.46534182  0.46636471
  0.46764467  0.47017317  0.47032037  0.47729077  0.47739991  0.48268966
  0.48380695  0.49040613  0.49441056  0.49780839  0.4984292   0.50486005
  0.50834306  0.51389346  0.5169655   0.52197745  0.5241769   0.53118498
  0.53339951  0.53847254  0.54324053  0.54947778  0.56646189  0.62649561
  0.63751642  0.64795843  0.65000024  0.65341221  0.65842876  0.65849085
  0.66743774  0.67545679  0.67754331  0.68371646  0.69093691  0.6973587
  0.70654493  0.71312443  0.71625897  0.72015801  0.72250296  0.72335084
  0.73976478  0.74698029  0.74735615  0.74813742  0.74824011  0.75179334
  0.75219856  0.7550196   0.7552641   0.75611935  0.76620304  0.76774497
  0.76789173  0.77337774  0.77347694  0.77355182  0.77726408  0.77948673
  0.78045766  0.78461106  0.78597834  0.79095529  0.79106008  0.79798112
  0.79854267  0.79893345  0.79973285  0.79994338  0.80876897  0.8144209
  0.81493548  0.81777009  0.82874679  0.83527462  0.8360927   0.83896147
  0.8503775   0.85103437  0.85189471  0.85553289  0.86490211  0.87691267
  0.89066091  0.9084174   0.91045421  0.91847612  0.92571919  0.92907989
  0.93063299  0.93891968  0.94225071  0.94578965  0.94834664  0.94843249
  0.9485018   0.95117908  0.95262297  0.95273473  0.95598185  0.96617584
  0.96636177  0.96684458  0.96804111  0.96827862  0.96865175  0.96894809
  0.97052562  0.97094078  0.97102585  0.97108516  0.97182004  0.9730669
  0.97451011  0.97520305  0.97731055  0.97801604  0.979404    0.98192387
  0.98252367  0.98511794  0.98527113  0.98558786  0.98629501  0.98679684
  0.98712562  0.99043061  0.99074671  0.99151856  0.99152968  0.99309554
  0.99340442  0.99412289  0.9953304   0.99565845  0.99601057  0.99654041
  0.99737434  0.9974539   0.99771467  0.997822    0.99849074  0.99866124
  0.9993156   0.99962387  0.99998558  1.00080087  1.00085859  1.00092686
  1.00118113  1.00151479  1.0016724   1.00189257  1.00216297  1.00250079
  1.00374916  1.00553423  1.00626436  1.00660919  1.00690037  1.00840243
  1.0085273   1.00909757  1.00920239  1.0099421   1.01106214  1.01111763
  1.0127031   1.01405909  1.01431816  1.01467423  1.01481741  1.01519148
  1.01520486  1.01583737  1.01601257  1.01655349  1.0167727   1.01692231
  1.01710893  1.01730579  1.01738723  1.01743995  1.01746638  1.01788187
  1.01942499  1.01966301  1.01978173  1.02025564  1.0210798   1.02398147
  1.02456278  1.02492096  1.02492559  1.02696311  1.02697649  1.03053938
  1.03259345  1.03491978  1.03502891  1.03654738  1.03708194  1.03887353
  1.03899152  1.03900889  1.04013658  1.040451    1.04126306  1.04142772
  1.04175083  1.04225238  1.04271005  1.04359352  1.04368414  1.04377348
  1.04402646  1.04458487  1.04586791  1.0459513   1.04632864  1.04646789
  1.04652704  1.04765824  1.04769042  1.04937441  1.04976829  1.05070948
  1.0507346   1.05119112  1.05143095  1.05166336  1.05320829  1.05340966
  1.05367951  1.0541082   1.05471829  1.05497537  1.05569672  1.05586758
  1.05671516  1.0571782   1.05814635  1.05863014  1.06026914  1.06034209
  1.06074105  1.06101326  1.06206324  1.06288808  1.06302407  1.0633436
  1.06344962  1.06402241  1.06403283  1.06442127  1.06579362  1.06631985
  1.06657361  1.06692558  1.06707948  1.06767475  1.0680018   1.07141114
  1.07149713  1.07203687  1.07209899  1.07249038  1.07281832  1.07373316
  1.0823494   1.08526643  1.08544106  1.08560497  1.08615873  1.08664144
  1.08736023  1.0896791   1.09187179  1.09202342  1.09228469  1.09311393
  1.09586358  1.09738965  1.0979657   1.09822771  1.09881971  1.10240578
  1.10252754  1.10394436  1.10578597  1.10592201  1.10894728  1.10920306
  1.10954977  1.1173126   1.12161541  1.12360835  1.12683194  1.12812518
  1.12843737  1.13103917  1.13143938  1.13496782  1.13860401  1.13886347
  1.13906188  1.14050633  1.14297351  1.14455776  1.15090196  1.15103861
  1.15286658  1.15415161  1.15436442  1.15510897  1.15754041  1.15790209
  1.1623479   1.16271727  1.16548216  1.16701483  1.16807396  1.16830129
  1.16926614  1.17251146  1.1729287   1.17312007  1.17364547  1.17378842
  1.17519006  1.17636838  1.17744327  1.18072704  1.1808158   1.18095472
  1.18162563  1.18406153  1.18714778  1.18882015  1.18941968  1.19099324
  1.19193699  1.19250115  1.19437989  1.19835998  1.19849883  1.20000248
  1.20063829  1.20124006  1.20212507  1.20382516  1.20559069  1.20567885
  1.20578909  1.20614606  1.20731184  1.2082355   1.20890506  1.20933473
  1.20940768  1.20950472  1.21139067  1.21146393  1.21175974  1.21262771
  1.21295056  1.21419721  1.21446857  1.21528265  1.21575765  1.21595251
  1.21628733  1.21767223  1.21900159  1.22120978  1.22158697  1.22363795
  1.22797908  1.2297868   1.23036875  1.23226051  1.23388714  1.23615057
  1.23662782  1.23870814  1.23929794  1.23948129  1.24198958  1.24288
  1.24770181  1.24814165  1.2494769   1.24968724  1.2502038   1.25087156
  1.25126099  1.25174554  1.25426105  1.2575219   1.25806523  1.25841348
  1.25865267  1.261818    1.26296633  1.26446124  1.2652553   1.26787773
  1.26810175  1.2694225   1.2703327   1.27046076  1.27193885  1.27617919
  1.27681526  1.27752289  1.27878236  1.27957526  1.27967464  1.28065259
  1.28239085  1.28328504  1.28455211  1.28488616  1.28538976  1.28646634
  1.28689313  1.28756427  1.2879204   1.28803246  1.28826939  1.28837743
  1.28847996  1.28856536  1.29057944  1.29177649  1.29224389  1.29334245
  1.29352954  1.2937479   1.29403879  1.2940722   1.29435566  1.29441599
  1.29444836  1.29590531  1.29634792  1.29700414  1.29743152  1.29858071
  1.29866851  1.29920222  1.30067711  1.30102186  1.30102898  1.30130916
  1.30214227  1.30275595  1.30331184  1.30338787  1.30463973  1.30522819
  1.30549383  1.30692616  1.30735454  1.30816744  1.30922927  1.30987931
  1.31008307  1.31123888  1.31129105  1.31130249  1.31309797  1.31315772
  1.31392968  1.31396308  1.31423056  1.31495875  1.31625061  1.31678773
  1.31684925  1.31719823  1.31788222  1.31797653  1.31873372  1.32068227
  1.32116212  1.32119265  1.32141041  1.32200653  1.32220657  1.32223654
  1.32229851  1.32249641  1.32298398  1.32303104  1.32317324  1.32370066
  1.32383191  1.32445353  1.32497719  1.32506579  1.32538077  1.32718999
  1.32811581  1.32812576  1.32826507  1.32856315  1.32888137  1.32910986
  1.32911386  1.32952517  1.32959331  1.33013836  1.33075971  1.330884
  1.33149894  1.33171556  1.33220398  1.33247479  1.33283012  1.33292685
  1.33315579  1.33324036  1.33569168  1.3358371   1.33584639  1.33629178
  1.33711122  1.33721164  1.33733728  1.3374812   1.33767683  1.337841
  1.33797412  1.33846355  1.33889347  1.3390382   1.33937457  1.33980946
  1.33982566  1.34071     1.34080761  1.34118767  1.34127972  1.34224545
  1.34251605  1.34270243  1.3429222   1.34326089  1.34360953  1.34380073
  1.34415853  1.34449424  1.34450999  1.34455086  1.34598097  1.3462361
  1.34762414  1.34825612  1.34849894  1.34890229  1.34925483  1.34955375
  1.34999801  1.35089074  1.35137389  1.35184511  1.35254162  1.35254836
  1.35452533  1.3547464   1.35549683  1.35593503  1.35609498  1.35656147
  1.35670993  1.35674032  1.3578075   1.35822406  1.35824514  1.35827707
  1.35831637  1.35897821  1.35897981  1.35968897  1.35989189  1.3602704
  1.3612147   1.36148157  1.3623917   1.36579801  1.36649288  1.36684987
  1.36838485  1.36840278  1.36900922  1.36921905  1.3702407   1.37089756
  1.37120259  1.37178196  1.3722201   1.37287546  1.37341902  1.37382174
  1.37400858  1.37480492  1.37556718  1.37577007  1.37602371  1.37647868
  1.37763008  1.3779119   1.37828151  1.37834709  1.37941662  1.37960238
  1.38283621  1.3867953   1.38716352  1.38773126  1.38833046  1.38874193
  1.38923148  1.39189955  1.39261063  1.39275732  1.39282705  1.39564906
  1.39746308  1.39769646  1.39913172  1.39970427  1.40105638  1.40466992
  1.40799559  1.4102745   1.41318034  1.41391041  1.41569406  1.41817396
  1.41853643  1.41952445  1.42264792  1.42276349  1.42352365  1.42567785
  1.42665763  1.42724942  1.43032435  1.43595218  1.43673604  1.43849247
  1.43877544  1.44170154  1.44172653  1.4433562   1.44538158  1.44689931
  1.44813947  1.4495      1.44966032  1.45101376  1.45154666  1.45297625
  1.4586248   1.46294142  1.46475878  1.46636578  1.46947579  1.47065231
  1.4743316   1.4769124   1.47802156  1.47882259  1.48166964  1.49281519
  1.49453766  1.50002903  1.50252251  1.51089717  1.51190927  1.51288057
  1.51301848  1.51545566  1.51690013  1.52063843  1.5212292   1.52402757
  1.52516651  1.52678404  1.52696566  1.52823907  1.53011802  1.53032875
  1.5319365   1.53356036  1.53404186  1.53505558  1.53508735  1.53575347
  1.53781155  1.53890434  1.54052104  1.54232135  1.54269891  1.54636243
  1.546841    1.54899591  1.55004122  1.55065814  1.55100036  1.55433322
  1.55492583  1.5598864   1.56791572  1.57133564  1.57191015  1.57460801
  1.57712599  1.57832286  1.57942841  1.57985616  1.58104792  1.58331742
  1.58404226  1.58406119  1.58588075  1.59011399  1.59036071  1.59153483
  1.59849799  1.60294884  1.60510565  1.61044323  1.61246681  1.61657367
  1.6187582   1.62067972  1.62270203  1.62531214  1.62882988  1.63068202
  1.63314437  1.63435666  1.63593905  1.63600624  1.63675355  1.63700312
  1.63813086  1.64076029  1.64248625  1.64457368  1.64568971  1.64579207
  1.65095814  1.65782893  1.66276251  1.66306308  1.66507656  1.66518102
  1.66755201  1.67947607  1.68337823  1.68348467  1.68381487  1.68393159
  1.68460847  1.68540464  1.68565726  1.69028816  1.69214019  1.69547546
  1.69769451  1.69991356  1.70104379  1.70357634  1.70481973  1.7049114
  1.71215482  1.71250832  1.71773141  1.72067413  1.72603641  1.75072515
  1.75877349  1.77838288  1.77890807  1.78765039  1.81790315  1.83850651
  1.84023632  1.94966365  1.96018197  1.96154407  1.96287268  2.00791643
  2.08281791  2.08505229  2.14395754  2.17274047  2.29386617  2.3034024
  2.32432423  2.39481423  2.41679054  2.41968096  2.42493495  2.42559994
  2.42843849  2.43867813  2.46154494  2.46596531  2.4713731   2.47373082
  2.4738712   2.47390337  2.47416953  2.55255486  2.56909431  2.61060919
  2.6219201   2.65514264  2.72229696  2.72911734  2.7397632   2.74321496
  2.74550399  2.75069201  2.75128113  2.75249122  2.77783623  2.83257346
  2.8390659   3.05457135  3.12139905  3.16638687]

  warnings.warn(

2022-12-16 10:37:11,798:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [-0.65140698 -0.41270178 -0.40102324 -0.35194191 -0.34374567 -0.23863523
 -0.191643   -0.16583193 -0.16040158 -0.12778218 -0.05408449 -0.01889222
  0.05994701  0.17154839  0.2715551   0.46412658  0.54386083  0.55797063
  0.55926334  0.5633303   0.56404705  0.57050972  0.57445013  0.57508275
  0.57639464  0.57785127  0.5804067   0.58887256  0.59299063  0.59536004
  0.5967599   0.59811542  0.59927634  0.59951746  0.60517465  0.6131402
  0.61412745  0.61443562  0.61538189  0.61699144  0.61909974  0.62749612
  0.63253255  0.64421706  0.64545583  0.65432478  0.65691858  0.66250648
  0.66976329  0.6710776   0.69536464  0.70559599  0.7128152   0.72103982
  0.7347991   0.74505107  0.75193383  0.75574849  0.76547726  0.76633832
  0.77184318  0.77869011  0.78993591  0.79112365  0.79117002  0.79571877
  0.79770769  0.80105419  0.8050488   0.80562537  0.80875324  0.80950258
  0.81277123  0.81414878  0.81944896  0.8252347   0.82569188  0.83088741
  0.83576843  0.83612006  0.84149531  0.84704427  0.84742265  0.85437631
  0.85632417  0.86626628  0.87682448  0.87722697  0.88871806  0.89061027
  0.89098137  0.89110954  0.89228643  0.89261592  0.89449432  0.90371921
  0.90526998  0.90912445  0.91896599  0.92036151  0.92359372  0.92702342
  0.92955653  0.93130058  0.93333361  0.93525866  0.93675073  0.93844236
  0.93867873  0.93952514  0.94031331  0.9438082   0.94620664  0.94790189
  0.94799505  0.95039702  0.95077176  0.95127232  0.95146533  0.95149066
  0.95275857  0.95377254  0.95544207  0.95624298  0.95799653  0.95962311
  0.96355317  0.96401101  0.96927742  0.96946815  0.9719217   0.97201542
  0.97257032  0.97266782  0.97674321  0.97784676  0.98721199  0.98915221
  0.9895175   0.99945679  0.99975846  1.0001795   1.00056614  1.00076865
  1.00139037  1.00229119  1.00351055  1.0042975   1.00747158  1.01113631
  1.01259638  1.01369308  1.0144922   1.01456691  1.01636799  1.01653566
  1.01933776  1.02043447  1.02136902  1.0239672   1.02820708  1.02823245
  1.03189398  1.03419329  1.03454847  1.03584389  1.03606272  1.03726426
  1.03812136  1.03846756  1.03881576  1.03919947  1.04189175  1.04270245
  1.04438985  1.04459202  1.04559111  1.04643193  1.04769462  1.04800031
  1.04830715  1.04835967  1.04947973  1.04987197  1.05128184  1.05296221
  1.0535375   1.05357518  1.0541414   1.05487229  1.0556082   1.05619604
  1.05660839  1.05750718  1.05795904  1.05967136  1.06007276  1.06017278
  1.0602743   1.06070188  1.06149313  1.06198482  1.06214597  1.06272724
  1.06302967  1.06481796  1.06512436  1.06526546  1.06616382  1.06726663
  1.06730024  1.06797923  1.0680483   1.06805516  1.06811024  1.06827667
  1.06838446  1.07261321  1.0730363   1.07399793  1.07449811  1.07467109
  1.07622457  1.07651791  1.07757478  1.07781333  1.07905167  1.08025227
  1.08283811  1.08334997  1.08836735  1.08918642  1.0909271   1.09104783
  1.09192021  1.09261969  1.09433399  1.09535753  1.09608815  1.09704465
  1.09711152  1.09865329  1.09994701  1.10013873  1.10043952  1.10046635
  1.10111678  1.10147411  1.1026015   1.10260188  1.1028941   1.10302156
  1.10405502  1.10527426  1.10683646  1.10779321  1.11033831  1.11120051
  1.11355591  1.11386375  1.11534067  1.11720571  1.11739661  1.11802196
  1.120849    1.12142546  1.12185387  1.12254791  1.12278666  1.12505577
  1.12533076  1.1271387   1.12810158  1.12836131  1.12975618  1.13577
  1.13933526  1.14164238  1.14352067  1.14681422  1.14687422  1.14886535
  1.15257797  1.15491356  1.1557982   1.15988174  1.16167444  1.16537574
  1.16559512  1.16571419  1.16726996  1.16762491  1.1683175   1.1690163
  1.17264243  1.17317795  1.17349946  1.17361232  1.17475823  1.17481573
  1.17498808  1.17767025  1.17823954  1.17879793  1.1791358   1.18106694
  1.18313548  1.18468439  1.184811    1.1855385   1.18594262  1.18721587
  1.1872966   1.18915692  1.19138928  1.19228594  1.19683591  1.19708771
  1.19776843  1.19843374  1.20172706  1.20277622  1.20495645  1.21018267
  1.212022    1.21288954  1.21532901  1.21572713  1.21631955  1.21805099
  1.21986229  1.22066195  1.22194513  1.22379303  1.2238786   1.22528937
  1.22620281  1.22645989  1.22668436  1.22724237  1.22880257  1.22944942
  1.2299603   1.23292043  1.23364244  1.2345268   1.23585078  1.23945827
  1.24105575  1.24108002  1.24243908  1.24459519  1.24508391  1.24534868
  1.24537054  1.24537264  1.24597191  1.24628582  1.24695805  1.24797696
  1.24807784  1.2483614   1.24896187  1.24902063  1.24905624  1.25035246
  1.25059782  1.25183012  1.25238028  1.25287936  1.25496438  1.25568391
  1.25577651  1.25581277  1.25678505  1.25847654  1.26111332  1.26196863
  1.26248858  1.26290092  1.26324465  1.26345548  1.26346228  1.26482839
  1.26509854  1.26559076  1.26571736  1.26707942  1.26793281  1.26961823
  1.26986971  1.26987316  1.27003109  1.27087     1.27106054  1.27312202
  1.27489658  1.27508611  1.27619941  1.2776062   1.27828603  1.2793771
  1.2795607   1.27993495  1.28015207  1.28279452  1.28281652  1.28292454
  1.28345049  1.28428346  1.28478382  1.28482     1.28550028  1.28595345
  1.28725038  1.28746599  1.28806534  1.28845985  1.28875576  1.28934846
  1.29049179  1.29132243  1.29136155  1.29262791  1.29384382  1.29396271
  1.29559416  1.29585937  1.29630618  1.29761198  1.29799582  1.29917976
  1.30198727  1.30221141  1.3023268   1.30268147  1.30381662  1.30755166
  1.30788139  1.30801966  1.30856362  1.3085819   1.30977987  1.30995385
  1.31087191  1.31192478  1.31409728  1.314513    1.31515284  1.31556525
  1.31702663  1.32071182  1.321468    1.32208686  1.32400731  1.32440821
  1.32509675  1.32589044  1.32601604  1.3277755   1.32879382  1.32907881
  1.32951559  1.32967284  1.3304205   1.33073375  1.3308781   1.33183774
  1.33256752  1.3328989   1.33903411  1.34066767  1.34183258  1.34283223
  1.34704596  1.34860057  1.3487062   1.34900579  1.34972813  1.34993639
  1.35095237  1.35154577  1.35203738  1.35210219  1.35418542  1.35426156
  1.35597793  1.35609995  1.35618993  1.35619072  1.35625841  1.35634237
  1.35742218  1.35743791  1.35892366  1.36084245  1.36175594  1.36183145
  1.36197461  1.36237914  1.36278178  1.36345077  1.3646327   1.36493339
  1.36729978  1.36781431  1.36794363  1.36797841  1.36857607  1.36930392
  1.36980846  1.37046738  1.37383365  1.37449439  1.37461859  1.37600247
  1.3783915   1.37965634  1.38079189  1.38095396  1.38197614  1.38231388
  1.38352263  1.38380226  1.38388776  1.38496021  1.3850595   1.38625835
  1.387218    1.3874021   1.3880312   1.38834508  1.39026408  1.39143012
  1.39201626  1.39206339  1.3924908   1.39260763  1.39295293  1.39336953
  1.39413003  1.39450296  1.39471787  1.39505112  1.39567985  1.39588357
  1.39591126  1.39598445  1.39714537  1.39721857  1.39725576  1.39835475
  1.39864676  1.39886948  1.39907906  1.40134902  1.40265908  1.40277238
  1.40324078  1.40386495  1.40393514  1.40509806  1.40532868  1.40555603
  1.40616441  1.40644671  1.40818511  1.40967878  1.40969094  1.41026495
  1.41055271  1.41063348  1.41161353  1.41233155  1.41445998  1.41597311
  1.41621166  1.41636545  1.41688408  1.41706685  1.41749753  1.41854832
  1.41877658  1.41886354  1.41886615  1.42014709  1.42034218  1.42080578
  1.4208326   1.42118928  1.42145933  1.42188065  1.42197548  1.42224922
  1.42241426  1.42300381  1.42314336  1.42390234  1.42408302  1.42412957
  1.42554707  1.42572297  1.42635959  1.42677282  1.42737046  1.42755481
  1.42756209  1.42795942  1.42806966  1.42891651  1.42991045  1.43034907
  1.4309297   1.43124067  1.43241473  1.43244162  1.43258127  1.43315744
  1.43364809  1.43377652  1.43397906  1.43409348  1.43416733  1.43417891
  1.4342072   1.43523811  1.43524199  1.43576053  1.43796453  1.43881054
  1.43918593  1.43918801  1.43948971  1.44027171  1.44045318  1.44111835
  1.44141965  1.44511281  1.44521645  1.44603546  1.44705538  1.44707088
  1.4474748   1.44841726  1.44875208  1.44930389  1.44969514  1.45033028
  1.45082019  1.45094128  1.45103304  1.45129633  1.45309258  1.45384664
  1.45404297  1.45694321  1.45705325  1.45787574  1.45796953  1.4591093
  1.46221981  1.46281772  1.46453112  1.46484313  1.4666739   1.46985977
  1.47004098  1.47215785  1.47277944  1.47396241  1.47578286  1.47664803
  1.47682954  1.47856661  1.48045165  1.48095905  1.48110859  1.48434848
  1.48516044  1.48851969  1.48885878  1.48967318  1.49071605  1.49165
  1.49219916  1.49351714  1.49485465  1.49504932  1.50359781  1.5042569
  1.50703307  1.50751775  1.50803812  1.51237733  1.51458646  1.51624362
  1.51811336  1.52119504  1.53414364  1.53536404  1.53678873  1.54525224
  1.54707568  1.55168356  1.55589775  1.55737657  1.55973709  1.55980039
  1.56114011  1.57119275  1.57145481  1.57233018  1.5736193   1.57717373
  1.57783486  1.57991749  1.58114481  1.58196244  1.58276966  1.58311406
  1.58324661  1.584755    1.58518009  1.58591797  1.59105079  1.59460642
  1.59528574  1.59632387  1.59662153  1.59804702  1.59957599  1.6043821
  1.60646624  1.60709941  1.60718597  1.60887788  1.61004171  1.61077008
  1.61295849  1.6134179   1.61364507  1.61420157  1.61741027  1.61787732
  1.61916142  1.61926801  1.61983183  1.62148025  1.62342286  1.62368622
  1.62370746  1.62392063  1.62493063  1.62863353  1.62999671  1.63068072
  1.63495403  1.63568942  1.6357092   1.63593484  1.63688999  1.63694361
  1.64113381  1.64115927  1.64189582  1.64406089  1.64782762  1.65086832
  1.65087712  1.6525617   1.65319588  1.65590036  1.65656643  1.65735678
  1.65786065  1.65816675  1.65913943  1.66280365  1.66462875  1.66864473
  1.66936587  1.6723593   1.67256502  1.67274423  1.67461242  1.67984465
  1.68261262  1.68970106  1.69261801  1.70176302  1.70648911  1.7079789
  1.71703538  1.72177751  1.72631094  1.73600957  1.74067775  1.76061995
  1.76279315  1.76996284  1.79128255  1.81519116  1.81766144  1.82752602
  1.83396501  1.84094091  1.84418654  1.85095356  1.86954206  1.89535183
  1.91404297  1.93629163  1.9681892   1.97013153  1.98118569  1.99213019
  2.06088922  2.06390198  2.08640231  2.13461893  2.21494579  2.31197117
  2.32833161  2.34047976  2.36400333  2.36850816  2.37313813  2.37317229
  2.37669282  2.37905614  2.37966253  2.38028197  2.41209444  2.50531803
  2.54622007  2.59266196  2.6052657   2.6056113   2.61060357  2.6444026
  2.64481742  2.65409408  2.6696787   2.69469486  2.70158852  2.71924336
  2.72402091  2.72987638  2.77292723  2.80119025  2.95346394  2.96664931
  2.97479412  2.99240829  3.03704235  3.05021691]

  warnings.warn(

2022-12-16 10:37:11,799:INFO:Calculating mean and std
2022-12-16 10:37:11,800:INFO:Creating metrics dataframe
2022-12-16 10:37:11,804:INFO:Uploading results into container
2022-12-16 10:37:11,805:INFO:Uploading model into container now
2022-12-16 10:37:11,805:INFO:master_model_container: 18
2022-12-16 10:37:11,805:INFO:display_container: 2
2022-12-16 10:37:11,806:INFO:PassiveAggressiveRegressor(random_state=5099)
2022-12-16 10:37:11,806:INFO:create_model() successfully completed......................................
2022-12-16 10:37:11,949:ERROR:create_model() for PassiveAggressiveRegressor(random_state=5099) raised an exception or returned all 0.0:
2022-12-16 10:37:11,949:ERROR:Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 795, in compare_models
    assert (
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 811, in compare_models
    assert (
AssertionError

2022-12-16 10:37:11,949:INFO:Initializing Huber Regressor
2022-12-16 10:37:11,949:INFO:Total runtime is 1.24484680891037 minutes
2022-12-16 10:37:11,950:INFO:SubProcess create_model() called ==================================
2022-12-16 10:37:11,950:INFO:Initializing create_model()
2022-12-16 10:37:11,950:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002281239F8E0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022810EC8B20>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:37:11,950:INFO:Checking exceptions
2022-12-16 10:37:11,952:INFO:Importing libraries
2022-12-16 10:37:11,953:INFO:Copying training dataset
2022-12-16 10:37:11,957:INFO:Defining folds
2022-12-16 10:37:11,958:INFO:Declaring metric variables
2022-12-16 10:37:11,958:INFO:Importing untrained model
2022-12-16 10:37:11,958:INFO:Huber Regressor Imported successfully
2022-12-16 10:37:11,958:INFO:Starting cross validation
2022-12-16 10:37:11,960:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:37:14,624:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-16 10:37:14,780:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-16 10:37:14,810:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-16 10:37:14,815:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-16 10:37:14,831:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-16 10:37:14,885:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-16 10:37:14,893:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-16 10:37:15,002:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-16 10:37:15,089:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.43717275 2.44421593 2.45540932 2.46502033 2.47637753 2.49199846
 2.49243637 2.49650365 3.70357539 3.85145295 3.85284094 3.86036513
 3.8701395  3.87221958 3.87280195 3.87991334 3.88020959 3.88025138
 3.88075487 3.88177981 3.88943765 3.89117619 3.89424216 3.8949201
 3.89802941 3.89951486 3.90024521 3.90055026 3.90077321 3.90223789
 3.90254553 3.90398357 3.90444864 3.90515819 3.90612819 3.90649619
 3.9067449  3.91052433 3.91130014 3.91230525 3.91305542 3.91309008
 3.91438006 3.91445112 3.91457714 3.91488865 3.91576113 3.91673215
 3.91772448 3.9179083  3.91803979 3.91907353 3.91935491 3.92009753
 3.92062681 3.92093565 3.92093715 3.92113206 3.92129842 3.9215732
 3.92205738 3.92233217 3.92252994 3.92315675 3.92491711 3.92493685
 3.92525568 3.92558834 3.92593264 3.92639461 3.92647708 3.92664691
 3.92730874 3.92776934 3.9290453  3.92913175 3.92917117 3.92950797
 3.929548   3.93026989 3.93051654 3.93071989 3.93084333 3.93223221
 3.9323495  3.93292106 3.93310323 3.9332344  3.93350137 3.93359716
 3.9336973  3.93370043 3.93371241 3.93378819 3.93379288 3.93382705
 3.93421774 3.93448976 3.93459084 3.93471388 3.93514771 3.93540157
 3.93606797 3.93644037 3.9365172  3.93685111 3.93712618 3.93751287
 3.93759442 3.93761659 3.93764667 3.93782316 3.9380423  3.93808169
 3.93837935 3.93846152 3.93861396 3.93864645 3.93875792 3.93880019
 3.93892239 3.93908937 3.93923436 3.93943276 3.93951517 3.93969632
 3.93974306 3.93996631 3.94001112 3.94017238 3.94038427 3.94049935
 3.94051055 3.94058957 3.94088862 3.94090267 3.94100323 3.94106296
 3.94121667 3.94129333 3.94148972 3.94164157 3.94174031 3.94180366
 3.94185373 3.94195706 3.94197723 3.94198407 3.94205736 3.94211169
 3.94221275 3.94248231 3.94253713 3.94266097 3.94270118 3.94278085
 3.94280317 3.94285334 3.94291712 3.94323272 3.94334763 3.94340234
 3.94349934 3.94358899 3.94361494 3.94396484 3.94400561 3.94404988
 3.94430664 3.94433328 3.94439252 3.94474493 3.94495629 3.94502882
 3.94507178 3.9451891  3.94530086 3.94532905 3.94543621 3.94549495
 3.94570664 3.94575042 3.94576735 3.94588921 3.94610246 3.94627524
 3.94632752 3.94653525 3.94669709 3.94687953 3.9469872  3.94702734
 3.9470677  3.94734913 3.94736653 3.94750414 3.94781077 3.94781261
 3.94786911 3.94799138 3.94801109 3.94804392 3.94819628 3.94832937
 3.94839045 3.94851238 3.94854854 3.94867327 3.94883199 3.94887936
 3.94890652 3.94908398 3.94911542 3.94917824 3.94925662 3.94943673
 3.94947845 3.94968982 3.94991737 3.94993046 3.94996032 3.95013867
 3.95017333 3.95017338 3.95019374 3.95041835 3.95042537 3.95047588
 3.95048008 3.95068164 3.95073672 3.95080222 3.95081148 3.95085849
 3.95093827 3.95098919 3.95099699 3.951187   3.95124811 3.95125006
 3.95127378 3.95129325 3.95146211 3.95147075 3.95151353 3.95174425
 3.95176084 3.95179545 3.95184543 3.95194171 3.95195717 3.95217259
 3.95222826 3.95223322 3.95227453 3.95245264 3.95250358 3.95251142
 3.9526695  3.95267572 3.95270157 3.95277594 3.95281874 3.95284457
 3.95290604 3.95293201 3.95299349 3.95306498 3.95309978 3.95312873
 3.95351223 3.95352077 3.95385164 3.95385627 3.95406716 3.95412421
 3.95412592 3.95420384 3.95422229 3.9542883  3.95437919 3.95465946
 3.95476284 3.95492018 3.95495058 3.9550347  3.95514872 3.95516086
 3.95536725 3.95555127 3.95561142 3.95562945 3.95572226 3.95575885
 3.95591504 3.95599442 3.95617611 3.95619308 3.95629538 3.95633244
 3.95639588 3.95653395 3.95654504 3.95657313 3.9566406  3.95668831
 3.95671864 3.95678499 3.95680646 3.9568146  3.95681563 3.95685668
 3.9568669  3.9569492  3.9570314  3.95706766 3.95710808 3.95712875
 3.95718095 3.95719528 3.95727582 3.95765127 3.95782228 3.9579553
 3.95799637 3.95814847 3.95816782 3.95831966 3.95846113 3.95847198
 3.95850301 3.95883328 3.95884568 3.95888853 3.95897148 3.95924897
 3.95936461 3.9593829  3.95951495 3.95969181 3.95976919 3.9597878
 3.95991326 3.95992784 3.95996452 3.96007867 3.96009889 3.96018048
 3.96025389 3.9603863  3.96060428 3.96070101 3.96076224 3.96082943
 3.96098499 3.96098822 3.96101691 3.96106465 3.96119594 3.96120841
 3.96121019 3.96126842 3.96128567 3.96131889 3.96141118 3.96142763
 3.9616784  3.96184774 3.9618976  3.96193064 3.96200824 3.96213414
 3.96219122 3.96224483 3.96226933 3.96228854 3.96252575 3.96257925
 3.96262882 3.96271319 3.96280116 3.96284878 3.96285927 3.96292448
 3.96317964 3.96319236 3.96321597 3.9632442  3.9632676  3.9633388
 3.96353707 3.96355878 3.96363041 3.9638286  3.96387698 3.96398189
 3.96411172 3.96432883 3.96433087 3.96435551 3.96438461 3.9644359
 3.96447333 3.96448172 3.96456488 3.96457758 3.96464014 3.96469757
 3.96485856 3.96496796 3.9650861  3.96514168 3.96523601 3.96528899
 3.9653215  3.96547485 3.9655653  3.96561295 3.96566151 3.96583114
 3.96592019 3.96594016 3.9661469  3.96620976 3.96653317 3.96655846
 3.96698225 3.96707556 3.96723772 3.96728786 3.96730747 3.96734024
 3.96736576 3.96755922 3.96761562 3.96791416 3.96792577 3.96793143
 3.96821424 3.96822338 3.96826459 3.9682754  3.96829774 3.9684348
 3.96851541 3.96855335 3.96856578 3.96864241 3.96871317 3.96878264
 3.96906288 3.96909667 3.96914493 3.96931236 3.9694272  3.96958597
 3.96960511 3.96966872 3.96978805 3.96981462 3.97001823 3.97016431
 3.97045048 3.97051161 3.97061068 3.97066951 3.97067187 3.97069304
 3.97079235 3.97082434 3.97083732 3.97088663 3.97092489 3.97093879
 3.9709452  3.97095269 3.97098659 3.97110609 3.97125803 3.97128243
 3.97129511 3.9715202  3.97156782 3.97164631 3.97165434 3.97178472
 3.97187573 3.97206703 3.97208526 3.97209284 3.97210752 3.97211856
 3.97212407 3.97216179 3.9723935  3.97256802 3.97257183 3.97260301
 3.97266289 3.97269958 3.97288898 3.97289973 3.97292848 3.97296535
 3.97297731 3.97300752 3.97307677 3.9730911  3.97318597 3.97325487
 3.97328335 3.97333391 3.97336356 3.97347183 3.97365692 3.97368357
 3.97370791 3.97374448 3.97376021 3.97390676 3.97395172 3.97409999
 3.97416255 3.97418165 3.97421589 3.97422436 3.97433823 3.97447086
 3.97450397 3.9745409  3.9745505  3.97460622 3.97503889 3.97509576
 3.97523736 3.97549452 3.97577326 3.97577457 3.97581645 3.97592892
 3.97602835 3.97611809 3.97627478 3.97628813 3.9763337  3.97635405
 3.9764252  3.97662123 3.97668024 3.97685365 3.97697715 3.97707311
 3.97717328 3.97723234 3.97736678 3.97739285 3.97752617 3.97763622
 3.97773282 3.97778998 3.97783664 3.97801423 3.9780405  3.97811716
 3.97814267 3.97815483 3.9782076  3.97857767 3.97858283 3.97873563
 3.97886895 3.9788782  3.97889411 3.97892085 3.97892673 3.97895528
 3.97900808 3.97902668 3.97904793 3.97907417 3.97914825 3.97922559
 3.97929183 3.97940126 3.97952636 3.9796528  3.97970001 3.97982778
 3.97988555 3.97988628 3.97992494 3.98000542 3.98008063 3.98016624
 3.98029211 3.98038205 3.98063969 3.98065475 3.98073672 3.9808544
 3.98108509 3.98122777 3.98124935 3.98139346 3.98168782 3.98175672
 3.9818433  3.98195989 3.98217382 3.98226557 3.98237792 3.98269877
 3.98298541 3.98298715 3.98325676 3.98329729 3.98341089 3.98342417
 3.98342762 3.98349744 3.98353271 3.98386639 3.98397139 3.9843273
 3.98469083 3.98501395 3.98503153 3.98523777 3.98526414 3.98571528
 3.98598456 3.98650137 3.98669464 3.98670555 3.98681066 3.98723408
 3.98724155 3.98728376 3.98769397 3.98807477 3.98812771 3.9881371
 3.98835279 3.98858495 3.98863819 3.98873363 3.98911287 3.9891789
 3.98924222 3.9892978  3.98985693 3.99004573 3.99010205 3.99075304
 3.99088091 3.99105978 3.99125833 3.99133865 3.9914027  3.99150135
 3.9916503  3.99188909 3.99228929 3.99247551 3.99258998 3.99264423
 3.99285288 3.99292185 3.9931646  3.99356407 3.99357977 3.99359853
 3.99373331 3.99415036 3.99415306 3.99416261 3.99429362 3.9944496
 3.99448141 3.99463909 3.99469566 3.99587677 3.99599268 3.99615026
 3.99618626 3.99632302 3.99642531 3.99658404 3.99674858 3.99692253
 3.99697334 3.99698287 3.99698615 3.99728618 3.99730494 3.99754804
 3.99759968 3.99823471 3.99831316 3.9983386  3.99856171 3.99898406
 3.99961935 3.99993163 3.99995818 4.00060363 4.00086079 4.00090886
 4.00104775 4.00110707 4.00116956 4.00118247 4.00121763 4.00129147
 4.00132855 4.00156363 4.00183775 4.00194747 4.00206133 4.00218698
 4.00252505 4.00254653 4.00309545 4.00357059 4.00385602 4.00386574
 4.00410664 4.00427855 4.00536144 4.00588337 4.00593791 4.00601833
 4.00608195 4.00733865 4.00770756 4.0079922  4.00811416 4.00848332
 4.00937124 4.00941933 4.01037249 4.01083972 4.01090644 4.01154093
 4.01154755 4.01166505 4.01376098 4.01378894 4.0138249  4.0138267
 4.01398339 4.01400313 4.01467043 4.01477145 4.01534028 4.01562954
 4.01602158 4.01627705 4.01689876 4.016965   4.01815703 4.01879055
 4.01945552 4.0194651  4.02022463 4.0213335  4.02278287 4.02325761
 4.02345146 4.02373248 4.02491401 4.02692244 4.02847944 4.0289468
 4.02898918 4.03029261 4.03055825 4.03075757 4.03120104 4.03246137
 4.03616755 4.03924481 4.04003319 4.0422446  4.0424665  4.04263673
 4.04350341 4.04383303 4.04470873 4.05101717 4.05378405 4.05496694
 4.05703857 4.06495228 4.06521019 4.06650488 4.06817746 4.07090877
 4.07098717 4.08525104 4.08721503 4.08785678 4.08859476 4.0888837
 4.09545302 4.10036211 4.1053173  4.1061035  4.11495955 4.11965687
 4.14388411 4.23419359 4.87244241 4.88817814 4.89160805 4.89247489
 4.9053136  4.91147109 4.91480312 4.93124889 4.93399638 4.93428551
 4.93885989 4.94331562 4.94333364 4.9463638  4.94760726 4.94991618
 4.95059046 4.95265692 4.95451153 4.95557037 4.95611896 4.95677513
 4.95730624 4.96021846 4.96373863 4.96437648 4.9643953  4.96475642
 4.96502188 4.96504058 4.97344892 4.97449039 4.97498547 4.97737721
 4.97832509 4.98033663 4.98035529 4.98456045 4.98594513 4.98938542
 4.9894453  5.00754395 5.01252843 5.04549558 5.10117725]

  warnings.warn(

2022-12-16 10:37:15,154:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.73584268 1.7393993  1.74977546 1.75663467 1.77986995 1.79104437
 1.80104533 1.8160329  3.76817068 3.79177565 3.80629721 3.80934447
 3.81895482 3.85877539 3.87107258 3.87795415 3.87885627 3.8789659
 3.88053504 3.88068958 3.88205617 3.88284126 3.88343722 3.88393709
 3.88418837 3.88860713 3.89102351 3.89117093 3.89239705 3.89449476
 3.89490837 3.89534882 3.89778108 3.89952055 3.90120966 3.90406748
 3.90447067 3.90526869 3.90926852 3.91177452 3.9142393  3.91434262
 3.91614184 3.91730261 3.91793613 3.91938455 3.91993526 3.92146518
 3.92235095 3.92302697 3.92333619 3.92354907 3.92499435 3.92597948
 3.92604184 3.92645168 3.92775237 3.92818241 3.9283135  3.92860157
 3.92920966 3.93012635 3.93023658 3.93040345 3.93070011 3.93109915
 3.93117531 3.9313975  3.93142519 3.9314255  3.93160825 3.93167956
 3.93191445 3.93205176 3.93248206 3.9335983  3.93473285 3.93521412
 3.93537195 3.93625969 3.93633792 3.93637589 3.93648325 3.93679737
 3.93700762 3.93714338 3.93731042 3.93770008 3.9378591  3.9378772
 3.9379191  3.93807338 3.93815875 3.93822195 3.93853896 3.93875626
 3.93905793 3.93913101 3.93938617 3.93959169 3.93979705 3.94085525
 3.94130522 3.94167945 3.9417652  3.94188676 3.94194586 3.94210108
 3.94229075 3.94260768 3.94290214 3.94340654 3.94355443 3.94363681
 3.94365703 3.94385956 3.94438214 3.9448673  3.94490218 3.94499072
 3.94533069 3.94545976 3.94548911 3.94549523 3.94550475 3.9455281
 3.94558973 3.94565223 3.94569167 3.94587098 3.94608443 3.94612762
 3.94623782 3.94631721 3.94692694 3.94722982 3.94731927 3.94738278
 3.94764821 3.94772623 3.94774817 3.94781691 3.94784923 3.94802116
 3.94804919 3.94809441 3.948258   3.94832142 3.94839803 3.94856214
 3.9487007  3.94882054 3.94892921 3.94898288 3.94904624 3.94908754
 3.94918688 3.94921331 3.94926344 3.94947387 3.94953924 3.94956142
 3.94959805 3.94962544 3.94964921 3.94965681 3.94970833 3.94978808
 3.94987801 3.95037089 3.950405   3.95040781 3.95045635 3.9505761
 3.95059587 3.95070944 3.95079648 3.95090423 3.95094505 3.95095532
 3.95104193 3.95135011 3.95158978 3.95166064 3.95177483 3.9520401
 3.95213783 3.95219016 3.95226288 3.95227613 3.95233134 3.95239391
 3.9524586  3.95246079 3.95260002 3.95279151 3.9528301  3.9529946
 3.9530037  3.95307491 3.95312338 3.95342542 3.95343804 3.95344081
 3.9536052  3.95361843 3.95372824 3.95381504 3.95383337 3.9539468
 3.95406961 3.9540761  3.95424307 3.95434112 3.95441999 3.95458468
 3.95460057 3.95464529 3.95472257 3.95483069 3.95483337 3.95488416
 3.95488876 3.95490574 3.95539127 3.95541274 3.95541406 3.95557985
 3.95560575 3.95565462 3.95569714 3.95590688 3.95593077 3.95607281
 3.95613303 3.95624563 3.9564125  3.95645439 3.95652479 3.95657236
 3.95657531 3.95657801 3.95657802 3.95669199 3.95671826 3.95676883
 3.95678274 3.9567966  3.95681038 3.95691489 3.95703929 3.95726938
 3.95732954 3.95739238 3.95768205 3.95786009 3.95790816 3.95800795
 3.95806742 3.95815108 3.9585372  3.9585865  3.95871643 3.95873743
 3.95894964 3.95897389 3.95916139 3.95920597 3.95923605 3.95924004
 3.9592571  3.95928765 3.95935255 3.95944909 3.95947457 3.95977901
 3.95978285 3.95992295 3.96006415 3.96028807 3.96033522 3.96066186
 3.96071875 3.96077164 3.96080065 3.96097067 3.96100117 3.96107054
 3.96107903 3.96117126 3.96125969 3.96128305 3.96135793 3.96136703
 3.96141537 3.96154234 3.96159948 3.96164402 3.9616574  3.96170431
 3.96181342 3.96195411 3.9620864  3.96217047 3.96220766 3.96239945
 3.96240085 3.96241842 3.96256198 3.96265209 3.96275063 3.96280562
 3.96281324 3.96294291 3.96296898 3.96304737 3.96305683 3.96319054
 3.96319326 3.96329643 3.96329767 3.96330518 3.96334403 3.96339451
 3.96343602 3.9636332  3.9636445  3.96393983 3.96398724 3.96398931
 3.96419071 3.96419833 3.96422074 3.96434201 3.96434787 3.96436939
 3.96442999 3.96448754 3.96451107 3.96455393 3.9646739  3.96468075
 3.96468241 3.96471762 3.96482249 3.96483263 3.96497474 3.96522905
 3.96532126 3.96546999 3.96556979 3.96557253 3.96566832 3.96577672
 3.9657979  3.965812   3.96592141 3.96593525 3.96598784 3.96601224
 3.96612147 3.96628501 3.96629164 3.96631255 3.96641805 3.96645033
 3.96663448 3.96667222 3.96672465 3.96698694 3.96699909 3.96711502
 3.96711527 3.96725329 3.96739068 3.96741864 3.96745128 3.96753119
 3.96759396 3.96760538 3.96762586 3.96772619 3.96776441 3.96779847
 3.96799517 3.96814648 3.96820955 3.96836047 3.96839522 3.96845224
 3.96865795 3.96866335 3.96872388 3.96874163 3.96879173 3.96884838
 3.9690682  3.96915808 3.96918522 3.96938487 3.96953704 3.96955494
 3.96981678 3.9698351  3.96984538 3.96985698 3.96993261 3.97001708
 3.97011646 3.97023967 3.97026621 3.97028755 3.97040181 3.97041849
 3.97049471 3.9705638  3.9705732  3.97060034 3.97062118 3.97065777
 3.97074837 3.97074905 3.9707811  3.97089031 3.97092251 3.97094691
 3.97094824 3.97097459 3.97097557 3.97118227 3.97121059 3.97130116
 3.97137405 3.97139975 3.97181859 3.97208864 3.97231804 3.97246945
 3.97251002 3.97264791 3.97266519 3.97282661 3.97284544 3.97286569
 3.97287594 3.97302574 3.97308765 3.97313937 3.97333093 3.97337977
 3.97340696 3.97348623 3.97353588 3.97378489 3.9738016  3.97394442
 3.97396515 3.97408622 3.97416047 3.97433256 3.97435983 3.97440314
 3.97441819 3.9746736  3.97471287 3.9747505  3.97485023 3.9749667
 3.97501158 3.97501987 3.97502097 3.97521299 3.97533088 3.97545776
 3.97546166 3.97555091 3.9756263  3.97563585 3.97566451 3.97569984
 3.97570524 3.97572504 3.97582444 3.97583672 3.97587849 3.97591525
 3.97596116 3.97597852 3.97606784 3.97610194 3.97643385 3.97648822
 3.97662872 3.97667204 3.9766929  3.97675741 3.97679646 3.97692143
 3.97696226 3.97700303 3.97720065 3.97735431 3.97745102 3.97777919
 3.97788696 3.97789944 3.97792239 3.97792983 3.978198   3.97831662
 3.97839184 3.978396   3.97840925 3.97844193 3.97852838 3.97853698
 3.97856101 3.97857544 3.97871759 3.97888317 3.9790397  3.9790527
 3.97926808 3.97931472 3.97936365 3.97939575 3.9794071  3.97950638
 3.97968153 3.97976277 3.9797669  3.97986266 3.9800188  3.98007607
 3.98011751 3.98011913 3.98012796 3.9802827  3.98031337 3.98037088
 3.98050451 3.98062416 3.98069839 3.98081827 3.98092118 3.98102833
 3.98104433 3.9810925  3.98116803 3.981227   3.98125831 3.98128667
 3.98131835 3.98140255 3.98144311 3.98147464 3.98154907 3.9816556
 3.98167184 3.98170204 3.98178541 3.98219865 3.98230771 3.98237834
 3.98241539 3.98243282 3.98244883 3.982449   3.98256159 3.98269902
 3.982731   3.98273222 3.9827858  3.98292612 3.98313131 3.98321264
 3.98324137 3.98352219 3.98361316 3.9836249  3.98375095 3.98376683
 3.98381551 3.98391702 3.98403585 3.98405396 3.98406405 3.9841387
 3.98423512 3.98429338 3.98442926 3.98448263 3.98507569 3.98527606
 3.9852924  3.98546071 3.9854789  3.98557791 3.98564536 3.98572683
 3.98580756 3.98626171 3.98633921 3.98635214 3.98636169 3.98647539
 3.98649572 3.98650796 3.98657196 3.986625   3.98667234 3.98679477
 3.98687825 3.98689183 3.98701398 3.98704775 3.98706348 3.9871603
 3.98723049 3.98729172 3.98764188 3.98767593 3.98781495 3.98785785
 3.987905   3.98793212 3.988032   3.98810715 3.98812268 3.98813556
 3.98813755 3.98818172 3.98820221 3.98834878 3.98845878 3.98850402
 3.98853754 3.98871015 3.98871918 3.98879458 3.98896317 3.98924582
 3.9892461  3.98931856 3.98938585 3.98942823 3.98953405 3.98959825
 3.98970578 3.98973697 3.98996146 3.99001648 3.99003408 3.9901877
 3.99025813 3.99031415 3.99032439 3.9904317  3.99060622 3.99068025
 3.99075986 3.99081942 3.99086992 3.99135514 3.99152547 3.99155135
 3.99215412 3.99216319 3.99237648 3.99237706 3.99237937 3.99243062
 3.99251479 3.99255324 3.99258102 3.99275547 3.99287452 3.99322497
 3.99331475 3.99331509 3.9935817  3.99378837 3.99389059 3.99404572
 3.9940567  3.99432052 3.99459956 3.99466046 3.99469775 3.99482248
 3.99493985 3.99495346 3.99499673 3.9949985  3.99504756 3.99511545
 3.99517092 3.99550385 3.99600178 3.99606724 3.99615341 3.99649271
 3.99649325 3.99659034 3.99684787 3.99742629 3.99757843 3.99778039
 3.99785741 3.99787553 3.99798681 3.99815526 3.99819099 3.99835724
 3.99905183 3.99917388 3.99946409 3.99958494 3.99958971 4.00021177
 4.00073403 4.00089616 4.00096267 4.00118076 4.00154613 4.00171822
 4.00182259 4.00183496 4.00242753 4.00246276 4.00247748 4.00273408
 4.00282913 4.00293844 4.00373974 4.00408736 4.00461341 4.00465766
 4.00488561 4.00488675 4.00540788 4.00633696 4.00696873 4.00725393
 4.00743005 4.00756364 4.0077189  4.00792583 4.00826477 4.00861375
 4.00870748 4.00891468 4.00945177 4.00963448 4.00964845 4.00970416
 4.00984736 4.01009659 4.0101457  4.01031003 4.01095656 4.01133965
 4.01158835 4.01164955 4.0134166  4.01360887 4.01381511 4.01438784
 4.01504618 4.01508199 4.01527345 4.0153396  4.016166   4.01639994
 4.01682794 4.01692566 4.01746972 4.01827198 4.0184684  4.0187549
 4.01943774 4.01987869 4.02061605 4.02293456 4.02405901 4.02461599
 4.0255552  4.02648331 4.02665474 4.02751654 4.02772986 4.02913268
 4.02951593 4.03153622 4.03164048 4.0323375  4.03260297 4.03404306
 4.03656243 4.04198384 4.04610052 4.04920163 4.05073821 4.05208472
 4.05400819 4.05413497 4.09553982 4.13304559 4.24818435 4.25014518
 4.88032402 4.92500739 4.93287767 4.94424501 4.95259954 4.97011613
 4.97373616 4.97707663 4.97716199 4.97869186 4.98041347 4.98118557
 4.98385102 4.98449472 4.9895749  4.98999273 4.99020544 4.99103037
 4.99196117 4.9990717  4.99973049 5.00013572 5.000633   5.00065184
 5.00268894 5.00282328 5.00389358 5.00402433 5.00492498 5.00614447
 5.0065816  5.0066396  5.00692136 5.00736374 5.01197431 5.0121501
 5.01313054 5.01717935 5.0190145  5.02311138 5.03381301 5.04072716
 5.04322291 5.06701429]

  warnings.warn(

2022-12-16 10:37:15,162:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.31392992 3.34085348 3.34253905 3.34844446 3.34904354 3.35174035
 3.35955717 3.36178687 3.36445257 3.36844958 3.38344514 3.85538521
 3.89799133 3.89841131 3.90240581 3.90246069 3.90257829 3.90458327
 3.9046921  3.90817942 3.91019474 3.91040286 3.91079629 3.91324445
 3.91352768 3.91445396 3.91531378 3.91677118 3.91759987 3.91777448
 3.91950054 3.91956391 3.91981246 3.91987317 3.9204459  3.92262245
 3.92367132 3.92442766 3.9252016  3.92524727 3.92624897 3.92653345
 3.92661643 3.9274362  3.92871292 3.93183351 3.93190277 3.93214018
 3.93246956 3.93303701 3.93379109 3.93384126 3.93407792 3.93496205
 3.93789495 3.93809763 3.93922939 3.93943653 3.93952434 3.9397428
 3.93975997 3.94032059 3.94042957 3.94057116 3.94057307 3.9410441
 3.94135681 3.94138043 3.94142076 3.94159959 3.9416387  3.94176444
 3.94211158 3.94212655 3.94230626 3.94306444 3.94307629 3.94337198
 3.94392896 3.94427789 3.94456228 3.94490924 3.94501539 3.9454055
 3.94563793 3.94576466 3.94578608 3.94582882 3.94603941 3.9463722
 3.94661363 3.94669367 3.94690576 3.9472784  3.94747347 3.94820604
 3.94832184 3.94848403 3.948542   3.94855714 3.94887236 3.94891313
 3.94892768 3.94910005 3.94948272 3.94958492 3.94964932 3.94966666
 3.94983977 3.949865   3.94998596 3.95005001 3.95015715 3.95030105
 3.95058806 3.95091345 3.95118923 3.9514213  3.95161444 3.95172215
 3.95179155 3.95211248 3.95217629 3.95228738 3.95246895 3.95248872
 3.95251204 3.95256424 3.95263099 3.95267299 3.9527987  3.95347846
 3.95401952 3.95418861 3.95420195 3.95437202 3.95447208 3.95450284
 3.95473706 3.95510117 3.95527031 3.95541705 3.95570047 3.95572143
 3.95590605 3.95608507 3.95615485 3.95629083 3.95651013 3.95658829
 3.95670936 3.95681525 3.95683367 3.95686886 3.95708262 3.9571621
 3.95734059 3.95735203 3.95752874 3.95754895 3.95761176 3.9578137
 3.95784729 3.95790422 3.95804111 3.9580916  3.95821163 3.95826142
 3.95842807 3.95846262 3.9585581  3.95860147 3.958756   3.95879102
 3.95884317 3.95892942 3.95900839 3.95907098 3.95939228 3.95951154
 3.95961945 3.95966198 3.95968613 3.95971436 3.95983294 3.95983462
 3.95985514 3.95990793 3.9600074  3.96004848 3.96007131 3.96023759
 3.96034897 3.96053164 3.96055379 3.96071849 3.96077569 3.96092864
 3.96095184 3.96096633 3.96103116 3.96105585 3.96107792 3.96108754
 3.96108878 3.96113118 3.96119289 3.96120584 3.96121695 3.96122997
 3.96124081 3.9614328  3.96150835 3.96153411 3.96159991 3.961607
 3.96162717 3.96165507 3.96198965 3.96215845 3.96225049 3.9624762
 3.96277208 3.96281345 3.9628354  3.96287278 3.96301554 3.9630773
 3.96309995 3.96314255 3.96315293 3.96326226 3.96328418 3.96330036
 3.9634466  3.96346351 3.96347597 3.96351407 3.96382388 3.96383894
 3.964129   3.96414127 3.96416598 3.96427168 3.9643186  3.96444875
 3.96450422 3.96451031 3.9645258  3.96453878 3.9645694  3.96464747
 3.96472111 3.96475918 3.96504438 3.96507195 3.96507753 3.96509168
 3.96515656 3.96517497 3.96518909 3.96525554 3.965285   3.96537527
 3.96537607 3.9654051  3.96561023 3.96562666 3.96565737 3.96579602
 3.96607339 3.96607933 3.96625992 3.96630472 3.96643327 3.96651699
 3.96670195 3.96684639 3.96710227 3.96721901 3.96732875 3.96745453
 3.96745998 3.96746381 3.96747577 3.96765391 3.9677072  3.96774764
 3.96777467 3.96778792 3.9678561  3.96802751 3.96808448 3.96830388
 3.96835996 3.96838596 3.96840187 3.96849897 3.96853503 3.96867026
 3.96870069 3.96882002 3.96890032 3.96891783 3.96892654 3.96893889
 3.96894583 3.96895607 3.96896946 3.96905265 3.96908086 3.96917088
 3.96917937 3.96919862 3.96924768 3.96937085 3.96938372 3.96943522
 3.96945908 3.96947853 3.969496   3.96954956 3.96955033 3.96960064
 3.96962001 3.96967167 3.96973472 3.96976721 3.96986387 3.96987863
 3.96997163 3.97004053 3.97006574 3.97011213 3.97016839 3.97027282
 3.97029946 3.97033769 3.97035617 3.97037659 3.97040129 3.97071025
 3.97078988 3.97084601 3.97088098 3.97089371 3.97091582 3.97096136
 3.97097141 3.97100047 3.9710795  3.97118051 3.97118976 3.97120648
 3.9713177  3.97135965 3.97139028 3.9713936  3.97143793 3.97154188
 3.97164615 3.97167185 3.97168299 3.97170766 3.97193558 3.9719462
 3.97195768 3.97202978 3.97205869 3.97209029 3.97209219 3.9721489
 3.97224866 3.97234098 3.97245804 3.97256359 3.97256952 3.97263688
 3.97265765 3.97272649 3.97288375 3.97290454 3.97294196 3.97299453
 3.97301958 3.97302089 3.97303925 3.97307415 3.9731125  3.97311526
 3.97322348 3.97334571 3.97345869 3.97353888 3.9736003  3.97361086
 3.97362122 3.97372162 3.97374966 3.97403957 3.97404504 3.97414415
 3.97426774 3.97431574 3.9743747  3.97445373 3.97455028 3.97457747
 3.97462477 3.97467712 3.97468085 3.97469082 3.97482891 3.97492118
 3.9750879  3.97510278 3.97516292 3.9751739  3.97517424 3.97523821
 3.97525015 3.97525684 3.97531764 3.97542834 3.97545435 3.97548935
 3.97555275 3.97561108 3.97563751 3.97567443 3.97567928 3.97571291
 3.97572868 3.97591571 3.97594155 3.97596903 3.97604442 3.97606787
 3.97606932 3.9761533  3.97618463 3.97625341 3.97628533 3.97629038
 3.97640656 3.97642959 3.97646597 3.97652163 3.97666028 3.97666713
 3.97667966 3.97672459 3.9767545  3.97689679 3.97695786 3.97696241
 3.97701971 3.97703687 3.97707453 3.97714436 3.977154   3.97727722
 3.97757943 3.9775881  3.97761985 3.97764192 3.97766096 3.9779933
 3.97820386 3.97827695 3.97829828 3.97831171 3.97831207 3.9784738
 3.97849877 3.97854424 3.97855794 3.97874243 3.97875749 3.97881077
 3.97886537 3.9788655  3.97888021 3.97889583 3.97889816 3.97894826
 3.97895498 3.9789608  3.97898873 3.97907767 3.97912648 3.97914505
 3.97916667 3.97917348 3.97921544 3.97927176 3.97930159 3.97935002
 3.97946475 3.97946616 3.97951744 3.97959555 3.97971134 3.97989552
 3.9799688  3.97998754 3.98000054 3.98000618 3.98002141 3.98003486
 3.98015138 3.98041033 3.980426   3.98056964 3.98058905 3.9806035
 3.98064118 3.98068428 3.9807129  3.98076183 3.98077278 3.98085677
 3.98097589 3.98098787 3.98110463 3.98120217 3.98136456 3.98143744
 3.98147673 3.9816542  3.98171591 3.98172745 3.9817506  3.98175841
 3.98185143 3.98188703 3.98190161 3.98190252 3.98198944 3.98200002
 3.98201848 3.98203846 3.98208094 3.9822766  3.98228712 3.98231817
 3.98241127 3.98245015 3.98248757 3.98261541 3.98262714 3.98275707
 3.98277847 3.98278032 3.98302763 3.98304769 3.98311061 3.98318398
 3.98328182 3.983403   3.98340937 3.98356487 3.98357435 3.98359755
 3.98364274 3.98370583 3.98372676 3.98373312 3.98386642 3.98388546
 3.98392524 3.98411129 3.9841258  3.98417121 3.98429768 3.984384
 3.98448369 3.98452468 3.98452487 3.98457731 3.9847135  3.98486823
 3.98490448 3.9849123  3.98491315 3.98495406 3.98500858 3.98510517
 3.98511407 3.98514539 3.98524398 3.98542423 3.98544948 3.98551695
 3.98552232 3.98559623 3.98564241 3.98564308 3.98566824 3.98573044
 3.98574351 3.98575452 3.98581594 3.98590121 3.98595062 3.98595724
 3.98597653 3.98606013 3.98611477 3.98616614 3.98618228 3.98627964
 3.98628095 3.98640661 3.98651106 3.98652828 3.98657343 3.98678867
 3.98697028 3.98702438 3.98703122 3.98715451 3.98743908 3.98745218
 3.98746887 3.98747182 3.98754611 3.98760687 3.98792007 3.98795245
 3.98797004 3.9880431  3.98804915 3.98810313 3.98817161 3.9882828
 3.98840255 3.9887443  3.98875568 3.98882482 3.98883511 3.98885942
 3.98895358 3.9890334  3.98912883 3.98931011 3.98942752 3.98957677
 3.98963055 3.98984769 3.9899393  3.99020621 3.99021027 3.99032965
 3.99033371 3.99040203 3.990482   3.99055827 3.99061994 3.99070859
 3.990737   3.99085071 3.99091875 3.99106993 3.99107871 3.99115014
 3.99116051 3.99133407 3.99142411 3.991437   3.99163984 3.99164001
 3.9916537  3.99185607 3.99201959 3.99219079 3.99221899 3.99260804
 3.99264974 3.99268098 3.99271903 3.99281374 3.99297444 3.9930318
 3.99364829 3.99365203 3.99372637 3.99375722 3.99387718 3.99391814
 3.99401093 3.99428612 3.99445966 3.99448096 3.9946744  3.99481765
 3.9948917  3.9949048  3.99495824 3.99496792 3.99533019 3.99534923
 3.99561111 3.99585283 3.99599101 3.99653572 3.99656216 3.99682128
 3.99692099 3.99697505 3.99721463 3.99734201 3.99753979 3.99813993
 3.9981731  3.99836552 3.99865149 3.9987472  3.99900358 3.99907096
 3.9991202  3.99921024 3.99932812 3.999421   3.99950067 3.99956192
 3.99960891 3.99973321 3.99984955 4.00016054 4.00034112 4.00065899
 4.00075628 4.00081676 4.00087246 4.00127186 4.00147024 4.00149077
 4.00164155 4.00175942 4.00197539 4.0021488  4.00224807 4.00230357
 4.00308952 4.00329388 4.00334582 4.00335709 4.00420561 4.00444483
 4.00546264 4.00560036 4.00585832 4.00647975 4.00661552 4.00754608
 4.0076763  4.00788113 4.0083177  4.00875411 4.00905714 4.00917424
 4.00935804 4.00946863 4.009527   4.01094436 4.01107476 4.01112994
 4.01186297 4.01243789 4.01302812 4.01311325 4.013261   4.01333168
 4.01367715 4.01381323 4.01393861 4.0149027  4.01502352 4.01564768
 4.0159364  4.0162333  4.0173437  4.01922393 4.02063703 4.020994
 4.02115164 4.02144285 4.02169474 4.02240451 4.02297684 4.02345304
 4.02397735 4.02546089 4.02554074 4.02635793 4.02802871 4.02913626
 4.02938775 4.03003704 4.03138123 4.0331624  4.03571632 4.03587081
 4.03764179 4.04174862 4.04661149 4.0523654  4.08681687 4.91262671
 4.91514066 4.94117518 4.94782996 4.96099485 4.9624128  4.96490908
 4.96691536 4.96733833 4.96786559 4.96850507 4.96874157 4.96960957
 4.96973243 4.97093936 4.97358938 4.97376929 4.97406548 4.97426007
 4.97452842 4.97824369 4.97918252 4.97978858 4.98232685 4.98306574
 4.98501016 4.98578231 4.98578698 4.98740116 4.98764928 4.98773151
 4.98846066 4.98885319 4.99006789 4.99024837 4.99165962 4.99537806
 4.9969655  4.99767952 5.00420983 5.00508462 5.00616742 5.0145123
 5.03645427]

  warnings.warn(

2022-12-16 10:37:15,165:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.96047128 1.98330386 1.99464668 2.00304661 2.00361804 2.01068133
 2.01786103 2.02472868 2.0258846  2.03229376 2.03987169 2.04048234
 3.65241057 3.77765077 3.78699756 3.79256775 3.79571477 3.80478495
 3.81599507 3.81674884 3.83564085 3.84047209 3.84512359 3.85903817
 3.86029304 3.86199565 3.86833508 3.87204634 3.87835278 3.88315963
 3.88765392 3.88781664 3.88933838 3.89024063 3.89138867 3.89276281
 3.89381699 3.8940979  3.89447142 3.89515826 3.89581623 3.89586921
 3.89694927 3.89810258 3.89811505 3.89888398 3.89922136 3.90091207
 3.90097572 3.90366742 3.9041777  3.9044839  3.90458011 3.90484563
 3.90503412 3.90570041 3.90575818 3.90602154 3.90602396 3.90683731
 3.90712533 3.90761302 3.90783219 3.90811887 3.91091877 3.91126322
 3.91140022 3.91179152 3.91237468 3.91258892 3.91291683 3.91297327
 3.91331451 3.9134086  3.91356829 3.91421333 3.91426909 3.91429805
 3.91453772 3.91504051 3.91527829 3.91556302 3.91572356 3.91602824
 3.91623518 3.91703262 3.91717224 3.91752756 3.91770848 3.91797436
 3.91807064 3.91822079 3.91863357 3.91882892 3.91894319 3.919539
 3.91972278 3.91975839 3.91982746 3.91988982 3.91994407 3.91999414
 3.92115491 3.92164748 3.92178838 3.92192106 3.92203513 3.92223934
 3.92228702 3.92265284 3.92306533 3.92328371 3.92328465 3.92349017
 3.92376663 3.92384647 3.92387183 3.92389452 3.92485258 3.92504691
 3.92570882 3.92587579 3.92616373 3.9263646  3.92642466 3.92665472
 3.92682362 3.92683288 3.92703741 3.9272124  3.92738735 3.9274918
 3.92749759 3.92750622 3.92750717 3.92788616 3.92823044 3.9282379
 3.92830395 3.92858837 3.92869915 3.92871428 3.92884763 3.92914957
 3.92922304 3.92950177 3.929528   3.9296874  3.93025108 3.93075758
 3.93100635 3.93102905 3.93124863 3.93134974 3.93143893 3.93176106
 3.93181174 3.93227725 3.93235407 3.93249173 3.93285498 3.93288586
 3.93288925 3.93292297 3.93346653 3.93353472 3.93358573 3.93373506
 3.93378523 3.93400145 3.93415773 3.93416523 3.93421729 3.93422552
 3.93438207 3.93454349 3.93463623 3.93487912 3.93511662 3.93522484
 3.93545344 3.93546039 3.93551535 3.93558426 3.93582782 3.93607739
 3.9363465  3.93635248 3.93635706 3.9366375  3.93664691 3.93721461
 3.93727217 3.93742242 3.93754352 3.93775251 3.93795472 3.93845155
 3.93871959 3.9389902  3.93914606 3.93961749 3.93974455 3.93978095
 3.93981343 3.94018122 3.94019955 3.94048739 3.94062805 3.94067278
 3.94071509 3.94130509 3.94143525 3.94144375 3.94149263 3.94164042
 3.94171031 3.94198996 3.9423104  3.94239829 3.94240333 3.94251998
 3.94260796 3.94267178 3.94294598 3.94303282 3.94305257 3.94317031
 3.94335861 3.94351421 3.94353124 3.94356773 3.94375163 3.94375303
 3.94380125 3.9439393  3.9439888  3.94415103 3.94435505 3.94451799
 3.94460498 3.94466415 3.94475006 3.94488726 3.94495051 3.94505216
 3.94508409 3.94517962 3.94547859 3.94564559 3.94565073 3.94581854
 3.94612842 3.94625958 3.94630278 3.94635278 3.94645345 3.94650932
 3.9466879  3.94675152 3.94679422 3.9469252  3.94702357 3.94717444
 3.94763222 3.94775297 3.94777451 3.94804124 3.94822812 3.94824026
 3.9485655  3.9487025  3.94881554 3.94895209 3.9490238  3.94925576
 3.94927257 3.94929654 3.94961544 3.94962477 3.94964482 3.94965851
 3.94976892 3.94983306 3.94998485 3.95006878 3.95066199 3.95067304
 3.9507021  3.95084562 3.95090379 3.95091546 3.95103901 3.95111835
 3.9511819  3.95122378 3.95124293 3.95139643 3.95147818 3.95149178
 3.95159047 3.9518156  3.95183131 3.95188633 3.95188714 3.95199027
 3.95235511 3.95319477 3.95320898 3.95324114 3.95325537 3.9533566
 3.9534418  3.95349587 3.95355647 3.9536402  3.9537591  3.95377955
 3.95381855 3.95382676 3.9538878  3.95393114 3.95396569 3.95397967
 3.95412088 3.95454373 3.95466851 3.95467524 3.95473646 3.95474775
 3.95474866 3.95479612 3.95487699 3.9549812  3.95501943 3.95512483
 3.95535339 3.95543809 3.95561173 3.95561941 3.9557402  3.9558772
 3.9558953  3.95602178 3.95602749 3.95614312 3.95626887 3.95633226
 3.95634971 3.95676239 3.95683714 3.956897   3.95691197 3.95726155
 3.95733543 3.95733819 3.95742445 3.9574683  3.95748738 3.95754316
 3.95755022 3.9576736  3.9577437  3.95784651 3.9579412  3.95796683
 3.95797949 3.95800826 3.95813996 3.95818411 3.95820314 3.95832864
 3.95852997 3.95858538 3.95864026 3.95866712 3.95891419 3.95891719
 3.95908918 3.95916578 3.95918991 3.95924988 3.95931074 3.95936155
 3.95937083 3.95948154 3.95950291 3.95955862 3.95992671 3.96004233
 3.96007777 3.96025175 3.96026844 3.96027253 3.96037574 3.96042794
 3.96053975 3.9605979  3.96081216 3.96089375 3.96102344 3.96118285
 3.96135736 3.96161567 3.96169862 3.9618222  3.96182906 3.96217462
 3.96218503 3.96221354 3.96228795 3.96231964 3.96232778 3.96246525
 3.96252957 3.96256902 3.96262622 3.96275548 3.96295443 3.96297271
 3.96307099 3.96327383 3.96329364 3.96340532 3.96341083 3.96348204
 3.96352015 3.96367801 3.96380965 3.96382509 3.96385275 3.96392372
 3.96394326 3.96398767 3.96407977 3.96430513 3.9643843  3.9644169
 3.96442966 3.96445929 3.96452272 3.96455294 3.96477963 3.96485314
 3.96498611 3.96520259 3.96551462 3.96559051 3.96565767 3.96567045
 3.96591789 3.96592938 3.96593742 3.96598656 3.9660216  3.96609315
 3.96625126 3.96645401 3.96653924 3.96656377 3.96664263 3.96667345
 3.96675103 3.96678458 3.96679596 3.96692508 3.967003   3.96703776
 3.96723783 3.96730517 3.9673641  3.96741927 3.96742102 3.9674544
 3.96752929 3.96782985 3.96812036 3.96815186 3.96816923 3.96846926
 3.9685189  3.9686745  3.9687288  3.9688565  3.96891166 3.968919
 3.96891946 3.96894129 3.96902725 3.96917603 3.96922683 3.96932648
 3.96937163 3.96947237 3.96974682 3.96987424 3.969882   3.97004021
 3.97034517 3.9703648  3.9704642  3.97049414 3.97057799 3.97067317
 3.97100487 3.97126055 3.97137259 3.97141682 3.97145978 3.97153992
 3.97157766 3.97161347 3.97163255 3.97165651 3.97167064 3.97169978
 3.97171192 3.97171332 3.97172639 3.97193727 3.97202387 3.97202715
 3.97213076 3.97214604 3.97221734 3.97225515 3.97242995 3.97248863
 3.97260125 3.97263644 3.97274538 3.97311902 3.97316206 3.97321336
 3.97371672 3.97386873 3.97403986 3.97426749 3.97443229 3.97454851
 3.97463867 3.97475977 3.97484919 3.97506747 3.97522931 3.97527112
 3.97544087 3.97544363 3.97547785 3.97556975 3.97559472 3.97596961
 3.97605331 3.97628472 3.97642762 3.97651375 3.97660411 3.97687647
 3.97696857 3.9770259  3.97703936 3.97720746 3.97733403 3.97738314
 3.97747631 3.97749829 3.97750797 3.97756917 3.97758972 3.97779814
 3.97797794 3.97825245 3.97825913 3.97827422 3.97898273 3.97905981
 3.97913791 3.9791461  3.97931444 3.97949932 3.97954803 3.9795974
 3.97988686 3.97997679 3.98004664 3.98008419 3.98053183 3.98054353
 3.980689   3.98097968 3.98107324 3.981334   3.98172383 3.98179966
 3.98184785 3.9821622  3.98243814 3.98253406 3.98264593 3.98313477
 3.98316767 3.98333217 3.983333   3.98339331 3.98402238 3.98426275
 3.98433582 3.98445295 3.98464498 3.98506058 3.98533346 3.98541627
 3.98544745 3.9855327  3.98582211 3.98583644 3.98601654 3.98609945
 3.9863286  3.98634896 3.98637423 3.98639889 3.98678923 3.98679444
 3.98682259 3.98714495 3.98738297 3.98777434 3.98803711 3.98824959
 3.98841184 3.98859366 3.9886168  3.98865338 3.98868682 3.98874218
 3.98877325 3.9889398  3.98905639 3.98908889 3.98911947 3.98921536
 3.98932991 3.98946485 3.98951232 3.98959336 3.98967423 3.98967929
 3.98978179 3.98978371 3.99024177 3.99064255 3.99070752 3.9908134
 3.99083661 3.99085969 3.99123386 3.99166361 3.99170078 3.99243277
 3.99259267 3.99271042 3.99280589 3.99291908 3.99302112 3.99309607
 3.99326419 3.99329234 3.99349706 3.99355851 3.99361652 3.99393538
 3.9940947  3.99421198 3.99454738 3.99474184 3.99520833 3.99523047
 3.99536628 3.99567598 3.99581336 3.99593903 3.99597615 3.99604749
 3.99611946 3.99621422 3.99644    3.99649273 3.99675148 3.99682531
 3.9969546  3.99729264 3.99743899 3.99750452 3.99810052 3.99831622
 3.99849229 3.99853902 3.9991156  3.99916794 3.99919201 3.99921739
 3.99925108 3.99973968 3.99980006 3.99989817 3.99993359 3.9999405
 4.00009298 4.000228   4.0002343  4.00068036 4.00069176 4.00078419
 4.0010019  4.00108428 4.00124258 4.00167278 4.00223036 4.00236265
 4.00251606 4.00269067 4.0028549  4.00330947 4.00399642 4.00460856
 4.004818   4.00486189 4.00509151 4.00522813 4.00526791 4.00534348
 4.0055677  4.00624196 4.00664013 4.00697117 4.00701223 4.0072988
 4.00731715 4.00752709 4.00790234 4.00820395 4.00827307 4.00840432
 4.00892549 4.00892683 4.01002172 4.01085023 4.01113274 4.01170737
 4.01226016 4.01239322 4.01279139 4.01380688 4.01389835 4.01392578
 4.01423357 4.0144867  4.01497322 4.01509979 4.01527145 4.01537912
 4.01617713 4.01636071 4.0165479  4.01726736 4.01753327 4.01784918
 4.01790256 4.01952407 4.02114533 4.02135598 4.02143804 4.02208254
 4.0221613  4.02253162 4.022587   4.02266068 4.0236351  4.02626206
 4.02639845 4.02887901 4.02893578 4.02945628 4.03072694 4.03173064
 4.03267542 4.03384115 4.03541767 4.03559776 4.03589498 4.03602284
 4.03768862 4.03782528 4.0386082  4.0389335  4.03973089 4.04196568
 4.04293882 4.04338732 4.04486367 4.04584891 4.05205439 4.05279818
 4.05320252 4.05465338 4.05737384 4.05939327 4.06091111 4.06739206
 4.0780494  4.08634353 4.10291854 4.10369381 4.12364437 4.22194494
 4.8018156  4.82263997 4.86701986 4.87199375 4.9109764  4.91161685
 4.91219491 4.91517425 4.91598828 4.92503302 4.92694118 4.93280851
 4.93370401 4.93550676 4.93753413 4.94216168 4.94426062 4.95797531
 4.9612991  4.96345597 4.96615806 4.97039109 4.97275573 4.97356993
 4.97383309 4.97586636 4.97705976 4.97866139 4.98034543 4.98328652
 4.98389858 4.98680422 4.98996128 4.99004855 4.9925343  5.00118235
 5.00434433 5.00691771 5.00969636 5.01205714 5.03333254 5.06807209
 5.12236367]

  warnings.warn(

2022-12-16 10:37:15,175:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.65271651 2.71240837 2.72215961 2.72643048 2.73519667 2.75719883
 3.89409348 3.89887575 3.90025588 3.90418589 3.909268   3.91239329
 3.91616112 3.91764768 3.91894673 3.92048361 3.92086337 3.92237135
 3.92389324 3.92441959 3.92451669 3.92728562 3.92793659 3.92881134
 3.93120162 3.93129624 3.93165201 3.932866   3.93477032 3.9347846
 3.93507767 3.93569417 3.93635224 3.93653924 3.93734842 3.93761082
 3.93797051 3.93856555 3.93948329 3.94021363 3.94060612 3.94063834
 3.94108505 3.94148722 3.94157714 3.94177426 3.94224727 3.94322396
 3.94380051 3.9438139  3.94404484 3.94417481 3.94418051 3.94437823
 3.94444391 3.94466239 3.9447065  3.9452798  3.94552999 3.94601605
 3.9461813  3.94637687 3.94672676 3.94742506 3.94821229 3.94822363
 3.94823545 3.94838546 3.94963285 3.94977422 3.94993652 3.94997617
 3.95014246 3.95024158 3.95028095 3.95049217 3.95081812 3.95137409
 3.95145584 3.95192831 3.9519731  3.95198845 3.952542   3.95256342
 3.95295806 3.95325649 3.95349203 3.95354369 3.95362755 3.95365721
 3.95373014 3.9538267  3.95412315 3.95422123 3.95425405 3.95427632
 3.95432099 3.95449194 3.95491077 3.95515667 3.95527613 3.95576143
 3.95583089 3.95595006 3.95601202 3.95608925 3.95622358 3.95625567
 3.95627859 3.95634636 3.95635752 3.95645848 3.95663638 3.95684583
 3.95687358 3.95700018 3.95708741 3.9576128  3.95767339 3.95779325
 3.95782973 3.9581569  3.95822086 3.95838774 3.95862813 3.95865411
 3.95882658 3.95899073 3.95906988 3.95917729 3.95927841 3.95945237
 3.95955697 3.95971776 3.95981346 3.9598141  3.96008884 3.96012148
 3.96018513 3.96031164 3.96039037 3.9604297  3.96079508 3.96082352
 3.96085066 3.96085535 3.9610575  3.96107868 3.96139682 3.96149545
 3.96167066 3.96194969 3.9619508  3.96202836 3.96205939 3.96215313
 3.96220891 3.96227992 3.9623079  3.96248746 3.96252555 3.96253877
 3.96255413 3.96267159 3.96282279 3.96283325 3.9630029  3.9631225
 3.9632956  3.96333293 3.96340932 3.96341359 3.96353723 3.96375244
 3.96380056 3.9638112  3.96385355 3.96405318 3.96411332 3.96411809
 3.96416564 3.96426028 3.96427295 3.96442814 3.96444188 3.96452043
 3.96467087 3.9646811  3.9647086  3.96494719 3.96511712 3.965166
 3.96517277 3.96528159 3.96537069 3.96537823 3.96551799 3.96569274
 3.96593715 3.96596193 3.96598128 3.96598732 3.96601905 3.9661517
 3.96618645 3.96619036 3.96625015 3.96629391 3.96635977 3.96658081
 3.96660313 3.96667187 3.96680179 3.96681655 3.96685654 3.96692853
 3.96693397 3.96696099 3.96714688 3.96722642 3.9672765  3.96750578
 3.96753503 3.96760941 3.96762538 3.96765478 3.96766586 3.96776893
 3.96815141 3.96825754 3.96833567 3.96835813 3.96873464 3.96875863
 3.96877086 3.96887593 3.96890875 3.96892354 3.96900374 3.96900576
 3.96909582 3.96909681 3.96914587 3.96915809 3.96936582 3.96937492
 3.96938989 3.96941673 3.96942186 3.96956737 3.96974466 3.9698813
 3.9698961  3.97006267 3.97009195 3.970207   3.97024969 3.97030531
 3.9704609  3.97047933 3.97061783 3.97079224 3.97082262 3.97084171
 3.97086713 3.97108422 3.97115573 3.97117903 3.97125777 3.97128956
 3.97138973 3.97145042 3.97147622 3.97153975 3.97164355 3.97165503
 3.97168264 3.97172058 3.97176378 3.97177664 3.97178134 3.97189143
 3.97189632 3.97213471 3.9721436  3.97217869 3.97217995 3.97253523
 3.97257685 3.97261053 3.97267009 3.97267368 3.97300827 3.97303359
 3.97307028 3.973084   3.97309257 3.97313016 3.97315259 3.97323761
 3.97336249 3.9734658  3.97349284 3.97369203 3.97373783 3.97375753
 3.97376965 3.97383664 3.97392368 3.97399267 3.97404136 3.97406771
 3.97409872 3.97411311 3.97415356 3.9742559  3.97444135 3.97445719
 3.97449473 3.9745109  3.97452001 3.97462185 3.97469495 3.97482611
 3.97486069 3.97489656 3.97496688 3.97512075 3.97519008 3.97525337
 3.97526768 3.9752834  3.9752961  3.97534893 3.97540532 3.97541315
 3.97544985 3.97547186 3.97548566 3.97549333 3.97551871 3.97560815
 3.97562133 3.9756296  3.97565201 3.97568256 3.97574457 3.97584169
 3.97592231 3.97607626 3.97618714 3.97625522 3.97629502 3.97642254
 3.97650929 3.97657332 3.97657378 3.97661571 3.9767874  3.97689471
 3.97691497 3.9772324  3.97731434 3.97739227 3.97740794 3.97742409
 3.97746561 3.97754603 3.97759238 3.97759685 3.97775407 3.97775793
 3.97787205 3.97789319 3.97797929 3.97803827 3.9780439  3.97819174
 3.97821769 3.97829356 3.97830389 3.97830723 3.97837111 3.97838132
 3.97842129 3.97843361 3.97844557 3.97845828 3.97847531 3.97857246
 3.97863116 3.97866938 3.97870136 3.97881752 3.9788326  3.97892722
 3.97912445 3.97913185 3.97918286 3.97926811 3.97935928 3.97939876
 3.97944567 3.97946439 3.97950608 3.97958926 3.97964239 3.97965216
 3.97973654 3.9797506  3.97975452 3.9797924  3.97989993 3.97992619
 3.97999212 3.98015833 3.98019611 3.98020083 3.98023354 3.98027783
 3.98039888 3.98049206 3.9808567  3.98094274 3.98102079 3.98105023
 3.98106201 3.98118878 3.98126291 3.98129176 3.98129473 3.98139963
 3.98141699 3.98151185 3.98155594 3.98167639 3.98168124 3.98170884
 3.9817324  3.98177975 3.9818639  3.98186459 3.98198021 3.98215246
 3.98222743 3.98230356 3.98239063 3.98258565 3.98268708 3.98270236
 3.9827578  3.9828157  3.98288247 3.9830292  3.98306768 3.98308341
 3.98324199 3.98325915 3.98334705 3.98338361 3.98340136 3.98345501
 3.98347159 3.98350169 3.98362125 3.98367967 3.98379706 3.983836
 3.98391411 3.98393217 3.98402901 3.98435948 3.98438197 3.98440416
 3.98452864 3.98455111 3.98475647 3.98478895 3.98479642 3.98484352
 3.98494425 3.98500599 3.98503426 3.98504491 3.98508733 3.98509352
 3.9851005  3.98511669 3.98511773 3.98516627 3.98519584 3.98522109
 3.98539893 3.98543981 3.98556251 3.98558672 3.98562128 3.98568731
 3.98569081 3.98570887 3.98571709 3.98573176 3.98595177 3.98610657
 3.98610853 3.98623232 3.98640069 3.98649472 3.98662807 3.986657
 3.98666578 3.98673467 3.98678234 3.98681425 3.9868168  3.98682394
 3.98693094 3.98707266 3.98709561 3.98712711 3.98723125 3.98723161
 3.98726468 3.98735547 3.98752177 3.98762073 3.987639   3.98764224
 3.98765681 3.98769765 3.9877627  3.98785792 3.98787432 3.9879393
 3.98797201 3.98813332 3.9881337  3.98821048 3.98822772 3.98824585
 3.98826132 3.98831443 3.98841408 3.98853855 3.98854682 3.98855236
 3.98861816 3.98864948 3.98876704 3.98883976 3.98895211 3.98909466
 3.98914049 3.98927406 3.98935283 3.98941824 3.98945276 3.9894806
 3.98955775 3.98956538 3.98961108 3.98963534 3.98966781 3.9897797
 3.98997805 3.99009839 3.99012513 3.99021306 3.99021793 3.99022195
 3.99022703 3.99025646 3.99029871 3.99041117 3.99045037 3.99049518
 3.9905054  3.99059868 3.99060317 3.99060663 3.99066904 3.99069776
 3.99081925 3.9908408  3.99092048 3.99103379 3.99109976 3.99114401
 3.99123867 3.99132377 3.99137604 3.99143153 3.99155848 3.99161284
 3.99166588 3.99178556 3.99187325 3.99192456 3.99199421 3.99203162
 3.99213845 3.99221378 3.99222344 3.99227307 3.99231971 3.99232368
 3.99232692 3.99235216 3.9923587  3.99242273 3.99244924 3.99254841
 3.99257513 3.99261255 3.99262678 3.99262751 3.99279609 3.99282654
 3.99285021 3.99288281 3.9929254  3.99293703 3.99297294 3.99297778
 3.99309494 3.99311907 3.99315249 3.99320018 3.99330045 3.99330553
 3.99344225 3.993489   3.99353495 3.99365728 3.99366453 3.99368653
 3.99369976 3.99390708 3.99410669 3.99432168 3.99450086 3.99453915
 3.99455815 3.9946706  3.99469514 3.99479374 3.99494561 3.99526715
 3.99538548 3.99544011 3.99558905 3.99571436 3.99578874 3.99585982
 3.99590991 3.99594756 3.99595583 3.99596493 3.99601774 3.99609157
 3.99618881 3.99624942 3.99644691 3.99651996 3.99657872 3.99659195
 3.99667097 3.99669961 3.99671329 3.9968224  3.99723392 3.99728035
 3.99728797 3.99734012 3.99739679 3.99746769 3.99761624 3.99778531
 3.99793351 3.99804846 3.9982356  3.99830874 3.99831027 3.99832052
 3.99836032 3.99840906 3.99860542 3.99875891 3.99899132 3.99915042
 3.99944809 3.99951236 3.99988779 4.00002918 4.00004711 4.00057572
 4.00064903 4.00080617 4.00096133 4.00129337 4.00130051 4.00132852
 4.00171421 4.00172313 4.00209696 4.00217402 4.00240637 4.00245801
 4.00248609 4.00260592 4.00280113 4.00283359 4.00289378 4.00292686
 4.00325905 4.00327526 4.0034874  4.0035826  4.00359612 4.00376327
 4.0038649  4.00434722 4.00436779 4.00444264 4.00475253 4.00544867
 4.00560373 4.00565644 4.00596308 4.00607467 4.00624055 4.00635864
 4.0063701  4.00638523 4.00699156 4.00719104 4.00738862 4.00775128
 4.00778393 4.00799168 4.00806118 4.00821743 4.00902473 4.00913794
 4.00932471 4.00948037 4.00952055 4.0097353  4.01044854 4.01059384
 4.01064256 4.01092176 4.0109848  4.01103108 4.01149741 4.01184591
 4.01190893 4.01213913 4.01216521 4.0123001  4.01241622 4.01246906
 4.01279699 4.01285133 4.0133792  4.01347005 4.01373667 4.01376125
 4.01388617 4.01402141 4.01421084 4.01445339 4.01489984 4.01500461
 4.01534137 4.01546128 4.01569593 4.016498   4.01749719 4.01781758
 4.01827972 4.01844821 4.01929664 4.01945165 4.01949487 4.01979842
 4.02010561 4.02024339 4.02040544 4.02066356 4.02080802 4.02122263
 4.02159584 4.02202547 4.02240072 4.02253548 4.02276439 4.02286037
 4.02332294 4.02499305 4.02501477 4.02643476 4.02685971 4.02740215
 4.02823245 4.03138704 4.0315868  4.03283039 4.03360693 4.03449115
 4.03731362 4.03848846 4.03908936 4.04201777 4.0649324  4.13540861
 4.91202993 4.92869193 4.95189989 4.95752715 4.96524137 4.96847839
 4.96933419 4.97066202 4.97099293 4.97105665 4.97266014 4.97391236
 4.97463604 4.97505624 4.97531453 4.97579092 4.97713362 4.97744814
 4.97930439 4.98178128 4.98359064 4.98396412 4.9840176  4.98413213
 4.98674524 4.98708002 4.98736167 4.98759012 4.99100952 4.99228634
 4.99441394 4.99607535 4.99615935 4.99679892 5.00085906 5.00211646
 5.00257947 5.00386557 5.0145066  5.01917264 5.02137418 5.05392594]

  warnings.warn(

2022-12-16 10:37:15,221:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.01944139 2.03619934 2.04070027 2.04930015 2.05351397 2.0833303
 3.60674198 3.61759818 3.85384862 3.86546827 3.87563338 3.88911824
 3.89170057 3.8930876  3.89531506 3.90006538 3.90207928 3.90292269
 3.90306499 3.90363475 3.90463699 3.90554415 3.90742946 3.90755858
 3.90795632 3.91002518 3.91103933 3.91356863 3.91471671 3.91489865
 3.91513632 3.91530338 3.91581047 3.91600727 3.9162811  3.91635997
 3.91652882 3.92010618 3.92023333 3.9212879  3.92187234 3.92205963
 3.92393854 3.92470665 3.92515349 3.92581805 3.92660865 3.9271869
 3.92742147 3.92754399 3.92777482 3.92840059 3.92888116 3.92930845
 3.93047053 3.93073177 3.93100862 3.93201028 3.93295824 3.93362413
 3.93370365 3.9339266  3.93445247 3.93496699 3.93516567 3.9358929
 3.93619947 3.9378316  3.93793057 3.93805219 3.93811495 3.93852441
 3.93896403 3.93922076 3.93938451 3.94003196 3.9405613  3.94087625
 3.94088638 3.94100946 3.94125983 3.94134098 3.94135095 3.94135824
 3.94173999 3.9418371  3.9418693  3.9422387  3.94230771 3.94255661
 3.94267264 3.94296403 3.94343643 3.94414895 3.94451824 3.94472464
 3.94476944 3.94525477 3.94562002 3.94575107 3.94580876 3.94596597
 3.94605717 3.94616648 3.94648347 3.94657515 3.94658122 3.94670772
 3.94678797 3.94685928 3.94696669 3.94732826 3.9473899  3.94740371
 3.94748962 3.94758564 3.94786546 3.94791721 3.9479221  3.94796044
 3.94811856 3.94833743 3.94854205 3.94864591 3.9487309  3.94894563
 3.94906132 3.94908033 3.94922637 3.94924308 3.94937186 3.94948629
 3.94950137 3.94973244 3.9497346  3.94975999 3.95009348 3.9505241
 3.95057323 3.95064728 3.95083683 3.95107053 3.95112998 3.9514715
 3.95174776 3.95191628 3.9519396  3.95236831 3.95237367 3.95265561
 3.952685   3.95270761 3.95271902 3.95299837 3.95316927 3.95338083
 3.95368422 3.95375907 3.95380743 3.95382482 3.953903   3.95390649
 3.95400336 3.95401492 3.95409757 3.95419268 3.9544261  3.95448693
 3.95449075 3.95455408 3.95464917 3.9546516  3.95476577 3.95491572
 3.95500331 3.9550211  3.95506401 3.95512668 3.95516436 3.95530781
 3.95539784 3.95540483 3.95565424 3.95580416 3.95588706 3.95596618
 3.95634002 3.95642445 3.95654515 3.95655763 3.95665451 3.95679144
 3.95681087 3.95692943 3.95718552 3.95722693 3.95726461 3.95727502
 3.95748247 3.95757989 3.95769128 3.95770127 3.95783823 3.95791175
 3.95794671 3.95800248 3.95813718 3.95817093 3.95824903 3.95847276
 3.95856313 3.95856327 3.95860137 3.95864917 3.95872231 3.95887693
 3.95890185 3.9590003  3.95907621 3.9591156  3.95927447 3.95937002
 3.95945133 3.95946713 3.9594861  3.95954472 3.95966642 3.95966831
 3.95972624 3.95979761 3.95989616 3.96003641 3.96013677 3.96015116
 3.96020826 3.96022106 3.96026358 3.96043405 3.96056636 3.96056899
 3.96064374 3.96068687 3.96070174 3.96070913 3.960779   3.96084192
 3.96087668 3.96101063 3.96130094 3.96155474 3.96156671 3.96160772
 3.96181485 3.96182734 3.96183643 3.961863   3.96195542 3.96212046
 3.96240882 3.96251509 3.96265047 3.96266626 3.96267892 3.96282184
 3.96293218 3.96295765 3.96303523 3.96304458 3.96312691 3.96318688
 3.96319505 3.96331937 3.96336853 3.96338512 3.96347354 3.96351008
 3.96351964 3.96356857 3.9637098  3.96380052 3.96382663 3.963995
 3.96407138 3.96412192 3.964281   3.96437673 3.96440038 3.96467278
 3.96478412 3.96491545 3.96497904 3.96503336 3.9650964  3.96514545
 3.96519725 3.96528813 3.9653096  3.96534801 3.96538229 3.96538494
 3.96559127 3.96559578 3.96572943 3.96578383 3.96584781 3.96584975
 3.96585311 3.96591905 3.96592272 3.96597914 3.9660386  3.96604776
 3.96606199 3.96611071 3.96613159 3.96617212 3.96625955 3.9662645
 3.9662667  3.96633026 3.96633267 3.96641469 3.96641674 3.96655916
 3.96665067 3.96696869 3.9670102  3.96702356 3.96705453 3.9671122
 3.96720335 3.96721498 3.96727258 3.96729521 3.96738583 3.96749942
 3.96757725 3.96766457 3.96769848 3.96772836 3.96774133 3.96774628
 3.96791559 3.96791574 3.96806508 3.96807263 3.96808257 3.96812959
 3.96818522 3.96818749 3.96823765 3.9684237  3.96849171 3.96849792
 3.96855223 3.96860613 3.96863165 3.96867719 3.96874268 3.96887322
 3.9688816  3.96894328 3.96895943 3.96896799 3.96903528 3.96907357
 3.96910312 3.96922427 3.96924242 3.96924342 3.96925357 3.96926686
 3.9692767  3.96930817 3.96933257 3.96936544 3.96955618 3.96959044
 3.96966975 3.96985484 3.96989655 3.96995575 3.97009121 3.97023754
 3.97049619 3.97053063 3.97060026 3.97084546 3.97089748 3.97101005
 3.97128758 3.97129162 3.97130367 3.97131542 3.97131691 3.97134943
 3.9713561  3.97135678 3.97151397 3.97155129 3.97155385 3.97155725
 3.9716338  3.97164501 3.97173254 3.97180611 3.97183434 3.9718787
 3.97188359 3.9718916  3.97197233 3.97215048 3.97215212 3.97216448
 3.97229009 3.97245561 3.97258219 3.97262596 3.97263142 3.97272683
 3.97280701 3.97303067 3.9730431  3.9730803  3.97314368 3.97324866
 3.97326425 3.97343977 3.97349719 3.9735369  3.97367918 3.9737075
 3.97387908 3.97396719 3.97397136 3.97400685 3.97412465 3.97413947
 3.974165   3.97418561 3.97421371 3.97428378 3.97436856 3.97437438
 3.97443165 3.97448529 3.97451759 3.97455499 3.97458085 3.97463328
 3.97463879 3.97479873 3.97487161 3.97492027 3.97501284 3.97501355
 3.97503111 3.97503484 3.97504174 3.97506047 3.97508345 3.97522885
 3.97531318 3.97539112 3.97562733 3.97568573 3.97590192 3.97602311
 3.97603051 3.976159   3.97626114 3.97643473 3.97651195 3.9768499
 3.97694183 3.97698023 3.97706106 3.97717679 3.9772366  3.97731157
 3.97739887 3.97742786 3.97755318 3.97756726 3.97759377 3.9776002
 3.97761573 3.97766588 3.97772426 3.97774466 3.97778256 3.97788542
 3.97789875 3.97790443 3.97810244 3.97815202 3.97823425 3.9783771
 3.97841519 3.97845915 3.97848848 3.97852301 3.97857917 3.97866542
 3.97880409 3.97881593 3.97889673 3.97889796 3.97908497 3.9790896
 3.97909356 3.97919963 3.97924491 3.97927177 3.9792851  3.97932922
 3.97933752 3.97936841 3.9794109  3.97952102 3.97955774 3.97964815
 3.97975171 3.97978565 3.97985292 3.98018624 3.98029484 3.9803676
 3.98046162 3.98047666 3.98051671 3.98052737 3.98058712 3.98062495
 3.98068116 3.98070984 3.98071258 3.98085951 3.98086334 3.98091732
 3.98092909 3.9809521  3.98107098 3.98115649 3.98128294 3.98129937
 3.98131763 3.98134269 3.98137326 3.98147272 3.98167629 3.98177517
 3.98178686 3.98181199 3.98184968 3.9821576  3.98226101 3.98226609
 3.98230581 3.98234082 3.98234308 3.98239762 3.98252452 3.98274483
 3.9828132  3.98282249 3.98282469 3.98283807 3.98286145 3.98291882
 3.98299983 3.98317221 3.98320476 3.9833821  3.98340481 3.98344418
 3.9834876  3.98357713 3.98363573 3.98373508 3.98380943 3.9838388
 3.98384314 3.98402035 3.98419514 3.98433553 3.9843788  3.9843821
 3.98441643 3.98446671 3.98448808 3.98451288 3.9845197  3.98461863
 3.98470807 3.9848742  3.98503904 3.98510905 3.98516218 3.98522122
 3.9856178  3.9857481  3.98582384 3.98587063 3.98588108 3.98593109
 3.98596523 3.98628813 3.98632812 3.98633819 3.98639781 3.98642437
 3.98661056 3.9866777  3.98677503 3.98707401 3.98715571 3.9871565
 3.98719676 3.98742317 3.98746116 3.98749249 3.98755607 3.98765501
 3.98787552 3.9879281  3.98802474 3.98813549 3.98844497 3.98853318
 3.98859487 3.98883824 3.98884055 3.98909079 3.98919244 3.98920678
 3.98939159 3.98943711 3.98944974 3.98946533 3.9896671  3.98971584
 3.98976022 3.98978035 3.98983495 3.98984065 3.98984512 3.98984947
 3.98987723 3.98992455 3.99000425 3.99003611 3.99008802 3.99009943
 3.99021034 3.99042122 3.99052187 3.99062982 3.99073962 3.99083475
 3.99088217 3.99090647 3.99090966 3.99097675 3.99100979 3.99120641
 3.99126832 3.9912969  3.99131833 3.99133379 3.99139451 3.99142264
 3.99156761 3.99163755 3.99169748 3.99191839 3.99192738 3.99197464
 3.99199793 3.99200428 3.99213962 3.99222261 3.99223747 3.99226492
 3.99229544 3.99248424 3.99262194 3.99266356 3.99272176 3.99276462
 3.99301707 3.99305398 3.99311395 3.99312937 3.99319878 3.99336653
 3.99348989 3.99354342 3.9940029  3.99412323 3.99423084 3.9944613
 3.99448239 3.99486136 3.9953197  3.9958611  3.99589147 3.99590761
 3.99597416 3.99611328 3.99696174 3.99708691 3.99710034 3.99719634
 3.99760943 3.99777563 3.99792551 3.99834099 3.99835905 3.99850891
 3.99856586 3.99861216 3.99862581 3.99904956 3.9995881  3.99981023
 3.99993297 4.00009996 4.00026864 4.00042614 4.00049618 4.00055893
 4.00065818 4.00085146 4.00173287 4.00176449 4.00212759 4.00308994
 4.0037187  4.00387974 4.0039089  4.00396805 4.00414812 4.00417091
 4.00425707 4.00436616 4.00480786 4.00504304 4.0051817  4.00533718
 4.00562386 4.00671152 4.00704998 4.00711818 4.00725363 4.00726146
 4.00735737 4.00779767 4.00812631 4.00831692 4.00881726 4.00912164
 4.00915909 4.00939655 4.00948421 4.01032277 4.01065318 4.01065672
 4.01094347 4.01131709 4.01145113 4.01152526 4.01176697 4.01178516
 4.01202714 4.0122547  4.01257581 4.01278511 4.01300776 4.01318505
 4.01332068 4.01349861 4.01416404 4.01423952 4.01492371 4.01613756
 4.01627563 4.01718933 4.01726553 4.01765107 4.01779653 4.01955306
 4.02062404 4.02075238 4.02082524 4.02100941 4.02102051 4.0210723
 4.02216549 4.02316663 4.02366683 4.02434716 4.02769079 4.02837921
 4.02956614 4.03047714 4.03070686 4.03358214 4.03524464 4.03695931
 4.03717345 4.03783666 4.03971023 4.04046248 4.04098301 4.0448339
 4.04600758 4.05408621 4.07027367 4.21415704 4.91770011 4.93632457
 4.94576106 4.95262533 4.97448999 4.97539828 4.98303556 4.98500458
 4.9889523  4.98927419 4.99018727 4.99105304 4.99209292 4.9931741
 4.99476981 4.99509447 4.99598415 4.99864162 5.00045919 5.00068411
 5.0014048  5.00493743 5.00538834 5.00598162 5.01011113 5.01095415
 5.01528189 5.01594972 5.01965727 5.02008582 5.03123695 5.03403372
 5.04597801 5.04935147 5.05474759 5.05797404 5.06954648 5.18838938]

  warnings.warn(

2022-12-16 10:37:15,267:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.95108635 1.9598154  2.00305989 2.00697019 2.00829898 2.01887297
 2.01907153 2.03226814 2.0361734  2.03733014 2.06520418 2.0952715
 2.19342998 3.73732048 3.79790231 3.80210314 3.8045171  3.81871554
 3.83900528 3.84653264 3.84703219 3.84840134 3.85155016 3.8528538
 3.85550343 3.85737261 3.85762552 3.85808442 3.85885945 3.86114237
 3.86503218 3.86687896 3.86921698 3.87175417 3.87280028 3.87419389
 3.87450557 3.87527965 3.8760967  3.87628838 3.88160724 3.88162934
 3.88215101 3.88283204 3.88329174 3.88708456 3.88786298 3.88827259
 3.8884026  3.8891752  3.89022989 3.89064392 3.8906638  3.8907272
 3.89089351 3.89168538 3.89188805 3.89214749 3.8921709  3.89261329
 3.89273849 3.89294681 3.89344765 3.89354999 3.89422111 3.89449694
 3.89475732 3.89492159 3.89531402 3.895393   3.89543445 3.89562922
 3.89607035 3.89678046 3.89705189 3.89709703 3.8975632  3.8990783
 3.89937811 3.89965082 3.89996062 3.90022357 3.90051964 3.90072754
 3.90096715 3.90105301 3.90107253 3.90124049 3.90131048 3.90223161
 3.90238699 3.90312904 3.90315549 3.90321987 3.90325459 3.90331492
 3.90362627 3.9037152  3.90371957 3.90387207 3.90432217 3.90525851
 3.90526914 3.90566328 3.90575012 3.9057626  3.9058542  3.90604563
 3.9062997  3.90635076 3.90656711 3.90675972 3.90678364 3.90688312
 3.90692768 3.90703174 3.90810142 3.90843061 3.90881512 3.9090557
 3.90921674 3.90937203 3.90970375 3.90979668 3.9097999  3.9100213
 3.9101503  3.91019671 3.9104872  3.91050909 3.91054019 3.91159777
 3.91161017 3.91163887 3.91168676 3.91194727 3.9120493  3.91211985
 3.91212411 3.91213552 3.91239217 3.91240722 3.91283629 3.91287988
 3.91295565 3.91339886 3.91391548 3.91417968 3.91424939 3.91426981
 3.91431936 3.91451274 3.91467529 3.91469167 3.91501165 3.91534504
 3.91546243 3.91556128 3.91558857 3.91571994 3.91577887 3.9157835
 3.91588735 3.91612163 3.91642692 3.91676135 3.91683436 3.91692145
 3.91701236 3.91709943 3.91723962 3.9172797  3.91744989 3.91747208
 3.91759961 3.91774852 3.91777704 3.91829606 3.9183892  3.91871375
 3.91878225 3.91884598 3.91886232 3.91893625 3.91899133 3.91900891
 3.91901926 3.9191782  3.91926612 3.91936256 3.92001762 3.92020633
 3.92057324 3.92063299 3.92063706 3.92072112 3.92089746 3.92112425
 3.92129414 3.92135139 3.92142531 3.92146418 3.92146827 3.92147451
 3.92147954 3.92151982 3.92154458 3.92169706 3.92170049 3.92176387
 3.92190931 3.92207044 3.92220151 3.92221296 3.92263878 3.92264853
 3.9227931  3.92290482 3.92293022 3.9229962  3.92319807 3.92320398
 3.9233517  3.92342555 3.92344085 3.92352743 3.92352802 3.92363228
 3.92366642 3.92374233 3.92388192 3.92390837 3.92395048 3.92462548
 3.92475213 3.9248621  3.92488118 3.92490877 3.92492859 3.92495579
 3.92503669 3.92517641 3.92539288 3.92543902 3.92572697 3.92609866
 3.92648802 3.92652648 3.926546   3.92666626 3.92681441 3.92695637
 3.92715356 3.92723825 3.92727113 3.92729174 3.92729502 3.9276094
 3.92769809 3.92795144 3.92800671 3.92801994 3.92804869 3.92806171
 3.92817486 3.92827773 3.92827804 3.92833227 3.92844606 3.92860236
 3.92864165 3.92867813 3.92906008 3.92916681 3.9293987  3.92972798
 3.92986507 3.92997929 3.93000121 3.9301684  3.93025967 3.93034134
 3.93051252 3.93064455 3.93069607 3.93073758 3.93074098 3.93078355
 3.9310502  3.93131369 3.93146134 3.93179077 3.93180717 3.93187442
 3.93194505 3.93204028 3.93209736 3.93220307 3.93236699 3.93244731
 3.9324694  3.9325113  3.9325785  3.93264355 3.9326922  3.93270259
 3.9327239  3.93274669 3.93291758 3.93293802 3.93302622 3.93308697
 3.93312267 3.93329641 3.93331034 3.93341681 3.93342985 3.93349322
 3.93357366 3.93388935 3.93393854 3.93400044 3.93404949 3.93416626
 3.93447203 3.9345243  3.93464322 3.9346468  3.93467555 3.93477472
 3.93487346 3.93493476 3.93508588 3.93510855 3.9355368  3.93567593
 3.93571634 3.93592513 3.93594555 3.93600695 3.93600793 3.93603887
 3.93607152 3.93613532 3.93614129 3.93615502 3.93620307 3.93623385
 3.9362964  3.93651671 3.9366228  3.93664354 3.93667045 3.93678213
 3.93679678 3.93680157 3.93698722 3.93714571 3.93726132 3.93727663
 3.93753142 3.93794199 3.93850477 3.93864636 3.93875003 3.9387891
 3.93882593 3.93885849 3.93886991 3.93905806 3.93925449 3.93941004
 3.93971025 3.93975065 3.9398513  3.93989962 3.93992153 3.94023382
 3.94025448 3.94026805 3.94029229 3.94031127 3.94034107 3.94040969
 3.94063749 3.94068599 3.94080738 3.9408217  3.94088609 3.94095129
 3.94095281 3.94108583 3.94109063 3.94115206 3.94123136 3.94148569
 3.94157971 3.9417671  3.9418037  3.94189685 3.94204005 3.94210473
 3.94222486 3.94227587 3.94234168 3.94244242 3.94288882 3.94294225
 3.9430359  3.94334963 3.94338314 3.94379142 3.9438471  3.94428853
 3.9443126  3.94438427 3.94453477 3.94454273 3.94480492 3.94509503
 3.94513883 3.94533595 3.94539824 3.94559081 3.94600203 3.94603853
 3.94623159 3.94628517 3.94630623 3.94634053 3.94643056 3.94664723
 3.94683357 3.946969   3.94696985 3.94722718 3.94725325 3.94727999
 3.94732174 3.94737321 3.94738619 3.94747576 3.94764927 3.94781959
 3.94807102 3.94825041 3.94838318 3.94848857 3.94867078 3.94867618
 3.9487838  3.94879116 3.94893782 3.94895358 3.94908063 3.94912215
 3.94925295 3.94928279 3.94928427 3.94933798 3.94934771 3.94941917
 3.94948815 3.9496687  3.94977488 3.94978321 3.94978882 3.9498242
 3.95006403 3.950151   3.95060059 3.95087823 3.95097397 3.95107226
 3.95111218 3.95136389 3.95146004 3.95153195 3.95181495 3.95183247
 3.95187244 3.95190259 3.95197915 3.95213827 3.95233524 3.95249
 3.95256427 3.95268638 3.95268944 3.95285484 3.95287713 3.95302656
 3.95304143 3.95310354 3.9532536  3.95334631 3.95348754 3.9535824
 3.95360439 3.95361988 3.95361988 3.95377619 3.95378703 3.95382246
 3.95423579 3.95436376 3.95436591 3.95438221 3.95439578 3.95461325
 3.95469332 3.95477597 3.95520842 3.95527041 3.95550714 3.9557676
 3.9560779  3.95638051 3.95641198 3.95644128 3.95650757 3.95685092
 3.95691628 3.95695572 3.9569832  3.95698739 3.95700136 3.95744359
 3.95787198 3.95798353 3.95801491 3.95808747 3.9581615  3.95829684
 3.95845031 3.9585339  3.95877997 3.9588121  3.95914774 3.95945731
 3.95951728 3.95961426 3.95981168 3.96001797 3.96008258 3.96015676
 3.9603232  3.9603922  3.96049924 3.9607905  3.96085562 3.9610673
 3.96108484 3.96113887 3.96118524 3.96128835 3.9616981  3.96179129
 3.96191677 3.96224797 3.96225739 3.96258495 3.96261596 3.96265355
 3.96272784 3.96281425 3.96283161 3.96303685 3.96312643 3.9633233
 3.96365272 3.96374391 3.96419759 3.96435038 3.96461391 3.96463189
 3.96464846 3.96481031 3.96488122 3.9649076  3.96491834 3.9650263
 3.96516603 3.96519404 3.96557914 3.96575769 3.96576559 3.96582953
 3.96586484 3.96611997 3.96646382 3.96647139 3.9664941  3.96655229
 3.96660534 3.96682284 3.96690435 3.96693155 3.96694146 3.96713426
 3.96723225 3.96763905 3.9676628  3.96777172 3.96790403 3.96793536
 3.96798123 3.96803399 3.96844217 3.96844891 3.96864559 3.96873082
 3.96930676 3.96948769 3.96973309 3.97000497 3.97009419 3.97034898
 3.97053164 3.97120097 3.97126903 3.97131594 3.97146055 3.97149954
 3.97152509 3.97167394 3.97174032 3.97186658 3.97206094 3.9725488
 3.97260961 3.97291999 3.97307691 3.97307912 3.97312627 3.97352192
 3.97381174 3.97397662 3.97404427 3.97413013 3.97430671 3.97441626
 3.97466033 3.97536232 3.97543692 3.97543778 3.97558759 3.97596811
 3.976435   3.97652767 3.97653236 3.97668051 3.97674977 3.97680293
 3.97693852 3.97694959 3.9770739  3.97720511 3.97725157 3.97734024
 3.97735709 3.97742332 3.97746372 3.97779361 3.97787712 3.97804848
 3.97811433 3.97813296 3.97870393 3.97881659 3.9788684  3.97934124
 3.97960258 3.97976473 3.97996431 3.97998581 3.98026231 3.98082458
 3.9815369  3.98154777 3.98155793 3.98193313 3.98218427 3.98241992
 3.98268807 3.98270699 3.98286117 3.98323995 3.98327016 3.98343108
 3.98380369 3.98381799 3.98388164 3.98424271 3.98427843 3.98440557
 3.98448577 3.98489847 3.98510501 3.98531913 3.98567164 3.98592368
 3.98602008 3.98656768 3.98676533 3.98706718 3.98754214 3.98759116
 3.98783575 3.98791554 3.98813973 3.98852967 3.98864456 3.98887662
 3.98929321 3.98977763 3.9898751  3.98988246 3.98990689 3.99059958
 3.99080099 3.99122074 3.99131864 3.99210054 3.99222022 3.9923425
 3.99258016 3.99302264 3.99335434 3.99384182 3.99390786 3.99411571
 3.99430266 3.99470534 3.99536791 3.99547773 3.99555603 3.9965879
 3.99779935 3.99817675 3.99838933 3.99855986 3.99862251 3.99889149
 3.9990973  3.99941395 3.99949374 3.99984604 3.99999512 4.000036
 4.00005393 4.00013741 4.00106179 4.00115041 4.00175201 4.00202043
 4.00204613 4.00223235 4.00242411 4.00253749 4.00264013 4.00279476
 4.00279495 4.0029636  4.0040172  4.00453681 4.00471856 4.00539337
 4.00569523 4.00597957 4.00694207 4.00698641 4.00825064 4.00905051
 4.00923315 4.01072405 4.01101104 4.01135138 4.01140368 4.01206157
 4.01361842 4.01442201 4.01459808 4.01500954 4.0174484  4.01809133
 4.01892461 4.02078583 4.02142375 4.02190698 4.02290796 4.02422545
 4.02924002 4.03114841 4.03424644 4.03508087 4.03615081 4.0374444
 4.03852685 4.04758755 4.04768264 4.04789987 4.04999875 4.053677
 4.05426356 4.0551257  4.06273716 4.0666225  4.06680089 4.07695088
 4.08163891 4.08610105 4.09437994 4.09653683 4.09689482 4.09710122
 4.10731472 4.11082191 4.11124994 4.15237062 4.17619105 4.18880897
 4.77958862 4.79112278 4.79662931 4.79729261 4.80714255 4.81132577
 4.81664338 4.88726349 4.89967741 4.89978463 4.90846857 4.91076664
 4.91654949 4.91728601 4.91862884 4.919847   4.92230936 4.92242452
 4.92438778 4.92639041 4.92711065 4.92781517 4.92996701 4.93650048
 4.93701845 4.93966727 4.93987514 4.9425125  4.94710638 4.95307105
 4.95328238 4.95346957 4.95635515 4.95931141 4.95994642 4.99751047]

  warnings.warn(

2022-12-16 10:37:15,306:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.03701787 2.0428503  2.04408587 2.04859539 2.04878441 2.05908314
 2.06277693 2.06563408 3.57054056 3.58224657 3.84801961 3.85125684
 3.86558376 3.86630256 3.86963006 3.87504807 3.87571635 3.87712302
 3.87791836 3.87923473 3.87943619 3.88665614 3.88690763 3.88718569
 3.88761454 3.88830243 3.89010013 3.89031774 3.89248106 3.89327525
 3.89350895 3.89376506 3.89399191 3.89457096 3.89481806 3.89528472
 3.89607096 3.89702313 3.89735007 3.89940762 3.9003209  3.9008317
 3.90136995 3.90153677 3.90504767 3.9055982  3.9068618  3.90693109
 3.90848362 3.91150437 3.91228774 3.91259594 3.91299845 3.91340448
 3.91441608 3.91623318 3.91691483 3.91948159 3.91948843 3.92063264
 3.92125843 3.92188016 3.92261501 3.92272645 3.92284877 3.92318284
 3.92335763 3.9234576  3.92415071 3.92435473 3.92447993 3.92497479
 3.92537934 3.92579642 3.9273025  3.9283417  3.92836032 3.92858184
 3.9287172  3.92953645 3.92953956 3.93011365 3.930152   3.93033459
 3.93045646 3.9305937  3.93074538 3.93079554 3.93100437 3.9310679
 3.93125505 3.93128516 3.93132801 3.93148601 3.93222194 3.93229059
 3.93256292 3.93260778 3.93262833 3.93266825 3.933151   3.93375361
 3.93384879 3.9340539  3.93419892 3.93445242 3.93480208 3.93496989
 3.93532572 3.93564976 3.93572428 3.93629523 3.93695855 3.93700228
 3.93700991 3.93709326 3.93731553 3.93743138 3.93779421 3.93780287
 3.93788488 3.93809353 3.93861487 3.93864854 3.93893137 3.93893944
 3.93924467 3.93949726 3.93951501 3.93961327 3.93997247 3.94029212
 3.94052432 3.9406144  3.94066253 3.94159313 3.94159958 3.9416344
 3.9416587  3.94166422 3.94170551 3.94178076 3.9418614  3.94214057
 3.94248175 3.94253514 3.94258848 3.94261146 3.94302446 3.94348477
 3.94357988 3.94397377 3.94414735 3.94417855 3.94421308 3.94434632
 3.94435346 3.9448926  3.94489595 3.94494181 3.94512211 3.94516603
 3.94528991 3.94534115 3.94548547 3.94548938 3.94563592 3.94567629
 3.94571308 3.94582886 3.94598207 3.94609944 3.94619651 3.94620499
 3.94637017 3.94639276 3.94650973 3.94729956 3.94746116 3.94765601
 3.94773237 3.94784831 3.94791637 3.94820934 3.94849827 3.94856113
 3.94857539 3.94881659 3.94884815 3.94910664 3.94923193 3.9493387
 3.94935076 3.94953668 3.94979289 3.94990267 3.94992027 3.949997
 3.95035173 3.95040775 3.95044288 3.95107788 3.95119215 3.95122706
 3.95138463 3.95140432 3.95141681 3.95153779 3.95164631 3.95170474
 3.95173597 3.95177037 3.9518033  3.95181516 3.95185705 3.95210567
 3.95220901 3.9522253  3.95223853 3.9524515  3.9524855  3.95257422
 3.95274537 3.95300691 3.95304639 3.95328707 3.9533257  3.95370704
 3.9538662  3.95388838 3.95402592 3.954034   3.95405068 3.95422454
 3.95423218 3.95433729 3.95446617 3.95458229 3.95478239 3.95536482
 3.95539433 3.95547097 3.95555783 3.95559435 3.95577613 3.95596854
 3.9559905  3.95606038 3.95629308 3.95635994 3.9563992  3.95674618
 3.95679633 3.95681203 3.95700403 3.95704369 3.95705934 3.95707388
 3.9571479  3.95723142 3.95735695 3.95738217 3.95746229 3.95758045
 3.95761021 3.95771764 3.95774316 3.95780623 3.95781628 3.95792394
 3.95802257 3.95822525 3.95827113 3.95863735 3.95867755 3.95868526
 3.95870045 3.95873257 3.95889466 3.95891304 3.95894799 3.95925257
 3.95929838 3.95936126 3.95947985 3.95951263 3.9595374  3.96024224
 3.96026571 3.96057538 3.96058987 3.96085709 3.96087903 3.96091457
 3.96093352 3.96101583 3.96108844 3.96109543 3.961367   3.96143519
 3.96145506 3.96148123 3.96160037 3.96188249 3.96199485 3.96206863
 3.96211323 3.96224926 3.96224997 3.96239268 3.9624165  3.96265679
 3.96268792 3.96270816 3.96296714 3.96312877 3.96316063 3.96348875
 3.96394234 3.96402368 3.96409928 3.96421714 3.96425336 3.96426378
 3.96441894 3.96449545 3.96450914 3.96469168 3.96483327 3.96485405
 3.96492392 3.96494362 3.964963   3.96497413 3.96497748 3.96501018
 3.96507776 3.96511267 3.96536852 3.96547431 3.96557179 3.96581117
 3.96599353 3.96600548 3.96618452 3.96619682 3.96628737 3.96631446
 3.96638959 3.96645004 3.96664014 3.96684904 3.9669828  3.96699083
 3.96706313 3.96712561 3.96718708 3.96752876 3.96755213 3.96756989
 3.96767841 3.9678802  3.9679945  3.96800114 3.96802543 3.96806348
 3.96810738 3.96836444 3.96845613 3.96864806 3.96866001 3.9687033
 3.96870823 3.96889105 3.96892197 3.96908465 3.96922352 3.96925499
 3.96932753 3.96938606 3.9694719  3.96954937 3.96970601 3.96971201
 3.96972988 3.96980639 3.96986378 3.97001871 3.9700387  3.97024575
 3.97055516 3.97057129 3.97073609 3.970741   3.97084636 3.97090197
 3.97092609 3.97094676 3.97095321 3.970973   3.97101016 3.97102744
 3.97116881 3.97138033 3.97145215 3.97146185 3.97146544 3.97156055
 3.97168673 3.97188538 3.97193023 3.97198186 3.97198964 3.9720795
 3.97212906 3.97249111 3.97255666 3.97260728 3.97261969 3.97262456
 3.97268229 3.97276072 3.97281823 3.97296258 3.97305692 3.97310037
 3.97311557 3.97318034 3.97323427 3.97323665 3.97331635 3.9733272
 3.97341106 3.97354035 3.97357724 3.97378355 3.97386345 3.97388255
 3.97392944 3.97397261 3.97398762 3.97402203 3.97406423 3.97408614
 3.97409386 3.97414207 3.97425335 3.97444617 3.97459473 3.97460909
 3.97461099 3.97476812 3.97479793 3.97480673 3.9750828  3.97508384
 3.97518738 3.97520496 3.97522687 3.97528788 3.97528923 3.97529761
 3.97537408 3.97537827 3.97538564 3.97544054 3.97548171 3.97548948
 3.97564747 3.97566564 3.9757044  3.97572884 3.9757318  3.97581347
 3.9759008  3.97602739 3.97606633 3.97630407 3.97632298 3.97635388
 3.97637536 3.97654379 3.97674757 3.97686615 3.97688461 3.97691553
 3.97695804 3.97718458 3.97721024 3.977261   3.97732581 3.97732736
 3.97733857 3.97735255 3.977393   3.97762074 3.97762226 3.97764349
 3.97765914 3.97766803 3.97777969 3.97782268 3.97786018 3.97798985
 3.97800344 3.97807435 3.9780892  3.9781811  3.97826035 3.9783229
 3.97836898 3.97844009 3.97861361 3.97863564 3.9786784  3.97878582
 3.97892674 3.97913644 3.97921766 3.97921805 3.97922881 3.97923013
 3.97927227 3.9793277  3.97939068 3.97950607 3.97984829 3.98013728
 3.98022115 3.98028168 3.98039882 3.98043976 3.9806649  3.98107297
 3.98122083 3.98126636 3.98134785 3.98135474 3.98137355 3.98140531
 3.98141367 3.98145049 3.98149247 3.981703   3.98178867 3.98178984
 3.98180257 3.98193358 3.9821171  3.9821727  3.98220264 3.98226878
 3.98231297 3.98246985 3.98254717 3.98262871 3.98263562 3.98278425
 3.98292471 3.98294795 3.98295196 3.98297005 3.98298001 3.98319547
 3.98320817 3.98328201 3.9833136  3.98332387 3.98356042 3.98360227
 3.9836376  3.98386222 3.98391591 3.9841477  3.98423747 3.98429139
 3.98431383 3.98441416 3.98449244 3.98450483 3.98451924 3.98456898
 3.98477848 3.98479819 3.98481067 3.98485634 3.98488993 3.98492163
 3.98492511 3.98497752 3.9852919  3.98541367 3.98547355 3.98547931
 3.98548928 3.98550963 3.98567596 3.98569905 3.98577693 3.98580802
 3.9858791  3.98589956 3.98590847 3.98611479 3.98622337 3.98634303
 3.98685719 3.98695114 3.98698987 3.98725747 3.98729136 3.98731817
 3.98740069 3.98766254 3.98795465 3.98797944 3.98805677 3.98805726
 3.98806672 3.98810843 3.98812414 3.98818227 3.9882325  3.98824024
 3.98831763 3.98858852 3.98860341 3.98866071 3.98897409 3.98917
 3.98923129 3.98925181 3.98929478 3.98942228 3.98944841 3.98947006
 3.98982917 3.98984769 3.98993827 3.99005605 3.99009701 3.99015624
 3.99021225 3.99045357 3.99049961 3.99062116 3.99066644 3.99079004
 3.99108841 3.99114299 3.99127929 3.99129384 3.99149471 3.99161928
 3.99165359 3.99170524 3.99170863 3.99179275 3.99212137 3.99213459
 3.9922364  3.99265203 3.99305647 3.99316556 3.99316746 3.99328398
 3.99328493 3.99332716 3.99362414 3.99364077 3.99366087 3.99368416
 3.99374143 3.99379533 3.99380158 3.99382536 3.99413368 3.99428797
 3.99441532 3.99443049 3.9946345  3.99475507 3.9947634  3.99477294
 3.99484358 3.99487731 3.99524814 3.99530319 3.99537084 3.99602673
 3.99606243 3.99643525 3.99652746 3.99655555 3.99677236 3.99679356
 3.99690401 3.99731496 3.99736707 3.99744608 3.99752362 3.99755939
 3.99794465 3.99797234 3.9981784  3.9981895  3.99824722 3.99824829
 3.99867247 3.99896068 3.99922884 3.99939597 3.99950278 3.99959448
 3.99962656 3.99976762 3.99994384 4.00028148 4.000286   4.00064461
 4.00091079 4.00097262 4.00123007 4.00156368 4.00174759 4.002037
 4.00216299 4.00242356 4.00327466 4.00334803 4.00344348 4.00352385
 4.00384476 4.00389663 4.00400134 4.00403668 4.00427893 4.00437861
 4.00443763 4.00475606 4.00481089 4.0054015  4.00543774 4.0055181
 4.00569618 4.00572497 4.00709534 4.00734553 4.00765165 4.00797857
 4.00805763 4.00807153 4.00834046 4.00854333 4.00866107 4.00884081
 4.00908365 4.0092716  4.01027576 4.01035873 4.01098349 4.01100697
 4.01106441 4.01112678 4.011129   4.01112928 4.01129478 4.01132852
 4.01149066 4.01149517 4.01155058 4.01228563 4.01330336 4.01344953
 4.01354059 4.01365903 4.01419113 4.01460217 4.01462776 4.01464962
 4.01512753 4.01527181 4.01583506 4.01592983 4.01626177 4.01636423
 4.0164609  4.01694236 4.01725614 4.01793298 4.01846041 4.01858566
 4.01881412 4.01883727 4.01897286 4.02163013 4.02200525 4.02201832
 4.02206017 4.02248444 4.02267219 4.02280171 4.02297524 4.02311384
 4.0245092  4.02470428 4.02592943 4.02889892 4.03011421 4.03107566
 4.03349472 4.03417242 4.03481512 4.03784127 4.04011858 4.04314525
 4.04350577 4.04453496 4.07361017 4.07365294 4.24339568 4.27605936
 4.88190808 4.93823098 4.94182116 4.94916818 4.95147055 4.95541757
 4.9718117  4.97440033 4.97761353 4.98112062 4.98170778 4.98422257
 4.98591555 4.98593586 4.98770036 4.98795432 4.98883595 4.98999581
 4.9901929  4.99398853 4.99938563 4.99986113 5.00076136 5.00099195
 5.00579469 5.00700591 5.0074176  5.01147141 5.01153794 5.01223519
 5.02337946 5.02697963 5.03841542]

  warnings.warn(

2022-12-16 10:37:16,293:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-16 10:37:16,423:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-16 10:37:16,465:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.97816529 2.0242779  3.75095599 3.7537636  3.87569479 3.88561928
 3.8890051  3.88936139 3.89120037 3.89157194 3.89503349 3.89630569
 3.89701414 3.897106   3.9057211  3.90831015 3.90832015 3.90842691
 3.90865162 3.91019842 3.91135743 3.91369583 3.91400098 3.91542819
 3.91584105 3.91718142 3.91792439 3.91802531 3.9181362  3.92052154
 3.92071169 3.92431632 3.92534782 3.92613379 3.92615484 3.92619402
 3.92625417 3.92721806 3.92771017 3.92806356 3.92844841 3.92902276
 3.93017379 3.9306026  3.93138868 3.93142477 3.93246095 3.93281163
 3.93287699 3.9330999  3.93365763 3.93366109 3.93476501 3.93494746
 3.93583242 3.93590223 3.93611998 3.93619461 3.93705517 3.93850066
 3.93879859 3.93938536 3.94071748 3.94113787 3.94163299 3.94172425
 3.94183402 3.94217149 3.94232539 3.94234577 3.94241193 3.94278657
 3.94322128 3.94333868 3.94369733 3.94412178 3.9441818  3.94450079
 3.94469064 3.94471749 3.9447965  3.94507643 3.94544674 3.94547883
 3.94555248 3.94572066 3.94572906 3.94591939 3.94641867 3.94644288
 3.94644647 3.94667971 3.94678035 3.94720093 3.94752582 3.94842859
 3.94844668 3.94847078 3.94882265 3.94885147 3.94914222 3.94920813
 3.94938832 3.94955377 3.94977438 3.94985351 3.94999417 3.95020318
 3.95043248 3.95069121 3.95073743 3.95077086 3.95089304 3.95162394
 3.95182687 3.95184455 3.95212944 3.95218811 3.95230634 3.95248646
 3.95255178 3.9534381  3.95345187 3.95439556 3.95452732 3.95470278
 3.95472123 3.95504629 3.9550539  3.9550648  3.95507212 3.9551105
 3.9551205  3.95541023 3.95541325 3.95542634 3.95560239 3.95561686
 3.95578092 3.9561157  3.95616914 3.9563344  3.95635038 3.95668217
 3.95684246 3.95690146 3.95698211 3.95722623 3.95755152 3.95762545
 3.95768653 3.95780059 3.95781718 3.95789679 3.95790308 3.9579342
 3.95821706 3.95823027 3.95835698 3.95839826 3.95841741 3.958422
 3.95862598 3.95864488 3.95910799 3.95917334 3.95920155 3.95941362
 3.95942471 3.95966482 3.95980282 3.96024375 3.96040968 3.96045007
 3.9610577  3.96111168 3.96114269 3.96116899 3.96120392 3.96134853
 3.96143936 3.96146047 3.96152037 3.96154709 3.9615785  3.96157906
 3.9615837  3.96166708 3.9618716  3.96188948 3.96196745 3.96199879
 3.96222038 3.96240882 3.9624508  3.96256615 3.96272484 3.96286567
 3.96286871 3.96291136 3.96296886 3.96316248 3.96322757 3.96328707
 3.96354639 3.9636656  3.96381679 3.96393858 3.96402552 3.96411416
 3.96428913 3.96429559 3.96431403 3.96437813 3.96443491 3.9644379
 3.96448614 3.96448815 3.96449489 3.96469429 3.96484744 3.96503821
 3.96508394 3.96516059 3.96530892 3.96542178 3.96544211 3.96546776
 3.96556428 3.96600096 3.96605256 3.96612936 3.96613796 3.96618517
 3.96622664 3.96632867 3.96635088 3.96637728 3.96675705 3.96679667
 3.96684587 3.96694143 3.96729773 3.96733196 3.96736058 3.96740124
 3.96741015 3.96746353 3.96747185 3.96751387 3.96751836 3.96752428
 3.96760087 3.96762693 3.96763752 3.9676584  3.96772581 3.96774794
 3.96777094 3.9677792  3.96785047 3.96786309 3.96787631 3.96787697
 3.96794951 3.9679546  3.96798911 3.96819869 3.96832687 3.96832911
 3.9683898  3.96841612 3.96842025 3.96845045 3.96848908 3.96850122
 3.96854219 3.96880218 3.96889197 3.96889472 3.96894782 3.96896464
 3.96897347 3.96929087 3.96938321 3.96939816 3.96949953 3.96953734
 3.96956006 3.96957412 3.96975753 3.9698029  3.96986545 3.96986979
 3.96989377 3.97001442 3.97004745 3.97014376 3.97017794 3.97024121
 3.97034346 3.97062726 3.9706988  3.97078697 3.97090215 3.9709508
 3.97100163 3.97102039 3.9710386  3.97106374 3.97115091 3.97124986
 3.97130455 3.97135719 3.97160988 3.97161474 3.97161516 3.9717384
 3.97176034 3.97176651 3.97180068 3.97195984 3.97199559 3.97214366
 3.97220596 3.97224173 3.97226167 3.97234812 3.97249671 3.97251185
 3.97258568 3.9726298  3.97263107 3.97268794 3.97277059 3.97306019
 3.97307774 3.97316662 3.97329045 3.97335933 3.97336959 3.97340087
 3.97351486 3.973572   3.97367971 3.9737782  3.97383128 3.97387747
 3.97389648 3.97407634 3.97413972 3.97424698 3.97431193 3.97436513
 3.97450862 3.97451401 3.97464297 3.97472386 3.9748259  3.97490311
 3.97495596 3.97497551 3.97502567 3.97508863 3.97509063 3.97510738
 3.97511422 3.97522264 3.97528722 3.97534704 3.97535922 3.97535939
 3.97541794 3.97544441 3.97569167 3.97569207 3.97578724 3.97581581
 3.97600039 3.97600224 3.97601766 3.97607379 3.97611753 3.97624308
 3.97628662 3.97633439 3.97637    3.9764075  3.97644685 3.97646105
 3.97651221 3.97652183 3.9766027  3.97686678 3.97687213 3.97688266
 3.97695281 3.97696704 3.97696946 3.97697693 3.9769855  3.97704952
 3.97709254 3.97709666 3.97717558 3.97726754 3.97745725 3.97757004
 3.97760619 3.97763612 3.97765904 3.97769303 3.97776632 3.97788861
 3.97792078 3.97796233 3.97806421 3.97808216 3.97809659 3.97817999
 3.97824635 3.97838349 3.97842327 3.97849946 3.97850713 3.97851244
 3.97854319 3.97855187 3.97870091 3.97880675 3.97880942 3.97886324
 3.97888458 3.97897232 3.97897802 3.97915472 3.97917356 3.97920083
 3.97924445 3.97944834 3.97946442 3.97951528 3.97951615 3.9795621
 3.97961049 3.97965608 3.97969977 3.97976449 3.97977301 3.97986887
 3.97988677 3.97988798 3.97989687 3.98000564 3.98004699 3.98013996
 3.98025233 3.98026336 3.98026831 3.98031418 3.98034033 3.98044387
 3.98055391 3.98060353 3.980662   3.98067678 3.98073548 3.9807726
 3.98077297 3.98077734 3.98084461 3.98089594 3.98090784 3.980914
 3.98093895 3.98098086 3.98110133 3.98112743 3.98112838 3.98121871
 3.98124225 3.98126646 3.9813471  3.98154832 3.98156837 3.98166371
 3.98169028 3.98170268 3.98172161 3.98172517 3.98182793 3.98186414
 3.9820095  3.98201785 3.98205401 3.98207171 3.98210063 3.98212867
 3.9821696  3.98227227 3.98227267 3.98238967 3.98244901 3.9824493
 3.98252692 3.9825295  3.98258204 3.98265819 3.9828016  3.98280939
 3.98287939 3.9828972  3.98293132 3.98294601 3.98298411 3.98302587
 3.9830699  3.98309593 3.98314491 3.98326698 3.98327908 3.9832875
 3.98331557 3.98331675 3.98337553 3.98347574 3.98349447 3.98354651
 3.98375723 3.98376142 3.98387641 3.98409558 3.98412521 3.98417947
 3.98423267 3.98430229 3.98430486 3.98430673 3.98442594 3.98445058
 3.98450507 3.98455703 3.98456422 3.98458357 3.98478244 3.98487231
 3.98488002 3.98492442 3.98501936 3.98516136 3.98516352 3.98536578
 3.98539426 3.98540292 3.98541813 3.98562194 3.98571145 3.98573471
 3.98581097 3.98592379 3.98598413 3.98599773 3.98599859 3.98605355
 3.98614878 3.98619946 3.98620502 3.98624481 3.98636675 3.98641301
 3.98648743 3.98650849 3.98673731 3.98675113 3.98689072 3.98689169
 3.98690173 3.98690255 3.98699251 3.98702734 3.98718907 3.98721654
 3.98726038 3.98730755 3.98739676 3.98740101 3.98745975 3.98760186
 3.98777967 3.98778574 3.98782596 3.9878519  3.98789477 3.98789781
 3.98790937 3.98795087 3.98798394 3.98799789 3.98814201 3.98830835
 3.98837994 3.98874785 3.98899567 3.98919438 3.98925417 3.98928495
 3.98929439 3.98938382 3.98945262 3.98947451 3.9895879  3.98973787
 3.98985621 3.98988635 3.98992727 3.98997686 3.99001599 3.99002983
 3.99008799 3.99013901 3.99020289 3.99020975 3.9902897  3.99030114
 3.99033218 3.99034402 3.99041826 3.99042911 3.99047114 3.99061465
 3.99067193 3.99071545 3.99082565 3.99082817 3.99085016 3.99086037
 3.99091499 3.99095119 3.99135796 3.99140589 3.99141495 3.99142735
 3.99147327 3.99151987 3.9915617  3.99170258 3.99181807 3.99184843
 3.99196762 3.99203868 3.99204062 3.99208355 3.99211859 3.99221945
 3.99229805 3.99241149 3.99248301 3.9925297  3.9925814  3.99261926
 3.99273019 3.99276674 3.99291836 3.99307428 3.99309359 3.99326084
 3.99331322 3.99346526 3.99349594 3.99355074 3.99358785 3.99368155
 3.99390581 3.99397143 3.99409783 3.99423936 3.99437148 3.99437909
 3.99447402 3.99452669 3.99493767 3.9949791  3.99511019 3.99519102
 3.99522167 3.99525978 3.99530038 3.99535274 3.99537086 3.99539928
 3.99541978 3.99575508 3.99575514 3.99577964 3.99581681 3.99587739
 3.99603366 3.99603492 3.99618855 3.99639657 3.9965533  3.99667274
 3.99718154 3.997376   3.9974176  3.99754217 3.99807359 3.99827026
 3.99847063 3.99899225 3.99907925 3.99928857 3.99937734 3.99983718
 3.99994009 3.99994955 3.9999781  4.00011931 4.00015136 4.00022965
 4.0003088  4.00033879 4.00044946 4.00073666 4.00082607 4.00092754
 4.00123583 4.00125318 4.00129674 4.00132523 4.0013567  4.00160008
 4.00165753 4.00171266 4.00192657 4.00194605 4.00200244 4.00202908
 4.00211492 4.00224684 4.00285813 4.00347664 4.00353959 4.00355214
 4.00372864 4.00379947 4.00384953 4.0039431  4.00428038 4.00435569
 4.00448287 4.00467076 4.00500359 4.00523609 4.00582942 4.00618811
 4.00619581 4.0062547  4.00635513 4.00667589 4.00686551 4.0070057
 4.00709793 4.00745008 4.00814801 4.00826438 4.00913858 4.00931039
 4.00957839 4.00961475 4.00973777 4.01025004 4.01054823 4.01063082
 4.01143319 4.01181601 4.01262719 4.0128431  4.01337638 4.01361743
 4.01495062 4.01534628 4.01554713 4.01615844 4.01660602 4.01662643
 4.0169616  4.01716057 4.01822014 4.01834882 4.01975174 4.02031468
 4.0213137  4.02210382 4.02266616 4.02413301 4.02421179 4.02456444
 4.02489203 4.02501122 4.02752388 4.02794124 4.03355004 4.03591964
 4.03702845 4.03977828 4.04092349 4.043749   4.04680233 4.04687784
 4.04739391 4.04927062 4.06369018 4.16354633 4.27056854 4.89672263
 4.91444081 4.93546957 4.95477453 4.95684071 4.96144251 4.96176688
 4.96780358 4.96918377 4.97273193 4.97346625 4.97445595 4.97681462
 4.97931555 4.98066074 4.98186243 4.98194944 4.98272758 4.98300316
 4.98365714 4.98445518 4.98484632 4.98592026 4.99157789 4.99333683
 4.99416599 4.99614419 4.99640976 4.99683017 4.99762848 4.99826091
 5.00036806 5.00070918 5.0060637  5.0135156  5.01497154 5.01727318
 5.01939297 5.02384951 5.02395612 5.02570688]

  warnings.warn(

2022-12-16 10:37:16,608:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.98702992 2.00349769 2.00838647 2.01608938 2.01664405 2.01951358
 2.02798499 2.02941345 2.02943453 2.0322687  2.03443778 2.03874905
 2.0395766  2.13313968 3.46265084 3.84504925 3.85698142 3.86381058
 3.86398109 3.86831841 3.87081728 3.87203099 3.8742291  3.88080784
 3.88122903 3.88774151 3.89275404 3.89300139 3.89365151 3.89377142
 3.8957683  3.89636464 3.896785   3.89842243 3.89848448 3.9010157
 3.90158    3.90269443 3.90366622 3.90522308 3.90538275 3.90544688
 3.90619947 3.90700784 3.90744076 3.90952857 3.90957353 3.91018311
 3.91049365 3.911116   3.91130543 3.91141658 3.91174467 3.91231014
 3.91339083 3.91356469 3.9136452  3.91391621 3.9140384  3.9150052
 3.91717734 3.91730779 3.91791186 3.9181617  3.91820634 3.91834941
 3.91874007 3.91924277 3.9193083  3.91936088 3.91963753 3.91974195
 3.91987685 3.92035641 3.92050595 3.9217458  3.92221722 3.92239036
 3.92242541 3.92402813 3.92440545 3.924473   3.9246365  3.92556078
 3.92569714 3.92588832 3.92609714 3.92622958 3.92630797 3.92644053
 3.92646927 3.92652146 3.92677009 3.92689965 3.92691089 3.92708055
 3.92730361 3.92743769 3.92747413 3.92780121 3.92804927 3.92811682
 3.92816884 3.92819301 3.92844206 3.92853683 3.92904013 3.9296862
 3.93020251 3.93029429 3.93034854 3.93060042 3.93109343 3.93109383
 3.93166772 3.93180956 3.93183019 3.93185915 3.93219073 3.93225631
 3.9323965  3.93240261 3.93264759 3.93272575 3.93278472 3.9329056
 3.93303248 3.93364866 3.93370993 3.93378724 3.9340081  3.93410706
 3.93428863 3.93445427 3.93524714 3.93533151 3.93565368 3.93565639
 3.93602374 3.93637365 3.93642154 3.93646879 3.93648188 3.93667373
 3.93670356 3.93670551 3.93727937 3.93735023 3.93776813 3.93813613
 3.93815463 3.9382696  3.93844142 3.93850301 3.93851706 3.93854926
 3.93860721 3.93875741 3.93892081 3.93904708 3.93906787 3.93909057
 3.93915986 3.93947836 3.93959856 3.9396226  3.93995917 3.94000281
 3.94006581 3.94008    3.94025063 3.94038537 3.94052905 3.9408767
 3.94093445 3.94114733 3.94116429 3.94117984 3.94128844 3.94129355
 3.94139774 3.94216619 3.94273338 3.94303816 3.9430786  3.94362608
 3.94365024 3.94370472 3.94376448 3.94378902 3.94384156 3.94390938
 3.94398088 3.94398941 3.94404404 3.94411205 3.94416557 3.94421784
 3.9442841  3.94433047 3.94450361 3.94454947 3.94455466 3.944557
 3.94467334 3.94469186 3.94471737 3.94486372 3.94488027 3.94490093
 3.94516735 3.94535639 3.94544969 3.94545332 3.94546324 3.9456065
 3.94561947 3.94576632 3.94581201 3.94587455 3.94592429 3.94595789
 3.94624058 3.94642483 3.94646913 3.94660489 3.94660694 3.94677517
 3.94682059 3.94684867 3.94687202 3.94693181 3.94700778 3.94708244
 3.94710913 3.94717009 3.94733612 3.94734208 3.94740341 3.94744727
 3.94753621 3.94754653 3.94767652 3.9476793  3.94774087 3.94778749
 3.94794384 3.94801158 3.94812621 3.94839603 3.94842456 3.9489857
 3.94916365 3.94917489 3.94919803 3.94955229 3.94971667 3.94978768
 3.94986779 3.9499613  3.94999092 3.95009058 3.95011163 3.9501154
 3.95012996 3.95020414 3.95028075 3.95055476 3.95061462 3.95079891
 3.95086564 3.95102158 3.95105396 3.95111347 3.95115297 3.95137346
 3.95149312 3.95151981 3.95152011 3.95157313 3.9517018  3.95171601
 3.95179198 3.95179286 3.95185764 3.9519171  3.95197959 3.9521389
 3.95240318 3.9524619  3.95250672 3.95252571 3.95255654 3.95255777
 3.95260652 3.95261797 3.9526442  3.95268191 3.95278821 3.95298462
 3.95324446 3.95338991 3.95341302 3.95383845 3.95404847 3.95404995
 3.95409915 3.95417019 3.9543616  3.95445406 3.95461624 3.9546648
 3.95480631 3.95483625 3.95491826 3.95497893 3.95503935 3.95519848
 3.95526981 3.95535393 3.95535404 3.95545538 3.95558789 3.95565268
 3.95571357 3.95580609 3.95598766 3.95600532 3.9561245  3.95630965
 3.95661714 3.95663573 3.95688484 3.95690026 3.95694855 3.95713957
 3.95723764 3.95732355 3.95735182 3.95735785 3.95739366 3.95747558
 3.95769102 3.95775174 3.95776703 3.95790004 3.95811502 3.95815095
 3.95822424 3.95834204 3.95834873 3.95839627 3.95843693 3.95845227
 3.95848515 3.95855269 3.95865158 3.95888436 3.95901627 3.95910517
 3.95911408 3.95918858 3.95921447 3.95960074 3.95971613 3.95974337
 3.95989971 3.95992199 3.96010378 3.96012173 3.96012644 3.96016116
 3.96017924 3.96060045 3.96060436 3.96064846 3.96071517 3.96073704
 3.9608938  3.96090589 3.96092679 3.96093025 3.96118603 3.96126201
 3.96129094 3.96130842 3.96146876 3.96152018 3.96155036 3.96155444
 3.96159689 3.96170564 3.96172377 3.96180663 3.96204008 3.96209542
 3.96210724 3.96216772 3.96218572 3.96259982 3.96265667 3.96280418
 3.96294914 3.96299749 3.96302533 3.96303729 3.96322277 3.96337837
 3.9635034  3.96381219 3.96382301 3.96393922 3.96395213 3.96401701
 3.96401928 3.96404516 3.96446082 3.96450576 3.96454379 3.96468964
 3.96482481 3.96486745 3.96509214 3.96515725 3.9651666  3.96525138
 3.96527856 3.96530936 3.96540627 3.96542243 3.96555896 3.96561553
 3.965826   3.96584503 3.96604794 3.96607219 3.96611471 3.96615474
 3.96619069 3.96621659 3.96625116 3.96628401 3.96660772 3.96675725
 3.96691567 3.96698125 3.9670017  3.96709526 3.96719003 3.96724319
 3.96743852 3.96747515 3.96756785 3.96758179 3.96773285 3.96790007
 3.9679042  3.96791641 3.96796347 3.96801879 3.96811398 3.96812831
 3.96823065 3.96825324 3.96827832 3.96832198 3.96841167 3.96845675
 3.96846663 3.96848961 3.96853532 3.96862407 3.96875898 3.96900605
 3.96902319 3.96904284 3.96908716 3.9693241  3.9693994  3.9693995
 3.96941561 3.96943275 3.96944074 3.96965212 3.96978881 3.9698341
 3.97000819 3.97002779 3.97006229 3.97033814 3.97055799 3.97060858
 3.97062133 3.97068289 3.97069834 3.97074141 3.970767   3.9709829
 3.97099485 3.97107782 3.9711032  3.97123411 3.97129225 3.97129269
 3.97141686 3.97149207 3.97173643 3.97186305 3.97188321 3.97209395
 3.97210117 3.97221637 3.972253   3.97229183 3.97229761 3.9723357
 3.97237459 3.97239466 3.97241278 3.9725005  3.97254997 3.97272995
 3.97277716 3.97284514 3.97291526 3.97291633 3.9729203  3.97311294
 3.9733024  3.97331246 3.9734335  3.97353678 3.97360915 3.97367818
 3.97370311 3.973721   3.97393356 3.9742122  3.97433069 3.97434972
 3.97440398 3.97450325 3.97451719 3.97454124 3.97455691 3.97465895
 3.97466812 3.97470186 3.9747743  3.97488728 3.97490513 3.97500233
 3.9750265  3.97504465 3.97514303 3.97519259 3.97529579 3.97543649
 3.97544781 3.97562625 3.97593702 3.9760171  3.97617388 3.97624064
 3.97626144 3.97643652 3.97646208 3.97659358 3.97660735 3.97668159
 3.97680115 3.97681186 3.97694041 3.97709896 3.97730747 3.97738614
 3.97754984 3.97757119 3.97778812 3.97823947 3.97845174 3.97865089
 3.97883009 3.97884329 3.97888877 3.97911398 3.97913817 3.9791486
 3.97916346 3.97918864 3.97924064 3.97928847 3.97951165 3.97961894
 3.97967444 3.97974546 3.979854   3.97985409 3.98006386 3.98006618
 3.98014312 3.98016474 3.98017936 3.98021303 3.9803631  3.98073668
 3.98079351 3.98084271 3.9808634  3.98102745 3.98105754 3.98136449
 3.98158627 3.98175437 3.98178228 3.98179669 3.98190025 3.9820529
 3.98208665 3.98209341 3.98221252 3.98228068 3.98257997 3.98275771
 3.98288014 3.98304329 3.98304938 3.98309232 3.98325916 3.98336438
 3.98341994 3.9835056  3.98378332 3.98379266 3.9838572  3.98394161
 3.98407293 3.98407552 3.98418236 3.98429912 3.98429962 3.98430817
 3.98433099 3.98452082 3.98479661 3.98496456 3.98508165 3.9853072
 3.98536414 3.98545477 3.98546887 3.98551358 3.98574955 3.98595119
 3.98598941 3.98653903 3.98662265 3.98674254 3.98678902 3.98679775
 3.98682826 3.98690298 3.98698447 3.98713481 3.98714804 3.98760215
 3.98794751 3.98797685 3.98809329 3.98812698 3.98818036 3.9885389
 3.98860727 3.98870906 3.98884952 3.98897234 3.98944    3.98966831
 3.98975959 3.99013599 3.99044495 3.99065486 3.99079129 3.9908546
 3.99114163 3.99136234 3.99138376 3.99141803 3.99189326 3.99216758
 3.99225005 3.99225052 3.99238167 3.9923925  3.99246312 3.99257733
 3.99270894 3.99275367 3.99289034 3.99299309 3.99321844 3.99330485
 3.99332418 3.99342905 3.99370476 3.99376494 3.99386603 3.99388445
 3.99409131 3.99424353 3.99464483 3.99467171 3.99477143 3.9953167
 3.99540974 3.99554405 3.99585902 3.99587051 3.99587639 3.99613407
 3.99615454 3.99628922 3.9970747  3.99720797 3.99748383 3.99748494
 3.99774721 3.99812438 3.99856128 3.99881905 3.99888905 3.99898876
 3.99904424 3.99968924 4.00014408 4.00057862 4.00090062 4.00131138
 4.00132711 4.00138959 4.00157206 4.00167045 4.00227743 4.00337068
 4.00408341 4.00434341 4.00454899 4.00457793 4.00462524 4.00477199
 4.00477505 4.00521877 4.00534798 4.00627759 4.00670214 4.00714571
 4.00729175 4.00824121 4.00841517 4.00842627 4.00921185 4.009233
 4.00926999 4.00937362 4.00955174 4.01064685 4.01072772 4.01083093
 4.01089354 4.01170008 4.01198209 4.01240687 4.01266212 4.01299191
 4.0140649  4.01464008 4.01473123 4.01539756 4.01614071 4.01866267
 4.01889708 4.01894037 4.02000619 4.02028091 4.02223106 4.02312928
 4.02390597 4.02437991 4.02450826 4.02567885 4.02633194 4.02772623
 4.02804578 4.02871762 4.03092858 4.03278849 4.03361697 4.03450731
 4.03774143 4.0400158  4.04713309 4.0485265  4.04873807 4.04896481
 4.04933648 4.05110317 4.05148141 4.05619992 4.05716142 4.05783642
 4.0596184  4.0609569  4.06120588 4.07535765 4.12752394 4.23384263
 4.87838806 4.87870311 4.91121577 4.9119027  4.91277166 4.91998957
 4.95036718 4.9505909  4.9514353  4.95603397 4.956726   4.95715548
 4.95852907 4.96150672 4.96626278 4.96684168 4.97195302 4.97229077
 4.9723351  4.97502052 4.97689021 4.97751014 4.98279634 4.98290114
 4.98323516 4.98374743 4.98443237 4.98477325 4.98633335 4.98786865
 4.98926544 4.98954269 4.98957111 4.99059006 4.99201447 4.99311127
 4.99525722 4.99928465 5.01179176 5.06559486]

  warnings.warn(

2022-12-16 10:37:16,611:INFO:Calculating mean and std
2022-12-16 10:37:16,612:INFO:Creating metrics dataframe
2022-12-16 10:37:16,617:INFO:Uploading results into container
2022-12-16 10:37:16,619:INFO:Uploading model into container now
2022-12-16 10:37:16,620:INFO:master_model_container: 19
2022-12-16 10:37:16,621:INFO:display_container: 2
2022-12-16 10:37:16,622:INFO:HuberRegressor()
2022-12-16 10:37:16,622:INFO:create_model() successfully completed......................................
2022-12-16 10:37:16,844:WARNING:create_model() for HuberRegressor() raised an exception or returned all 0.0, trying without fit_kwargs:
2022-12-16 10:37:16,845:WARNING:Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 795, in compare_models
    assert (
AssertionError

2022-12-16 10:37:16,845:INFO:Initializing create_model()
2022-12-16 10:37:16,845:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002281239F8E0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022810EC8B20>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:37:16,846:INFO:Checking exceptions
2022-12-16 10:37:16,849:INFO:Importing libraries
2022-12-16 10:37:16,850:INFO:Copying training dataset
2022-12-16 10:37:16,857:INFO:Defining folds
2022-12-16 10:37:16,858:INFO:Declaring metric variables
2022-12-16 10:37:16,858:INFO:Importing untrained model
2022-12-16 10:37:16,859:INFO:Huber Regressor Imported successfully
2022-12-16 10:37:16,859:INFO:Starting cross validation
2022-12-16 10:37:16,861:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:37:19,346:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-16 10:37:19,525:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-16 10:37:19,535:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-16 10:37:19,786:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-16 10:37:19,848:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.95108635 1.9598154  2.00305989 2.00697019 2.00829898 2.01887297
 2.01907153 2.03226814 2.0361734  2.03733014 2.06520418 2.0952715
 2.19342998 3.73732048 3.79790231 3.80210314 3.8045171  3.81871554
 3.83900528 3.84653264 3.84703219 3.84840134 3.85155016 3.8528538
 3.85550343 3.85737261 3.85762552 3.85808442 3.85885945 3.86114237
 3.86503218 3.86687896 3.86921698 3.87175417 3.87280028 3.87419389
 3.87450557 3.87527965 3.8760967  3.87628838 3.88160724 3.88162934
 3.88215101 3.88283204 3.88329174 3.88708456 3.88786298 3.88827259
 3.8884026  3.8891752  3.89022989 3.89064392 3.8906638  3.8907272
 3.89089351 3.89168538 3.89188805 3.89214749 3.8921709  3.89261329
 3.89273849 3.89294681 3.89344765 3.89354999 3.89422111 3.89449694
 3.89475732 3.89492159 3.89531402 3.895393   3.89543445 3.89562922
 3.89607035 3.89678046 3.89705189 3.89709703 3.8975632  3.8990783
 3.89937811 3.89965082 3.89996062 3.90022357 3.90051964 3.90072754
 3.90096715 3.90105301 3.90107253 3.90124049 3.90131048 3.90223161
 3.90238699 3.90312904 3.90315549 3.90321987 3.90325459 3.90331492
 3.90362627 3.9037152  3.90371957 3.90387207 3.90432217 3.90525851
 3.90526914 3.90566328 3.90575012 3.9057626  3.9058542  3.90604563
 3.9062997  3.90635076 3.90656711 3.90675972 3.90678364 3.90688312
 3.90692768 3.90703174 3.90810142 3.90843061 3.90881512 3.9090557
 3.90921674 3.90937203 3.90970375 3.90979668 3.9097999  3.9100213
 3.9101503  3.91019671 3.9104872  3.91050909 3.91054019 3.91159777
 3.91161017 3.91163887 3.91168676 3.91194727 3.9120493  3.91211985
 3.91212411 3.91213552 3.91239217 3.91240722 3.91283629 3.91287988
 3.91295565 3.91339886 3.91391548 3.91417968 3.91424939 3.91426981
 3.91431936 3.91451274 3.91467529 3.91469167 3.91501165 3.91534504
 3.91546243 3.91556128 3.91558857 3.91571994 3.91577887 3.9157835
 3.91588735 3.91612163 3.91642692 3.91676135 3.91683436 3.91692145
 3.91701236 3.91709943 3.91723962 3.9172797  3.91744989 3.91747208
 3.91759961 3.91774852 3.91777704 3.91829606 3.9183892  3.91871375
 3.91878225 3.91884598 3.91886232 3.91893625 3.91899133 3.91900891
 3.91901926 3.9191782  3.91926612 3.91936256 3.92001762 3.92020633
 3.92057324 3.92063299 3.92063706 3.92072112 3.92089746 3.92112425
 3.92129414 3.92135139 3.92142531 3.92146418 3.92146827 3.92147451
 3.92147954 3.92151982 3.92154458 3.92169706 3.92170049 3.92176387
 3.92190931 3.92207044 3.92220151 3.92221296 3.92263878 3.92264853
 3.9227931  3.92290482 3.92293022 3.9229962  3.92319807 3.92320398
 3.9233517  3.92342555 3.92344085 3.92352743 3.92352802 3.92363228
 3.92366642 3.92374233 3.92388192 3.92390837 3.92395048 3.92462548
 3.92475213 3.9248621  3.92488118 3.92490877 3.92492859 3.92495579
 3.92503669 3.92517641 3.92539288 3.92543902 3.92572697 3.92609866
 3.92648802 3.92652648 3.926546   3.92666626 3.92681441 3.92695637
 3.92715356 3.92723825 3.92727113 3.92729174 3.92729502 3.9276094
 3.92769809 3.92795144 3.92800671 3.92801994 3.92804869 3.92806171
 3.92817486 3.92827773 3.92827804 3.92833227 3.92844606 3.92860236
 3.92864165 3.92867813 3.92906008 3.92916681 3.9293987  3.92972798
 3.92986507 3.92997929 3.93000121 3.9301684  3.93025967 3.93034134
 3.93051252 3.93064455 3.93069607 3.93073758 3.93074098 3.93078355
 3.9310502  3.93131369 3.93146134 3.93179077 3.93180717 3.93187442
 3.93194505 3.93204028 3.93209736 3.93220307 3.93236699 3.93244731
 3.9324694  3.9325113  3.9325785  3.93264355 3.9326922  3.93270259
 3.9327239  3.93274669 3.93291758 3.93293802 3.93302622 3.93308697
 3.93312267 3.93329641 3.93331034 3.93341681 3.93342985 3.93349322
 3.93357366 3.93388935 3.93393854 3.93400044 3.93404949 3.93416626
 3.93447203 3.9345243  3.93464322 3.9346468  3.93467555 3.93477472
 3.93487346 3.93493476 3.93508588 3.93510855 3.9355368  3.93567593
 3.93571634 3.93592513 3.93594555 3.93600695 3.93600793 3.93603887
 3.93607152 3.93613532 3.93614129 3.93615502 3.93620307 3.93623385
 3.9362964  3.93651671 3.9366228  3.93664354 3.93667045 3.93678213
 3.93679678 3.93680157 3.93698722 3.93714571 3.93726132 3.93727663
 3.93753142 3.93794199 3.93850477 3.93864636 3.93875003 3.9387891
 3.93882593 3.93885849 3.93886991 3.93905806 3.93925449 3.93941004
 3.93971025 3.93975065 3.9398513  3.93989962 3.93992153 3.94023382
 3.94025448 3.94026805 3.94029229 3.94031127 3.94034107 3.94040969
 3.94063749 3.94068599 3.94080738 3.9408217  3.94088609 3.94095129
 3.94095281 3.94108583 3.94109063 3.94115206 3.94123136 3.94148569
 3.94157971 3.9417671  3.9418037  3.94189685 3.94204005 3.94210473
 3.94222486 3.94227587 3.94234168 3.94244242 3.94288882 3.94294225
 3.9430359  3.94334963 3.94338314 3.94379142 3.9438471  3.94428853
 3.9443126  3.94438427 3.94453477 3.94454273 3.94480492 3.94509503
 3.94513883 3.94533595 3.94539824 3.94559081 3.94600203 3.94603853
 3.94623159 3.94628517 3.94630623 3.94634053 3.94643056 3.94664723
 3.94683357 3.946969   3.94696985 3.94722718 3.94725325 3.94727999
 3.94732174 3.94737321 3.94738619 3.94747576 3.94764927 3.94781959
 3.94807102 3.94825041 3.94838318 3.94848857 3.94867078 3.94867618
 3.9487838  3.94879116 3.94893782 3.94895358 3.94908063 3.94912215
 3.94925295 3.94928279 3.94928427 3.94933798 3.94934771 3.94941917
 3.94948815 3.9496687  3.94977488 3.94978321 3.94978882 3.9498242
 3.95006403 3.950151   3.95060059 3.95087823 3.95097397 3.95107226
 3.95111218 3.95136389 3.95146004 3.95153195 3.95181495 3.95183247
 3.95187244 3.95190259 3.95197915 3.95213827 3.95233524 3.95249
 3.95256427 3.95268638 3.95268944 3.95285484 3.95287713 3.95302656
 3.95304143 3.95310354 3.9532536  3.95334631 3.95348754 3.9535824
 3.95360439 3.95361988 3.95361988 3.95377619 3.95378703 3.95382246
 3.95423579 3.95436376 3.95436591 3.95438221 3.95439578 3.95461325
 3.95469332 3.95477597 3.95520842 3.95527041 3.95550714 3.9557676
 3.9560779  3.95638051 3.95641198 3.95644128 3.95650757 3.95685092
 3.95691628 3.95695572 3.9569832  3.95698739 3.95700136 3.95744359
 3.95787198 3.95798353 3.95801491 3.95808747 3.9581615  3.95829684
 3.95845031 3.9585339  3.95877997 3.9588121  3.95914774 3.95945731
 3.95951728 3.95961426 3.95981168 3.96001797 3.96008258 3.96015676
 3.9603232  3.9603922  3.96049924 3.9607905  3.96085562 3.9610673
 3.96108484 3.96113887 3.96118524 3.96128835 3.9616981  3.96179129
 3.96191677 3.96224797 3.96225739 3.96258495 3.96261596 3.96265355
 3.96272784 3.96281425 3.96283161 3.96303685 3.96312643 3.9633233
 3.96365272 3.96374391 3.96419759 3.96435038 3.96461391 3.96463189
 3.96464846 3.96481031 3.96488122 3.9649076  3.96491834 3.9650263
 3.96516603 3.96519404 3.96557914 3.96575769 3.96576559 3.96582953
 3.96586484 3.96611997 3.96646382 3.96647139 3.9664941  3.96655229
 3.96660534 3.96682284 3.96690435 3.96693155 3.96694146 3.96713426
 3.96723225 3.96763905 3.9676628  3.96777172 3.96790403 3.96793536
 3.96798123 3.96803399 3.96844217 3.96844891 3.96864559 3.96873082
 3.96930676 3.96948769 3.96973309 3.97000497 3.97009419 3.97034898
 3.97053164 3.97120097 3.97126903 3.97131594 3.97146055 3.97149954
 3.97152509 3.97167394 3.97174032 3.97186658 3.97206094 3.9725488
 3.97260961 3.97291999 3.97307691 3.97307912 3.97312627 3.97352192
 3.97381174 3.97397662 3.97404427 3.97413013 3.97430671 3.97441626
 3.97466033 3.97536232 3.97543692 3.97543778 3.97558759 3.97596811
 3.976435   3.97652767 3.97653236 3.97668051 3.97674977 3.97680293
 3.97693852 3.97694959 3.9770739  3.97720511 3.97725157 3.97734024
 3.97735709 3.97742332 3.97746372 3.97779361 3.97787712 3.97804848
 3.97811433 3.97813296 3.97870393 3.97881659 3.9788684  3.97934124
 3.97960258 3.97976473 3.97996431 3.97998581 3.98026231 3.98082458
 3.9815369  3.98154777 3.98155793 3.98193313 3.98218427 3.98241992
 3.98268807 3.98270699 3.98286117 3.98323995 3.98327016 3.98343108
 3.98380369 3.98381799 3.98388164 3.98424271 3.98427843 3.98440557
 3.98448577 3.98489847 3.98510501 3.98531913 3.98567164 3.98592368
 3.98602008 3.98656768 3.98676533 3.98706718 3.98754214 3.98759116
 3.98783575 3.98791554 3.98813973 3.98852967 3.98864456 3.98887662
 3.98929321 3.98977763 3.9898751  3.98988246 3.98990689 3.99059958
 3.99080099 3.99122074 3.99131864 3.99210054 3.99222022 3.9923425
 3.99258016 3.99302264 3.99335434 3.99384182 3.99390786 3.99411571
 3.99430266 3.99470534 3.99536791 3.99547773 3.99555603 3.9965879
 3.99779935 3.99817675 3.99838933 3.99855986 3.99862251 3.99889149
 3.9990973  3.99941395 3.99949374 3.99984604 3.99999512 4.000036
 4.00005393 4.00013741 4.00106179 4.00115041 4.00175201 4.00202043
 4.00204613 4.00223235 4.00242411 4.00253749 4.00264013 4.00279476
 4.00279495 4.0029636  4.0040172  4.00453681 4.00471856 4.00539337
 4.00569523 4.00597957 4.00694207 4.00698641 4.00825064 4.00905051
 4.00923315 4.01072405 4.01101104 4.01135138 4.01140368 4.01206157
 4.01361842 4.01442201 4.01459808 4.01500954 4.0174484  4.01809133
 4.01892461 4.02078583 4.02142375 4.02190698 4.02290796 4.02422545
 4.02924002 4.03114841 4.03424644 4.03508087 4.03615081 4.0374444
 4.03852685 4.04758755 4.04768264 4.04789987 4.04999875 4.053677
 4.05426356 4.0551257  4.06273716 4.0666225  4.06680089 4.07695088
 4.08163891 4.08610105 4.09437994 4.09653683 4.09689482 4.09710122
 4.10731472 4.11082191 4.11124994 4.15237062 4.17619105 4.18880897
 4.77958862 4.79112278 4.79662931 4.79729261 4.80714255 4.81132577
 4.81664338 4.88726349 4.89967741 4.89978463 4.90846857 4.91076664
 4.91654949 4.91728601 4.91862884 4.919847   4.92230936 4.92242452
 4.92438778 4.92639041 4.92711065 4.92781517 4.92996701 4.93650048
 4.93701845 4.93966727 4.93987514 4.9425125  4.94710638 4.95307105
 4.95328238 4.95346957 4.95635515 4.95931141 4.95994642 4.99751047]

  warnings.warn(

2022-12-16 10:37:19,982:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.43717275 2.44421593 2.45540932 2.46502033 2.47637753 2.49199846
 2.49243637 2.49650365 3.70357539 3.85145295 3.85284094 3.86036513
 3.8701395  3.87221958 3.87280195 3.87991334 3.88020959 3.88025138
 3.88075487 3.88177981 3.88943765 3.89117619 3.89424216 3.8949201
 3.89802941 3.89951486 3.90024521 3.90055026 3.90077321 3.90223789
 3.90254553 3.90398357 3.90444864 3.90515819 3.90612819 3.90649619
 3.9067449  3.91052433 3.91130014 3.91230525 3.91305542 3.91309008
 3.91438006 3.91445112 3.91457714 3.91488865 3.91576113 3.91673215
 3.91772448 3.9179083  3.91803979 3.91907353 3.91935491 3.92009753
 3.92062681 3.92093565 3.92093715 3.92113206 3.92129842 3.9215732
 3.92205738 3.92233217 3.92252994 3.92315675 3.92491711 3.92493685
 3.92525568 3.92558834 3.92593264 3.92639461 3.92647708 3.92664691
 3.92730874 3.92776934 3.9290453  3.92913175 3.92917117 3.92950797
 3.929548   3.93026989 3.93051654 3.93071989 3.93084333 3.93223221
 3.9323495  3.93292106 3.93310323 3.9332344  3.93350137 3.93359716
 3.9336973  3.93370043 3.93371241 3.93378819 3.93379288 3.93382705
 3.93421774 3.93448976 3.93459084 3.93471388 3.93514771 3.93540157
 3.93606797 3.93644037 3.9365172  3.93685111 3.93712618 3.93751287
 3.93759442 3.93761659 3.93764667 3.93782316 3.9380423  3.93808169
 3.93837935 3.93846152 3.93861396 3.93864645 3.93875792 3.93880019
 3.93892239 3.93908937 3.93923436 3.93943276 3.93951517 3.93969632
 3.93974306 3.93996631 3.94001112 3.94017238 3.94038427 3.94049935
 3.94051055 3.94058957 3.94088862 3.94090267 3.94100323 3.94106296
 3.94121667 3.94129333 3.94148972 3.94164157 3.94174031 3.94180366
 3.94185373 3.94195706 3.94197723 3.94198407 3.94205736 3.94211169
 3.94221275 3.94248231 3.94253713 3.94266097 3.94270118 3.94278085
 3.94280317 3.94285334 3.94291712 3.94323272 3.94334763 3.94340234
 3.94349934 3.94358899 3.94361494 3.94396484 3.94400561 3.94404988
 3.94430664 3.94433328 3.94439252 3.94474493 3.94495629 3.94502882
 3.94507178 3.9451891  3.94530086 3.94532905 3.94543621 3.94549495
 3.94570664 3.94575042 3.94576735 3.94588921 3.94610246 3.94627524
 3.94632752 3.94653525 3.94669709 3.94687953 3.9469872  3.94702734
 3.9470677  3.94734913 3.94736653 3.94750414 3.94781077 3.94781261
 3.94786911 3.94799138 3.94801109 3.94804392 3.94819628 3.94832937
 3.94839045 3.94851238 3.94854854 3.94867327 3.94883199 3.94887936
 3.94890652 3.94908398 3.94911542 3.94917824 3.94925662 3.94943673
 3.94947845 3.94968982 3.94991737 3.94993046 3.94996032 3.95013867
 3.95017333 3.95017338 3.95019374 3.95041835 3.95042537 3.95047588
 3.95048008 3.95068164 3.95073672 3.95080222 3.95081148 3.95085849
 3.95093827 3.95098919 3.95099699 3.951187   3.95124811 3.95125006
 3.95127378 3.95129325 3.95146211 3.95147075 3.95151353 3.95174425
 3.95176084 3.95179545 3.95184543 3.95194171 3.95195717 3.95217259
 3.95222826 3.95223322 3.95227453 3.95245264 3.95250358 3.95251142
 3.9526695  3.95267572 3.95270157 3.95277594 3.95281874 3.95284457
 3.95290604 3.95293201 3.95299349 3.95306498 3.95309978 3.95312873
 3.95351223 3.95352077 3.95385164 3.95385627 3.95406716 3.95412421
 3.95412592 3.95420384 3.95422229 3.9542883  3.95437919 3.95465946
 3.95476284 3.95492018 3.95495058 3.9550347  3.95514872 3.95516086
 3.95536725 3.95555127 3.95561142 3.95562945 3.95572226 3.95575885
 3.95591504 3.95599442 3.95617611 3.95619308 3.95629538 3.95633244
 3.95639588 3.95653395 3.95654504 3.95657313 3.9566406  3.95668831
 3.95671864 3.95678499 3.95680646 3.9568146  3.95681563 3.95685668
 3.9568669  3.9569492  3.9570314  3.95706766 3.95710808 3.95712875
 3.95718095 3.95719528 3.95727582 3.95765127 3.95782228 3.9579553
 3.95799637 3.95814847 3.95816782 3.95831966 3.95846113 3.95847198
 3.95850301 3.95883328 3.95884568 3.95888853 3.95897148 3.95924897
 3.95936461 3.9593829  3.95951495 3.95969181 3.95976919 3.9597878
 3.95991326 3.95992784 3.95996452 3.96007867 3.96009889 3.96018048
 3.96025389 3.9603863  3.96060428 3.96070101 3.96076224 3.96082943
 3.96098499 3.96098822 3.96101691 3.96106465 3.96119594 3.96120841
 3.96121019 3.96126842 3.96128567 3.96131889 3.96141118 3.96142763
 3.9616784  3.96184774 3.9618976  3.96193064 3.96200824 3.96213414
 3.96219122 3.96224483 3.96226933 3.96228854 3.96252575 3.96257925
 3.96262882 3.96271319 3.96280116 3.96284878 3.96285927 3.96292448
 3.96317964 3.96319236 3.96321597 3.9632442  3.9632676  3.9633388
 3.96353707 3.96355878 3.96363041 3.9638286  3.96387698 3.96398189
 3.96411172 3.96432883 3.96433087 3.96435551 3.96438461 3.9644359
 3.96447333 3.96448172 3.96456488 3.96457758 3.96464014 3.96469757
 3.96485856 3.96496796 3.9650861  3.96514168 3.96523601 3.96528899
 3.9653215  3.96547485 3.9655653  3.96561295 3.96566151 3.96583114
 3.96592019 3.96594016 3.9661469  3.96620976 3.96653317 3.96655846
 3.96698225 3.96707556 3.96723772 3.96728786 3.96730747 3.96734024
 3.96736576 3.96755922 3.96761562 3.96791416 3.96792577 3.96793143
 3.96821424 3.96822338 3.96826459 3.9682754  3.96829774 3.9684348
 3.96851541 3.96855335 3.96856578 3.96864241 3.96871317 3.96878264
 3.96906288 3.96909667 3.96914493 3.96931236 3.9694272  3.96958597
 3.96960511 3.96966872 3.96978805 3.96981462 3.97001823 3.97016431
 3.97045048 3.97051161 3.97061068 3.97066951 3.97067187 3.97069304
 3.97079235 3.97082434 3.97083732 3.97088663 3.97092489 3.97093879
 3.9709452  3.97095269 3.97098659 3.97110609 3.97125803 3.97128243
 3.97129511 3.9715202  3.97156782 3.97164631 3.97165434 3.97178472
 3.97187573 3.97206703 3.97208526 3.97209284 3.97210752 3.97211856
 3.97212407 3.97216179 3.9723935  3.97256802 3.97257183 3.97260301
 3.97266289 3.97269958 3.97288898 3.97289973 3.97292848 3.97296535
 3.97297731 3.97300752 3.97307677 3.9730911  3.97318597 3.97325487
 3.97328335 3.97333391 3.97336356 3.97347183 3.97365692 3.97368357
 3.97370791 3.97374448 3.97376021 3.97390676 3.97395172 3.97409999
 3.97416255 3.97418165 3.97421589 3.97422436 3.97433823 3.97447086
 3.97450397 3.9745409  3.9745505  3.97460622 3.97503889 3.97509576
 3.97523736 3.97549452 3.97577326 3.97577457 3.97581645 3.97592892
 3.97602835 3.97611809 3.97627478 3.97628813 3.9763337  3.97635405
 3.9764252  3.97662123 3.97668024 3.97685365 3.97697715 3.97707311
 3.97717328 3.97723234 3.97736678 3.97739285 3.97752617 3.97763622
 3.97773282 3.97778998 3.97783664 3.97801423 3.9780405  3.97811716
 3.97814267 3.97815483 3.9782076  3.97857767 3.97858283 3.97873563
 3.97886895 3.9788782  3.97889411 3.97892085 3.97892673 3.97895528
 3.97900808 3.97902668 3.97904793 3.97907417 3.97914825 3.97922559
 3.97929183 3.97940126 3.97952636 3.9796528  3.97970001 3.97982778
 3.97988555 3.97988628 3.97992494 3.98000542 3.98008063 3.98016624
 3.98029211 3.98038205 3.98063969 3.98065475 3.98073672 3.9808544
 3.98108509 3.98122777 3.98124935 3.98139346 3.98168782 3.98175672
 3.9818433  3.98195989 3.98217382 3.98226557 3.98237792 3.98269877
 3.98298541 3.98298715 3.98325676 3.98329729 3.98341089 3.98342417
 3.98342762 3.98349744 3.98353271 3.98386639 3.98397139 3.9843273
 3.98469083 3.98501395 3.98503153 3.98523777 3.98526414 3.98571528
 3.98598456 3.98650137 3.98669464 3.98670555 3.98681066 3.98723408
 3.98724155 3.98728376 3.98769397 3.98807477 3.98812771 3.9881371
 3.98835279 3.98858495 3.98863819 3.98873363 3.98911287 3.9891789
 3.98924222 3.9892978  3.98985693 3.99004573 3.99010205 3.99075304
 3.99088091 3.99105978 3.99125833 3.99133865 3.9914027  3.99150135
 3.9916503  3.99188909 3.99228929 3.99247551 3.99258998 3.99264423
 3.99285288 3.99292185 3.9931646  3.99356407 3.99357977 3.99359853
 3.99373331 3.99415036 3.99415306 3.99416261 3.99429362 3.9944496
 3.99448141 3.99463909 3.99469566 3.99587677 3.99599268 3.99615026
 3.99618626 3.99632302 3.99642531 3.99658404 3.99674858 3.99692253
 3.99697334 3.99698287 3.99698615 3.99728618 3.99730494 3.99754804
 3.99759968 3.99823471 3.99831316 3.9983386  3.99856171 3.99898406
 3.99961935 3.99993163 3.99995818 4.00060363 4.00086079 4.00090886
 4.00104775 4.00110707 4.00116956 4.00118247 4.00121763 4.00129147
 4.00132855 4.00156363 4.00183775 4.00194747 4.00206133 4.00218698
 4.00252505 4.00254653 4.00309545 4.00357059 4.00385602 4.00386574
 4.00410664 4.00427855 4.00536144 4.00588337 4.00593791 4.00601833
 4.00608195 4.00733865 4.00770756 4.0079922  4.00811416 4.00848332
 4.00937124 4.00941933 4.01037249 4.01083972 4.01090644 4.01154093
 4.01154755 4.01166505 4.01376098 4.01378894 4.0138249  4.0138267
 4.01398339 4.01400313 4.01467043 4.01477145 4.01534028 4.01562954
 4.01602158 4.01627705 4.01689876 4.016965   4.01815703 4.01879055
 4.01945552 4.0194651  4.02022463 4.0213335  4.02278287 4.02325761
 4.02345146 4.02373248 4.02491401 4.02692244 4.02847944 4.0289468
 4.02898918 4.03029261 4.03055825 4.03075757 4.03120104 4.03246137
 4.03616755 4.03924481 4.04003319 4.0422446  4.0424665  4.04263673
 4.04350341 4.04383303 4.04470873 4.05101717 4.05378405 4.05496694
 4.05703857 4.06495228 4.06521019 4.06650488 4.06817746 4.07090877
 4.07098717 4.08525104 4.08721503 4.08785678 4.08859476 4.0888837
 4.09545302 4.10036211 4.1053173  4.1061035  4.11495955 4.11965687
 4.14388411 4.23419359 4.87244241 4.88817814 4.89160805 4.89247489
 4.9053136  4.91147109 4.91480312 4.93124889 4.93399638 4.93428551
 4.93885989 4.94331562 4.94333364 4.9463638  4.94760726 4.94991618
 4.95059046 4.95265692 4.95451153 4.95557037 4.95611896 4.95677513
 4.95730624 4.96021846 4.96373863 4.96437648 4.9643953  4.96475642
 4.96502188 4.96504058 4.97344892 4.97449039 4.97498547 4.97737721
 4.97832509 4.98033663 4.98035529 4.98456045 4.98594513 4.98938542
 4.9894453  5.00754395 5.01252843 5.04549558 5.10117725]

  warnings.warn(

2022-12-16 10:37:20,009:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.31392992 3.34085348 3.34253905 3.34844446 3.34904354 3.35174035
 3.35955717 3.36178687 3.36445257 3.36844958 3.38344514 3.85538521
 3.89799133 3.89841131 3.90240581 3.90246069 3.90257829 3.90458327
 3.9046921  3.90817942 3.91019474 3.91040286 3.91079629 3.91324445
 3.91352768 3.91445396 3.91531378 3.91677118 3.91759987 3.91777448
 3.91950054 3.91956391 3.91981246 3.91987317 3.9204459  3.92262245
 3.92367132 3.92442766 3.9252016  3.92524727 3.92624897 3.92653345
 3.92661643 3.9274362  3.92871292 3.93183351 3.93190277 3.93214018
 3.93246956 3.93303701 3.93379109 3.93384126 3.93407792 3.93496205
 3.93789495 3.93809763 3.93922939 3.93943653 3.93952434 3.9397428
 3.93975997 3.94032059 3.94042957 3.94057116 3.94057307 3.9410441
 3.94135681 3.94138043 3.94142076 3.94159959 3.9416387  3.94176444
 3.94211158 3.94212655 3.94230626 3.94306444 3.94307629 3.94337198
 3.94392896 3.94427789 3.94456228 3.94490924 3.94501539 3.9454055
 3.94563793 3.94576466 3.94578608 3.94582882 3.94603941 3.9463722
 3.94661363 3.94669367 3.94690576 3.9472784  3.94747347 3.94820604
 3.94832184 3.94848403 3.948542   3.94855714 3.94887236 3.94891313
 3.94892768 3.94910005 3.94948272 3.94958492 3.94964932 3.94966666
 3.94983977 3.949865   3.94998596 3.95005001 3.95015715 3.95030105
 3.95058806 3.95091345 3.95118923 3.9514213  3.95161444 3.95172215
 3.95179155 3.95211248 3.95217629 3.95228738 3.95246895 3.95248872
 3.95251204 3.95256424 3.95263099 3.95267299 3.9527987  3.95347846
 3.95401952 3.95418861 3.95420195 3.95437202 3.95447208 3.95450284
 3.95473706 3.95510117 3.95527031 3.95541705 3.95570047 3.95572143
 3.95590605 3.95608507 3.95615485 3.95629083 3.95651013 3.95658829
 3.95670936 3.95681525 3.95683367 3.95686886 3.95708262 3.9571621
 3.95734059 3.95735203 3.95752874 3.95754895 3.95761176 3.9578137
 3.95784729 3.95790422 3.95804111 3.9580916  3.95821163 3.95826142
 3.95842807 3.95846262 3.9585581  3.95860147 3.958756   3.95879102
 3.95884317 3.95892942 3.95900839 3.95907098 3.95939228 3.95951154
 3.95961945 3.95966198 3.95968613 3.95971436 3.95983294 3.95983462
 3.95985514 3.95990793 3.9600074  3.96004848 3.96007131 3.96023759
 3.96034897 3.96053164 3.96055379 3.96071849 3.96077569 3.96092864
 3.96095184 3.96096633 3.96103116 3.96105585 3.96107792 3.96108754
 3.96108878 3.96113118 3.96119289 3.96120584 3.96121695 3.96122997
 3.96124081 3.9614328  3.96150835 3.96153411 3.96159991 3.961607
 3.96162717 3.96165507 3.96198965 3.96215845 3.96225049 3.9624762
 3.96277208 3.96281345 3.9628354  3.96287278 3.96301554 3.9630773
 3.96309995 3.96314255 3.96315293 3.96326226 3.96328418 3.96330036
 3.9634466  3.96346351 3.96347597 3.96351407 3.96382388 3.96383894
 3.964129   3.96414127 3.96416598 3.96427168 3.9643186  3.96444875
 3.96450422 3.96451031 3.9645258  3.96453878 3.9645694  3.96464747
 3.96472111 3.96475918 3.96504438 3.96507195 3.96507753 3.96509168
 3.96515656 3.96517497 3.96518909 3.96525554 3.965285   3.96537527
 3.96537607 3.9654051  3.96561023 3.96562666 3.96565737 3.96579602
 3.96607339 3.96607933 3.96625992 3.96630472 3.96643327 3.96651699
 3.96670195 3.96684639 3.96710227 3.96721901 3.96732875 3.96745453
 3.96745998 3.96746381 3.96747577 3.96765391 3.9677072  3.96774764
 3.96777467 3.96778792 3.9678561  3.96802751 3.96808448 3.96830388
 3.96835996 3.96838596 3.96840187 3.96849897 3.96853503 3.96867026
 3.96870069 3.96882002 3.96890032 3.96891783 3.96892654 3.96893889
 3.96894583 3.96895607 3.96896946 3.96905265 3.96908086 3.96917088
 3.96917937 3.96919862 3.96924768 3.96937085 3.96938372 3.96943522
 3.96945908 3.96947853 3.969496   3.96954956 3.96955033 3.96960064
 3.96962001 3.96967167 3.96973472 3.96976721 3.96986387 3.96987863
 3.96997163 3.97004053 3.97006574 3.97011213 3.97016839 3.97027282
 3.97029946 3.97033769 3.97035617 3.97037659 3.97040129 3.97071025
 3.97078988 3.97084601 3.97088098 3.97089371 3.97091582 3.97096136
 3.97097141 3.97100047 3.9710795  3.97118051 3.97118976 3.97120648
 3.9713177  3.97135965 3.97139028 3.9713936  3.97143793 3.97154188
 3.97164615 3.97167185 3.97168299 3.97170766 3.97193558 3.9719462
 3.97195768 3.97202978 3.97205869 3.97209029 3.97209219 3.9721489
 3.97224866 3.97234098 3.97245804 3.97256359 3.97256952 3.97263688
 3.97265765 3.97272649 3.97288375 3.97290454 3.97294196 3.97299453
 3.97301958 3.97302089 3.97303925 3.97307415 3.9731125  3.97311526
 3.97322348 3.97334571 3.97345869 3.97353888 3.9736003  3.97361086
 3.97362122 3.97372162 3.97374966 3.97403957 3.97404504 3.97414415
 3.97426774 3.97431574 3.9743747  3.97445373 3.97455028 3.97457747
 3.97462477 3.97467712 3.97468085 3.97469082 3.97482891 3.97492118
 3.9750879  3.97510278 3.97516292 3.9751739  3.97517424 3.97523821
 3.97525015 3.97525684 3.97531764 3.97542834 3.97545435 3.97548935
 3.97555275 3.97561108 3.97563751 3.97567443 3.97567928 3.97571291
 3.97572868 3.97591571 3.97594155 3.97596903 3.97604442 3.97606787
 3.97606932 3.9761533  3.97618463 3.97625341 3.97628533 3.97629038
 3.97640656 3.97642959 3.97646597 3.97652163 3.97666028 3.97666713
 3.97667966 3.97672459 3.9767545  3.97689679 3.97695786 3.97696241
 3.97701971 3.97703687 3.97707453 3.97714436 3.977154   3.97727722
 3.97757943 3.9775881  3.97761985 3.97764192 3.97766096 3.9779933
 3.97820386 3.97827695 3.97829828 3.97831171 3.97831207 3.9784738
 3.97849877 3.97854424 3.97855794 3.97874243 3.97875749 3.97881077
 3.97886537 3.9788655  3.97888021 3.97889583 3.97889816 3.97894826
 3.97895498 3.9789608  3.97898873 3.97907767 3.97912648 3.97914505
 3.97916667 3.97917348 3.97921544 3.97927176 3.97930159 3.97935002
 3.97946475 3.97946616 3.97951744 3.97959555 3.97971134 3.97989552
 3.9799688  3.97998754 3.98000054 3.98000618 3.98002141 3.98003486
 3.98015138 3.98041033 3.980426   3.98056964 3.98058905 3.9806035
 3.98064118 3.98068428 3.9807129  3.98076183 3.98077278 3.98085677
 3.98097589 3.98098787 3.98110463 3.98120217 3.98136456 3.98143744
 3.98147673 3.9816542  3.98171591 3.98172745 3.9817506  3.98175841
 3.98185143 3.98188703 3.98190161 3.98190252 3.98198944 3.98200002
 3.98201848 3.98203846 3.98208094 3.9822766  3.98228712 3.98231817
 3.98241127 3.98245015 3.98248757 3.98261541 3.98262714 3.98275707
 3.98277847 3.98278032 3.98302763 3.98304769 3.98311061 3.98318398
 3.98328182 3.983403   3.98340937 3.98356487 3.98357435 3.98359755
 3.98364274 3.98370583 3.98372676 3.98373312 3.98386642 3.98388546
 3.98392524 3.98411129 3.9841258  3.98417121 3.98429768 3.984384
 3.98448369 3.98452468 3.98452487 3.98457731 3.9847135  3.98486823
 3.98490448 3.9849123  3.98491315 3.98495406 3.98500858 3.98510517
 3.98511407 3.98514539 3.98524398 3.98542423 3.98544948 3.98551695
 3.98552232 3.98559623 3.98564241 3.98564308 3.98566824 3.98573044
 3.98574351 3.98575452 3.98581594 3.98590121 3.98595062 3.98595724
 3.98597653 3.98606013 3.98611477 3.98616614 3.98618228 3.98627964
 3.98628095 3.98640661 3.98651106 3.98652828 3.98657343 3.98678867
 3.98697028 3.98702438 3.98703122 3.98715451 3.98743908 3.98745218
 3.98746887 3.98747182 3.98754611 3.98760687 3.98792007 3.98795245
 3.98797004 3.9880431  3.98804915 3.98810313 3.98817161 3.9882828
 3.98840255 3.9887443  3.98875568 3.98882482 3.98883511 3.98885942
 3.98895358 3.9890334  3.98912883 3.98931011 3.98942752 3.98957677
 3.98963055 3.98984769 3.9899393  3.99020621 3.99021027 3.99032965
 3.99033371 3.99040203 3.990482   3.99055827 3.99061994 3.99070859
 3.990737   3.99085071 3.99091875 3.99106993 3.99107871 3.99115014
 3.99116051 3.99133407 3.99142411 3.991437   3.99163984 3.99164001
 3.9916537  3.99185607 3.99201959 3.99219079 3.99221899 3.99260804
 3.99264974 3.99268098 3.99271903 3.99281374 3.99297444 3.9930318
 3.99364829 3.99365203 3.99372637 3.99375722 3.99387718 3.99391814
 3.99401093 3.99428612 3.99445966 3.99448096 3.9946744  3.99481765
 3.9948917  3.9949048  3.99495824 3.99496792 3.99533019 3.99534923
 3.99561111 3.99585283 3.99599101 3.99653572 3.99656216 3.99682128
 3.99692099 3.99697505 3.99721463 3.99734201 3.99753979 3.99813993
 3.9981731  3.99836552 3.99865149 3.9987472  3.99900358 3.99907096
 3.9991202  3.99921024 3.99932812 3.999421   3.99950067 3.99956192
 3.99960891 3.99973321 3.99984955 4.00016054 4.00034112 4.00065899
 4.00075628 4.00081676 4.00087246 4.00127186 4.00147024 4.00149077
 4.00164155 4.00175942 4.00197539 4.0021488  4.00224807 4.00230357
 4.00308952 4.00329388 4.00334582 4.00335709 4.00420561 4.00444483
 4.00546264 4.00560036 4.00585832 4.00647975 4.00661552 4.00754608
 4.0076763  4.00788113 4.0083177  4.00875411 4.00905714 4.00917424
 4.00935804 4.00946863 4.009527   4.01094436 4.01107476 4.01112994
 4.01186297 4.01243789 4.01302812 4.01311325 4.013261   4.01333168
 4.01367715 4.01381323 4.01393861 4.0149027  4.01502352 4.01564768
 4.0159364  4.0162333  4.0173437  4.01922393 4.02063703 4.020994
 4.02115164 4.02144285 4.02169474 4.02240451 4.02297684 4.02345304
 4.02397735 4.02546089 4.02554074 4.02635793 4.02802871 4.02913626
 4.02938775 4.03003704 4.03138123 4.0331624  4.03571632 4.03587081
 4.03764179 4.04174862 4.04661149 4.0523654  4.08681687 4.91262671
 4.91514066 4.94117518 4.94782996 4.96099485 4.9624128  4.96490908
 4.96691536 4.96733833 4.96786559 4.96850507 4.96874157 4.96960957
 4.96973243 4.97093936 4.97358938 4.97376929 4.97406548 4.97426007
 4.97452842 4.97824369 4.97918252 4.97978858 4.98232685 4.98306574
 4.98501016 4.98578231 4.98578698 4.98740116 4.98764928 4.98773151
 4.98846066 4.98885319 4.99006789 4.99024837 4.99165962 4.99537806
 4.9969655  4.99767952 5.00420983 5.00508462 5.00616742 5.0145123
 5.03645427]

  warnings.warn(

2022-12-16 10:37:20,285:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.73584268 1.7393993  1.74977546 1.75663467 1.77986995 1.79104437
 1.80104533 1.8160329  3.76817068 3.79177565 3.80629721 3.80934447
 3.81895482 3.85877539 3.87107258 3.87795415 3.87885627 3.8789659
 3.88053504 3.88068958 3.88205617 3.88284126 3.88343722 3.88393709
 3.88418837 3.88860713 3.89102351 3.89117093 3.89239705 3.89449476
 3.89490837 3.89534882 3.89778108 3.89952055 3.90120966 3.90406748
 3.90447067 3.90526869 3.90926852 3.91177452 3.9142393  3.91434262
 3.91614184 3.91730261 3.91793613 3.91938455 3.91993526 3.92146518
 3.92235095 3.92302697 3.92333619 3.92354907 3.92499435 3.92597948
 3.92604184 3.92645168 3.92775237 3.92818241 3.9283135  3.92860157
 3.92920966 3.93012635 3.93023658 3.93040345 3.93070011 3.93109915
 3.93117531 3.9313975  3.93142519 3.9314255  3.93160825 3.93167956
 3.93191445 3.93205176 3.93248206 3.9335983  3.93473285 3.93521412
 3.93537195 3.93625969 3.93633792 3.93637589 3.93648325 3.93679737
 3.93700762 3.93714338 3.93731042 3.93770008 3.9378591  3.9378772
 3.9379191  3.93807338 3.93815875 3.93822195 3.93853896 3.93875626
 3.93905793 3.93913101 3.93938617 3.93959169 3.93979705 3.94085525
 3.94130522 3.94167945 3.9417652  3.94188676 3.94194586 3.94210108
 3.94229075 3.94260768 3.94290214 3.94340654 3.94355443 3.94363681
 3.94365703 3.94385956 3.94438214 3.9448673  3.94490218 3.94499072
 3.94533069 3.94545976 3.94548911 3.94549523 3.94550475 3.9455281
 3.94558973 3.94565223 3.94569167 3.94587098 3.94608443 3.94612762
 3.94623782 3.94631721 3.94692694 3.94722982 3.94731927 3.94738278
 3.94764821 3.94772623 3.94774817 3.94781691 3.94784923 3.94802116
 3.94804919 3.94809441 3.948258   3.94832142 3.94839803 3.94856214
 3.9487007  3.94882054 3.94892921 3.94898288 3.94904624 3.94908754
 3.94918688 3.94921331 3.94926344 3.94947387 3.94953924 3.94956142
 3.94959805 3.94962544 3.94964921 3.94965681 3.94970833 3.94978808
 3.94987801 3.95037089 3.950405   3.95040781 3.95045635 3.9505761
 3.95059587 3.95070944 3.95079648 3.95090423 3.95094505 3.95095532
 3.95104193 3.95135011 3.95158978 3.95166064 3.95177483 3.9520401
 3.95213783 3.95219016 3.95226288 3.95227613 3.95233134 3.95239391
 3.9524586  3.95246079 3.95260002 3.95279151 3.9528301  3.9529946
 3.9530037  3.95307491 3.95312338 3.95342542 3.95343804 3.95344081
 3.9536052  3.95361843 3.95372824 3.95381504 3.95383337 3.9539468
 3.95406961 3.9540761  3.95424307 3.95434112 3.95441999 3.95458468
 3.95460057 3.95464529 3.95472257 3.95483069 3.95483337 3.95488416
 3.95488876 3.95490574 3.95539127 3.95541274 3.95541406 3.95557985
 3.95560575 3.95565462 3.95569714 3.95590688 3.95593077 3.95607281
 3.95613303 3.95624563 3.9564125  3.95645439 3.95652479 3.95657236
 3.95657531 3.95657801 3.95657802 3.95669199 3.95671826 3.95676883
 3.95678274 3.9567966  3.95681038 3.95691489 3.95703929 3.95726938
 3.95732954 3.95739238 3.95768205 3.95786009 3.95790816 3.95800795
 3.95806742 3.95815108 3.9585372  3.9585865  3.95871643 3.95873743
 3.95894964 3.95897389 3.95916139 3.95920597 3.95923605 3.95924004
 3.9592571  3.95928765 3.95935255 3.95944909 3.95947457 3.95977901
 3.95978285 3.95992295 3.96006415 3.96028807 3.96033522 3.96066186
 3.96071875 3.96077164 3.96080065 3.96097067 3.96100117 3.96107054
 3.96107903 3.96117126 3.96125969 3.96128305 3.96135793 3.96136703
 3.96141537 3.96154234 3.96159948 3.96164402 3.9616574  3.96170431
 3.96181342 3.96195411 3.9620864  3.96217047 3.96220766 3.96239945
 3.96240085 3.96241842 3.96256198 3.96265209 3.96275063 3.96280562
 3.96281324 3.96294291 3.96296898 3.96304737 3.96305683 3.96319054
 3.96319326 3.96329643 3.96329767 3.96330518 3.96334403 3.96339451
 3.96343602 3.9636332  3.9636445  3.96393983 3.96398724 3.96398931
 3.96419071 3.96419833 3.96422074 3.96434201 3.96434787 3.96436939
 3.96442999 3.96448754 3.96451107 3.96455393 3.9646739  3.96468075
 3.96468241 3.96471762 3.96482249 3.96483263 3.96497474 3.96522905
 3.96532126 3.96546999 3.96556979 3.96557253 3.96566832 3.96577672
 3.9657979  3.965812   3.96592141 3.96593525 3.96598784 3.96601224
 3.96612147 3.96628501 3.96629164 3.96631255 3.96641805 3.96645033
 3.96663448 3.96667222 3.96672465 3.96698694 3.96699909 3.96711502
 3.96711527 3.96725329 3.96739068 3.96741864 3.96745128 3.96753119
 3.96759396 3.96760538 3.96762586 3.96772619 3.96776441 3.96779847
 3.96799517 3.96814648 3.96820955 3.96836047 3.96839522 3.96845224
 3.96865795 3.96866335 3.96872388 3.96874163 3.96879173 3.96884838
 3.9690682  3.96915808 3.96918522 3.96938487 3.96953704 3.96955494
 3.96981678 3.9698351  3.96984538 3.96985698 3.96993261 3.97001708
 3.97011646 3.97023967 3.97026621 3.97028755 3.97040181 3.97041849
 3.97049471 3.9705638  3.9705732  3.97060034 3.97062118 3.97065777
 3.97074837 3.97074905 3.9707811  3.97089031 3.97092251 3.97094691
 3.97094824 3.97097459 3.97097557 3.97118227 3.97121059 3.97130116
 3.97137405 3.97139975 3.97181859 3.97208864 3.97231804 3.97246945
 3.97251002 3.97264791 3.97266519 3.97282661 3.97284544 3.97286569
 3.97287594 3.97302574 3.97308765 3.97313937 3.97333093 3.97337977
 3.97340696 3.97348623 3.97353588 3.97378489 3.9738016  3.97394442
 3.97396515 3.97408622 3.97416047 3.97433256 3.97435983 3.97440314
 3.97441819 3.9746736  3.97471287 3.9747505  3.97485023 3.9749667
 3.97501158 3.97501987 3.97502097 3.97521299 3.97533088 3.97545776
 3.97546166 3.97555091 3.9756263  3.97563585 3.97566451 3.97569984
 3.97570524 3.97572504 3.97582444 3.97583672 3.97587849 3.97591525
 3.97596116 3.97597852 3.97606784 3.97610194 3.97643385 3.97648822
 3.97662872 3.97667204 3.9766929  3.97675741 3.97679646 3.97692143
 3.97696226 3.97700303 3.97720065 3.97735431 3.97745102 3.97777919
 3.97788696 3.97789944 3.97792239 3.97792983 3.978198   3.97831662
 3.97839184 3.978396   3.97840925 3.97844193 3.97852838 3.97853698
 3.97856101 3.97857544 3.97871759 3.97888317 3.9790397  3.9790527
 3.97926808 3.97931472 3.97936365 3.97939575 3.9794071  3.97950638
 3.97968153 3.97976277 3.9797669  3.97986266 3.9800188  3.98007607
 3.98011751 3.98011913 3.98012796 3.9802827  3.98031337 3.98037088
 3.98050451 3.98062416 3.98069839 3.98081827 3.98092118 3.98102833
 3.98104433 3.9810925  3.98116803 3.981227   3.98125831 3.98128667
 3.98131835 3.98140255 3.98144311 3.98147464 3.98154907 3.9816556
 3.98167184 3.98170204 3.98178541 3.98219865 3.98230771 3.98237834
 3.98241539 3.98243282 3.98244883 3.982449   3.98256159 3.98269902
 3.982731   3.98273222 3.9827858  3.98292612 3.98313131 3.98321264
 3.98324137 3.98352219 3.98361316 3.9836249  3.98375095 3.98376683
 3.98381551 3.98391702 3.98403585 3.98405396 3.98406405 3.9841387
 3.98423512 3.98429338 3.98442926 3.98448263 3.98507569 3.98527606
 3.9852924  3.98546071 3.9854789  3.98557791 3.98564536 3.98572683
 3.98580756 3.98626171 3.98633921 3.98635214 3.98636169 3.98647539
 3.98649572 3.98650796 3.98657196 3.986625   3.98667234 3.98679477
 3.98687825 3.98689183 3.98701398 3.98704775 3.98706348 3.9871603
 3.98723049 3.98729172 3.98764188 3.98767593 3.98781495 3.98785785
 3.987905   3.98793212 3.988032   3.98810715 3.98812268 3.98813556
 3.98813755 3.98818172 3.98820221 3.98834878 3.98845878 3.98850402
 3.98853754 3.98871015 3.98871918 3.98879458 3.98896317 3.98924582
 3.9892461  3.98931856 3.98938585 3.98942823 3.98953405 3.98959825
 3.98970578 3.98973697 3.98996146 3.99001648 3.99003408 3.9901877
 3.99025813 3.99031415 3.99032439 3.9904317  3.99060622 3.99068025
 3.99075986 3.99081942 3.99086992 3.99135514 3.99152547 3.99155135
 3.99215412 3.99216319 3.99237648 3.99237706 3.99237937 3.99243062
 3.99251479 3.99255324 3.99258102 3.99275547 3.99287452 3.99322497
 3.99331475 3.99331509 3.9935817  3.99378837 3.99389059 3.99404572
 3.9940567  3.99432052 3.99459956 3.99466046 3.99469775 3.99482248
 3.99493985 3.99495346 3.99499673 3.9949985  3.99504756 3.99511545
 3.99517092 3.99550385 3.99600178 3.99606724 3.99615341 3.99649271
 3.99649325 3.99659034 3.99684787 3.99742629 3.99757843 3.99778039
 3.99785741 3.99787553 3.99798681 3.99815526 3.99819099 3.99835724
 3.99905183 3.99917388 3.99946409 3.99958494 3.99958971 4.00021177
 4.00073403 4.00089616 4.00096267 4.00118076 4.00154613 4.00171822
 4.00182259 4.00183496 4.00242753 4.00246276 4.00247748 4.00273408
 4.00282913 4.00293844 4.00373974 4.00408736 4.00461341 4.00465766
 4.00488561 4.00488675 4.00540788 4.00633696 4.00696873 4.00725393
 4.00743005 4.00756364 4.0077189  4.00792583 4.00826477 4.00861375
 4.00870748 4.00891468 4.00945177 4.00963448 4.00964845 4.00970416
 4.00984736 4.01009659 4.0101457  4.01031003 4.01095656 4.01133965
 4.01158835 4.01164955 4.0134166  4.01360887 4.01381511 4.01438784
 4.01504618 4.01508199 4.01527345 4.0153396  4.016166   4.01639994
 4.01682794 4.01692566 4.01746972 4.01827198 4.0184684  4.0187549
 4.01943774 4.01987869 4.02061605 4.02293456 4.02405901 4.02461599
 4.0255552  4.02648331 4.02665474 4.02751654 4.02772986 4.02913268
 4.02951593 4.03153622 4.03164048 4.0323375  4.03260297 4.03404306
 4.03656243 4.04198384 4.04610052 4.04920163 4.05073821 4.05208472
 4.05400819 4.05413497 4.09553982 4.13304559 4.24818435 4.25014518
 4.88032402 4.92500739 4.93287767 4.94424501 4.95259954 4.97011613
 4.97373616 4.97707663 4.97716199 4.97869186 4.98041347 4.98118557
 4.98385102 4.98449472 4.9895749  4.98999273 4.99020544 4.99103037
 4.99196117 4.9990717  4.99973049 5.00013572 5.000633   5.00065184
 5.00268894 5.00282328 5.00389358 5.00402433 5.00492498 5.00614447
 5.0065816  5.0066396  5.00692136 5.00736374 5.01197431 5.0121501
 5.01313054 5.01717935 5.0190145  5.02311138 5.03381301 5.04072716
 5.04322291 5.06701429]

  warnings.warn(

2022-12-16 10:37:20,330:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-16 10:37:20,347:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-16 10:37:20,430:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-16 10:37:20,487:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-16 10:37:20,681:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.65271651 2.71240837 2.72215961 2.72643048 2.73519667 2.75719883
 3.89409348 3.89887575 3.90025588 3.90418589 3.909268   3.91239329
 3.91616112 3.91764768 3.91894673 3.92048361 3.92086337 3.92237135
 3.92389324 3.92441959 3.92451669 3.92728562 3.92793659 3.92881134
 3.93120162 3.93129624 3.93165201 3.932866   3.93477032 3.9347846
 3.93507767 3.93569417 3.93635224 3.93653924 3.93734842 3.93761082
 3.93797051 3.93856555 3.93948329 3.94021363 3.94060612 3.94063834
 3.94108505 3.94148722 3.94157714 3.94177426 3.94224727 3.94322396
 3.94380051 3.9438139  3.94404484 3.94417481 3.94418051 3.94437823
 3.94444391 3.94466239 3.9447065  3.9452798  3.94552999 3.94601605
 3.9461813  3.94637687 3.94672676 3.94742506 3.94821229 3.94822363
 3.94823545 3.94838546 3.94963285 3.94977422 3.94993652 3.94997617
 3.95014246 3.95024158 3.95028095 3.95049217 3.95081812 3.95137409
 3.95145584 3.95192831 3.9519731  3.95198845 3.952542   3.95256342
 3.95295806 3.95325649 3.95349203 3.95354369 3.95362755 3.95365721
 3.95373014 3.9538267  3.95412315 3.95422123 3.95425405 3.95427632
 3.95432099 3.95449194 3.95491077 3.95515667 3.95527613 3.95576143
 3.95583089 3.95595006 3.95601202 3.95608925 3.95622358 3.95625567
 3.95627859 3.95634636 3.95635752 3.95645848 3.95663638 3.95684583
 3.95687358 3.95700018 3.95708741 3.9576128  3.95767339 3.95779325
 3.95782973 3.9581569  3.95822086 3.95838774 3.95862813 3.95865411
 3.95882658 3.95899073 3.95906988 3.95917729 3.95927841 3.95945237
 3.95955697 3.95971776 3.95981346 3.9598141  3.96008884 3.96012148
 3.96018513 3.96031164 3.96039037 3.9604297  3.96079508 3.96082352
 3.96085066 3.96085535 3.9610575  3.96107868 3.96139682 3.96149545
 3.96167066 3.96194969 3.9619508  3.96202836 3.96205939 3.96215313
 3.96220891 3.96227992 3.9623079  3.96248746 3.96252555 3.96253877
 3.96255413 3.96267159 3.96282279 3.96283325 3.9630029  3.9631225
 3.9632956  3.96333293 3.96340932 3.96341359 3.96353723 3.96375244
 3.96380056 3.9638112  3.96385355 3.96405318 3.96411332 3.96411809
 3.96416564 3.96426028 3.96427295 3.96442814 3.96444188 3.96452043
 3.96467087 3.9646811  3.9647086  3.96494719 3.96511712 3.965166
 3.96517277 3.96528159 3.96537069 3.96537823 3.96551799 3.96569274
 3.96593715 3.96596193 3.96598128 3.96598732 3.96601905 3.9661517
 3.96618645 3.96619036 3.96625015 3.96629391 3.96635977 3.96658081
 3.96660313 3.96667187 3.96680179 3.96681655 3.96685654 3.96692853
 3.96693397 3.96696099 3.96714688 3.96722642 3.9672765  3.96750578
 3.96753503 3.96760941 3.96762538 3.96765478 3.96766586 3.96776893
 3.96815141 3.96825754 3.96833567 3.96835813 3.96873464 3.96875863
 3.96877086 3.96887593 3.96890875 3.96892354 3.96900374 3.96900576
 3.96909582 3.96909681 3.96914587 3.96915809 3.96936582 3.96937492
 3.96938989 3.96941673 3.96942186 3.96956737 3.96974466 3.9698813
 3.9698961  3.97006267 3.97009195 3.970207   3.97024969 3.97030531
 3.9704609  3.97047933 3.97061783 3.97079224 3.97082262 3.97084171
 3.97086713 3.97108422 3.97115573 3.97117903 3.97125777 3.97128956
 3.97138973 3.97145042 3.97147622 3.97153975 3.97164355 3.97165503
 3.97168264 3.97172058 3.97176378 3.97177664 3.97178134 3.97189143
 3.97189632 3.97213471 3.9721436  3.97217869 3.97217995 3.97253523
 3.97257685 3.97261053 3.97267009 3.97267368 3.97300827 3.97303359
 3.97307028 3.973084   3.97309257 3.97313016 3.97315259 3.97323761
 3.97336249 3.9734658  3.97349284 3.97369203 3.97373783 3.97375753
 3.97376965 3.97383664 3.97392368 3.97399267 3.97404136 3.97406771
 3.97409872 3.97411311 3.97415356 3.9742559  3.97444135 3.97445719
 3.97449473 3.9745109  3.97452001 3.97462185 3.97469495 3.97482611
 3.97486069 3.97489656 3.97496688 3.97512075 3.97519008 3.97525337
 3.97526768 3.9752834  3.9752961  3.97534893 3.97540532 3.97541315
 3.97544985 3.97547186 3.97548566 3.97549333 3.97551871 3.97560815
 3.97562133 3.9756296  3.97565201 3.97568256 3.97574457 3.97584169
 3.97592231 3.97607626 3.97618714 3.97625522 3.97629502 3.97642254
 3.97650929 3.97657332 3.97657378 3.97661571 3.9767874  3.97689471
 3.97691497 3.9772324  3.97731434 3.97739227 3.97740794 3.97742409
 3.97746561 3.97754603 3.97759238 3.97759685 3.97775407 3.97775793
 3.97787205 3.97789319 3.97797929 3.97803827 3.9780439  3.97819174
 3.97821769 3.97829356 3.97830389 3.97830723 3.97837111 3.97838132
 3.97842129 3.97843361 3.97844557 3.97845828 3.97847531 3.97857246
 3.97863116 3.97866938 3.97870136 3.97881752 3.9788326  3.97892722
 3.97912445 3.97913185 3.97918286 3.97926811 3.97935928 3.97939876
 3.97944567 3.97946439 3.97950608 3.97958926 3.97964239 3.97965216
 3.97973654 3.9797506  3.97975452 3.9797924  3.97989993 3.97992619
 3.97999212 3.98015833 3.98019611 3.98020083 3.98023354 3.98027783
 3.98039888 3.98049206 3.9808567  3.98094274 3.98102079 3.98105023
 3.98106201 3.98118878 3.98126291 3.98129176 3.98129473 3.98139963
 3.98141699 3.98151185 3.98155594 3.98167639 3.98168124 3.98170884
 3.9817324  3.98177975 3.9818639  3.98186459 3.98198021 3.98215246
 3.98222743 3.98230356 3.98239063 3.98258565 3.98268708 3.98270236
 3.9827578  3.9828157  3.98288247 3.9830292  3.98306768 3.98308341
 3.98324199 3.98325915 3.98334705 3.98338361 3.98340136 3.98345501
 3.98347159 3.98350169 3.98362125 3.98367967 3.98379706 3.983836
 3.98391411 3.98393217 3.98402901 3.98435948 3.98438197 3.98440416
 3.98452864 3.98455111 3.98475647 3.98478895 3.98479642 3.98484352
 3.98494425 3.98500599 3.98503426 3.98504491 3.98508733 3.98509352
 3.9851005  3.98511669 3.98511773 3.98516627 3.98519584 3.98522109
 3.98539893 3.98543981 3.98556251 3.98558672 3.98562128 3.98568731
 3.98569081 3.98570887 3.98571709 3.98573176 3.98595177 3.98610657
 3.98610853 3.98623232 3.98640069 3.98649472 3.98662807 3.986657
 3.98666578 3.98673467 3.98678234 3.98681425 3.9868168  3.98682394
 3.98693094 3.98707266 3.98709561 3.98712711 3.98723125 3.98723161
 3.98726468 3.98735547 3.98752177 3.98762073 3.987639   3.98764224
 3.98765681 3.98769765 3.9877627  3.98785792 3.98787432 3.9879393
 3.98797201 3.98813332 3.9881337  3.98821048 3.98822772 3.98824585
 3.98826132 3.98831443 3.98841408 3.98853855 3.98854682 3.98855236
 3.98861816 3.98864948 3.98876704 3.98883976 3.98895211 3.98909466
 3.98914049 3.98927406 3.98935283 3.98941824 3.98945276 3.9894806
 3.98955775 3.98956538 3.98961108 3.98963534 3.98966781 3.9897797
 3.98997805 3.99009839 3.99012513 3.99021306 3.99021793 3.99022195
 3.99022703 3.99025646 3.99029871 3.99041117 3.99045037 3.99049518
 3.9905054  3.99059868 3.99060317 3.99060663 3.99066904 3.99069776
 3.99081925 3.9908408  3.99092048 3.99103379 3.99109976 3.99114401
 3.99123867 3.99132377 3.99137604 3.99143153 3.99155848 3.99161284
 3.99166588 3.99178556 3.99187325 3.99192456 3.99199421 3.99203162
 3.99213845 3.99221378 3.99222344 3.99227307 3.99231971 3.99232368
 3.99232692 3.99235216 3.9923587  3.99242273 3.99244924 3.99254841
 3.99257513 3.99261255 3.99262678 3.99262751 3.99279609 3.99282654
 3.99285021 3.99288281 3.9929254  3.99293703 3.99297294 3.99297778
 3.99309494 3.99311907 3.99315249 3.99320018 3.99330045 3.99330553
 3.99344225 3.993489   3.99353495 3.99365728 3.99366453 3.99368653
 3.99369976 3.99390708 3.99410669 3.99432168 3.99450086 3.99453915
 3.99455815 3.9946706  3.99469514 3.99479374 3.99494561 3.99526715
 3.99538548 3.99544011 3.99558905 3.99571436 3.99578874 3.99585982
 3.99590991 3.99594756 3.99595583 3.99596493 3.99601774 3.99609157
 3.99618881 3.99624942 3.99644691 3.99651996 3.99657872 3.99659195
 3.99667097 3.99669961 3.99671329 3.9968224  3.99723392 3.99728035
 3.99728797 3.99734012 3.99739679 3.99746769 3.99761624 3.99778531
 3.99793351 3.99804846 3.9982356  3.99830874 3.99831027 3.99832052
 3.99836032 3.99840906 3.99860542 3.99875891 3.99899132 3.99915042
 3.99944809 3.99951236 3.99988779 4.00002918 4.00004711 4.00057572
 4.00064903 4.00080617 4.00096133 4.00129337 4.00130051 4.00132852
 4.00171421 4.00172313 4.00209696 4.00217402 4.00240637 4.00245801
 4.00248609 4.00260592 4.00280113 4.00283359 4.00289378 4.00292686
 4.00325905 4.00327526 4.0034874  4.0035826  4.00359612 4.00376327
 4.0038649  4.00434722 4.00436779 4.00444264 4.00475253 4.00544867
 4.00560373 4.00565644 4.00596308 4.00607467 4.00624055 4.00635864
 4.0063701  4.00638523 4.00699156 4.00719104 4.00738862 4.00775128
 4.00778393 4.00799168 4.00806118 4.00821743 4.00902473 4.00913794
 4.00932471 4.00948037 4.00952055 4.0097353  4.01044854 4.01059384
 4.01064256 4.01092176 4.0109848  4.01103108 4.01149741 4.01184591
 4.01190893 4.01213913 4.01216521 4.0123001  4.01241622 4.01246906
 4.01279699 4.01285133 4.0133792  4.01347005 4.01373667 4.01376125
 4.01388617 4.01402141 4.01421084 4.01445339 4.01489984 4.01500461
 4.01534137 4.01546128 4.01569593 4.016498   4.01749719 4.01781758
 4.01827972 4.01844821 4.01929664 4.01945165 4.01949487 4.01979842
 4.02010561 4.02024339 4.02040544 4.02066356 4.02080802 4.02122263
 4.02159584 4.02202547 4.02240072 4.02253548 4.02276439 4.02286037
 4.02332294 4.02499305 4.02501477 4.02643476 4.02685971 4.02740215
 4.02823245 4.03138704 4.0315868  4.03283039 4.03360693 4.03449115
 4.03731362 4.03848846 4.03908936 4.04201777 4.0649324  4.13540861
 4.91202993 4.92869193 4.95189989 4.95752715 4.96524137 4.96847839
 4.96933419 4.97066202 4.97099293 4.97105665 4.97266014 4.97391236
 4.97463604 4.97505624 4.97531453 4.97579092 4.97713362 4.97744814
 4.97930439 4.98178128 4.98359064 4.98396412 4.9840176  4.98413213
 4.98674524 4.98708002 4.98736167 4.98759012 4.99100952 4.99228634
 4.99441394 4.99607535 4.99615935 4.99679892 5.00085906 5.00211646
 5.00257947 5.00386557 5.0145066  5.01917264 5.02137418 5.05392594]

  warnings.warn(

2022-12-16 10:37:20,707:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.96047128 1.98330386 1.99464668 2.00304661 2.00361804 2.01068133
 2.01786103 2.02472868 2.0258846  2.03229376 2.03987169 2.04048234
 3.65241057 3.77765077 3.78699756 3.79256775 3.79571477 3.80478495
 3.81599507 3.81674884 3.83564085 3.84047209 3.84512359 3.85903817
 3.86029304 3.86199565 3.86833508 3.87204634 3.87835278 3.88315963
 3.88765392 3.88781664 3.88933838 3.89024063 3.89138867 3.89276281
 3.89381699 3.8940979  3.89447142 3.89515826 3.89581623 3.89586921
 3.89694927 3.89810258 3.89811505 3.89888398 3.89922136 3.90091207
 3.90097572 3.90366742 3.9041777  3.9044839  3.90458011 3.90484563
 3.90503412 3.90570041 3.90575818 3.90602154 3.90602396 3.90683731
 3.90712533 3.90761302 3.90783219 3.90811887 3.91091877 3.91126322
 3.91140022 3.91179152 3.91237468 3.91258892 3.91291683 3.91297327
 3.91331451 3.9134086  3.91356829 3.91421333 3.91426909 3.91429805
 3.91453772 3.91504051 3.91527829 3.91556302 3.91572356 3.91602824
 3.91623518 3.91703262 3.91717224 3.91752756 3.91770848 3.91797436
 3.91807064 3.91822079 3.91863357 3.91882892 3.91894319 3.919539
 3.91972278 3.91975839 3.91982746 3.91988982 3.91994407 3.91999414
 3.92115491 3.92164748 3.92178838 3.92192106 3.92203513 3.92223934
 3.92228702 3.92265284 3.92306533 3.92328371 3.92328465 3.92349017
 3.92376663 3.92384647 3.92387183 3.92389452 3.92485258 3.92504691
 3.92570882 3.92587579 3.92616373 3.9263646  3.92642466 3.92665472
 3.92682362 3.92683288 3.92703741 3.9272124  3.92738735 3.9274918
 3.92749759 3.92750622 3.92750717 3.92788616 3.92823044 3.9282379
 3.92830395 3.92858837 3.92869915 3.92871428 3.92884763 3.92914957
 3.92922304 3.92950177 3.929528   3.9296874  3.93025108 3.93075758
 3.93100635 3.93102905 3.93124863 3.93134974 3.93143893 3.93176106
 3.93181174 3.93227725 3.93235407 3.93249173 3.93285498 3.93288586
 3.93288925 3.93292297 3.93346653 3.93353472 3.93358573 3.93373506
 3.93378523 3.93400145 3.93415773 3.93416523 3.93421729 3.93422552
 3.93438207 3.93454349 3.93463623 3.93487912 3.93511662 3.93522484
 3.93545344 3.93546039 3.93551535 3.93558426 3.93582782 3.93607739
 3.9363465  3.93635248 3.93635706 3.9366375  3.93664691 3.93721461
 3.93727217 3.93742242 3.93754352 3.93775251 3.93795472 3.93845155
 3.93871959 3.9389902  3.93914606 3.93961749 3.93974455 3.93978095
 3.93981343 3.94018122 3.94019955 3.94048739 3.94062805 3.94067278
 3.94071509 3.94130509 3.94143525 3.94144375 3.94149263 3.94164042
 3.94171031 3.94198996 3.9423104  3.94239829 3.94240333 3.94251998
 3.94260796 3.94267178 3.94294598 3.94303282 3.94305257 3.94317031
 3.94335861 3.94351421 3.94353124 3.94356773 3.94375163 3.94375303
 3.94380125 3.9439393  3.9439888  3.94415103 3.94435505 3.94451799
 3.94460498 3.94466415 3.94475006 3.94488726 3.94495051 3.94505216
 3.94508409 3.94517962 3.94547859 3.94564559 3.94565073 3.94581854
 3.94612842 3.94625958 3.94630278 3.94635278 3.94645345 3.94650932
 3.9466879  3.94675152 3.94679422 3.9469252  3.94702357 3.94717444
 3.94763222 3.94775297 3.94777451 3.94804124 3.94822812 3.94824026
 3.9485655  3.9487025  3.94881554 3.94895209 3.9490238  3.94925576
 3.94927257 3.94929654 3.94961544 3.94962477 3.94964482 3.94965851
 3.94976892 3.94983306 3.94998485 3.95006878 3.95066199 3.95067304
 3.9507021  3.95084562 3.95090379 3.95091546 3.95103901 3.95111835
 3.9511819  3.95122378 3.95124293 3.95139643 3.95147818 3.95149178
 3.95159047 3.9518156  3.95183131 3.95188633 3.95188714 3.95199027
 3.95235511 3.95319477 3.95320898 3.95324114 3.95325537 3.9533566
 3.9534418  3.95349587 3.95355647 3.9536402  3.9537591  3.95377955
 3.95381855 3.95382676 3.9538878  3.95393114 3.95396569 3.95397967
 3.95412088 3.95454373 3.95466851 3.95467524 3.95473646 3.95474775
 3.95474866 3.95479612 3.95487699 3.9549812  3.95501943 3.95512483
 3.95535339 3.95543809 3.95561173 3.95561941 3.9557402  3.9558772
 3.9558953  3.95602178 3.95602749 3.95614312 3.95626887 3.95633226
 3.95634971 3.95676239 3.95683714 3.956897   3.95691197 3.95726155
 3.95733543 3.95733819 3.95742445 3.9574683  3.95748738 3.95754316
 3.95755022 3.9576736  3.9577437  3.95784651 3.9579412  3.95796683
 3.95797949 3.95800826 3.95813996 3.95818411 3.95820314 3.95832864
 3.95852997 3.95858538 3.95864026 3.95866712 3.95891419 3.95891719
 3.95908918 3.95916578 3.95918991 3.95924988 3.95931074 3.95936155
 3.95937083 3.95948154 3.95950291 3.95955862 3.95992671 3.96004233
 3.96007777 3.96025175 3.96026844 3.96027253 3.96037574 3.96042794
 3.96053975 3.9605979  3.96081216 3.96089375 3.96102344 3.96118285
 3.96135736 3.96161567 3.96169862 3.9618222  3.96182906 3.96217462
 3.96218503 3.96221354 3.96228795 3.96231964 3.96232778 3.96246525
 3.96252957 3.96256902 3.96262622 3.96275548 3.96295443 3.96297271
 3.96307099 3.96327383 3.96329364 3.96340532 3.96341083 3.96348204
 3.96352015 3.96367801 3.96380965 3.96382509 3.96385275 3.96392372
 3.96394326 3.96398767 3.96407977 3.96430513 3.9643843  3.9644169
 3.96442966 3.96445929 3.96452272 3.96455294 3.96477963 3.96485314
 3.96498611 3.96520259 3.96551462 3.96559051 3.96565767 3.96567045
 3.96591789 3.96592938 3.96593742 3.96598656 3.9660216  3.96609315
 3.96625126 3.96645401 3.96653924 3.96656377 3.96664263 3.96667345
 3.96675103 3.96678458 3.96679596 3.96692508 3.967003   3.96703776
 3.96723783 3.96730517 3.9673641  3.96741927 3.96742102 3.9674544
 3.96752929 3.96782985 3.96812036 3.96815186 3.96816923 3.96846926
 3.9685189  3.9686745  3.9687288  3.9688565  3.96891166 3.968919
 3.96891946 3.96894129 3.96902725 3.96917603 3.96922683 3.96932648
 3.96937163 3.96947237 3.96974682 3.96987424 3.969882   3.97004021
 3.97034517 3.9703648  3.9704642  3.97049414 3.97057799 3.97067317
 3.97100487 3.97126055 3.97137259 3.97141682 3.97145978 3.97153992
 3.97157766 3.97161347 3.97163255 3.97165651 3.97167064 3.97169978
 3.97171192 3.97171332 3.97172639 3.97193727 3.97202387 3.97202715
 3.97213076 3.97214604 3.97221734 3.97225515 3.97242995 3.97248863
 3.97260125 3.97263644 3.97274538 3.97311902 3.97316206 3.97321336
 3.97371672 3.97386873 3.97403986 3.97426749 3.97443229 3.97454851
 3.97463867 3.97475977 3.97484919 3.97506747 3.97522931 3.97527112
 3.97544087 3.97544363 3.97547785 3.97556975 3.97559472 3.97596961
 3.97605331 3.97628472 3.97642762 3.97651375 3.97660411 3.97687647
 3.97696857 3.9770259  3.97703936 3.97720746 3.97733403 3.97738314
 3.97747631 3.97749829 3.97750797 3.97756917 3.97758972 3.97779814
 3.97797794 3.97825245 3.97825913 3.97827422 3.97898273 3.97905981
 3.97913791 3.9791461  3.97931444 3.97949932 3.97954803 3.9795974
 3.97988686 3.97997679 3.98004664 3.98008419 3.98053183 3.98054353
 3.980689   3.98097968 3.98107324 3.981334   3.98172383 3.98179966
 3.98184785 3.9821622  3.98243814 3.98253406 3.98264593 3.98313477
 3.98316767 3.98333217 3.983333   3.98339331 3.98402238 3.98426275
 3.98433582 3.98445295 3.98464498 3.98506058 3.98533346 3.98541627
 3.98544745 3.9855327  3.98582211 3.98583644 3.98601654 3.98609945
 3.9863286  3.98634896 3.98637423 3.98639889 3.98678923 3.98679444
 3.98682259 3.98714495 3.98738297 3.98777434 3.98803711 3.98824959
 3.98841184 3.98859366 3.9886168  3.98865338 3.98868682 3.98874218
 3.98877325 3.9889398  3.98905639 3.98908889 3.98911947 3.98921536
 3.98932991 3.98946485 3.98951232 3.98959336 3.98967423 3.98967929
 3.98978179 3.98978371 3.99024177 3.99064255 3.99070752 3.9908134
 3.99083661 3.99085969 3.99123386 3.99166361 3.99170078 3.99243277
 3.99259267 3.99271042 3.99280589 3.99291908 3.99302112 3.99309607
 3.99326419 3.99329234 3.99349706 3.99355851 3.99361652 3.99393538
 3.9940947  3.99421198 3.99454738 3.99474184 3.99520833 3.99523047
 3.99536628 3.99567598 3.99581336 3.99593903 3.99597615 3.99604749
 3.99611946 3.99621422 3.99644    3.99649273 3.99675148 3.99682531
 3.9969546  3.99729264 3.99743899 3.99750452 3.99810052 3.99831622
 3.99849229 3.99853902 3.9991156  3.99916794 3.99919201 3.99921739
 3.99925108 3.99973968 3.99980006 3.99989817 3.99993359 3.9999405
 4.00009298 4.000228   4.0002343  4.00068036 4.00069176 4.00078419
 4.0010019  4.00108428 4.00124258 4.00167278 4.00223036 4.00236265
 4.00251606 4.00269067 4.0028549  4.00330947 4.00399642 4.00460856
 4.004818   4.00486189 4.00509151 4.00522813 4.00526791 4.00534348
 4.0055677  4.00624196 4.00664013 4.00697117 4.00701223 4.0072988
 4.00731715 4.00752709 4.00790234 4.00820395 4.00827307 4.00840432
 4.00892549 4.00892683 4.01002172 4.01085023 4.01113274 4.01170737
 4.01226016 4.01239322 4.01279139 4.01380688 4.01389835 4.01392578
 4.01423357 4.0144867  4.01497322 4.01509979 4.01527145 4.01537912
 4.01617713 4.01636071 4.0165479  4.01726736 4.01753327 4.01784918
 4.01790256 4.01952407 4.02114533 4.02135598 4.02143804 4.02208254
 4.0221613  4.02253162 4.022587   4.02266068 4.0236351  4.02626206
 4.02639845 4.02887901 4.02893578 4.02945628 4.03072694 4.03173064
 4.03267542 4.03384115 4.03541767 4.03559776 4.03589498 4.03602284
 4.03768862 4.03782528 4.0386082  4.0389335  4.03973089 4.04196568
 4.04293882 4.04338732 4.04486367 4.04584891 4.05205439 4.05279818
 4.05320252 4.05465338 4.05737384 4.05939327 4.06091111 4.06739206
 4.0780494  4.08634353 4.10291854 4.10369381 4.12364437 4.22194494
 4.8018156  4.82263997 4.86701986 4.87199375 4.9109764  4.91161685
 4.91219491 4.91517425 4.91598828 4.92503302 4.92694118 4.93280851
 4.93370401 4.93550676 4.93753413 4.94216168 4.94426062 4.95797531
 4.9612991  4.96345597 4.96615806 4.97039109 4.97275573 4.97356993
 4.97383309 4.97586636 4.97705976 4.97866139 4.98034543 4.98328652
 4.98389858 4.98680422 4.98996128 4.99004855 4.9925343  5.00118235
 5.00434433 5.00691771 5.00969636 5.01205714 5.03333254 5.06807209
 5.12236367]

  warnings.warn(

2022-12-16 10:37:20,746:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.03701787 2.0428503  2.04408587 2.04859539 2.04878441 2.05908314
 2.06277693 2.06563408 3.57054056 3.58224657 3.84801961 3.85125684
 3.86558376 3.86630256 3.86963006 3.87504807 3.87571635 3.87712302
 3.87791836 3.87923473 3.87943619 3.88665614 3.88690763 3.88718569
 3.88761454 3.88830243 3.89010013 3.89031774 3.89248106 3.89327525
 3.89350895 3.89376506 3.89399191 3.89457096 3.89481806 3.89528472
 3.89607096 3.89702313 3.89735007 3.89940762 3.9003209  3.9008317
 3.90136995 3.90153677 3.90504767 3.9055982  3.9068618  3.90693109
 3.90848362 3.91150437 3.91228774 3.91259594 3.91299845 3.91340448
 3.91441608 3.91623318 3.91691483 3.91948159 3.91948843 3.92063264
 3.92125843 3.92188016 3.92261501 3.92272645 3.92284877 3.92318284
 3.92335763 3.9234576  3.92415071 3.92435473 3.92447993 3.92497479
 3.92537934 3.92579642 3.9273025  3.9283417  3.92836032 3.92858184
 3.9287172  3.92953645 3.92953956 3.93011365 3.930152   3.93033459
 3.93045646 3.9305937  3.93074538 3.93079554 3.93100437 3.9310679
 3.93125505 3.93128516 3.93132801 3.93148601 3.93222194 3.93229059
 3.93256292 3.93260778 3.93262833 3.93266825 3.933151   3.93375361
 3.93384879 3.9340539  3.93419892 3.93445242 3.93480208 3.93496989
 3.93532572 3.93564976 3.93572428 3.93629523 3.93695855 3.93700228
 3.93700991 3.93709326 3.93731553 3.93743138 3.93779421 3.93780287
 3.93788488 3.93809353 3.93861487 3.93864854 3.93893137 3.93893944
 3.93924467 3.93949726 3.93951501 3.93961327 3.93997247 3.94029212
 3.94052432 3.9406144  3.94066253 3.94159313 3.94159958 3.9416344
 3.9416587  3.94166422 3.94170551 3.94178076 3.9418614  3.94214057
 3.94248175 3.94253514 3.94258848 3.94261146 3.94302446 3.94348477
 3.94357988 3.94397377 3.94414735 3.94417855 3.94421308 3.94434632
 3.94435346 3.9448926  3.94489595 3.94494181 3.94512211 3.94516603
 3.94528991 3.94534115 3.94548547 3.94548938 3.94563592 3.94567629
 3.94571308 3.94582886 3.94598207 3.94609944 3.94619651 3.94620499
 3.94637017 3.94639276 3.94650973 3.94729956 3.94746116 3.94765601
 3.94773237 3.94784831 3.94791637 3.94820934 3.94849827 3.94856113
 3.94857539 3.94881659 3.94884815 3.94910664 3.94923193 3.9493387
 3.94935076 3.94953668 3.94979289 3.94990267 3.94992027 3.949997
 3.95035173 3.95040775 3.95044288 3.95107788 3.95119215 3.95122706
 3.95138463 3.95140432 3.95141681 3.95153779 3.95164631 3.95170474
 3.95173597 3.95177037 3.9518033  3.95181516 3.95185705 3.95210567
 3.95220901 3.9522253  3.95223853 3.9524515  3.9524855  3.95257422
 3.95274537 3.95300691 3.95304639 3.95328707 3.9533257  3.95370704
 3.9538662  3.95388838 3.95402592 3.954034   3.95405068 3.95422454
 3.95423218 3.95433729 3.95446617 3.95458229 3.95478239 3.95536482
 3.95539433 3.95547097 3.95555783 3.95559435 3.95577613 3.95596854
 3.9559905  3.95606038 3.95629308 3.95635994 3.9563992  3.95674618
 3.95679633 3.95681203 3.95700403 3.95704369 3.95705934 3.95707388
 3.9571479  3.95723142 3.95735695 3.95738217 3.95746229 3.95758045
 3.95761021 3.95771764 3.95774316 3.95780623 3.95781628 3.95792394
 3.95802257 3.95822525 3.95827113 3.95863735 3.95867755 3.95868526
 3.95870045 3.95873257 3.95889466 3.95891304 3.95894799 3.95925257
 3.95929838 3.95936126 3.95947985 3.95951263 3.9595374  3.96024224
 3.96026571 3.96057538 3.96058987 3.96085709 3.96087903 3.96091457
 3.96093352 3.96101583 3.96108844 3.96109543 3.961367   3.96143519
 3.96145506 3.96148123 3.96160037 3.96188249 3.96199485 3.96206863
 3.96211323 3.96224926 3.96224997 3.96239268 3.9624165  3.96265679
 3.96268792 3.96270816 3.96296714 3.96312877 3.96316063 3.96348875
 3.96394234 3.96402368 3.96409928 3.96421714 3.96425336 3.96426378
 3.96441894 3.96449545 3.96450914 3.96469168 3.96483327 3.96485405
 3.96492392 3.96494362 3.964963   3.96497413 3.96497748 3.96501018
 3.96507776 3.96511267 3.96536852 3.96547431 3.96557179 3.96581117
 3.96599353 3.96600548 3.96618452 3.96619682 3.96628737 3.96631446
 3.96638959 3.96645004 3.96664014 3.96684904 3.9669828  3.96699083
 3.96706313 3.96712561 3.96718708 3.96752876 3.96755213 3.96756989
 3.96767841 3.9678802  3.9679945  3.96800114 3.96802543 3.96806348
 3.96810738 3.96836444 3.96845613 3.96864806 3.96866001 3.9687033
 3.96870823 3.96889105 3.96892197 3.96908465 3.96922352 3.96925499
 3.96932753 3.96938606 3.9694719  3.96954937 3.96970601 3.96971201
 3.96972988 3.96980639 3.96986378 3.97001871 3.9700387  3.97024575
 3.97055516 3.97057129 3.97073609 3.970741   3.97084636 3.97090197
 3.97092609 3.97094676 3.97095321 3.970973   3.97101016 3.97102744
 3.97116881 3.97138033 3.97145215 3.97146185 3.97146544 3.97156055
 3.97168673 3.97188538 3.97193023 3.97198186 3.97198964 3.9720795
 3.97212906 3.97249111 3.97255666 3.97260728 3.97261969 3.97262456
 3.97268229 3.97276072 3.97281823 3.97296258 3.97305692 3.97310037
 3.97311557 3.97318034 3.97323427 3.97323665 3.97331635 3.9733272
 3.97341106 3.97354035 3.97357724 3.97378355 3.97386345 3.97388255
 3.97392944 3.97397261 3.97398762 3.97402203 3.97406423 3.97408614
 3.97409386 3.97414207 3.97425335 3.97444617 3.97459473 3.97460909
 3.97461099 3.97476812 3.97479793 3.97480673 3.9750828  3.97508384
 3.97518738 3.97520496 3.97522687 3.97528788 3.97528923 3.97529761
 3.97537408 3.97537827 3.97538564 3.97544054 3.97548171 3.97548948
 3.97564747 3.97566564 3.9757044  3.97572884 3.9757318  3.97581347
 3.9759008  3.97602739 3.97606633 3.97630407 3.97632298 3.97635388
 3.97637536 3.97654379 3.97674757 3.97686615 3.97688461 3.97691553
 3.97695804 3.97718458 3.97721024 3.977261   3.97732581 3.97732736
 3.97733857 3.97735255 3.977393   3.97762074 3.97762226 3.97764349
 3.97765914 3.97766803 3.97777969 3.97782268 3.97786018 3.97798985
 3.97800344 3.97807435 3.9780892  3.9781811  3.97826035 3.9783229
 3.97836898 3.97844009 3.97861361 3.97863564 3.9786784  3.97878582
 3.97892674 3.97913644 3.97921766 3.97921805 3.97922881 3.97923013
 3.97927227 3.9793277  3.97939068 3.97950607 3.97984829 3.98013728
 3.98022115 3.98028168 3.98039882 3.98043976 3.9806649  3.98107297
 3.98122083 3.98126636 3.98134785 3.98135474 3.98137355 3.98140531
 3.98141367 3.98145049 3.98149247 3.981703   3.98178867 3.98178984
 3.98180257 3.98193358 3.9821171  3.9821727  3.98220264 3.98226878
 3.98231297 3.98246985 3.98254717 3.98262871 3.98263562 3.98278425
 3.98292471 3.98294795 3.98295196 3.98297005 3.98298001 3.98319547
 3.98320817 3.98328201 3.9833136  3.98332387 3.98356042 3.98360227
 3.9836376  3.98386222 3.98391591 3.9841477  3.98423747 3.98429139
 3.98431383 3.98441416 3.98449244 3.98450483 3.98451924 3.98456898
 3.98477848 3.98479819 3.98481067 3.98485634 3.98488993 3.98492163
 3.98492511 3.98497752 3.9852919  3.98541367 3.98547355 3.98547931
 3.98548928 3.98550963 3.98567596 3.98569905 3.98577693 3.98580802
 3.9858791  3.98589956 3.98590847 3.98611479 3.98622337 3.98634303
 3.98685719 3.98695114 3.98698987 3.98725747 3.98729136 3.98731817
 3.98740069 3.98766254 3.98795465 3.98797944 3.98805677 3.98805726
 3.98806672 3.98810843 3.98812414 3.98818227 3.9882325  3.98824024
 3.98831763 3.98858852 3.98860341 3.98866071 3.98897409 3.98917
 3.98923129 3.98925181 3.98929478 3.98942228 3.98944841 3.98947006
 3.98982917 3.98984769 3.98993827 3.99005605 3.99009701 3.99015624
 3.99021225 3.99045357 3.99049961 3.99062116 3.99066644 3.99079004
 3.99108841 3.99114299 3.99127929 3.99129384 3.99149471 3.99161928
 3.99165359 3.99170524 3.99170863 3.99179275 3.99212137 3.99213459
 3.9922364  3.99265203 3.99305647 3.99316556 3.99316746 3.99328398
 3.99328493 3.99332716 3.99362414 3.99364077 3.99366087 3.99368416
 3.99374143 3.99379533 3.99380158 3.99382536 3.99413368 3.99428797
 3.99441532 3.99443049 3.9946345  3.99475507 3.9947634  3.99477294
 3.99484358 3.99487731 3.99524814 3.99530319 3.99537084 3.99602673
 3.99606243 3.99643525 3.99652746 3.99655555 3.99677236 3.99679356
 3.99690401 3.99731496 3.99736707 3.99744608 3.99752362 3.99755939
 3.99794465 3.99797234 3.9981784  3.9981895  3.99824722 3.99824829
 3.99867247 3.99896068 3.99922884 3.99939597 3.99950278 3.99959448
 3.99962656 3.99976762 3.99994384 4.00028148 4.000286   4.00064461
 4.00091079 4.00097262 4.00123007 4.00156368 4.00174759 4.002037
 4.00216299 4.00242356 4.00327466 4.00334803 4.00344348 4.00352385
 4.00384476 4.00389663 4.00400134 4.00403668 4.00427893 4.00437861
 4.00443763 4.00475606 4.00481089 4.0054015  4.00543774 4.0055181
 4.00569618 4.00572497 4.00709534 4.00734553 4.00765165 4.00797857
 4.00805763 4.00807153 4.00834046 4.00854333 4.00866107 4.00884081
 4.00908365 4.0092716  4.01027576 4.01035873 4.01098349 4.01100697
 4.01106441 4.01112678 4.011129   4.01112928 4.01129478 4.01132852
 4.01149066 4.01149517 4.01155058 4.01228563 4.01330336 4.01344953
 4.01354059 4.01365903 4.01419113 4.01460217 4.01462776 4.01464962
 4.01512753 4.01527181 4.01583506 4.01592983 4.01626177 4.01636423
 4.0164609  4.01694236 4.01725614 4.01793298 4.01846041 4.01858566
 4.01881412 4.01883727 4.01897286 4.02163013 4.02200525 4.02201832
 4.02206017 4.02248444 4.02267219 4.02280171 4.02297524 4.02311384
 4.0245092  4.02470428 4.02592943 4.02889892 4.03011421 4.03107566
 4.03349472 4.03417242 4.03481512 4.03784127 4.04011858 4.04314525
 4.04350577 4.04453496 4.07361017 4.07365294 4.24339568 4.27605936
 4.88190808 4.93823098 4.94182116 4.94916818 4.95147055 4.95541757
 4.9718117  4.97440033 4.97761353 4.98112062 4.98170778 4.98422257
 4.98591555 4.98593586 4.98770036 4.98795432 4.98883595 4.98999581
 4.9901929  4.99398853 4.99938563 4.99986113 5.00076136 5.00099195
 5.00579469 5.00700591 5.0074176  5.01147141 5.01153794 5.01223519
 5.02337946 5.02697963 5.03841542]

  warnings.warn(

2022-12-16 10:37:20,764:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.01944139 2.03619934 2.04070027 2.04930015 2.05351397 2.0833303
 3.60674198 3.61759818 3.85384862 3.86546827 3.87563338 3.88911824
 3.89170057 3.8930876  3.89531506 3.90006538 3.90207928 3.90292269
 3.90306499 3.90363475 3.90463699 3.90554415 3.90742946 3.90755858
 3.90795632 3.91002518 3.91103933 3.91356863 3.91471671 3.91489865
 3.91513632 3.91530338 3.91581047 3.91600727 3.9162811  3.91635997
 3.91652882 3.92010618 3.92023333 3.9212879  3.92187234 3.92205963
 3.92393854 3.92470665 3.92515349 3.92581805 3.92660865 3.9271869
 3.92742147 3.92754399 3.92777482 3.92840059 3.92888116 3.92930845
 3.93047053 3.93073177 3.93100862 3.93201028 3.93295824 3.93362413
 3.93370365 3.9339266  3.93445247 3.93496699 3.93516567 3.9358929
 3.93619947 3.9378316  3.93793057 3.93805219 3.93811495 3.93852441
 3.93896403 3.93922076 3.93938451 3.94003196 3.9405613  3.94087625
 3.94088638 3.94100946 3.94125983 3.94134098 3.94135095 3.94135824
 3.94173999 3.9418371  3.9418693  3.9422387  3.94230771 3.94255661
 3.94267264 3.94296403 3.94343643 3.94414895 3.94451824 3.94472464
 3.94476944 3.94525477 3.94562002 3.94575107 3.94580876 3.94596597
 3.94605717 3.94616648 3.94648347 3.94657515 3.94658122 3.94670772
 3.94678797 3.94685928 3.94696669 3.94732826 3.9473899  3.94740371
 3.94748962 3.94758564 3.94786546 3.94791721 3.9479221  3.94796044
 3.94811856 3.94833743 3.94854205 3.94864591 3.9487309  3.94894563
 3.94906132 3.94908033 3.94922637 3.94924308 3.94937186 3.94948629
 3.94950137 3.94973244 3.9497346  3.94975999 3.95009348 3.9505241
 3.95057323 3.95064728 3.95083683 3.95107053 3.95112998 3.9514715
 3.95174776 3.95191628 3.9519396  3.95236831 3.95237367 3.95265561
 3.952685   3.95270761 3.95271902 3.95299837 3.95316927 3.95338083
 3.95368422 3.95375907 3.95380743 3.95382482 3.953903   3.95390649
 3.95400336 3.95401492 3.95409757 3.95419268 3.9544261  3.95448693
 3.95449075 3.95455408 3.95464917 3.9546516  3.95476577 3.95491572
 3.95500331 3.9550211  3.95506401 3.95512668 3.95516436 3.95530781
 3.95539784 3.95540483 3.95565424 3.95580416 3.95588706 3.95596618
 3.95634002 3.95642445 3.95654515 3.95655763 3.95665451 3.95679144
 3.95681087 3.95692943 3.95718552 3.95722693 3.95726461 3.95727502
 3.95748247 3.95757989 3.95769128 3.95770127 3.95783823 3.95791175
 3.95794671 3.95800248 3.95813718 3.95817093 3.95824903 3.95847276
 3.95856313 3.95856327 3.95860137 3.95864917 3.95872231 3.95887693
 3.95890185 3.9590003  3.95907621 3.9591156  3.95927447 3.95937002
 3.95945133 3.95946713 3.9594861  3.95954472 3.95966642 3.95966831
 3.95972624 3.95979761 3.95989616 3.96003641 3.96013677 3.96015116
 3.96020826 3.96022106 3.96026358 3.96043405 3.96056636 3.96056899
 3.96064374 3.96068687 3.96070174 3.96070913 3.960779   3.96084192
 3.96087668 3.96101063 3.96130094 3.96155474 3.96156671 3.96160772
 3.96181485 3.96182734 3.96183643 3.961863   3.96195542 3.96212046
 3.96240882 3.96251509 3.96265047 3.96266626 3.96267892 3.96282184
 3.96293218 3.96295765 3.96303523 3.96304458 3.96312691 3.96318688
 3.96319505 3.96331937 3.96336853 3.96338512 3.96347354 3.96351008
 3.96351964 3.96356857 3.9637098  3.96380052 3.96382663 3.963995
 3.96407138 3.96412192 3.964281   3.96437673 3.96440038 3.96467278
 3.96478412 3.96491545 3.96497904 3.96503336 3.9650964  3.96514545
 3.96519725 3.96528813 3.9653096  3.96534801 3.96538229 3.96538494
 3.96559127 3.96559578 3.96572943 3.96578383 3.96584781 3.96584975
 3.96585311 3.96591905 3.96592272 3.96597914 3.9660386  3.96604776
 3.96606199 3.96611071 3.96613159 3.96617212 3.96625955 3.9662645
 3.9662667  3.96633026 3.96633267 3.96641469 3.96641674 3.96655916
 3.96665067 3.96696869 3.9670102  3.96702356 3.96705453 3.9671122
 3.96720335 3.96721498 3.96727258 3.96729521 3.96738583 3.96749942
 3.96757725 3.96766457 3.96769848 3.96772836 3.96774133 3.96774628
 3.96791559 3.96791574 3.96806508 3.96807263 3.96808257 3.96812959
 3.96818522 3.96818749 3.96823765 3.9684237  3.96849171 3.96849792
 3.96855223 3.96860613 3.96863165 3.96867719 3.96874268 3.96887322
 3.9688816  3.96894328 3.96895943 3.96896799 3.96903528 3.96907357
 3.96910312 3.96922427 3.96924242 3.96924342 3.96925357 3.96926686
 3.9692767  3.96930817 3.96933257 3.96936544 3.96955618 3.96959044
 3.96966975 3.96985484 3.96989655 3.96995575 3.97009121 3.97023754
 3.97049619 3.97053063 3.97060026 3.97084546 3.97089748 3.97101005
 3.97128758 3.97129162 3.97130367 3.97131542 3.97131691 3.97134943
 3.9713561  3.97135678 3.97151397 3.97155129 3.97155385 3.97155725
 3.9716338  3.97164501 3.97173254 3.97180611 3.97183434 3.9718787
 3.97188359 3.9718916  3.97197233 3.97215048 3.97215212 3.97216448
 3.97229009 3.97245561 3.97258219 3.97262596 3.97263142 3.97272683
 3.97280701 3.97303067 3.9730431  3.9730803  3.97314368 3.97324866
 3.97326425 3.97343977 3.97349719 3.9735369  3.97367918 3.9737075
 3.97387908 3.97396719 3.97397136 3.97400685 3.97412465 3.97413947
 3.974165   3.97418561 3.97421371 3.97428378 3.97436856 3.97437438
 3.97443165 3.97448529 3.97451759 3.97455499 3.97458085 3.97463328
 3.97463879 3.97479873 3.97487161 3.97492027 3.97501284 3.97501355
 3.97503111 3.97503484 3.97504174 3.97506047 3.97508345 3.97522885
 3.97531318 3.97539112 3.97562733 3.97568573 3.97590192 3.97602311
 3.97603051 3.976159   3.97626114 3.97643473 3.97651195 3.9768499
 3.97694183 3.97698023 3.97706106 3.97717679 3.9772366  3.97731157
 3.97739887 3.97742786 3.97755318 3.97756726 3.97759377 3.9776002
 3.97761573 3.97766588 3.97772426 3.97774466 3.97778256 3.97788542
 3.97789875 3.97790443 3.97810244 3.97815202 3.97823425 3.9783771
 3.97841519 3.97845915 3.97848848 3.97852301 3.97857917 3.97866542
 3.97880409 3.97881593 3.97889673 3.97889796 3.97908497 3.9790896
 3.97909356 3.97919963 3.97924491 3.97927177 3.9792851  3.97932922
 3.97933752 3.97936841 3.9794109  3.97952102 3.97955774 3.97964815
 3.97975171 3.97978565 3.97985292 3.98018624 3.98029484 3.9803676
 3.98046162 3.98047666 3.98051671 3.98052737 3.98058712 3.98062495
 3.98068116 3.98070984 3.98071258 3.98085951 3.98086334 3.98091732
 3.98092909 3.9809521  3.98107098 3.98115649 3.98128294 3.98129937
 3.98131763 3.98134269 3.98137326 3.98147272 3.98167629 3.98177517
 3.98178686 3.98181199 3.98184968 3.9821576  3.98226101 3.98226609
 3.98230581 3.98234082 3.98234308 3.98239762 3.98252452 3.98274483
 3.9828132  3.98282249 3.98282469 3.98283807 3.98286145 3.98291882
 3.98299983 3.98317221 3.98320476 3.9833821  3.98340481 3.98344418
 3.9834876  3.98357713 3.98363573 3.98373508 3.98380943 3.9838388
 3.98384314 3.98402035 3.98419514 3.98433553 3.9843788  3.9843821
 3.98441643 3.98446671 3.98448808 3.98451288 3.9845197  3.98461863
 3.98470807 3.9848742  3.98503904 3.98510905 3.98516218 3.98522122
 3.9856178  3.9857481  3.98582384 3.98587063 3.98588108 3.98593109
 3.98596523 3.98628813 3.98632812 3.98633819 3.98639781 3.98642437
 3.98661056 3.9866777  3.98677503 3.98707401 3.98715571 3.9871565
 3.98719676 3.98742317 3.98746116 3.98749249 3.98755607 3.98765501
 3.98787552 3.9879281  3.98802474 3.98813549 3.98844497 3.98853318
 3.98859487 3.98883824 3.98884055 3.98909079 3.98919244 3.98920678
 3.98939159 3.98943711 3.98944974 3.98946533 3.9896671  3.98971584
 3.98976022 3.98978035 3.98983495 3.98984065 3.98984512 3.98984947
 3.98987723 3.98992455 3.99000425 3.99003611 3.99008802 3.99009943
 3.99021034 3.99042122 3.99052187 3.99062982 3.99073962 3.99083475
 3.99088217 3.99090647 3.99090966 3.99097675 3.99100979 3.99120641
 3.99126832 3.9912969  3.99131833 3.99133379 3.99139451 3.99142264
 3.99156761 3.99163755 3.99169748 3.99191839 3.99192738 3.99197464
 3.99199793 3.99200428 3.99213962 3.99222261 3.99223747 3.99226492
 3.99229544 3.99248424 3.99262194 3.99266356 3.99272176 3.99276462
 3.99301707 3.99305398 3.99311395 3.99312937 3.99319878 3.99336653
 3.99348989 3.99354342 3.9940029  3.99412323 3.99423084 3.9944613
 3.99448239 3.99486136 3.9953197  3.9958611  3.99589147 3.99590761
 3.99597416 3.99611328 3.99696174 3.99708691 3.99710034 3.99719634
 3.99760943 3.99777563 3.99792551 3.99834099 3.99835905 3.99850891
 3.99856586 3.99861216 3.99862581 3.99904956 3.9995881  3.99981023
 3.99993297 4.00009996 4.00026864 4.00042614 4.00049618 4.00055893
 4.00065818 4.00085146 4.00173287 4.00176449 4.00212759 4.00308994
 4.0037187  4.00387974 4.0039089  4.00396805 4.00414812 4.00417091
 4.00425707 4.00436616 4.00480786 4.00504304 4.0051817  4.00533718
 4.00562386 4.00671152 4.00704998 4.00711818 4.00725363 4.00726146
 4.00735737 4.00779767 4.00812631 4.00831692 4.00881726 4.00912164
 4.00915909 4.00939655 4.00948421 4.01032277 4.01065318 4.01065672
 4.01094347 4.01131709 4.01145113 4.01152526 4.01176697 4.01178516
 4.01202714 4.0122547  4.01257581 4.01278511 4.01300776 4.01318505
 4.01332068 4.01349861 4.01416404 4.01423952 4.01492371 4.01613756
 4.01627563 4.01718933 4.01726553 4.01765107 4.01779653 4.01955306
 4.02062404 4.02075238 4.02082524 4.02100941 4.02102051 4.0210723
 4.02216549 4.02316663 4.02366683 4.02434716 4.02769079 4.02837921
 4.02956614 4.03047714 4.03070686 4.03358214 4.03524464 4.03695931
 4.03717345 4.03783666 4.03971023 4.04046248 4.04098301 4.0448339
 4.04600758 4.05408621 4.07027367 4.21415704 4.91770011 4.93632457
 4.94576106 4.95262533 4.97448999 4.97539828 4.98303556 4.98500458
 4.9889523  4.98927419 4.99018727 4.99105304 4.99209292 4.9931741
 4.99476981 4.99509447 4.99598415 4.99864162 5.00045919 5.00068411
 5.0014048  5.00493743 5.00538834 5.00598162 5.01011113 5.01095415
 5.01528189 5.01594972 5.01965727 5.02008582 5.03123695 5.03403372
 5.04597801 5.04935147 5.05474759 5.05797404 5.06954648 5.18838938]

  warnings.warn(

2022-12-16 10:37:21,766:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-16 10:37:21,803:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-16 10:37:22,152:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.97816529 2.0242779  3.75095599 3.7537636  3.87569479 3.88561928
 3.8890051  3.88936139 3.89120037 3.89157194 3.89503349 3.89630569
 3.89701414 3.897106   3.9057211  3.90831015 3.90832015 3.90842691
 3.90865162 3.91019842 3.91135743 3.91369583 3.91400098 3.91542819
 3.91584105 3.91718142 3.91792439 3.91802531 3.9181362  3.92052154
 3.92071169 3.92431632 3.92534782 3.92613379 3.92615484 3.92619402
 3.92625417 3.92721806 3.92771017 3.92806356 3.92844841 3.92902276
 3.93017379 3.9306026  3.93138868 3.93142477 3.93246095 3.93281163
 3.93287699 3.9330999  3.93365763 3.93366109 3.93476501 3.93494746
 3.93583242 3.93590223 3.93611998 3.93619461 3.93705517 3.93850066
 3.93879859 3.93938536 3.94071748 3.94113787 3.94163299 3.94172425
 3.94183402 3.94217149 3.94232539 3.94234577 3.94241193 3.94278657
 3.94322128 3.94333868 3.94369733 3.94412178 3.9441818  3.94450079
 3.94469064 3.94471749 3.9447965  3.94507643 3.94544674 3.94547883
 3.94555248 3.94572066 3.94572906 3.94591939 3.94641867 3.94644288
 3.94644647 3.94667971 3.94678035 3.94720093 3.94752582 3.94842859
 3.94844668 3.94847078 3.94882265 3.94885147 3.94914222 3.94920813
 3.94938832 3.94955377 3.94977438 3.94985351 3.94999417 3.95020318
 3.95043248 3.95069121 3.95073743 3.95077086 3.95089304 3.95162394
 3.95182687 3.95184455 3.95212944 3.95218811 3.95230634 3.95248646
 3.95255178 3.9534381  3.95345187 3.95439556 3.95452732 3.95470278
 3.95472123 3.95504629 3.9550539  3.9550648  3.95507212 3.9551105
 3.9551205  3.95541023 3.95541325 3.95542634 3.95560239 3.95561686
 3.95578092 3.9561157  3.95616914 3.9563344  3.95635038 3.95668217
 3.95684246 3.95690146 3.95698211 3.95722623 3.95755152 3.95762545
 3.95768653 3.95780059 3.95781718 3.95789679 3.95790308 3.9579342
 3.95821706 3.95823027 3.95835698 3.95839826 3.95841741 3.958422
 3.95862598 3.95864488 3.95910799 3.95917334 3.95920155 3.95941362
 3.95942471 3.95966482 3.95980282 3.96024375 3.96040968 3.96045007
 3.9610577  3.96111168 3.96114269 3.96116899 3.96120392 3.96134853
 3.96143936 3.96146047 3.96152037 3.96154709 3.9615785  3.96157906
 3.9615837  3.96166708 3.9618716  3.96188948 3.96196745 3.96199879
 3.96222038 3.96240882 3.9624508  3.96256615 3.96272484 3.96286567
 3.96286871 3.96291136 3.96296886 3.96316248 3.96322757 3.96328707
 3.96354639 3.9636656  3.96381679 3.96393858 3.96402552 3.96411416
 3.96428913 3.96429559 3.96431403 3.96437813 3.96443491 3.9644379
 3.96448614 3.96448815 3.96449489 3.96469429 3.96484744 3.96503821
 3.96508394 3.96516059 3.96530892 3.96542178 3.96544211 3.96546776
 3.96556428 3.96600096 3.96605256 3.96612936 3.96613796 3.96618517
 3.96622664 3.96632867 3.96635088 3.96637728 3.96675705 3.96679667
 3.96684587 3.96694143 3.96729773 3.96733196 3.96736058 3.96740124
 3.96741015 3.96746353 3.96747185 3.96751387 3.96751836 3.96752428
 3.96760087 3.96762693 3.96763752 3.9676584  3.96772581 3.96774794
 3.96777094 3.9677792  3.96785047 3.96786309 3.96787631 3.96787697
 3.96794951 3.9679546  3.96798911 3.96819869 3.96832687 3.96832911
 3.9683898  3.96841612 3.96842025 3.96845045 3.96848908 3.96850122
 3.96854219 3.96880218 3.96889197 3.96889472 3.96894782 3.96896464
 3.96897347 3.96929087 3.96938321 3.96939816 3.96949953 3.96953734
 3.96956006 3.96957412 3.96975753 3.9698029  3.96986545 3.96986979
 3.96989377 3.97001442 3.97004745 3.97014376 3.97017794 3.97024121
 3.97034346 3.97062726 3.9706988  3.97078697 3.97090215 3.9709508
 3.97100163 3.97102039 3.9710386  3.97106374 3.97115091 3.97124986
 3.97130455 3.97135719 3.97160988 3.97161474 3.97161516 3.9717384
 3.97176034 3.97176651 3.97180068 3.97195984 3.97199559 3.97214366
 3.97220596 3.97224173 3.97226167 3.97234812 3.97249671 3.97251185
 3.97258568 3.9726298  3.97263107 3.97268794 3.97277059 3.97306019
 3.97307774 3.97316662 3.97329045 3.97335933 3.97336959 3.97340087
 3.97351486 3.973572   3.97367971 3.9737782  3.97383128 3.97387747
 3.97389648 3.97407634 3.97413972 3.97424698 3.97431193 3.97436513
 3.97450862 3.97451401 3.97464297 3.97472386 3.9748259  3.97490311
 3.97495596 3.97497551 3.97502567 3.97508863 3.97509063 3.97510738
 3.97511422 3.97522264 3.97528722 3.97534704 3.97535922 3.97535939
 3.97541794 3.97544441 3.97569167 3.97569207 3.97578724 3.97581581
 3.97600039 3.97600224 3.97601766 3.97607379 3.97611753 3.97624308
 3.97628662 3.97633439 3.97637    3.9764075  3.97644685 3.97646105
 3.97651221 3.97652183 3.9766027  3.97686678 3.97687213 3.97688266
 3.97695281 3.97696704 3.97696946 3.97697693 3.9769855  3.97704952
 3.97709254 3.97709666 3.97717558 3.97726754 3.97745725 3.97757004
 3.97760619 3.97763612 3.97765904 3.97769303 3.97776632 3.97788861
 3.97792078 3.97796233 3.97806421 3.97808216 3.97809659 3.97817999
 3.97824635 3.97838349 3.97842327 3.97849946 3.97850713 3.97851244
 3.97854319 3.97855187 3.97870091 3.97880675 3.97880942 3.97886324
 3.97888458 3.97897232 3.97897802 3.97915472 3.97917356 3.97920083
 3.97924445 3.97944834 3.97946442 3.97951528 3.97951615 3.9795621
 3.97961049 3.97965608 3.97969977 3.97976449 3.97977301 3.97986887
 3.97988677 3.97988798 3.97989687 3.98000564 3.98004699 3.98013996
 3.98025233 3.98026336 3.98026831 3.98031418 3.98034033 3.98044387
 3.98055391 3.98060353 3.980662   3.98067678 3.98073548 3.9807726
 3.98077297 3.98077734 3.98084461 3.98089594 3.98090784 3.980914
 3.98093895 3.98098086 3.98110133 3.98112743 3.98112838 3.98121871
 3.98124225 3.98126646 3.9813471  3.98154832 3.98156837 3.98166371
 3.98169028 3.98170268 3.98172161 3.98172517 3.98182793 3.98186414
 3.9820095  3.98201785 3.98205401 3.98207171 3.98210063 3.98212867
 3.9821696  3.98227227 3.98227267 3.98238967 3.98244901 3.9824493
 3.98252692 3.9825295  3.98258204 3.98265819 3.9828016  3.98280939
 3.98287939 3.9828972  3.98293132 3.98294601 3.98298411 3.98302587
 3.9830699  3.98309593 3.98314491 3.98326698 3.98327908 3.9832875
 3.98331557 3.98331675 3.98337553 3.98347574 3.98349447 3.98354651
 3.98375723 3.98376142 3.98387641 3.98409558 3.98412521 3.98417947
 3.98423267 3.98430229 3.98430486 3.98430673 3.98442594 3.98445058
 3.98450507 3.98455703 3.98456422 3.98458357 3.98478244 3.98487231
 3.98488002 3.98492442 3.98501936 3.98516136 3.98516352 3.98536578
 3.98539426 3.98540292 3.98541813 3.98562194 3.98571145 3.98573471
 3.98581097 3.98592379 3.98598413 3.98599773 3.98599859 3.98605355
 3.98614878 3.98619946 3.98620502 3.98624481 3.98636675 3.98641301
 3.98648743 3.98650849 3.98673731 3.98675113 3.98689072 3.98689169
 3.98690173 3.98690255 3.98699251 3.98702734 3.98718907 3.98721654
 3.98726038 3.98730755 3.98739676 3.98740101 3.98745975 3.98760186
 3.98777967 3.98778574 3.98782596 3.9878519  3.98789477 3.98789781
 3.98790937 3.98795087 3.98798394 3.98799789 3.98814201 3.98830835
 3.98837994 3.98874785 3.98899567 3.98919438 3.98925417 3.98928495
 3.98929439 3.98938382 3.98945262 3.98947451 3.9895879  3.98973787
 3.98985621 3.98988635 3.98992727 3.98997686 3.99001599 3.99002983
 3.99008799 3.99013901 3.99020289 3.99020975 3.9902897  3.99030114
 3.99033218 3.99034402 3.99041826 3.99042911 3.99047114 3.99061465
 3.99067193 3.99071545 3.99082565 3.99082817 3.99085016 3.99086037
 3.99091499 3.99095119 3.99135796 3.99140589 3.99141495 3.99142735
 3.99147327 3.99151987 3.9915617  3.99170258 3.99181807 3.99184843
 3.99196762 3.99203868 3.99204062 3.99208355 3.99211859 3.99221945
 3.99229805 3.99241149 3.99248301 3.9925297  3.9925814  3.99261926
 3.99273019 3.99276674 3.99291836 3.99307428 3.99309359 3.99326084
 3.99331322 3.99346526 3.99349594 3.99355074 3.99358785 3.99368155
 3.99390581 3.99397143 3.99409783 3.99423936 3.99437148 3.99437909
 3.99447402 3.99452669 3.99493767 3.9949791  3.99511019 3.99519102
 3.99522167 3.99525978 3.99530038 3.99535274 3.99537086 3.99539928
 3.99541978 3.99575508 3.99575514 3.99577964 3.99581681 3.99587739
 3.99603366 3.99603492 3.99618855 3.99639657 3.9965533  3.99667274
 3.99718154 3.997376   3.9974176  3.99754217 3.99807359 3.99827026
 3.99847063 3.99899225 3.99907925 3.99928857 3.99937734 3.99983718
 3.99994009 3.99994955 3.9999781  4.00011931 4.00015136 4.00022965
 4.0003088  4.00033879 4.00044946 4.00073666 4.00082607 4.00092754
 4.00123583 4.00125318 4.00129674 4.00132523 4.0013567  4.00160008
 4.00165753 4.00171266 4.00192657 4.00194605 4.00200244 4.00202908
 4.00211492 4.00224684 4.00285813 4.00347664 4.00353959 4.00355214
 4.00372864 4.00379947 4.00384953 4.0039431  4.00428038 4.00435569
 4.00448287 4.00467076 4.00500359 4.00523609 4.00582942 4.00618811
 4.00619581 4.0062547  4.00635513 4.00667589 4.00686551 4.0070057
 4.00709793 4.00745008 4.00814801 4.00826438 4.00913858 4.00931039
 4.00957839 4.00961475 4.00973777 4.01025004 4.01054823 4.01063082
 4.01143319 4.01181601 4.01262719 4.0128431  4.01337638 4.01361743
 4.01495062 4.01534628 4.01554713 4.01615844 4.01660602 4.01662643
 4.0169616  4.01716057 4.01822014 4.01834882 4.01975174 4.02031468
 4.0213137  4.02210382 4.02266616 4.02413301 4.02421179 4.02456444
 4.02489203 4.02501122 4.02752388 4.02794124 4.03355004 4.03591964
 4.03702845 4.03977828 4.04092349 4.043749   4.04680233 4.04687784
 4.04739391 4.04927062 4.06369018 4.16354633 4.27056854 4.89672263
 4.91444081 4.93546957 4.95477453 4.95684071 4.96144251 4.96176688
 4.96780358 4.96918377 4.97273193 4.97346625 4.97445595 4.97681462
 4.97931555 4.98066074 4.98186243 4.98194944 4.98272758 4.98300316
 4.98365714 4.98445518 4.98484632 4.98592026 4.99157789 4.99333683
 4.99416599 4.99614419 4.99640976 4.99683017 4.99762848 4.99826091
 5.00036806 5.00070918 5.0060637  5.0135156  5.01497154 5.01727318
 5.01939297 5.02384951 5.02395612 5.02570688]

  warnings.warn(

2022-12-16 10:37:22,159:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.98702992 2.00349769 2.00838647 2.01608938 2.01664405 2.01951358
 2.02798499 2.02941345 2.02943453 2.0322687  2.03443778 2.03874905
 2.0395766  2.13313968 3.46265084 3.84504925 3.85698142 3.86381058
 3.86398109 3.86831841 3.87081728 3.87203099 3.8742291  3.88080784
 3.88122903 3.88774151 3.89275404 3.89300139 3.89365151 3.89377142
 3.8957683  3.89636464 3.896785   3.89842243 3.89848448 3.9010157
 3.90158    3.90269443 3.90366622 3.90522308 3.90538275 3.90544688
 3.90619947 3.90700784 3.90744076 3.90952857 3.90957353 3.91018311
 3.91049365 3.911116   3.91130543 3.91141658 3.91174467 3.91231014
 3.91339083 3.91356469 3.9136452  3.91391621 3.9140384  3.9150052
 3.91717734 3.91730779 3.91791186 3.9181617  3.91820634 3.91834941
 3.91874007 3.91924277 3.9193083  3.91936088 3.91963753 3.91974195
 3.91987685 3.92035641 3.92050595 3.9217458  3.92221722 3.92239036
 3.92242541 3.92402813 3.92440545 3.924473   3.9246365  3.92556078
 3.92569714 3.92588832 3.92609714 3.92622958 3.92630797 3.92644053
 3.92646927 3.92652146 3.92677009 3.92689965 3.92691089 3.92708055
 3.92730361 3.92743769 3.92747413 3.92780121 3.92804927 3.92811682
 3.92816884 3.92819301 3.92844206 3.92853683 3.92904013 3.9296862
 3.93020251 3.93029429 3.93034854 3.93060042 3.93109343 3.93109383
 3.93166772 3.93180956 3.93183019 3.93185915 3.93219073 3.93225631
 3.9323965  3.93240261 3.93264759 3.93272575 3.93278472 3.9329056
 3.93303248 3.93364866 3.93370993 3.93378724 3.9340081  3.93410706
 3.93428863 3.93445427 3.93524714 3.93533151 3.93565368 3.93565639
 3.93602374 3.93637365 3.93642154 3.93646879 3.93648188 3.93667373
 3.93670356 3.93670551 3.93727937 3.93735023 3.93776813 3.93813613
 3.93815463 3.9382696  3.93844142 3.93850301 3.93851706 3.93854926
 3.93860721 3.93875741 3.93892081 3.93904708 3.93906787 3.93909057
 3.93915986 3.93947836 3.93959856 3.9396226  3.93995917 3.94000281
 3.94006581 3.94008    3.94025063 3.94038537 3.94052905 3.9408767
 3.94093445 3.94114733 3.94116429 3.94117984 3.94128844 3.94129355
 3.94139774 3.94216619 3.94273338 3.94303816 3.9430786  3.94362608
 3.94365024 3.94370472 3.94376448 3.94378902 3.94384156 3.94390938
 3.94398088 3.94398941 3.94404404 3.94411205 3.94416557 3.94421784
 3.9442841  3.94433047 3.94450361 3.94454947 3.94455466 3.944557
 3.94467334 3.94469186 3.94471737 3.94486372 3.94488027 3.94490093
 3.94516735 3.94535639 3.94544969 3.94545332 3.94546324 3.9456065
 3.94561947 3.94576632 3.94581201 3.94587455 3.94592429 3.94595789
 3.94624058 3.94642483 3.94646913 3.94660489 3.94660694 3.94677517
 3.94682059 3.94684867 3.94687202 3.94693181 3.94700778 3.94708244
 3.94710913 3.94717009 3.94733612 3.94734208 3.94740341 3.94744727
 3.94753621 3.94754653 3.94767652 3.9476793  3.94774087 3.94778749
 3.94794384 3.94801158 3.94812621 3.94839603 3.94842456 3.9489857
 3.94916365 3.94917489 3.94919803 3.94955229 3.94971667 3.94978768
 3.94986779 3.9499613  3.94999092 3.95009058 3.95011163 3.9501154
 3.95012996 3.95020414 3.95028075 3.95055476 3.95061462 3.95079891
 3.95086564 3.95102158 3.95105396 3.95111347 3.95115297 3.95137346
 3.95149312 3.95151981 3.95152011 3.95157313 3.9517018  3.95171601
 3.95179198 3.95179286 3.95185764 3.9519171  3.95197959 3.9521389
 3.95240318 3.9524619  3.95250672 3.95252571 3.95255654 3.95255777
 3.95260652 3.95261797 3.9526442  3.95268191 3.95278821 3.95298462
 3.95324446 3.95338991 3.95341302 3.95383845 3.95404847 3.95404995
 3.95409915 3.95417019 3.9543616  3.95445406 3.95461624 3.9546648
 3.95480631 3.95483625 3.95491826 3.95497893 3.95503935 3.95519848
 3.95526981 3.95535393 3.95535404 3.95545538 3.95558789 3.95565268
 3.95571357 3.95580609 3.95598766 3.95600532 3.9561245  3.95630965
 3.95661714 3.95663573 3.95688484 3.95690026 3.95694855 3.95713957
 3.95723764 3.95732355 3.95735182 3.95735785 3.95739366 3.95747558
 3.95769102 3.95775174 3.95776703 3.95790004 3.95811502 3.95815095
 3.95822424 3.95834204 3.95834873 3.95839627 3.95843693 3.95845227
 3.95848515 3.95855269 3.95865158 3.95888436 3.95901627 3.95910517
 3.95911408 3.95918858 3.95921447 3.95960074 3.95971613 3.95974337
 3.95989971 3.95992199 3.96010378 3.96012173 3.96012644 3.96016116
 3.96017924 3.96060045 3.96060436 3.96064846 3.96071517 3.96073704
 3.9608938  3.96090589 3.96092679 3.96093025 3.96118603 3.96126201
 3.96129094 3.96130842 3.96146876 3.96152018 3.96155036 3.96155444
 3.96159689 3.96170564 3.96172377 3.96180663 3.96204008 3.96209542
 3.96210724 3.96216772 3.96218572 3.96259982 3.96265667 3.96280418
 3.96294914 3.96299749 3.96302533 3.96303729 3.96322277 3.96337837
 3.9635034  3.96381219 3.96382301 3.96393922 3.96395213 3.96401701
 3.96401928 3.96404516 3.96446082 3.96450576 3.96454379 3.96468964
 3.96482481 3.96486745 3.96509214 3.96515725 3.9651666  3.96525138
 3.96527856 3.96530936 3.96540627 3.96542243 3.96555896 3.96561553
 3.965826   3.96584503 3.96604794 3.96607219 3.96611471 3.96615474
 3.96619069 3.96621659 3.96625116 3.96628401 3.96660772 3.96675725
 3.96691567 3.96698125 3.9670017  3.96709526 3.96719003 3.96724319
 3.96743852 3.96747515 3.96756785 3.96758179 3.96773285 3.96790007
 3.9679042  3.96791641 3.96796347 3.96801879 3.96811398 3.96812831
 3.96823065 3.96825324 3.96827832 3.96832198 3.96841167 3.96845675
 3.96846663 3.96848961 3.96853532 3.96862407 3.96875898 3.96900605
 3.96902319 3.96904284 3.96908716 3.9693241  3.9693994  3.9693995
 3.96941561 3.96943275 3.96944074 3.96965212 3.96978881 3.9698341
 3.97000819 3.97002779 3.97006229 3.97033814 3.97055799 3.97060858
 3.97062133 3.97068289 3.97069834 3.97074141 3.970767   3.9709829
 3.97099485 3.97107782 3.9711032  3.97123411 3.97129225 3.97129269
 3.97141686 3.97149207 3.97173643 3.97186305 3.97188321 3.97209395
 3.97210117 3.97221637 3.972253   3.97229183 3.97229761 3.9723357
 3.97237459 3.97239466 3.97241278 3.9725005  3.97254997 3.97272995
 3.97277716 3.97284514 3.97291526 3.97291633 3.9729203  3.97311294
 3.9733024  3.97331246 3.9734335  3.97353678 3.97360915 3.97367818
 3.97370311 3.973721   3.97393356 3.9742122  3.97433069 3.97434972
 3.97440398 3.97450325 3.97451719 3.97454124 3.97455691 3.97465895
 3.97466812 3.97470186 3.9747743  3.97488728 3.97490513 3.97500233
 3.9750265  3.97504465 3.97514303 3.97519259 3.97529579 3.97543649
 3.97544781 3.97562625 3.97593702 3.9760171  3.97617388 3.97624064
 3.97626144 3.97643652 3.97646208 3.97659358 3.97660735 3.97668159
 3.97680115 3.97681186 3.97694041 3.97709896 3.97730747 3.97738614
 3.97754984 3.97757119 3.97778812 3.97823947 3.97845174 3.97865089
 3.97883009 3.97884329 3.97888877 3.97911398 3.97913817 3.9791486
 3.97916346 3.97918864 3.97924064 3.97928847 3.97951165 3.97961894
 3.97967444 3.97974546 3.979854   3.97985409 3.98006386 3.98006618
 3.98014312 3.98016474 3.98017936 3.98021303 3.9803631  3.98073668
 3.98079351 3.98084271 3.9808634  3.98102745 3.98105754 3.98136449
 3.98158627 3.98175437 3.98178228 3.98179669 3.98190025 3.9820529
 3.98208665 3.98209341 3.98221252 3.98228068 3.98257997 3.98275771
 3.98288014 3.98304329 3.98304938 3.98309232 3.98325916 3.98336438
 3.98341994 3.9835056  3.98378332 3.98379266 3.9838572  3.98394161
 3.98407293 3.98407552 3.98418236 3.98429912 3.98429962 3.98430817
 3.98433099 3.98452082 3.98479661 3.98496456 3.98508165 3.9853072
 3.98536414 3.98545477 3.98546887 3.98551358 3.98574955 3.98595119
 3.98598941 3.98653903 3.98662265 3.98674254 3.98678902 3.98679775
 3.98682826 3.98690298 3.98698447 3.98713481 3.98714804 3.98760215
 3.98794751 3.98797685 3.98809329 3.98812698 3.98818036 3.9885389
 3.98860727 3.98870906 3.98884952 3.98897234 3.98944    3.98966831
 3.98975959 3.99013599 3.99044495 3.99065486 3.99079129 3.9908546
 3.99114163 3.99136234 3.99138376 3.99141803 3.99189326 3.99216758
 3.99225005 3.99225052 3.99238167 3.9923925  3.99246312 3.99257733
 3.99270894 3.99275367 3.99289034 3.99299309 3.99321844 3.99330485
 3.99332418 3.99342905 3.99370476 3.99376494 3.99386603 3.99388445
 3.99409131 3.99424353 3.99464483 3.99467171 3.99477143 3.9953167
 3.99540974 3.99554405 3.99585902 3.99587051 3.99587639 3.99613407
 3.99615454 3.99628922 3.9970747  3.99720797 3.99748383 3.99748494
 3.99774721 3.99812438 3.99856128 3.99881905 3.99888905 3.99898876
 3.99904424 3.99968924 4.00014408 4.00057862 4.00090062 4.00131138
 4.00132711 4.00138959 4.00157206 4.00167045 4.00227743 4.00337068
 4.00408341 4.00434341 4.00454899 4.00457793 4.00462524 4.00477199
 4.00477505 4.00521877 4.00534798 4.00627759 4.00670214 4.00714571
 4.00729175 4.00824121 4.00841517 4.00842627 4.00921185 4.009233
 4.00926999 4.00937362 4.00955174 4.01064685 4.01072772 4.01083093
 4.01089354 4.01170008 4.01198209 4.01240687 4.01266212 4.01299191
 4.0140649  4.01464008 4.01473123 4.01539756 4.01614071 4.01866267
 4.01889708 4.01894037 4.02000619 4.02028091 4.02223106 4.02312928
 4.02390597 4.02437991 4.02450826 4.02567885 4.02633194 4.02772623
 4.02804578 4.02871762 4.03092858 4.03278849 4.03361697 4.03450731
 4.03774143 4.0400158  4.04713309 4.0485265  4.04873807 4.04896481
 4.04933648 4.05110317 4.05148141 4.05619992 4.05716142 4.05783642
 4.0596184  4.0609569  4.06120588 4.07535765 4.12752394 4.23384263
 4.87838806 4.87870311 4.91121577 4.9119027  4.91277166 4.91998957
 4.95036718 4.9505909  4.9514353  4.95603397 4.956726   4.95715548
 4.95852907 4.96150672 4.96626278 4.96684168 4.97195302 4.97229077
 4.9723351  4.97502052 4.97689021 4.97751014 4.98279634 4.98290114
 4.98323516 4.98374743 4.98443237 4.98477325 4.98633335 4.98786865
 4.98926544 4.98954269 4.98957111 4.99059006 4.99201447 4.99311127
 4.99525722 4.99928465 5.01179176 5.06559486]

  warnings.warn(

2022-12-16 10:37:22,165:INFO:Calculating mean and std
2022-12-16 10:37:22,169:INFO:Creating metrics dataframe
2022-12-16 10:37:22,183:INFO:Uploading results into container
2022-12-16 10:37:22,187:INFO:Uploading model into container now
2022-12-16 10:37:22,189:INFO:master_model_container: 20
2022-12-16 10:37:22,190:INFO:display_container: 2
2022-12-16 10:37:22,191:INFO:HuberRegressor()
2022-12-16 10:37:22,191:INFO:create_model() successfully completed......................................
2022-12-16 10:37:22,519:ERROR:create_model() for HuberRegressor() raised an exception or returned all 0.0:
2022-12-16 10:37:22,520:ERROR:Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 795, in compare_models
    assert (
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 811, in compare_models
    assert (
AssertionError

2022-12-16 10:37:22,521:INFO:Initializing K Neighbors Regressor
2022-12-16 10:37:22,522:INFO:Total runtime is 1.4210678060849509 minutes
2022-12-16 10:37:22,522:INFO:SubProcess create_model() called ==================================
2022-12-16 10:37:22,524:INFO:Initializing create_model()
2022-12-16 10:37:22,525:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002281239F8E0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022810EC8B20>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:37:22,525:INFO:Checking exceptions
2022-12-16 10:37:22,531:INFO:Importing libraries
2022-12-16 10:37:22,531:INFO:Copying training dataset
2022-12-16 10:37:22,546:INFO:Defining folds
2022-12-16 10:37:22,547:INFO:Declaring metric variables
2022-12-16 10:37:22,548:INFO:Importing untrained model
2022-12-16 10:37:22,549:INFO:K Neighbors Regressor Imported successfully
2022-12-16 10:37:22,549:INFO:Starting cross validation
2022-12-16 10:37:22,556:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:37:25,821:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [0.8 1.2 1.4 1.6 1.8 2.2 2.4 2.6 2.8 3.2 3.4 3.6 3.8 4.2 4.4 4.6 4.8]

  warnings.warn(

2022-12-16 10:37:25,838:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [0.8 1.2 1.4 1.6 1.8 2.2 2.4 2.6 2.8 3.2 3.4 3.6 3.8 4.2 4.4 4.6 4.8]

  warnings.warn(

2022-12-16 10:37:25,855:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [0.8 1.2 1.4 1.6 1.8 2.2 2.4 2.6 2.8 3.2 3.4 3.6 3.8 4.2 4.4 4.6 4.8]

  warnings.warn(

2022-12-16 10:37:25,956:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [0.6 0.8 1.2 1.4 1.6 1.8 2.2 2.4 2.6 2.8 3.2 3.4 3.6 3.8 4.2 4.4 4.6 4.8]

  warnings.warn(

2022-12-16 10:37:26,244:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [0.6 1.2 1.4 1.6 1.8 2.2 2.4 2.6 2.8 3.2 3.4 3.6 3.8 4.2 4.4 4.6 4.8]

  warnings.warn(

2022-12-16 10:37:26,299:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [0.8 1.4 1.6 1.8 2.2 2.4 2.6 2.8 3.2 3.4 3.6 3.8 4.2 4.4 4.6 4.8]

  warnings.warn(

2022-12-16 10:37:26,332:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [0.6 1.2 1.4 1.6 1.8 2.2 2.4 2.6 2.8 3.2 3.4 3.6 3.8 4.2 4.4 4.6 4.8]

  warnings.warn(

2022-12-16 10:37:26,332:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.2 1.4 1.6 1.8 2.2 2.4 2.6 2.8 3.2 3.4 3.6 3.8 4.2 4.4 4.6 4.8]

  warnings.warn(

2022-12-16 10:37:27,308:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [0.8 1.2 1.4 1.6 1.8 2.2 2.4 2.6 2.8 3.2 3.4 3.6 3.8 4.2 4.4 4.6 4.8]

  warnings.warn(

2022-12-16 10:37:27,314:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [0.6 1.2 1.4 1.6 1.8 2.2 2.4 2.6 2.8 3.2 3.4 3.6 3.8 4.2 4.4 4.6 4.8]

  warnings.warn(

2022-12-16 10:37:27,315:INFO:Calculating mean and std
2022-12-16 10:37:27,315:INFO:Creating metrics dataframe
2022-12-16 10:37:27,322:INFO:Uploading results into container
2022-12-16 10:37:27,324:INFO:Uploading model into container now
2022-12-16 10:37:27,325:INFO:master_model_container: 21
2022-12-16 10:37:27,325:INFO:display_container: 2
2022-12-16 10:37:27,325:INFO:KNeighborsRegressor(n_jobs=-1)
2022-12-16 10:37:27,325:INFO:create_model() successfully completed......................................
2022-12-16 10:37:27,510:WARNING:create_model() for KNeighborsRegressor(n_jobs=-1) raised an exception or returned all 0.0, trying without fit_kwargs:
2022-12-16 10:37:27,511:WARNING:Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 795, in compare_models
    assert (
AssertionError

2022-12-16 10:37:27,511:INFO:Initializing create_model()
2022-12-16 10:37:27,511:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002281239F8E0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022810EC8B20>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:37:27,511:INFO:Checking exceptions
2022-12-16 10:37:27,515:INFO:Importing libraries
2022-12-16 10:37:27,515:INFO:Copying training dataset
2022-12-16 10:37:27,524:INFO:Defining folds
2022-12-16 10:37:27,524:INFO:Declaring metric variables
2022-12-16 10:37:27,524:INFO:Importing untrained model
2022-12-16 10:37:27,525:INFO:K Neighbors Regressor Imported successfully
2022-12-16 10:37:27,525:INFO:Starting cross validation
2022-12-16 10:37:27,527:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:37:29,697:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [0.8 1.2 1.4 1.6 1.8 2.2 2.4 2.6 2.8 3.2 3.4 3.6 3.8 4.2 4.4 4.6 4.8]

  warnings.warn(

2022-12-16 10:37:29,736:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [0.8 1.2 1.4 1.6 1.8 2.2 2.4 2.6 2.8 3.2 3.4 3.6 3.8 4.2 4.4 4.6 4.8]

  warnings.warn(

2022-12-16 10:37:29,745:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [0.6 0.8 1.2 1.4 1.6 1.8 2.2 2.4 2.6 2.8 3.2 3.4 3.6 3.8 4.2 4.4 4.6 4.8]

  warnings.warn(

2022-12-16 10:37:29,769:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [0.6 1.2 1.4 1.6 1.8 2.2 2.4 2.6 2.8 3.2 3.4 3.6 3.8 4.2 4.4 4.6 4.8]

  warnings.warn(

2022-12-16 10:37:29,897:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.2 1.4 1.6 1.8 2.2 2.4 2.6 2.8 3.2 3.4 3.6 3.8 4.2 4.4 4.6 4.8]

  warnings.warn(

2022-12-16 10:37:29,908:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [0.8 1.2 1.4 1.6 1.8 2.2 2.4 2.6 2.8 3.2 3.4 3.6 3.8 4.2 4.4 4.6 4.8]

  warnings.warn(

2022-12-16 10:37:29,924:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [0.8 1.4 1.6 1.8 2.2 2.4 2.6 2.8 3.2 3.4 3.6 3.8 4.2 4.4 4.6 4.8]

  warnings.warn(

2022-12-16 10:37:29,928:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [0.6 1.2 1.4 1.6 1.8 2.2 2.4 2.6 2.8 3.2 3.4 3.6 3.8 4.2 4.4 4.6 4.8]

  warnings.warn(

2022-12-16 10:37:30,714:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [0.6 1.2 1.4 1.6 1.8 2.2 2.4 2.6 2.8 3.2 3.4 3.6 3.8 4.2 4.4 4.6 4.8]

  warnings.warn(

2022-12-16 10:37:30,730:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [0.8 1.2 1.4 1.6 1.8 2.2 2.4 2.6 2.8 3.2 3.4 3.6 3.8 4.2 4.4 4.6 4.8]

  warnings.warn(

2022-12-16 10:37:30,731:INFO:Calculating mean and std
2022-12-16 10:37:30,731:INFO:Creating metrics dataframe
2022-12-16 10:37:30,736:INFO:Uploading results into container
2022-12-16 10:37:30,737:INFO:Uploading model into container now
2022-12-16 10:37:30,738:INFO:master_model_container: 22
2022-12-16 10:37:30,738:INFO:display_container: 2
2022-12-16 10:37:30,738:INFO:KNeighborsRegressor(n_jobs=-1)
2022-12-16 10:37:30,738:INFO:create_model() successfully completed......................................
2022-12-16 10:37:30,900:ERROR:create_model() for KNeighborsRegressor(n_jobs=-1) raised an exception or returned all 0.0:
2022-12-16 10:37:30,901:ERROR:Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 795, in compare_models
    assert (
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 811, in compare_models
    assert (
AssertionError

2022-12-16 10:37:30,901:INFO:Initializing Decision Tree Regressor
2022-12-16 10:37:30,901:INFO:Total runtime is 1.5607214570045471 minutes
2022-12-16 10:37:30,901:INFO:SubProcess create_model() called ==================================
2022-12-16 10:37:30,902:INFO:Initializing create_model()
2022-12-16 10:37:30,902:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002281239F8E0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022810EC8B20>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:37:30,902:INFO:Checking exceptions
2022-12-16 10:37:30,905:INFO:Importing libraries
2022-12-16 10:37:30,905:INFO:Copying training dataset
2022-12-16 10:37:30,911:INFO:Defining folds
2022-12-16 10:37:30,911:INFO:Declaring metric variables
2022-12-16 10:37:30,911:INFO:Importing untrained model
2022-12-16 10:37:30,911:INFO:Decision Tree Regressor Imported successfully
2022-12-16 10:37:30,912:INFO:Starting cross validation
2022-12-16 10:37:30,914:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:37:32,903:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 163, in inverse_transform
    return self.classes_[y]
IndexError: arrays used as indices must be of integer (or boolean) type

  warnings.warn(

2022-12-16 10:37:32,931:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 163, in inverse_transform
    return self.classes_[y]
IndexError: arrays used as indices must be of integer (or boolean) type

  warnings.warn(

2022-12-16 10:37:32,958:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 163, in inverse_transform
    return self.classes_[y]
IndexError: arrays used as indices must be of integer (or boolean) type

  warnings.warn(

2022-12-16 10:37:33,005:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 163, in inverse_transform
    return self.classes_[y]
IndexError: arrays used as indices must be of integer (or boolean) type

  warnings.warn(

2022-12-16 10:37:33,010:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 163, in inverse_transform
    return self.classes_[y]
IndexError: arrays used as indices must be of integer (or boolean) type

  warnings.warn(

2022-12-16 10:37:33,026:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 163, in inverse_transform
    return self.classes_[y]
IndexError: arrays used as indices must be of integer (or boolean) type

  warnings.warn(

2022-12-16 10:37:33,058:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 163, in inverse_transform
    return self.classes_[y]
IndexError: arrays used as indices must be of integer (or boolean) type

  warnings.warn(

2022-12-16 10:37:33,087:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 163, in inverse_transform
    return self.classes_[y]
IndexError: arrays used as indices must be of integer (or boolean) type

  warnings.warn(

2022-12-16 10:37:33,823:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 163, in inverse_transform
    return self.classes_[y]
IndexError: arrays used as indices must be of integer (or boolean) type

  warnings.warn(

2022-12-16 10:37:33,831:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 163, in inverse_transform
    return self.classes_[y]
IndexError: arrays used as indices must be of integer (or boolean) type

  warnings.warn(

2022-12-16 10:37:33,832:INFO:Calculating mean and std
2022-12-16 10:37:33,832:INFO:Creating metrics dataframe
2022-12-16 10:37:33,836:INFO:Uploading results into container
2022-12-16 10:37:33,837:INFO:Uploading model into container now
2022-12-16 10:37:33,838:INFO:master_model_container: 23
2022-12-16 10:37:33,838:INFO:display_container: 2
2022-12-16 10:37:33,838:INFO:DecisionTreeRegressor(random_state=5099)
2022-12-16 10:37:33,838:INFO:create_model() successfully completed......................................
2022-12-16 10:37:33,979:WARNING:create_model() for DecisionTreeRegressor(random_state=5099) raised an exception or returned all 0.0, trying without fit_kwargs:
2022-12-16 10:37:33,980:WARNING:Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 795, in compare_models
    assert (
AssertionError

2022-12-16 10:37:33,980:INFO:Initializing create_model()
2022-12-16 10:37:33,980:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002281239F8E0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022810EC8B20>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:37:33,981:INFO:Checking exceptions
2022-12-16 10:37:33,985:INFO:Importing libraries
2022-12-16 10:37:33,985:INFO:Copying training dataset
2022-12-16 10:37:33,990:INFO:Defining folds
2022-12-16 10:37:33,990:INFO:Declaring metric variables
2022-12-16 10:37:33,991:INFO:Importing untrained model
2022-12-16 10:37:33,991:INFO:Decision Tree Regressor Imported successfully
2022-12-16 10:37:33,991:INFO:Starting cross validation
2022-12-16 10:37:33,993:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:37:35,959:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 163, in inverse_transform
    return self.classes_[y]
IndexError: arrays used as indices must be of integer (or boolean) type

  warnings.warn(

2022-12-16 10:37:35,983:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 163, in inverse_transform
    return self.classes_[y]
IndexError: arrays used as indices must be of integer (or boolean) type

  warnings.warn(

2022-12-16 10:37:36,002:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 163, in inverse_transform
    return self.classes_[y]
IndexError: arrays used as indices must be of integer (or boolean) type

  warnings.warn(

2022-12-16 10:37:36,045:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 163, in inverse_transform
    return self.classes_[y]
IndexError: arrays used as indices must be of integer (or boolean) type

  warnings.warn(

2022-12-16 10:37:36,055:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 163, in inverse_transform
    return self.classes_[y]
IndexError: arrays used as indices must be of integer (or boolean) type

  warnings.warn(

2022-12-16 10:37:36,082:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 163, in inverse_transform
    return self.classes_[y]
IndexError: arrays used as indices must be of integer (or boolean) type

  warnings.warn(

2022-12-16 10:37:36,109:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 163, in inverse_transform
    return self.classes_[y]
IndexError: arrays used as indices must be of integer (or boolean) type

  warnings.warn(

2022-12-16 10:37:36,156:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 163, in inverse_transform
    return self.classes_[y]
IndexError: arrays used as indices must be of integer (or boolean) type

  warnings.warn(

2022-12-16 10:37:36,989:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 163, in inverse_transform
    return self.classes_[y]
IndexError: arrays used as indices must be of integer (or boolean) type

  warnings.warn(

2022-12-16 10:37:37,000:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 163, in inverse_transform
    return self.classes_[y]
IndexError: arrays used as indices must be of integer (or boolean) type

  warnings.warn(

2022-12-16 10:37:37,006:INFO:Calculating mean and std
2022-12-16 10:37:37,007:INFO:Creating metrics dataframe
2022-12-16 10:37:37,014:INFO:Uploading results into container
2022-12-16 10:37:37,017:INFO:Uploading model into container now
2022-12-16 10:37:37,018:INFO:master_model_container: 24
2022-12-16 10:37:37,019:INFO:display_container: 2
2022-12-16 10:37:37,021:INFO:DecisionTreeRegressor(random_state=5099)
2022-12-16 10:37:37,021:INFO:create_model() successfully completed......................................
2022-12-16 10:37:37,230:ERROR:create_model() for DecisionTreeRegressor(random_state=5099) raised an exception or returned all 0.0:
2022-12-16 10:37:37,231:ERROR:Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 795, in compare_models
    assert (
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 811, in compare_models
    assert (
AssertionError

2022-12-16 10:37:37,231:INFO:Initializing Random Forest Regressor
2022-12-16 10:37:37,231:INFO:Total runtime is 1.6662247021993002 minutes
2022-12-16 10:37:37,231:INFO:SubProcess create_model() called ==================================
2022-12-16 10:37:37,232:INFO:Initializing create_model()
2022-12-16 10:37:37,232:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002281239F8E0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022810EC8B20>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:37:37,232:INFO:Checking exceptions
2022-12-16 10:37:37,239:INFO:Importing libraries
2022-12-16 10:37:37,239:INFO:Copying training dataset
2022-12-16 10:37:37,246:INFO:Defining folds
2022-12-16 10:37:37,247:INFO:Declaring metric variables
2022-12-16 10:37:37,247:INFO:Importing untrained model
2022-12-16 10:37:37,247:INFO:Random Forest Regressor Imported successfully
2022-12-16 10:37:37,248:INFO:Starting cross validation
2022-12-16 10:37:37,249:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:37:41,720:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.65 2.03 2.96 2.97 2.99 3.01 3.02 3.03 3.04 3.05 3.06 3.07 3.08 3.09
 3.1  3.32 3.33 3.35 3.39 3.41 3.42 3.43 3.46 3.47 3.48 3.49 3.5  3.59
 3.6  3.81 3.82 3.83 3.84 3.92 3.99 4.02 4.15]

  warnings.warn(

2022-12-16 10:37:41,797:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.41 2.9  2.98 3.11 3.12 3.14 3.17 3.18 3.2  3.21 3.28 3.29 3.3  3.33
 3.35 3.36 3.41 3.44 3.48 3.49 3.54 3.66 3.68 3.69 3.71 3.73 3.75 3.76
 3.77 3.79 3.8  3.82 3.83 3.84 3.85 3.86 3.87 3.89 3.9  3.98 4.05 4.24]

  warnings.warn(

2022-12-16 10:37:41,897:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.82 2.92 2.95 2.97 2.98 3.01 3.02 3.03 3.04 3.05 3.06 3.07 3.08 3.09
 3.1  3.12 3.14 3.21 3.42 3.43 3.44 3.47 3.49 3.57 3.61 3.62 3.71 3.76
 3.8  3.82 3.83 3.87 4.03 4.17]

  warnings.warn(

2022-12-16 10:37:42,118:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.67 2.68 2.69 2.7  2.72 2.97 2.98 2.99 3.02 3.03 3.06 3.07 3.09 3.11
 3.18 3.4  3.46 3.48 3.52 3.55 3.56 3.58 3.6  3.64 3.66 3.68 3.7  3.71
 3.72 3.73 3.74 3.85 3.86 4.02]

  warnings.warn(

2022-12-16 10:37:42,133:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.4  2.54 2.55 2.56 2.94 2.96 2.97 2.98 2.99 3.02 3.03 3.04 3.05 3.06
 3.08 3.09 3.1  3.14 3.16 3.18 3.23 3.24 3.25 3.59 3.6  3.69 3.7  3.76
 3.85 3.88 3.91 4.1  4.15 4.17]

  warnings.warn(

2022-12-16 10:37:42,149:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.75 1.83 1.89 2.63 2.64 2.66 2.68 2.69 2.86 2.89 2.96 2.97 2.98 2.99
 3.01 3.02 3.04 3.05 3.08 3.1  3.12 3.25 3.3  3.31 3.53 3.62 3.67 3.76
 3.8  3.84 3.85 3.92 3.93 3.95 3.97 3.99]

  warnings.warn(

2022-12-16 10:37:42,209:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.64 2.97 2.98 3.01 3.02 3.04 3.05 3.06 3.07 3.08 3.09 3.1  3.13 3.14
 3.2  3.24 3.25 3.26 3.3  3.31 3.43 3.44 3.58 3.59 3.6  3.64 3.67 3.72
 3.8  3.81 3.85 4.02 4.04]

  warnings.warn(

2022-12-16 10:37:42,346:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.51 2.61 2.63 2.66 2.7  2.71 2.72 2.74 2.75 2.76 2.77 2.88 2.93 2.94
 2.97 3.01 3.02 3.04 3.07 3.08 3.09 3.1  3.12 3.13 3.14 3.15 3.16 3.17
 3.19 3.2  3.21 3.25 3.26 3.3  3.37 3.38 3.43 3.52 3.58 3.63 3.7  3.72
 3.75 3.82 3.83 3.87 3.88 3.9  3.91]

  warnings.warn(

2022-12-16 10:37:43,970:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.88 2.92 2.96 2.97 2.98 2.99 3.02 3.03 3.04 3.05 3.06 3.07 3.08 3.09
 3.1  3.11 3.12 3.13 3.15 3.2  3.21 3.22 3.23 3.24 3.25 3.26 3.27 3.28
 3.29 3.32 3.38 3.43 3.5  3.79 3.81 3.87 3.94 4.02 4.09]

  warnings.warn(

2022-12-16 10:37:43,989:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.94 2.95 2.97 2.99 3.04 3.06 3.07 3.08 3.11 3.12 3.56 3.79 4.02 4.03
 4.07 4.17 4.46 4.79]

  warnings.warn(

2022-12-16 10:37:43,990:INFO:Calculating mean and std
2022-12-16 10:37:43,991:INFO:Creating metrics dataframe
2022-12-16 10:37:44,005:INFO:Uploading results into container
2022-12-16 10:37:44,008:INFO:Uploading model into container now
2022-12-16 10:37:44,010:INFO:master_model_container: 25
2022-12-16 10:37:44,010:INFO:display_container: 2
2022-12-16 10:37:44,012:INFO:RandomForestRegressor(n_jobs=-1, random_state=5099)
2022-12-16 10:37:44,012:INFO:create_model() successfully completed......................................
2022-12-16 10:37:44,258:WARNING:create_model() for RandomForestRegressor(n_jobs=-1, random_state=5099) raised an exception or returned all 0.0, trying without fit_kwargs:
2022-12-16 10:37:44,259:WARNING:Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 795, in compare_models
    assert (
AssertionError

2022-12-16 10:37:44,260:INFO:Initializing create_model()
2022-12-16 10:37:44,260:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002281239F8E0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022810EC8B20>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:37:44,260:INFO:Checking exceptions
2022-12-16 10:37:44,268:INFO:Importing libraries
2022-12-16 10:37:44,268:INFO:Copying training dataset
2022-12-16 10:37:44,283:INFO:Defining folds
2022-12-16 10:37:44,284:INFO:Declaring metric variables
2022-12-16 10:37:44,285:INFO:Importing untrained model
2022-12-16 10:37:44,286:INFO:Random Forest Regressor Imported successfully
2022-12-16 10:37:44,287:INFO:Starting cross validation
2022-12-16 10:37:44,292:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:37:48,822:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.65 2.03 2.96 2.97 2.99 3.01 3.02 3.03 3.04 3.05 3.06 3.07 3.08 3.09
 3.1  3.32 3.33 3.35 3.39 3.41 3.42 3.43 3.46 3.47 3.48 3.49 3.5  3.59
 3.6  3.81 3.82 3.83 3.84 3.92 3.99 4.02 4.15]

  warnings.warn(

2022-12-16 10:37:48,829:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.4  2.54 2.55 2.56 2.94 2.96 2.97 2.98 2.99 3.02 3.03 3.04 3.05 3.06
 3.08 3.09 3.1  3.14 3.16 3.18 3.23 3.24 3.25 3.59 3.6  3.69 3.7  3.76
 3.85 3.88 3.91 4.1  4.15 4.17]

  warnings.warn(

2022-12-16 10:37:48,832:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.67 2.68 2.69 2.7  2.72 2.97 2.98 2.99 3.02 3.03 3.06 3.07 3.09 3.11
 3.18 3.4  3.46 3.48 3.52 3.55 3.56 3.58 3.6  3.64 3.66 3.68 3.7  3.71
 3.72 3.73 3.74 3.85 3.86 4.02]

  warnings.warn(

2022-12-16 10:37:48,951:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.64 2.97 2.98 3.01 3.02 3.04 3.05 3.06 3.07 3.08 3.09 3.1  3.13 3.14
 3.2  3.24 3.25 3.26 3.3  3.31 3.43 3.44 3.58 3.59 3.6  3.64 3.67 3.72
 3.8  3.81 3.85 4.02 4.04]

  warnings.warn(

2022-12-16 10:37:49,044:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.82 2.92 2.95 2.97 2.98 3.01 3.02 3.03 3.04 3.05 3.06 3.07 3.08 3.09
 3.1  3.12 3.14 3.21 3.42 3.43 3.44 3.47 3.49 3.57 3.61 3.62 3.71 3.76
 3.8  3.82 3.83 3.87 4.03 4.17]

  warnings.warn(

2022-12-16 10:37:49,107:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.51 2.61 2.63 2.66 2.7  2.71 2.72 2.74 2.75 2.76 2.77 2.88 2.93 2.94
 2.97 3.01 3.02 3.04 3.07 3.08 3.09 3.1  3.12 3.13 3.14 3.15 3.16 3.17
 3.19 3.2  3.21 3.25 3.26 3.3  3.37 3.38 3.43 3.52 3.58 3.63 3.7  3.72
 3.75 3.82 3.83 3.87 3.88 3.9  3.91]

  warnings.warn(

2022-12-16 10:37:49,156:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.41 2.9  2.98 3.11 3.12 3.14 3.17 3.18 3.2  3.21 3.28 3.29 3.3  3.33
 3.35 3.36 3.41 3.44 3.48 3.49 3.54 3.66 3.68 3.69 3.71 3.73 3.75 3.76
 3.77 3.79 3.8  3.82 3.83 3.84 3.85 3.86 3.87 3.89 3.9  3.98 4.05 4.24]

  warnings.warn(

2022-12-16 10:37:49,156:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.75 1.83 1.89 2.63 2.64 2.66 2.68 2.69 2.86 2.89 2.96 2.97 2.98 2.99
 3.01 3.02 3.04 3.05 3.08 3.1  3.12 3.25 3.3  3.31 3.53 3.62 3.67 3.76
 3.8  3.84 3.85 3.92 3.93 3.95 3.97 3.99]

  warnings.warn(

2022-12-16 10:37:51,202:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.88 2.92 2.96 2.97 2.98 2.99 3.02 3.03 3.04 3.05 3.06 3.07 3.08 3.09
 3.1  3.11 3.12 3.13 3.15 3.2  3.21 3.22 3.23 3.24 3.25 3.26 3.27 3.28
 3.29 3.32 3.38 3.43 3.5  3.79 3.81 3.87 3.94 4.02 4.09]

  warnings.warn(

2022-12-16 10:37:51,294:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.94 2.95 2.97 2.99 3.04 3.06 3.07 3.08 3.11 3.12 3.56 3.79 4.02 4.03
 4.07 4.17 4.46 4.79]

  warnings.warn(

2022-12-16 10:37:51,296:INFO:Calculating mean and std
2022-12-16 10:37:51,298:INFO:Creating metrics dataframe
2022-12-16 10:37:51,310:INFO:Uploading results into container
2022-12-16 10:37:51,313:INFO:Uploading model into container now
2022-12-16 10:37:51,314:INFO:master_model_container: 26
2022-12-16 10:37:51,314:INFO:display_container: 2
2022-12-16 10:37:51,316:INFO:RandomForestRegressor(n_jobs=-1, random_state=5099)
2022-12-16 10:37:51,316:INFO:create_model() successfully completed......................................
2022-12-16 10:37:51,562:ERROR:create_model() for RandomForestRegressor(n_jobs=-1, random_state=5099) raised an exception or returned all 0.0:
2022-12-16 10:37:51,563:ERROR:Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 795, in compare_models
    assert (
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 811, in compare_models
    assert (
AssertionError

2022-12-16 10:37:51,564:INFO:Initializing Extra Trees Regressor
2022-12-16 10:37:51,564:INFO:Total runtime is 1.9051003336906434 minutes
2022-12-16 10:37:51,564:INFO:SubProcess create_model() called ==================================
2022-12-16 10:37:51,565:INFO:Initializing create_model()
2022-12-16 10:37:51,565:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002281239F8E0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022810EC8B20>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:37:51,566:INFO:Checking exceptions
2022-12-16 10:37:51,571:INFO:Importing libraries
2022-12-16 10:37:51,572:INFO:Copying training dataset
2022-12-16 10:37:51,584:INFO:Defining folds
2022-12-16 10:37:51,585:INFO:Declaring metric variables
2022-12-16 10:37:51,586:INFO:Importing untrained model
2022-12-16 10:37:51,587:INFO:Extra Trees Regressor Imported successfully
2022-12-16 10:37:51,588:INFO:Starting cross validation
2022-12-16 10:37:51,592:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:37:58,023:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [0.31 1.09 1.16 1.97 1.99 2.35 2.38 2.39 2.4  2.42 2.43 2.44 2.45 2.47
 2.48 2.5  2.51 2.52 2.53 2.54 2.55 2.56 2.57 2.58 2.59 2.6  2.61 2.62
 2.63 2.64 2.65 2.66 2.67 2.68 2.69 2.7  2.71 2.72 2.73 2.74 2.75 2.76
 2.77 2.78 2.79 2.8  2.81 2.82 2.83 2.84 2.85 2.86 2.87 2.88 2.89 2.9
 2.92 2.93 2.94 2.95 2.96 2.98 2.99 3.01 3.02 3.03 3.04 3.05 3.06 3.07
 3.08 3.09 3.1  3.11 3.12 3.13 3.14 3.15 3.16 3.17 3.18 3.19 3.2  3.21
 3.22 3.23 3.24 3.25 3.26 3.27 3.28 3.29 3.3  3.31 3.32 3.33 3.34 3.35
 3.36 3.37 3.38 3.39 3.4  3.41 3.42 3.43 3.44 3.45 3.46 3.47 3.48 3.49
 3.51 3.52 3.53 3.62 3.73 3.85 3.88 3.91 4.01 4.05 4.1  4.28 4.29 4.97]

  warnings.warn(

2022-12-16 10:37:58,128:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [0.27 0.29 0.35 1.04 1.09 1.39 1.47 2.08 2.09 2.72 2.76 2.78 2.8  2.81
 2.82 2.83 2.84 2.85 2.86 2.88 2.89 2.9  2.92 2.94 2.95 2.97 2.98 3.01
 3.02 3.03 3.04 3.05 3.06 3.07 3.08 3.09 3.1  3.11 3.12 3.13 3.14 3.15
 3.16 3.17 3.18 3.19 3.2  3.21 3.22 3.23 3.24 3.25 3.26 3.27 3.28 3.29
 3.3  3.31 3.32 3.33 3.34 3.35 3.36 3.37 3.38 3.39 3.4  3.41 3.42 3.43
 3.44 3.45 3.46 3.47 3.48 3.49 3.5  3.51 3.52 3.53 3.54 3.55 3.56 3.57
 3.58 3.59 3.6  3.61 3.62 3.63 3.64 3.65 3.66 3.67 3.69 3.7  3.74 3.75
 3.76 3.78 3.79 3.8  3.81 3.82 3.83 3.87 3.95 3.97 3.98 4.35 4.36 4.38
 4.39]

  warnings.warn(

2022-12-16 10:37:58,142:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [0.13 0.82 0.85 0.88 2.52 2.55 2.57 2.62 2.69 2.75 2.8  2.86 2.89 2.9
 2.92 2.93 2.94 2.95 2.96 2.97 2.98 2.99 3.01 3.02 3.03 3.04 3.05 3.06
 3.07 3.08 3.09 3.1  3.11 3.12 3.13 3.14 3.15 3.16 3.17 3.18 3.19 3.2
 3.21 3.22 3.23 3.24 3.25 3.26 3.27 3.28 3.29 3.3  3.31 3.32 3.33 3.34
 3.35 3.36 3.37 3.38 3.39 3.4  3.41 3.42 3.43 3.44 3.45 3.46 3.48 3.49
 3.51 3.52 3.53 3.54 3.56 3.58 3.62 3.64 3.68 3.77 3.78 3.79 3.83 3.93
 4.16 4.17 4.23 4.25 4.27 4.3  4.31 4.32 4.48]

  warnings.warn(

2022-12-16 10:37:58,309:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [0.28 0.32 0.36 1.2  1.91 2.03 2.07 2.39 2.42 2.51 2.52 2.65 2.71 2.73
 2.76 2.77 2.78 2.79 2.8  2.81 2.82 2.83 2.85 2.89 2.9  2.91 2.92 2.93
 2.94 2.95 2.96 2.97 2.98 2.99 3.01 3.02 3.03 3.04 3.05 3.06 3.07 3.08
 3.09 3.1  3.11 3.12 3.13 3.14 3.15 3.16 3.17 3.18 3.19 3.2  3.21 3.22
 3.23 3.24 3.25 3.26 3.27 3.28 3.29 3.3  3.31 3.32 3.33 3.34 3.35 3.36
 3.37 3.38 3.39 3.4  3.41 3.42 3.43 3.44 3.45 3.46 3.47 3.48 3.49 3.5
 3.51 3.52 3.53 3.54 3.55 3.56 3.58 3.59 3.61 3.62 3.64 3.66 3.69 3.74
 3.75 3.76 3.77 3.82 3.94 3.96 3.99 4.11 4.24 4.28]

  warnings.warn(

2022-12-16 10:37:58,450:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [0.42 1.14 1.18 2.02 2.04 2.05 2.47 2.49 2.56 2.58 2.62 2.64 2.67 2.68
 2.69 2.71 2.72 2.73 2.74 2.76 2.77 2.78 2.79 2.8  2.81 2.82 2.84 2.85
 2.87 2.88 2.89 2.9  2.91 2.92 2.93 2.94 2.96 2.97 2.98 2.99 3.01 3.02
 3.03 3.04 3.05 3.06 3.07 3.08 3.09 3.1  3.11 3.12 3.13 3.14 3.15 3.16
 3.17 3.18 3.19 3.2  3.21 3.22 3.23 3.24 3.25 3.26 3.27 3.28 3.29 3.3
 3.31 3.32 3.33 3.34 3.35 3.36 3.37 3.38 3.39 3.4  3.41 3.42 3.43 3.44
 3.45 3.46 3.47 3.48 3.49 3.5  3.51 3.52 3.54 3.55 3.56 3.57 3.58 3.6
 3.61 3.63 3.64 3.66 3.67 3.68 3.89 3.99 4.04 4.21 4.27 4.33 4.34 4.35
 4.36 4.37 4.96]

  warnings.warn(

2022-12-16 10:37:58,497:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [0.4  1.09 1.1  1.12 1.18 1.99 2.01 2.31 2.32 2.4  2.47 2.52 2.53 2.55
 2.56 2.57 2.58 2.59 2.6  2.61 2.62 2.63 2.65 2.67 2.68 2.69 2.7  2.71
 2.72 2.73 2.74 2.75 2.76 2.77 2.8  2.81 2.82 2.83 2.87 2.89 2.9  2.92
 2.93 2.94 2.95 2.97 2.98 2.99 3.01 3.02 3.03 3.04 3.05 3.06 3.07 3.08
 3.09 3.1  3.11 3.12 3.13 3.14 3.15 3.16 3.17 3.18 3.19 3.2  3.21 3.22
 3.23 3.24 3.25 3.26 3.27 3.28 3.29 3.3  3.31 3.32 3.33 3.34 3.35 3.36
 3.37 3.38 3.39 3.4  3.41 3.42 3.43 3.44 3.45 3.46 3.47 3.48 3.49 3.5
 3.51 3.52 3.54 3.55 3.57 3.58 3.59 3.6  3.61 3.62 3.63 3.64 3.65 3.67
 3.68 3.69 3.7  3.71 3.72 3.73 3.74 3.75 3.76 3.78 3.79 3.8  3.81 3.82
 3.83 3.84 3.85 3.86 3.87 3.88 3.89 3.91 3.92 3.93 3.94 3.95 3.96 3.97
 3.98 3.99 4.01 4.02 4.03 4.11 4.15 4.2  4.35 4.42 4.43 4.45 4.46 4.56]

  warnings.warn(

2022-12-16 10:37:58,629:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.15 2.01 2.03 2.41 2.54 2.62 2.63 2.64 2.65 2.66 2.67 2.68 2.69 2.7
 2.75 2.76 2.77 2.78 2.8  2.81 2.84 2.85 2.86 2.88 2.9  2.91 2.93 2.94
 2.96 2.97 2.98 2.99 3.01 3.02 3.03 3.04 3.05 3.06 3.07 3.08 3.09 3.1
 3.11 3.12 3.13 3.14 3.15 3.16 3.17 3.18 3.19 3.2  3.21 3.22 3.23 3.24
 3.25 3.26 3.27 3.28 3.29 3.3  3.31 3.32 3.33 3.34 3.35 3.36 3.37 3.38
 3.39 3.4  3.41 3.42 3.43 3.44 3.45 3.46 3.47 3.48 3.49 3.5  3.51 3.52
 3.53 3.54 3.55 3.56 3.57 3.58 3.59 3.6  3.61 3.62 3.63 3.64 3.65 3.66
 3.67 3.68 3.69 3.7  3.71 3.72 3.73 3.74 3.75 3.76 3.77 3.78 3.79 3.8
 3.81 3.82 3.83 3.84 3.85 3.86 3.87 3.91 3.95 3.98 4.01 4.04 4.08 4.18
 4.31 4.34 4.37 4.38 4.96 4.98]

  warnings.warn(

2022-12-16 10:38:00,998:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.1  1.11 1.21 1.24 1.25 1.27 1.31 1.32 2.04 2.1  2.48 2.5  2.51 2.52
 2.56 2.61 2.68 2.79 2.83 2.91 2.97 2.99 3.01 3.02 3.03 3.05 3.06 3.07
 3.08 3.09 3.1  3.11 3.12 3.13 3.14 3.15 3.16 3.17 3.18 3.19 3.2  3.21
 3.22 3.23 3.24 3.25 3.26 3.27 3.28 3.29 3.3  3.31 3.32 3.33 3.34 3.35
 3.36 3.37 3.38 3.39 3.4  3.41 3.42 3.43 3.44 3.45 3.46 3.47 3.48 3.49
 3.5  3.51 3.52 3.53 3.54 3.55 3.56 3.57 3.58 3.59 3.61 3.63 3.65 3.69
 3.71 3.72 3.74 3.75 3.76 3.77 3.8  3.82 3.83 3.85 3.87 3.88 3.99 4.03
 4.1  4.26 4.3  4.32 4.33]

  warnings.warn(

2022-12-16 10:38:01,021:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.1  2.51 2.55 2.62 2.65 2.66 2.69 2.72 2.74 2.75 2.76 2.78 2.79 2.8
 2.81 2.82 2.84 2.85 2.86 2.88 2.89 2.91 2.92 2.93 2.94 2.95 2.96 2.97
 2.98 2.99 3.01 3.02 3.03 3.04 3.05 3.06 3.07 3.08 3.09 3.1  3.11 3.12
 3.13 3.14 3.15 3.16 3.17 3.18 3.19 3.2  3.21 3.22 3.23 3.24 3.25 3.26
 3.27 3.28 3.29 3.3  3.31 3.32 3.33 3.34 3.35 3.36 3.37 3.38 3.39 3.4
 3.41 3.42 3.43 3.44 3.45 3.46 3.47 3.48 3.49 3.5  3.52 3.54 3.56 3.57
 3.61 3.62 3.64 3.65 3.68 3.7  3.75 3.81 3.86 3.89 3.93 4.03 4.05 4.06
 4.2  4.21 4.24 4.27 4.28 4.34 4.39 4.9 ]

  warnings.warn(

2022-12-16 10:38:01,023:INFO:Calculating mean and std
2022-12-16 10:38:01,024:INFO:Creating metrics dataframe
2022-12-16 10:38:01,041:INFO:Uploading results into container
2022-12-16 10:38:01,042:INFO:Uploading model into container now
2022-12-16 10:38:01,043:INFO:master_model_container: 27
2022-12-16 10:38:01,043:INFO:display_container: 2
2022-12-16 10:38:01,044:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=5099)
2022-12-16 10:38:01,044:INFO:create_model() successfully completed......................................
2022-12-16 10:38:01,320:WARNING:create_model() for ExtraTreesRegressor(n_jobs=-1, random_state=5099) raised an exception or returned all 0.0, trying without fit_kwargs:
2022-12-16 10:38:01,321:WARNING:Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 795, in compare_models
    assert (
AssertionError

2022-12-16 10:38:01,322:INFO:Initializing create_model()
2022-12-16 10:38:01,323:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002281239F8E0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022810EC8B20>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:38:01,323:INFO:Checking exceptions
2022-12-16 10:38:01,330:INFO:Importing libraries
2022-12-16 10:38:01,331:INFO:Copying training dataset
2022-12-16 10:38:01,340:INFO:Defining folds
2022-12-16 10:38:01,340:INFO:Declaring metric variables
2022-12-16 10:38:01,342:INFO:Importing untrained model
2022-12-16 10:38:01,343:INFO:Extra Trees Regressor Imported successfully
2022-12-16 10:38:01,343:INFO:Starting cross validation
2022-12-16 10:38:01,346:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:38:07,951:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [0.28 0.32 0.36 1.2  1.91 2.03 2.07 2.39 2.42 2.51 2.52 2.65 2.71 2.73
 2.76 2.77 2.78 2.79 2.8  2.81 2.82 2.83 2.85 2.89 2.9  2.91 2.92 2.93
 2.94 2.95 2.96 2.97 2.98 2.99 3.01 3.02 3.03 3.04 3.05 3.06 3.07 3.08
 3.09 3.1  3.11 3.12 3.13 3.14 3.15 3.16 3.17 3.18 3.19 3.2  3.21 3.22
 3.23 3.24 3.25 3.26 3.27 3.28 3.29 3.3  3.31 3.32 3.33 3.34 3.35 3.36
 3.37 3.38 3.39 3.4  3.41 3.42 3.43 3.44 3.45 3.46 3.47 3.48 3.49 3.5
 3.51 3.52 3.53 3.54 3.55 3.56 3.58 3.59 3.61 3.62 3.64 3.66 3.69 3.74
 3.75 3.76 3.77 3.82 3.94 3.96 3.99 4.11 4.24 4.28]

  warnings.warn(

2022-12-16 10:38:07,963:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [0.31 1.09 1.16 1.97 1.99 2.35 2.38 2.39 2.4  2.42 2.43 2.44 2.45 2.47
 2.48 2.5  2.51 2.52 2.53 2.54 2.55 2.56 2.57 2.58 2.59 2.6  2.61 2.62
 2.63 2.64 2.65 2.66 2.67 2.68 2.69 2.7  2.71 2.72 2.73 2.74 2.75 2.76
 2.77 2.78 2.79 2.8  2.81 2.82 2.83 2.84 2.85 2.86 2.87 2.88 2.89 2.9
 2.92 2.93 2.94 2.95 2.96 2.98 2.99 3.01 3.02 3.03 3.04 3.05 3.06 3.07
 3.08 3.09 3.1  3.11 3.12 3.13 3.14 3.15 3.16 3.17 3.18 3.19 3.2  3.21
 3.22 3.23 3.24 3.25 3.26 3.27 3.28 3.29 3.3  3.31 3.32 3.33 3.34 3.35
 3.36 3.37 3.38 3.39 3.4  3.41 3.42 3.43 3.44 3.45 3.46 3.47 3.48 3.49
 3.51 3.52 3.53 3.62 3.73 3.85 3.88 3.91 4.01 4.05 4.1  4.28 4.29 4.97]

  warnings.warn(

2022-12-16 10:38:07,976:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.15 2.01 2.03 2.41 2.54 2.62 2.63 2.64 2.65 2.66 2.67 2.68 2.69 2.7
 2.75 2.76 2.77 2.78 2.8  2.81 2.84 2.85 2.86 2.88 2.9  2.91 2.93 2.94
 2.96 2.97 2.98 2.99 3.01 3.02 3.03 3.04 3.05 3.06 3.07 3.08 3.09 3.1
 3.11 3.12 3.13 3.14 3.15 3.16 3.17 3.18 3.19 3.2  3.21 3.22 3.23 3.24
 3.25 3.26 3.27 3.28 3.29 3.3  3.31 3.32 3.33 3.34 3.35 3.36 3.37 3.38
 3.39 3.4  3.41 3.42 3.43 3.44 3.45 3.46 3.47 3.48 3.49 3.5  3.51 3.52
 3.53 3.54 3.55 3.56 3.57 3.58 3.59 3.6  3.61 3.62 3.63 3.64 3.65 3.66
 3.67 3.68 3.69 3.7  3.71 3.72 3.73 3.74 3.75 3.76 3.77 3.78 3.79 3.8
 3.81 3.82 3.83 3.84 3.85 3.86 3.87 3.91 3.95 3.98 4.01 4.04 4.08 4.18
 4.31 4.34 4.37 4.38 4.96 4.98]

  warnings.warn(

2022-12-16 10:38:08,049:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.18 2.05 2.08 2.62 2.71 2.72 2.76 2.78 2.8  2.81 2.85 2.88 2.89 2.9
 2.93 2.94 2.95 2.97 2.98 2.99 3.01 3.02 3.03 3.04 3.05 3.06 3.07 3.08
 3.09 3.1  3.11 3.12 3.13 3.14 3.15 3.16 3.17 3.18 3.19 3.2  3.21 3.22
 3.23 3.24 3.25 3.26 3.27 3.28 3.29 3.3  3.31 3.32 3.33 3.34 3.35 3.36
 3.37 3.38 3.39 3.4  3.41 3.42 3.43 3.44 3.45 3.46 3.47 3.48 3.49 3.5
 3.51 3.52 3.53 3.55 3.6  3.61 3.63 3.64 3.9  3.96 3.97 3.99 4.08 4.09
 4.15 4.3  4.31 4.32 4.33 4.34 4.35 4.61]

  warnings.warn(

2022-12-16 10:38:08,392:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [0.27 0.29 0.35 1.04 1.09 1.39 1.47 2.08 2.09 2.72 2.76 2.78 2.8  2.81
 2.82 2.83 2.84 2.85 2.86 2.88 2.89 2.9  2.92 2.94 2.95 2.97 2.98 3.01
 3.02 3.03 3.04 3.05 3.06 3.07 3.08 3.09 3.1  3.11 3.12 3.13 3.14 3.15
 3.16 3.17 3.18 3.19 3.2  3.21 3.22 3.23 3.24 3.25 3.26 3.27 3.28 3.29
 3.3  3.31 3.32 3.33 3.34 3.35 3.36 3.37 3.38 3.39 3.4  3.41 3.42 3.43
 3.44 3.45 3.46 3.47 3.48 3.49 3.5  3.51 3.52 3.53 3.54 3.55 3.56 3.57
 3.58 3.59 3.6  3.61 3.62 3.63 3.64 3.65 3.66 3.67 3.69 3.7  3.74 3.75
 3.76 3.78 3.79 3.8  3.81 3.82 3.83 3.87 3.95 3.97 3.98 4.35 4.36 4.38
 4.39]

  warnings.warn(

2022-12-16 10:38:08,414:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [0.13 0.82 0.85 0.88 2.52 2.55 2.57 2.62 2.69 2.75 2.8  2.86 2.89 2.9
 2.92 2.93 2.94 2.95 2.96 2.97 2.98 2.99 3.01 3.02 3.03 3.04 3.05 3.06
 3.07 3.08 3.09 3.1  3.11 3.12 3.13 3.14 3.15 3.16 3.17 3.18 3.19 3.2
 3.21 3.22 3.23 3.24 3.25 3.26 3.27 3.28 3.29 3.3  3.31 3.32 3.33 3.34
 3.35 3.36 3.37 3.38 3.39 3.4  3.41 3.42 3.43 3.44 3.45 3.46 3.48 3.49
 3.51 3.52 3.53 3.54 3.56 3.58 3.62 3.64 3.68 3.77 3.78 3.79 3.83 3.93
 4.16 4.17 4.23 4.25 4.27 4.3  4.31 4.32 4.48]

  warnings.warn(

2022-12-16 10:38:08,457:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [0.42 1.14 1.18 2.02 2.04 2.05 2.47 2.49 2.56 2.58 2.62 2.64 2.67 2.68
 2.69 2.71 2.72 2.73 2.74 2.76 2.77 2.78 2.79 2.8  2.81 2.82 2.84 2.85
 2.87 2.88 2.89 2.9  2.91 2.92 2.93 2.94 2.96 2.97 2.98 2.99 3.01 3.02
 3.03 3.04 3.05 3.06 3.07 3.08 3.09 3.1  3.11 3.12 3.13 3.14 3.15 3.16
 3.17 3.18 3.19 3.2  3.21 3.22 3.23 3.24 3.25 3.26 3.27 3.28 3.29 3.3
 3.31 3.32 3.33 3.34 3.35 3.36 3.37 3.38 3.39 3.4  3.41 3.42 3.43 3.44
 3.45 3.46 3.47 3.48 3.49 3.5  3.51 3.52 3.54 3.55 3.56 3.57 3.58 3.6
 3.61 3.63 3.64 3.66 3.67 3.68 3.89 3.99 4.04 4.21 4.27 4.33 4.34 4.35
 4.36 4.37 4.96]

  warnings.warn(

2022-12-16 10:38:08,481:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [0.4  1.09 1.1  1.12 1.18 1.99 2.01 2.31 2.32 2.4  2.47 2.52 2.53 2.55
 2.56 2.57 2.58 2.59 2.6  2.61 2.62 2.63 2.65 2.67 2.68 2.69 2.7  2.71
 2.72 2.73 2.74 2.75 2.76 2.77 2.8  2.81 2.82 2.83 2.87 2.89 2.9  2.92
 2.93 2.94 2.95 2.97 2.98 2.99 3.01 3.02 3.03 3.04 3.05 3.06 3.07 3.08
 3.09 3.1  3.11 3.12 3.13 3.14 3.15 3.16 3.17 3.18 3.19 3.2  3.21 3.22
 3.23 3.24 3.25 3.26 3.27 3.28 3.29 3.3  3.31 3.32 3.33 3.34 3.35 3.36
 3.37 3.38 3.39 3.4  3.41 3.42 3.43 3.44 3.45 3.46 3.47 3.48 3.49 3.5
 3.51 3.52 3.54 3.55 3.57 3.58 3.59 3.6  3.61 3.62 3.63 3.64 3.65 3.67
 3.68 3.69 3.7  3.71 3.72 3.73 3.74 3.75 3.76 3.78 3.79 3.8  3.81 3.82
 3.83 3.84 3.85 3.86 3.87 3.88 3.89 3.91 3.92 3.93 3.94 3.95 3.96 3.97
 3.98 3.99 4.01 4.02 4.03 4.11 4.15 4.2  4.35 4.42 4.43 4.45 4.46 4.56]

  warnings.warn(

2022-12-16 10:38:10,716:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.1  2.51 2.55 2.62 2.65 2.66 2.69 2.72 2.74 2.75 2.76 2.78 2.79 2.8
 2.81 2.82 2.84 2.85 2.86 2.88 2.89 2.91 2.92 2.93 2.94 2.95 2.96 2.97
 2.98 2.99 3.01 3.02 3.03 3.04 3.05 3.06 3.07 3.08 3.09 3.1  3.11 3.12
 3.13 3.14 3.15 3.16 3.17 3.18 3.19 3.2  3.21 3.22 3.23 3.24 3.25 3.26
 3.27 3.28 3.29 3.3  3.31 3.32 3.33 3.34 3.35 3.36 3.37 3.38 3.39 3.4
 3.41 3.42 3.43 3.44 3.45 3.46 3.47 3.48 3.49 3.5  3.52 3.54 3.56 3.57
 3.61 3.62 3.64 3.65 3.68 3.7  3.75 3.81 3.86 3.89 3.93 4.03 4.05 4.06
 4.2  4.21 4.24 4.27 4.28 4.34 4.39 4.9 ]

  warnings.warn(

2022-12-16 10:38:10,781:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.1  1.11 1.21 1.24 1.25 1.27 1.31 1.32 2.04 2.1  2.48 2.5  2.51 2.52
 2.56 2.61 2.68 2.79 2.83 2.91 2.97 2.99 3.01 3.02 3.03 3.05 3.06 3.07
 3.08 3.09 3.1  3.11 3.12 3.13 3.14 3.15 3.16 3.17 3.18 3.19 3.2  3.21
 3.22 3.23 3.24 3.25 3.26 3.27 3.28 3.29 3.3  3.31 3.32 3.33 3.34 3.35
 3.36 3.37 3.38 3.39 3.4  3.41 3.42 3.43 3.44 3.45 3.46 3.47 3.48 3.49
 3.5  3.51 3.52 3.53 3.54 3.55 3.56 3.57 3.58 3.59 3.61 3.63 3.65 3.69
 3.71 3.72 3.74 3.75 3.76 3.77 3.8  3.82 3.83 3.85 3.87 3.88 3.99 4.03
 4.1  4.26 4.3  4.32 4.33]

  warnings.warn(

2022-12-16 10:38:10,782:INFO:Calculating mean and std
2022-12-16 10:38:10,782:INFO:Creating metrics dataframe
2022-12-16 10:38:10,787:INFO:Uploading results into container
2022-12-16 10:38:10,788:INFO:Uploading model into container now
2022-12-16 10:38:10,789:INFO:master_model_container: 28
2022-12-16 10:38:10,789:INFO:display_container: 2
2022-12-16 10:38:10,789:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=5099)
2022-12-16 10:38:10,790:INFO:create_model() successfully completed......................................
2022-12-16 10:38:10,941:ERROR:create_model() for ExtraTreesRegressor(n_jobs=-1, random_state=5099) raised an exception or returned all 0.0:
2022-12-16 10:38:10,942:ERROR:Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 795, in compare_models
    assert (
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 811, in compare_models
    assert (
AssertionError

2022-12-16 10:38:10,942:INFO:Initializing AdaBoost Regressor
2022-12-16 10:38:10,942:INFO:Total runtime is 2.228061576684316 minutes
2022-12-16 10:38:10,943:INFO:SubProcess create_model() called ==================================
2022-12-16 10:38:10,943:INFO:Initializing create_model()
2022-12-16 10:38:10,943:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002281239F8E0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022810EC8B20>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:38:10,943:INFO:Checking exceptions
2022-12-16 10:38:10,947:INFO:Importing libraries
2022-12-16 10:38:10,948:INFO:Copying training dataset
2022-12-16 10:38:10,953:INFO:Defining folds
2022-12-16 10:38:10,954:INFO:Declaring metric variables
2022-12-16 10:38:10,954:INFO:Importing untrained model
2022-12-16 10:38:10,954:INFO:AdaBoost Regressor Imported successfully
2022-12-16 10:38:10,954:INFO:Starting cross validation
2022-12-16 10:38:10,956:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:38:15,250:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.39673913 2.46366145 2.47826087 2.59653465 2.68715084 2.89630996
 2.91233514 3.06976744 3.07092199 3.42341729 3.43169399 3.47371715
 3.4950495  3.51859956 3.52552817 3.52592593 3.5297619  3.54895666
 3.55858311 3.59708738 3.62430939 3.62648557 3.63020833 3.64848485
 3.68553459 3.72591207 3.74293785 3.82317073 3.83942065 3.84005563
 3.85850254 3.90104167 3.92272309 3.98133567]

  warnings.warn(

2022-12-16 10:38:15,278:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.47222222 2.47901235 2.48837209 2.51858736 2.52398524 2.54621849
 2.56455863 2.5770235  2.64779874 2.66868381 2.94016455 2.96092184
 3.02873563 3.05286738 3.08305369 3.08849558 3.2265625  3.29896907
 3.32432432 3.33480663 3.36049107 3.46496815 3.54887218 3.56028369
 3.57594168 3.59743954 3.64871582 3.66070223 3.66536965 3.67103784
 3.69444444 3.70126582 3.72022161 3.72137405 3.76535433 3.7691373
 3.81060353 3.84451855 3.87058824 3.91023843 3.92929293 4.1671159 ]

  warnings.warn(

2022-12-16 10:38:15,287:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.10737034 2.50327869 2.53805774 2.87868852 3.06808511 3.07352941
 3.14116095 3.21751969 3.22852512 3.24509804 3.31292517 3.46801347
 3.50983146 3.52445194 3.54379818 3.6        3.60520362 3.63904035
 3.65546218 3.67680921 3.69658936 3.73082822 3.74379345 3.77758164
 3.77936963 3.80186047 3.81268012 3.8185654  3.84942085 3.87272727
 3.9141791  3.91463974 3.93605769 3.97589597 4.00210084 4.0498323
 4.06612807]

  warnings.warn(

2022-12-16 10:38:15,336:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.51515152 2.0521542  2.19672131 2.21455494 2.26215022 2.37402597
 2.38980263 2.39791356 2.42377261 2.44245524 2.49728752 2.50246305
 2.57263158 2.57564576 2.58888889 2.59798995 2.61607143 2.62745098
 2.63602941 2.6772784  2.82471264 3.06511628 3.06532663 3.373599
 3.38235294 3.49479769 3.4976247  3.50236967 3.54651163 3.5509165
 3.57773512 3.66666667 3.69584439 3.70715631 3.71428571 3.71513353
 3.72296693 3.75958188 3.7704918  3.79522863 3.82402002 3.83141762
 3.84615385 3.88476999]

  warnings.warn(

2022-12-16 10:38:15,408:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.85488127 2.16326531 2.20742638 2.30769231 2.3470437  2.38669951
 2.42574257 2.42699725 2.44282744 2.48927614 2.48955068 2.58791209
 2.59821429 2.59925788 2.79920565 2.81150794 2.94232331 3.08974359
 3.09447674 3.20694864 3.25037037 3.3343527  3.46871686 3.46949153
 3.48072289 3.51162791 3.51844808 3.54683196 3.56487026 3.60504202
 3.63186813 3.66593407 3.67113276 3.6866015  3.72553431 3.78805395
 3.82147165]

  warnings.warn(

2022-12-16 10:38:15,420:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.45067927 2.50809061 2.57490865 2.59863946 2.79234973 3.13900415
 3.23513694 3.61245675 3.65       3.70068471 3.70761421 3.71031746
 3.74405436 3.75562701 3.7797619  3.78636959 3.7901524  3.79096045
 3.79106628 3.79310345 3.80023502 3.81568228 3.81877023 3.8245614
 3.82978723 3.83293556 3.85533333 3.89139719 3.90064995 3.9255751
 3.93277311 3.9371547  3.97783934 3.9787234  3.98473282 4.14442013]

  warnings.warn(

2022-12-16 10:38:15,476:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.27227723 2.30177515 2.32949513 2.38369781 2.39501438 2.40096852
 2.41182573 2.45877193 2.47520661 2.51137255 2.51580699 2.55822416
 2.59944751 2.65763889 2.77319588 2.80219111 2.90836653 3.0661157
 3.18918919 3.20168067 3.2032967  3.21940928 3.26691729 3.28247914
 3.36372361 3.39691358 3.43452381 3.43769968 3.49184783 3.53965517
 3.57864078 3.58128655 3.6        3.61891516 3.62706271 3.63531114
 3.64004376 3.65181932 3.66389351 3.66936791 3.67521368 3.68149718
 3.68854569 3.69743988 3.70760234 3.71351675 3.7260479  3.75099128
 3.75622776 3.77297297 3.79296563 3.79909194 3.80454928 3.85445205
 3.90301318 3.93678161 3.96368876 3.97427386 3.97816719]

  warnings.warn(

2022-12-16 10:38:15,501:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.35714286 2.44760213 2.49282297 2.59424084 2.64130435 2.77412281
 2.87453875 2.9850214  3.08567604 3.14382896 3.19518616 3.33911672
 3.39175258 3.54580153 3.56033058 3.58743842 3.59470468 3.59482759
 3.62953995 3.63257576 3.64206642 3.68283582 3.70599613 3.71428571
 3.72292546 3.73350254 3.75679172 3.76046176 3.80178838 3.8371869
 3.87931034]

  warnings.warn(

2022-12-16 10:38:17,551:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.55741775 1.73005837 1.98984772 2.41935484 2.42256214 2.43448276
 2.5212766  2.72629455 2.75294118 2.80098684 2.81891892 3.03527337
 3.12275449 3.22843823 3.28971256 3.33429395 3.34086629 3.40842491
 3.54403567 3.57029178 3.59030837 3.59269933 3.6134715  3.61953204
 3.62125341 3.64920635 3.65560821 3.66273187 3.6772009  3.69334975
 3.70785071 3.72086331 3.73525557 3.73938679 3.73991935 3.7400319
 3.74201898 3.74968394 3.75704093 3.75876289 3.76466049 3.77374784
 3.79616963 3.85391991]

  warnings.warn(

2022-12-16 10:38:17,562:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.53066038 2.53789731 2.67164179 2.68486352 2.73280943 2.83415536
 2.85286783 2.88827434 3.11949686 3.16118421 3.27469136 3.27741935
 3.3106383  3.41206675 3.52547009 3.53216374 3.54674221 3.55124654
 3.56291391 3.61538462 3.63904494 3.6412037  3.64354067 3.66425993
 3.66510903 3.66981132 3.67647059 3.71862182 3.71863958 3.72438672
 3.73882353 3.76615105 3.79848321 3.81788441 3.83425414 3.87431694
 3.91144359 4.04791929]

  warnings.warn(

2022-12-16 10:38:17,564:INFO:Calculating mean and std
2022-12-16 10:38:17,565:INFO:Creating metrics dataframe
2022-12-16 10:38:17,573:INFO:Uploading results into container
2022-12-16 10:38:17,574:INFO:Uploading model into container now
2022-12-16 10:38:17,574:INFO:master_model_container: 29
2022-12-16 10:38:17,574:INFO:display_container: 2
2022-12-16 10:38:17,575:INFO:AdaBoostRegressor(random_state=5099)
2022-12-16 10:38:17,575:INFO:create_model() successfully completed......................................
2022-12-16 10:38:17,741:WARNING:create_model() for AdaBoostRegressor(random_state=5099) raised an exception or returned all 0.0, trying without fit_kwargs:
2022-12-16 10:38:17,741:WARNING:Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 795, in compare_models
    assert (
AssertionError

2022-12-16 10:38:17,742:INFO:Initializing create_model()
2022-12-16 10:38:17,742:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002281239F8E0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022810EC8B20>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:38:17,742:INFO:Checking exceptions
2022-12-16 10:38:17,745:INFO:Importing libraries
2022-12-16 10:38:17,745:INFO:Copying training dataset
2022-12-16 10:38:17,750:INFO:Defining folds
2022-12-16 10:38:17,750:INFO:Declaring metric variables
2022-12-16 10:38:17,751:INFO:Importing untrained model
2022-12-16 10:38:17,751:INFO:AdaBoost Regressor Imported successfully
2022-12-16 10:38:17,751:INFO:Starting cross validation
2022-12-16 10:38:17,753:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:38:22,774:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.51515152 2.0521542  2.19672131 2.21455494 2.26215022 2.37402597
 2.38980263 2.39791356 2.42377261 2.44245524 2.49728752 2.50246305
 2.57263158 2.57564576 2.58888889 2.59798995 2.61607143 2.62745098
 2.63602941 2.6772784  2.82471264 3.06511628 3.06532663 3.373599
 3.38235294 3.49479769 3.4976247  3.50236967 3.54651163 3.5509165
 3.57773512 3.66666667 3.69584439 3.70715631 3.71428571 3.71513353
 3.72296693 3.75958188 3.7704918  3.79522863 3.82402002 3.83141762
 3.84615385 3.88476999]

  warnings.warn(

2022-12-16 10:38:22,835:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.27227723 2.30177515 2.32949513 2.38369781 2.39501438 2.40096852
 2.41182573 2.45877193 2.47520661 2.51137255 2.51580699 2.55822416
 2.59944751 2.65763889 2.77319588 2.80219111 2.90836653 3.0661157
 3.18918919 3.20168067 3.2032967  3.21940928 3.26691729 3.28247914
 3.36372361 3.39691358 3.43452381 3.43769968 3.49184783 3.53965517
 3.57864078 3.58128655 3.6        3.61891516 3.62706271 3.63531114
 3.64004376 3.65181932 3.66389351 3.66936791 3.67521368 3.68149718
 3.68854569 3.69743988 3.70760234 3.71351675 3.7260479  3.75099128
 3.75622776 3.77297297 3.79296563 3.79909194 3.80454928 3.85445205
 3.90301318 3.93678161 3.96368876 3.97427386 3.97816719]

  warnings.warn(

2022-12-16 10:38:22,839:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.35714286 2.44760213 2.49282297 2.59424084 2.64130435 2.77412281
 2.87453875 2.9850214  3.08567604 3.14382896 3.19518616 3.33911672
 3.39175258 3.54580153 3.56033058 3.58743842 3.59470468 3.59482759
 3.62953995 3.63257576 3.64206642 3.68283582 3.70599613 3.71428571
 3.72292546 3.73350254 3.75679172 3.76046176 3.80178838 3.8371869
 3.87931034]

  warnings.warn(

2022-12-16 10:38:22,861:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.85488127 2.16326531 2.20742638 2.30769231 2.3470437  2.38669951
 2.42574257 2.42699725 2.44282744 2.48927614 2.48955068 2.58791209
 2.59821429 2.59925788 2.79920565 2.81150794 2.94232331 3.08974359
 3.09447674 3.20694864 3.25037037 3.3343527  3.46871686 3.46949153
 3.48072289 3.51162791 3.51844808 3.54683196 3.56487026 3.60504202
 3.63186813 3.66593407 3.67113276 3.6866015  3.72553431 3.78805395
 3.82147165]

  warnings.warn(

2022-12-16 10:38:23,707:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.45067927 2.50809061 2.57490865 2.59863946 2.79234973 3.13900415
 3.23513694 3.61245675 3.65       3.70068471 3.70761421 3.71031746
 3.74405436 3.75562701 3.7797619  3.78636959 3.7901524  3.79096045
 3.79106628 3.79310345 3.80023502 3.81568228 3.81877023 3.8245614
 3.82978723 3.83293556 3.85533333 3.89139719 3.90064995 3.9255751
 3.93277311 3.9371547  3.97783934 3.9787234  3.98473282 4.14442013]

  warnings.warn(

2022-12-16 10:38:23,767:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.39673913 2.46366145 2.47826087 2.59653465 2.68715084 2.89630996
 2.91233514 3.06976744 3.07092199 3.42341729 3.43169399 3.47371715
 3.4950495  3.51859956 3.52552817 3.52592593 3.5297619  3.54895666
 3.55858311 3.59708738 3.62430939 3.62648557 3.63020833 3.64848485
 3.68553459 3.72591207 3.74293785 3.82317073 3.83942065 3.84005563
 3.85850254 3.90104167 3.92272309 3.98133567]

  warnings.warn(

2022-12-16 10:38:23,782:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.10737034 2.50327869 2.53805774 2.87868852 3.06808511 3.07352941
 3.14116095 3.21751969 3.22852512 3.24509804 3.31292517 3.46801347
 3.50983146 3.52445194 3.54379818 3.6        3.60520362 3.63904035
 3.65546218 3.67680921 3.69658936 3.73082822 3.74379345 3.77758164
 3.77936963 3.80186047 3.81268012 3.8185654  3.84942085 3.87272727
 3.9141791  3.91463974 3.93605769 3.97589597 4.00210084 4.0498323
 4.06612807]

  warnings.warn(

2022-12-16 10:38:23,838:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.47222222 2.47901235 2.48837209 2.51858736 2.52398524 2.54621849
 2.56455863 2.5770235  2.64779874 2.66868381 2.94016455 2.96092184
 3.02873563 3.05286738 3.08305369 3.08849558 3.2265625  3.29896907
 3.32432432 3.33480663 3.36049107 3.46496815 3.54887218 3.56028369
 3.57594168 3.59743954 3.64871582 3.66070223 3.66536965 3.67103784
 3.69444444 3.70126582 3.72022161 3.72137405 3.76535433 3.7691373
 3.81060353 3.84451855 3.87058824 3.91023843 3.92929293 4.1671159 ]

  warnings.warn(

2022-12-16 10:38:27,521:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.55741775 1.73005837 1.98984772 2.41935484 2.42256214 2.43448276
 2.5212766  2.72629455 2.75294118 2.80098684 2.81891892 3.03527337
 3.12275449 3.22843823 3.28971256 3.33429395 3.34086629 3.40842491
 3.54403567 3.57029178 3.59030837 3.59269933 3.6134715  3.61953204
 3.62125341 3.64920635 3.65560821 3.66273187 3.6772009  3.69334975
 3.70785071 3.72086331 3.73525557 3.73938679 3.73991935 3.7400319
 3.74201898 3.74968394 3.75704093 3.75876289 3.76466049 3.77374784
 3.79616963 3.85391991]

  warnings.warn(

2022-12-16 10:38:27,536:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.53066038 2.53789731 2.67164179 2.68486352 2.73280943 2.83415536
 2.85286783 2.88827434 3.11949686 3.16118421 3.27469136 3.27741935
 3.3106383  3.41206675 3.52547009 3.53216374 3.54674221 3.55124654
 3.56291391 3.61538462 3.63904494 3.6412037  3.64354067 3.66425993
 3.66510903 3.66981132 3.67647059 3.71862182 3.71863958 3.72438672
 3.73882353 3.76615105 3.79848321 3.81788441 3.83425414 3.87431694
 3.91144359 4.04791929]

  warnings.warn(

2022-12-16 10:38:27,538:INFO:Calculating mean and std
2022-12-16 10:38:27,541:INFO:Creating metrics dataframe
2022-12-16 10:38:27,554:INFO:Uploading results into container
2022-12-16 10:38:27,556:INFO:Uploading model into container now
2022-12-16 10:38:27,557:INFO:master_model_container: 30
2022-12-16 10:38:27,557:INFO:display_container: 2
2022-12-16 10:38:27,558:INFO:AdaBoostRegressor(random_state=5099)
2022-12-16 10:38:27,558:INFO:create_model() successfully completed......................................
2022-12-16 10:38:27,929:ERROR:create_model() for AdaBoostRegressor(random_state=5099) raised an exception or returned all 0.0:
2022-12-16 10:38:27,931:ERROR:Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 795, in compare_models
    assert (
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 811, in compare_models
    assert (
AssertionError

2022-12-16 10:38:27,932:INFO:Initializing Gradient Boosting Regressor
2022-12-16 10:38:27,932:INFO:Total runtime is 2.5112380425135297 minutes
2022-12-16 10:38:27,932:INFO:SubProcess create_model() called ==================================
2022-12-16 10:38:27,933:INFO:Initializing create_model()
2022-12-16 10:38:27,933:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002281239F8E0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022810EC8B20>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:38:27,933:INFO:Checking exceptions
2022-12-16 10:38:27,945:INFO:Importing libraries
2022-12-16 10:38:27,945:INFO:Copying training dataset
2022-12-16 10:38:27,964:INFO:Defining folds
2022-12-16 10:38:27,964:INFO:Declaring metric variables
2022-12-16 10:38:27,965:INFO:Importing untrained model
2022-12-16 10:38:27,967:INFO:Gradient Boosting Regressor Imported successfully
2022-12-16 10:38:27,968:INFO:Starting cross validation
2022-12-16 10:38:27,976:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:38:33,065:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.54095531 1.67679084 1.96803975 2.20859361 2.54006899 2.57496729
 2.68110383 2.71383689 2.74065411 2.76538038 2.8452168  2.86812822
 2.87280132 2.88266028 2.89541592 2.89938066 2.90004105 2.90247576
 2.90338251 2.91829862 2.92175477 2.9247636  2.93369393 2.94134684
 2.94570108 2.95680573 2.95788688 2.96681721 2.9685746  2.96890802
 2.97126305 2.97287277 2.97814869 2.97843222 2.98046065 2.98401869
 2.99463495 2.99675726 3.00352118 3.00369045 3.00497645 3.0056876
 3.00571889 3.00582536 3.00630653 3.00703191 3.00748593 3.00849178
 3.00906035 3.00968363 3.00980481 3.0102712  3.01027127 3.01057609
 3.01068257 3.01118613 3.01183324 3.01260453 3.012711   3.01302509
 3.01319217 3.01343191 3.01361266 3.0136928  3.01423594 3.01454084
 3.01523686 3.01546034 3.01556682 3.01572124 3.01594599 3.01656927
 3.01715684 3.01841559 3.0188018  3.0192016  3.01942508 3.01953156
 3.01991073 3.02001265 3.02082913 3.0221225  3.02276654 3.02302684
 3.02449963 3.02546396 3.02608724 3.0263683  3.02699158 3.0274675
 3.02788405 3.02991248 3.03033304 3.03073986 3.03276829 3.03610975
 3.03673304 3.03777929 3.04007449 3.04750268 3.04943899 3.05146742
 3.05212781 3.05438832 3.05464994 3.05835306 3.07120486 3.07843431
 3.10646279 3.10777581 3.10980425 3.11376899 3.11668989 3.1195457
 3.18225969 3.40238174 3.607802   3.9817297  4.0968256 ]

  warnings.warn(

2022-12-16 10:38:33,327:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.47746411 2.48269211 2.5877416  2.68079967 2.721635   2.72271408
 2.72354185 2.82443255 2.85556136 2.93915209 3.0023762  3.00816962
 3.0092487  3.00967377 3.01050154 3.01075286 3.01158062 3.01394132
 3.01500419 3.01608328 3.01650835 3.01691104 3.01733611 3.01758743
 3.0184152  3.01917824 3.02025733 3.02199647 3.0223973  3.02307555
 3.02347638 3.02629461 3.03311785 3.03633691 3.03835603 3.03943511
 3.05496505 3.05579281 3.05604413 3.0568719  3.06322444 3.07760007
 3.08713513 3.10626367 3.11186064 3.11508026 3.11658442 3.11746834
 3.13503692 3.16636876 3.18249018 3.21775703 3.24609141 3.24883707
 3.27890539 3.28082209 3.28164986 3.28190118 3.28272894 3.30407777
 3.30531928 3.31296883 3.32868973 3.33435385 3.3373043  3.33838339
 3.36363017 3.39165432 3.39315848 3.41961657 3.44294283 3.50049618
 3.57149628 3.6063772 ]

  warnings.warn(

2022-12-16 10:38:33,394:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.41521971 2.4507587  2.45965828 2.51933674 2.52937421 2.53175888
 2.53735158 2.54626715 2.56627338 2.6081266  2.72206312 2.73094392
 2.73278925 2.75828502 2.78594761 2.80424445 2.8329616  2.83353658
 2.84265368 2.85260561 2.85266375 2.85503561 2.86213505 2.86451971
 2.87743152 2.88654064 2.89099699 2.90329385 2.90887785 2.92716541
 2.92931225 2.93606851 2.93884628 2.94741411 2.95745158 2.95983624
 2.96006306 2.96244773 2.96542895 2.97434452 2.9751032  2.97672918
 2.98232188 2.98243984 2.98840538 2.98890498 2.98932122 2.99536588
 2.99775054 3.00334324 3.00540335 3.00778801 3.01210969 3.01338071
 3.02211976 3.02216589 3.02229628 3.02450442 3.02468095 3.02714983
 3.03009545 3.03027365 3.03154947 3.0371599  3.04495485 3.04912423
 3.05609541 3.05743038 3.0591343  3.06407277 3.07417444 3.07653902
 3.07734956 3.16092312 3.16717472 3.1675508  3.16993546 3.17515272
 3.1847111  3.19384069 3.19400292 3.21824286 3.28281732 3.30948329
 3.46089353 3.47090359]

  warnings.warn(

2022-12-16 10:38:33,431:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.18919747 2.5489642  2.61138849 2.6516383  2.72321426 2.73714218
 2.82038433 2.82551914 2.86046973 2.89359118 2.91291398 2.92296858
 2.93015722 2.94127671 2.94143517 2.94229622 2.94366439 2.94419429
 2.94743647 2.94801329 2.95128215 2.95161336 2.95179169 2.95543237
 2.95697936 2.95846893 2.96661772 2.96864433 2.97034843 2.97093616
 2.97446916 2.97475517 2.97563296 2.97776751 2.98080407 2.98275581
 2.98326536 2.99663854 2.99709031 2.99925109 3.00041488 3.00045755
 3.00104383 3.00220763 3.00488952 3.00551149 3.00605331 3.01068219
 3.0111728  3.01452787 3.01455146 3.01534515 3.01571526 3.01650895
 3.01669669 3.01811903 3.01839714 3.01956094 3.02054237 3.02113783
 3.02170617 3.02338042 3.02498351 3.02719942 3.0280355  3.03018073
 3.03021176 3.03099801 3.03153184 3.03216181 3.03405    3.0352138
 3.03675399 3.03784511 3.04063637 3.04184131 3.04235085 3.04368836
 3.04953456 3.09607064 3.13360578 3.15203362 3.17488463 3.17604843
 3.18350728 3.18452299 3.18534027 3.18882055 3.19268982 3.19385362
 3.20832462 3.2121364  3.2133002  3.24259277 3.58526866 3.70974196
 3.93787505 4.34212936]

  warnings.warn(

2022-12-16 10:38:33,561:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.68323506 2.69906719 2.70851332 2.71631981 2.72089945 2.72127761
 2.74539323 2.74788707 2.7515183  2.7735435  2.78176653 2.79987939
 2.80173647 2.80709284 2.81007704 2.8562546  2.8613037  2.86406108
 2.86588335 2.87051242 2.87368983 2.87877548 2.88413185 2.88532974
 2.88658197 2.88831522 2.89116161 2.89771587 2.8977902  2.8989681
 2.91191909 2.9140657  2.91890575 2.92075793 2.92270435 2.92426211
 2.92537572 2.92671223 2.92856441 2.93035896 2.93247715 2.93303033
 2.93471984 2.93488251 2.93900618 2.94052226 2.94237444 2.94448354
 2.94451299 2.94456217 2.94486328 2.94611745 2.94641435 2.94909614
 2.95010818 2.95018093 2.95464684 2.95649903 2.95775542 2.95868675
 2.96048976 2.96053894 2.97014155 2.97669581 2.97865906 2.9799405
 2.98451932 2.99139371 2.99155462 2.99340681 2.99363374 2.99495573
 2.99680791 2.99936111 3.00031209 3.00121329 3.00216427 3.00276222
 3.0046144  3.00567921 3.00640894 3.00753139 3.00826112 3.00849278
 3.00908031 3.01034496 3.01093249 3.01199146 3.01279509 3.01502332
 3.01539257 3.01657225 3.01681291 3.01842443 3.01906323 3.02056298
 3.02061216 3.02068578 3.02111521 3.02174501 3.0223857  3.02241516
 3.02246434 3.022696   3.02378079 3.02437873 3.02454818 3.02509738
 3.02514612 3.02623091 3.0269983  3.02715387 3.02951715 3.03022165
 3.03069683 3.03254901 3.0339111  3.03468756 3.03473674 3.03658892
 3.03748351 3.04556513 3.04741731 3.04858289 3.05047362 3.05449158
 3.0569417  3.06021297 3.06920881 3.07053113 3.08395736 3.09718268
 3.10365077 3.12021328 3.12519597 3.13843536 3.13914206 3.13947895
 3.1444281  3.14576567 3.14678584 3.14728544 3.15223459 3.15487521
 3.15665196 3.16300359 3.16939144 3.17260639 3.17417958 3.17808536
 3.18148647 3.1864398  3.18929295 3.19322852 3.2005354  3.20695895
 3.20730702 3.23523603 3.23573563 3.23622361 3.23922676 3.24304252
 3.24703325 3.25223188 3.26361735 3.26879439 3.29201726 3.85022443]

  warnings.warn(

2022-12-16 10:38:33,939:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.48005815 2.58604362 2.61072658 2.64140639 2.66294244 2.66625089
 2.71872894 2.72225141 2.7232696  2.72899369 2.74442353 2.74936996
 2.76121554 2.7640704  2.78928034 2.80015871 2.80840486 2.82973071
 2.85153398 2.86372278 2.87691417 2.87919905 2.88061687 2.88346093
 2.88424565 2.88848041 2.89251772 2.89335961 2.89629464 2.89929931
 2.89936851 2.90380463 2.90424574 2.90527242 2.90664869 2.90875106
 2.91204205 2.9158075  2.91624861 2.91654737 2.92075393 2.92855024
 2.92939221 2.93093986 2.95246174 2.97507765 2.98776764 2.99085514
 2.99227296 2.99511702 2.99612055 3.00051038 3.0037722  3.0050157
 3.00785976 3.00827752 3.00871863 3.00886329 3.01112158 3.01322395
 3.01577508 3.01606801 3.01651494 3.019359   3.02028039 3.0207215
 3.02102026 3.02216661 3.02312445 3.02386432 3.02522682 3.02807088
 3.03115314 3.03302313 3.04396989 3.04631272 3.05487828 3.05607842
 3.05752912 3.06023513 3.06247555 3.06708942 3.068116   3.069532
 3.07027186 3.0716241  3.07446816 3.07668156 3.08107631 3.08227473
 3.09252145 3.096891   3.1027862  3.10433577 3.10717983 3.12054264
 3.12154727 3.12351216 3.14175671 3.1532543  3.16398311 3.28104871
 3.28369323 3.28690591 3.29613093 3.29705327 3.30217139 3.30448813
 3.31580262 3.32654921]

  warnings.warn(

2022-12-16 10:38:34,199:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.32952128 2.44089766 2.56044961 2.65504902 2.65813017 2.72670691
 2.75882017 2.7876876  2.80866859 2.81866663 2.85757901 2.86512835
 2.87520619 2.91356714 2.93223828 2.93331115 2.94563378 2.94685412
 2.95507774 2.96246758 2.96430492 2.9646736  2.96537779 2.96574647
 2.9687714  2.97117117 2.97247588 2.97284455 2.97456478 2.97826926
 2.98433219 2.98435113 2.98470086 2.98560519 2.98616953 2.98653821
 2.98667806 2.98744254 2.98781121 2.9885154  2.98888408 2.99054886
 2.99196292 2.99247144 2.99323592 2.99430879 3.00300333 3.003372
 3.00407619 3.00444487 3.00484067 3.00520935 3.00591354 3.00628221
 3.00986958 3.01063406 3.01170692 3.01199361 3.0281277  3.03081285
 3.05551484 3.06866345 3.07658148 3.08630098 3.0863383  3.09560301
 3.09745528 3.10240111 3.10324866 3.1081945  3.11054878 3.11387478
 3.11427415 3.11464283 3.11485341 3.11522209 3.11534702 3.11571569
 3.11634216 3.11957393 3.11966816 3.12006753 3.1201027  3.12107225
 3.1211404  3.12142709 3.12144093 3.12214512 3.12251379 3.12687405
 3.12724272 3.1279385  3.12794692 3.12831559 3.12905524 3.13127292
 3.13196546 3.13233413 3.13266743 3.13490665 3.13775884 3.14584039
 3.1563514  3.16579437 3.20271042 3.20815489 3.22093927 3.2315786
 3.23630753 3.24098762 3.39386555 3.41234385 3.44286136 3.8332403
 3.92797529]

  warnings.warn(

2022-12-16 10:38:34,407:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.52295548 2.60844153 2.6508323  2.71682851 2.74253614 2.74604881
 2.76078592 2.78035468 2.78505963 2.81909609 2.83220448 2.83235059
 2.83971838 2.84213918 2.84432875 2.84505199 2.84607372 2.84621984
 2.84724157 2.85075152 2.85225542 2.85254364 2.85294109 2.85308264
 2.85327715 2.85342327 2.85443473 2.85725174 2.86013425 2.86071813
 2.86265989 2.86345727 2.86666516 2.87010087 2.87112248 2.87185599
 2.87214421 2.87287772 2.87302383 2.87706963 2.88110836 2.88123872
 2.88226045 2.89039747 2.89255448 2.90091549 2.90685253 2.91097681
 2.91363116 2.92043871 2.93070256 2.93569888 2.9365745  2.94346611
 2.96957427 2.970596   2.97846045 2.97895701 2.97948218 2.97972683
 2.98074856 2.98089468 2.98191641 2.98910957 2.9901313  2.9923297
 2.99335143 2.99349754 2.99359607 2.99451927 2.9946178  2.99476392
 2.99578565 2.99802922 2.99905095 2.9992956  3.00021879 3.00031733
 3.00046344 3.00148517 3.00171243 3.00273416 3.00297881 3.00400054
 3.00831267 3.00867834 3.0093344  3.00948052 3.00970007 3.01050225
 3.01102932 3.01193365 3.01229569 3.01320003 3.01331742 3.0140122
 3.01422176 3.01448527 3.01503393 3.01769541 3.02167843 3.02258276
 3.02270016 3.02360449 3.02616494 3.02718667 3.02733278 3.02835451
 3.03161981 3.03176593 3.03186446 3.03288619 3.03303231 3.03530303
 3.03554767 3.03628423 3.0365694  3.04081435 3.04226893 3.05523493
 3.07107598 3.08136603 3.08924418 3.10459971 3.11547727 3.11990024
 3.12420698 3.12979586 3.13986261 3.14894972 3.15302955 3.1628712
 3.16399634 3.16626771 3.16787595 3.17327567 3.17862012 3.18443592
 3.18723003 3.18744472 3.20015535 3.20245307 3.2076696  3.22498759
 3.230679   3.23995376 3.24822128 3.2511203  3.25214203 3.25228815
 3.25316983 3.25330988 3.25681983 3.2590094  3.31805623 3.3285794
 3.36424189 3.36525855 3.47247188]

  warnings.warn(

2022-12-16 10:38:37,232:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.55778408 2.56350827 2.5641636  2.58493131 2.59822041 2.60488974
 2.61898813 2.63869649 2.64560607 2.66102163 2.6693557  2.67244983
 2.69321755 2.69577725 2.74324069 2.74652356 2.76108321 2.76930787
 2.79770377 2.85911286 2.88958792 2.89138541 2.89591372 2.90905086
 2.95870741 2.96099123 2.96199028 2.96451818 2.97153366 2.97406155
 2.98815132 2.99213159 2.99313065 2.99641352 2.99794236 2.99894141
 2.99935852 3.00157673 3.00188641 3.00257578 3.00351932 3.00510367
 3.00579567 3.00685283 3.00785188 3.00832356 3.0101357  3.01054129
 3.01079688 3.01113476 3.01206715 3.01266359 3.01296565 3.01301509
 3.0130807  3.01366265 3.01401414 3.01407976 3.01660765 3.01729702
 3.01739526 3.01839296 3.0193412  3.01967908 3.01982491 3.02067813
 3.02320602 3.02355752 3.02684039 3.02833366 3.02936828 3.03068858
 3.04535255 3.04540981 3.04588917 3.04593201 3.04917204 3.05169993
 3.06216939 3.06498943 3.06545226 3.07115168 3.07971066 3.08742137
 3.08840081 3.09070425 3.10078765 3.10434486 3.10554132 3.10585134
 3.10958395 3.11826363 3.12079152 3.129702   3.13298487 3.13503787
 3.13551276 3.13586426 3.13732169 3.13832075 3.13914713 3.15881552
 3.16134342 3.16497778 3.17501707 3.18538818 3.18791607 3.19455867
 3.19990279 3.2027468  3.20318566 3.2130576  3.22807571 3.22901632
 3.23741204 3.23747765 3.23919089 3.24069491 3.24373815 3.27240933
 3.27569221 3.2782201  3.28776347 3.41261015 3.45532303 3.66978285
 3.67887391]

  warnings.warn(

2022-12-16 10:38:37,325:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.39896546 2.6158723  2.7573996  2.8247989  2.86552603 2.90845799
 2.91805527 2.92086379 2.9275498  2.92766655 2.94222688 2.9455662
 2.94565308 2.95016905 2.95637373 2.97208776 2.97241679 2.97717009
 2.98149698 2.98347172 2.98578772 2.98637534 2.98650749 2.98676738
 2.9869981  2.98737086 2.98931409 2.98968686 2.99027448 2.99089723
 2.99189067 2.99541704 2.99578981 3.00506962 3.00598137 3.00738562
 3.00797324 3.00859599 3.00896876 3.01028923 3.01091199 3.01116917
 3.01159885 3.01187237 3.01249513 3.01348857 3.01481113 3.0150683
 3.01580456 3.01649712 3.01701494 3.0173877  3.01933094 3.02091408
 3.02757927 3.03147841 3.03257689 3.0354805  3.04079986 3.06383494
 3.0689604  3.083077   3.085393   3.08697614 3.08956517 3.11334137
 3.14709952 3.17736389 3.18126303 3.18450309 3.23046979 3.23913629
 3.25994895 3.2958734  3.30685589 3.32535256 3.32656046 3.32887646
 3.35603962 3.35733808 3.40380532 4.36583404]

  warnings.warn(

2022-12-16 10:38:37,326:INFO:Calculating mean and std
2022-12-16 10:38:37,327:INFO:Creating metrics dataframe
2022-12-16 10:38:37,332:INFO:Uploading results into container
2022-12-16 10:38:37,332:INFO:Uploading model into container now
2022-12-16 10:38:37,333:INFO:master_model_container: 31
2022-12-16 10:38:37,333:INFO:display_container: 2
2022-12-16 10:38:37,334:INFO:GradientBoostingRegressor(random_state=5099)
2022-12-16 10:38:37,334:INFO:create_model() successfully completed......................................
2022-12-16 10:38:37,493:WARNING:create_model() for GradientBoostingRegressor(random_state=5099) raised an exception or returned all 0.0, trying without fit_kwargs:
2022-12-16 10:38:37,494:WARNING:Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 795, in compare_models
    assert (
AssertionError

2022-12-16 10:38:37,495:INFO:Initializing create_model()
2022-12-16 10:38:37,495:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002281239F8E0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022810EC8B20>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:38:37,496:INFO:Checking exceptions
2022-12-16 10:38:37,503:INFO:Importing libraries
2022-12-16 10:38:37,503:INFO:Copying training dataset
2022-12-16 10:38:37,514:INFO:Defining folds
2022-12-16 10:38:37,514:INFO:Declaring metric variables
2022-12-16 10:38:37,515:INFO:Importing untrained model
2022-12-16 10:38:37,516:INFO:Gradient Boosting Regressor Imported successfully
2022-12-16 10:38:37,517:INFO:Starting cross validation
2022-12-16 10:38:37,521:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:38:41,773:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.18919747 2.5489642  2.61138849 2.6516383  2.72321426 2.73714218
 2.82038433 2.82551914 2.86046973 2.89359118 2.91291398 2.92296858
 2.93015722 2.94127671 2.94143517 2.94229622 2.94366439 2.94419429
 2.94743647 2.94801329 2.95128215 2.95161336 2.95179169 2.95543237
 2.95697936 2.95846893 2.96661772 2.96864433 2.97034843 2.97093616
 2.97446916 2.97475517 2.97563296 2.97776751 2.98080407 2.98275581
 2.98326536 2.99663854 2.99709031 2.99925109 3.00041488 3.00045755
 3.00104383 3.00220763 3.00488952 3.00551149 3.00605331 3.01068219
 3.0111728  3.01452787 3.01455146 3.01534515 3.01571526 3.01650895
 3.01669669 3.01811903 3.01839714 3.01956094 3.02054237 3.02113783
 3.02170617 3.02338042 3.02498351 3.02719942 3.0280355  3.03018073
 3.03021176 3.03099801 3.03153184 3.03216181 3.03405    3.0352138
 3.03675399 3.03784511 3.04063637 3.04184131 3.04235085 3.04368836
 3.04953456 3.09607064 3.13360578 3.15203362 3.17488463 3.17604843
 3.18350728 3.18452299 3.18534027 3.18882055 3.19268982 3.19385362
 3.20832462 3.2121364  3.2133002  3.24259277 3.58526866 3.70974196
 3.93787505 4.34212936]

  warnings.warn(

2022-12-16 10:38:41,791:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.41521971 2.4507587  2.45965828 2.51933674 2.52937421 2.53175888
 2.53735158 2.54626715 2.56627338 2.6081266  2.72206312 2.73094392
 2.73278925 2.75828502 2.78594761 2.80424445 2.8329616  2.83353658
 2.84265368 2.85260561 2.85266375 2.85503561 2.86213505 2.86451971
 2.87743152 2.88654064 2.89099699 2.90329385 2.90887785 2.92716541
 2.92931225 2.93606851 2.93884628 2.94741411 2.95745158 2.95983624
 2.96006306 2.96244773 2.96542895 2.97434452 2.9751032  2.97672918
 2.98232188 2.98243984 2.98840538 2.98890498 2.98932122 2.99536588
 2.99775054 3.00334324 3.00540335 3.00778801 3.01210969 3.01338071
 3.02211976 3.02216589 3.02229628 3.02450442 3.02468095 3.02714983
 3.03009545 3.03027365 3.03154947 3.0371599  3.04495485 3.04912423
 3.05609541 3.05743038 3.0591343  3.06407277 3.07417444 3.07653902
 3.07734956 3.16092312 3.16717472 3.1675508  3.16993546 3.17515272
 3.1847111  3.19384069 3.19400292 3.21824286 3.28281732 3.30948329
 3.46089353 3.47090359]

  warnings.warn(

2022-12-16 10:38:41,806:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.47746411 2.48269211 2.5877416  2.68079967 2.721635   2.72271408
 2.72354185 2.82443255 2.85556136 2.93915209 3.0023762  3.00816962
 3.0092487  3.00967377 3.01050154 3.01075286 3.01158062 3.01394132
 3.01500419 3.01608328 3.01650835 3.01691104 3.01733611 3.01758743
 3.0184152  3.01917824 3.02025733 3.02199647 3.0223973  3.02307555
 3.02347638 3.02629461 3.03311785 3.03633691 3.03835603 3.03943511
 3.05496505 3.05579281 3.05604413 3.0568719  3.06322444 3.07760007
 3.08713513 3.10626367 3.11186064 3.11508026 3.11658442 3.11746834
 3.13503692 3.16636876 3.18249018 3.21775703 3.24609141 3.24883707
 3.27890539 3.28082209 3.28164986 3.28190118 3.28272894 3.30407777
 3.30531928 3.31296883 3.32868973 3.33435385 3.3373043  3.33838339
 3.36363017 3.39165432 3.39315848 3.41961657 3.44294283 3.50049618
 3.57149628 3.6063772 ]

  warnings.warn(

2022-12-16 10:38:41,892:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.48005815 2.58604362 2.61072658 2.64140639 2.66294244 2.66625089
 2.71872894 2.72225141 2.7232696  2.72899369 2.74442353 2.74936996
 2.76121554 2.7640704  2.78928034 2.80015871 2.80840486 2.82973071
 2.85153398 2.86372278 2.87691417 2.87919905 2.88061687 2.88346093
 2.88424565 2.88848041 2.89251772 2.89335961 2.89629464 2.89929931
 2.89936851 2.90380463 2.90424574 2.90527242 2.90664869 2.90875106
 2.91204205 2.9158075  2.91624861 2.91654737 2.92075393 2.92855024
 2.92939221 2.93093986 2.95246174 2.97507765 2.98776764 2.99085514
 2.99227296 2.99511702 2.99612055 3.00051038 3.0037722  3.0050157
 3.00785976 3.00827752 3.00871863 3.00886329 3.01112158 3.01322395
 3.01577508 3.01606801 3.01651494 3.019359   3.02028039 3.0207215
 3.02102026 3.02216661 3.02312445 3.02386432 3.02522682 3.02807088
 3.03115314 3.03302313 3.04396989 3.04631272 3.05487828 3.05607842
 3.05752912 3.06023513 3.06247555 3.06708942 3.068116   3.069532
 3.07027186 3.0716241  3.07446816 3.07668156 3.08107631 3.08227473
 3.09252145 3.096891   3.1027862  3.10433577 3.10717983 3.12054264
 3.12154727 3.12351216 3.14175671 3.1532543  3.16398311 3.28104871
 3.28369323 3.28690591 3.29613093 3.29705327 3.30217139 3.30448813
 3.31580262 3.32654921]

  warnings.warn(

2022-12-16 10:38:42,208:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.32952128 2.44089766 2.56044961 2.65504902 2.65813017 2.72670691
 2.75882017 2.7876876  2.80866859 2.81866663 2.85757901 2.86512835
 2.87520619 2.91356714 2.93223828 2.93331115 2.94563378 2.94685412
 2.95507774 2.96246758 2.96430492 2.9646736  2.96537779 2.96574647
 2.9687714  2.97117117 2.97247588 2.97284455 2.97456478 2.97826926
 2.98433219 2.98435113 2.98470086 2.98560519 2.98616953 2.98653821
 2.98667806 2.98744254 2.98781121 2.9885154  2.98888408 2.99054886
 2.99196292 2.99247144 2.99323592 2.99430879 3.00300333 3.003372
 3.00407619 3.00444487 3.00484067 3.00520935 3.00591354 3.00628221
 3.00986958 3.01063406 3.01170692 3.01199361 3.0281277  3.03081285
 3.05551484 3.06866345 3.07658148 3.08630098 3.0863383  3.09560301
 3.09745528 3.10240111 3.10324866 3.1081945  3.11054878 3.11387478
 3.11427415 3.11464283 3.11485341 3.11522209 3.11534702 3.11571569
 3.11634216 3.11957393 3.11966816 3.12006753 3.1201027  3.12107225
 3.1211404  3.12142709 3.12144093 3.12214512 3.12251379 3.12687405
 3.12724272 3.1279385  3.12794692 3.12831559 3.12905524 3.13127292
 3.13196546 3.13233413 3.13266743 3.13490665 3.13775884 3.14584039
 3.1563514  3.16579437 3.20271042 3.20815489 3.22093927 3.2315786
 3.23630753 3.24098762 3.39386555 3.41234385 3.44286136 3.8332403
 3.92797529]

  warnings.warn(

2022-12-16 10:38:42,227:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.54095531 1.67679084 1.96803975 2.20859361 2.54006899 2.57496729
 2.68110383 2.71383689 2.74065411 2.76538038 2.8452168  2.86812822
 2.87280132 2.88266028 2.89541592 2.89938066 2.90004105 2.90247576
 2.90338251 2.91829862 2.92175477 2.9247636  2.93369393 2.94134684
 2.94570108 2.95680573 2.95788688 2.96681721 2.9685746  2.96890802
 2.97126305 2.97287277 2.97814869 2.97843222 2.98046065 2.98401869
 2.99463495 2.99675726 3.00352118 3.00369045 3.00497645 3.0056876
 3.00571889 3.00582536 3.00630653 3.00703191 3.00748593 3.00849178
 3.00906035 3.00968363 3.00980481 3.0102712  3.01027127 3.01057609
 3.01068257 3.01118613 3.01183324 3.01260453 3.012711   3.01302509
 3.01319217 3.01343191 3.01361266 3.0136928  3.01423594 3.01454084
 3.01523686 3.01546034 3.01556682 3.01572124 3.01594599 3.01656927
 3.01715684 3.01841559 3.0188018  3.0192016  3.01942508 3.01953156
 3.01991073 3.02001265 3.02082913 3.0221225  3.02276654 3.02302684
 3.02449963 3.02546396 3.02608724 3.0263683  3.02699158 3.0274675
 3.02788405 3.02991248 3.03033304 3.03073986 3.03276829 3.03610975
 3.03673304 3.03777929 3.04007449 3.04750268 3.04943899 3.05146742
 3.05212781 3.05438832 3.05464994 3.05835306 3.07120486 3.07843431
 3.10646279 3.10777581 3.10980425 3.11376899 3.11668989 3.1195457
 3.18225969 3.40238174 3.607802   3.9817297  4.0968256 ]

  warnings.warn(

2022-12-16 10:38:42,244:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.68323506 2.69906719 2.70851332 2.71631981 2.72089945 2.72127761
 2.74539323 2.74788707 2.7515183  2.7735435  2.78176653 2.79987939
 2.80173647 2.80709284 2.81007704 2.8562546  2.8613037  2.86406108
 2.86588335 2.87051242 2.87368983 2.87877548 2.88413185 2.88532974
 2.88658197 2.88831522 2.89116161 2.89771587 2.8977902  2.8989681
 2.91191909 2.9140657  2.91890575 2.92075793 2.92270435 2.92426211
 2.92537572 2.92671223 2.92856441 2.93035896 2.93247715 2.93303033
 2.93471984 2.93488251 2.93900618 2.94052226 2.94237444 2.94448354
 2.94451299 2.94456217 2.94486328 2.94611745 2.94641435 2.94909614
 2.95010818 2.95018093 2.95464684 2.95649903 2.95775542 2.95868675
 2.96048976 2.96053894 2.97014155 2.97669581 2.97865906 2.9799405
 2.98451932 2.99139371 2.99155462 2.99340681 2.99363374 2.99495573
 2.99680791 2.99936111 3.00031209 3.00121329 3.00216427 3.00276222
 3.0046144  3.00567921 3.00640894 3.00753139 3.00826112 3.00849278
 3.00908031 3.01034496 3.01093249 3.01199146 3.01279509 3.01502332
 3.01539257 3.01657225 3.01681291 3.01842443 3.01906323 3.02056298
 3.02061216 3.02068578 3.02111521 3.02174501 3.0223857  3.02241516
 3.02246434 3.022696   3.02378079 3.02437873 3.02454818 3.02509738
 3.02514612 3.02623091 3.0269983  3.02715387 3.02951715 3.03022165
 3.03069683 3.03254901 3.0339111  3.03468756 3.03473674 3.03658892
 3.03748351 3.04556513 3.04741731 3.04858289 3.05047362 3.05449158
 3.0569417  3.06021297 3.06920881 3.07053113 3.08395736 3.09718268
 3.10365077 3.12021328 3.12519597 3.13843536 3.13914206 3.13947895
 3.1444281  3.14576567 3.14678584 3.14728544 3.15223459 3.15487521
 3.15665196 3.16300359 3.16939144 3.17260639 3.17417958 3.17808536
 3.18148647 3.1864398  3.18929295 3.19322852 3.2005354  3.20695895
 3.20730702 3.23523603 3.23573563 3.23622361 3.23922676 3.24304252
 3.24703325 3.25223188 3.26361735 3.26879439 3.29201726 3.85022443]

  warnings.warn(

2022-12-16 10:38:42,348:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.52295548 2.60844153 2.6508323  2.71682851 2.74253614 2.74604881
 2.76078592 2.78035468 2.78505963 2.81909609 2.83220448 2.83235059
 2.83971838 2.84213918 2.84432875 2.84505199 2.84607372 2.84621984
 2.84724157 2.85075152 2.85225542 2.85254364 2.85294109 2.85308264
 2.85327715 2.85342327 2.85443473 2.85725174 2.86013425 2.86071813
 2.86265989 2.86345727 2.86666516 2.87010087 2.87112248 2.87185599
 2.87214421 2.87287772 2.87302383 2.87706963 2.88110836 2.88123872
 2.88226045 2.89039747 2.89255448 2.90091549 2.90685253 2.91097681
 2.91363116 2.92043871 2.93070256 2.93569888 2.9365745  2.94346611
 2.96957427 2.970596   2.97846045 2.97895701 2.97948218 2.97972683
 2.98074856 2.98089468 2.98191641 2.98910957 2.9901313  2.9923297
 2.99335143 2.99349754 2.99359607 2.99451927 2.9946178  2.99476392
 2.99578565 2.99802922 2.99905095 2.9992956  3.00021879 3.00031733
 3.00046344 3.00148517 3.00171243 3.00273416 3.00297881 3.00400054
 3.00831267 3.00867834 3.0093344  3.00948052 3.00970007 3.01050225
 3.01102932 3.01193365 3.01229569 3.01320003 3.01331742 3.0140122
 3.01422176 3.01448527 3.01503393 3.01769541 3.02167843 3.02258276
 3.02270016 3.02360449 3.02616494 3.02718667 3.02733278 3.02835451
 3.03161981 3.03176593 3.03186446 3.03288619 3.03303231 3.03530303
 3.03554767 3.03628423 3.0365694  3.04081435 3.04226893 3.05523493
 3.07107598 3.08136603 3.08924418 3.10459971 3.11547727 3.11990024
 3.12420698 3.12979586 3.13986261 3.14894972 3.15302955 3.1628712
 3.16399634 3.16626771 3.16787595 3.17327567 3.17862012 3.18443592
 3.18723003 3.18744472 3.20015535 3.20245307 3.2076696  3.22498759
 3.230679   3.23995376 3.24822128 3.2511203  3.25214203 3.25228815
 3.25316983 3.25330988 3.25681983 3.2590094  3.31805623 3.3285794
 3.36424189 3.36525855 3.47247188]

  warnings.warn(

2022-12-16 10:38:44,812:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.39896546 2.6158723  2.7573996  2.8247989  2.86552603 2.90845799
 2.91805527 2.92086379 2.9275498  2.92766655 2.94222688 2.9455662
 2.94565308 2.95016905 2.95637373 2.97208776 2.97241679 2.97717009
 2.98149698 2.98347172 2.98578772 2.98637534 2.98650749 2.98676738
 2.9869981  2.98737086 2.98931409 2.98968686 2.99027448 2.99089723
 2.99189067 2.99541704 2.99578981 3.00506962 3.00598137 3.00738562
 3.00797324 3.00859599 3.00896876 3.01028923 3.01091199 3.01116917
 3.01159885 3.01187237 3.01249513 3.01348857 3.01481113 3.0150683
 3.01580456 3.01649712 3.01701494 3.0173877  3.01933094 3.02091408
 3.02757927 3.03147841 3.03257689 3.0354805  3.04079986 3.06383494
 3.0689604  3.083077   3.085393   3.08697614 3.08956517 3.11334137
 3.14709952 3.17736389 3.18126303 3.18450309 3.23046979 3.23913629
 3.25994895 3.2958734  3.30685589 3.32535256 3.32656046 3.32887646
 3.35603962 3.35733808 3.40380532 4.36583404]

  warnings.warn(

2022-12-16 10:38:44,840:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.55778408 2.56350827 2.5641636  2.58493131 2.59822041 2.60488974
 2.61898813 2.63869649 2.64560607 2.66102163 2.6693557  2.67244983
 2.69321755 2.69577725 2.74324069 2.74652356 2.76108321 2.76930787
 2.79770377 2.85911286 2.88958792 2.89138541 2.89591372 2.90905086
 2.95870741 2.96099123 2.96199028 2.96451818 2.97153366 2.97406155
 2.98815132 2.99213159 2.99313065 2.99641352 2.99794236 2.99894141
 2.99935852 3.00157673 3.00188641 3.00257578 3.00351932 3.00510367
 3.00579567 3.00685283 3.00785188 3.00832356 3.0101357  3.01054129
 3.01079688 3.01113476 3.01206715 3.01266359 3.01296565 3.01301509
 3.0130807  3.01366265 3.01401414 3.01407976 3.01660765 3.01729702
 3.01739526 3.01839296 3.0193412  3.01967908 3.01982491 3.02067813
 3.02320602 3.02355752 3.02684039 3.02833366 3.02936828 3.03068858
 3.04535255 3.04540981 3.04588917 3.04593201 3.04917204 3.05169993
 3.06216939 3.06498943 3.06545226 3.07115168 3.07971066 3.08742137
 3.08840081 3.09070425 3.10078765 3.10434486 3.10554132 3.10585134
 3.10958395 3.11826363 3.12079152 3.129702   3.13298487 3.13503787
 3.13551276 3.13586426 3.13732169 3.13832075 3.13914713 3.15881552
 3.16134342 3.16497778 3.17501707 3.18538818 3.18791607 3.19455867
 3.19990279 3.2027468  3.20318566 3.2130576  3.22807571 3.22901632
 3.23741204 3.23747765 3.23919089 3.24069491 3.24373815 3.27240933
 3.27569221 3.2782201  3.28776347 3.41261015 3.45532303 3.66978285
 3.67887391]

  warnings.warn(

2022-12-16 10:38:44,842:INFO:Calculating mean and std
2022-12-16 10:38:44,843:INFO:Creating metrics dataframe
2022-12-16 10:38:44,850:INFO:Uploading results into container
2022-12-16 10:38:44,851:INFO:Uploading model into container now
2022-12-16 10:38:44,852:INFO:master_model_container: 32
2022-12-16 10:38:44,852:INFO:display_container: 2
2022-12-16 10:38:44,852:INFO:GradientBoostingRegressor(random_state=5099)
2022-12-16 10:38:44,853:INFO:create_model() successfully completed......................................
2022-12-16 10:38:45,019:ERROR:create_model() for GradientBoostingRegressor(random_state=5099) raised an exception or returned all 0.0:
2022-12-16 10:38:45,020:ERROR:Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 795, in compare_models
    assert (
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 811, in compare_models
    assert (
AssertionError

2022-12-16 10:38:45,020:INFO:Initializing Light Gradient Boosting Machine
2022-12-16 10:38:45,020:INFO:Total runtime is 2.7960298299789432 minutes
2022-12-16 10:38:45,020:INFO:SubProcess create_model() called ==================================
2022-12-16 10:38:45,021:INFO:Initializing create_model()
2022-12-16 10:38:45,021:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002281239F8E0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022810EC8B20>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:38:45,021:INFO:Checking exceptions
2022-12-16 10:38:45,024:INFO:Importing libraries
2022-12-16 10:38:45,024:INFO:Copying training dataset
2022-12-16 10:38:45,029:INFO:Defining folds
2022-12-16 10:38:45,029:INFO:Declaring metric variables
2022-12-16 10:38:45,030:INFO:Importing untrained model
2022-12-16 10:38:45,030:INFO:Light Gradient Boosting Machine Imported successfully
2022-12-16 10:38:45,030:INFO:Starting cross validation
2022-12-16 10:38:45,032:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:38:47,596:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.75604475 1.99794264 2.9006507  2.95051687 2.96074876 2.96719246
 2.971124   2.97838903 2.98187017 2.98216849 2.98278108 2.98282717
 2.98291721 2.9845533  2.98645701 2.99114956 2.99119565 2.99128568
 2.99455712 2.99469324 2.99482549 2.99560416 2.99565025 2.99574028
 2.99675437 2.99702143 2.99737638 2.99797118 2.99874175 3.0007913
 3.0029256  3.00306172 3.00324942 3.0038826  3.00397264 3.00401872
 3.00410876 3.00552603 3.00557729 3.00574486 3.01493098 3.0177166
 3.01836574 3.0190227  3.02797027 3.02803225 3.03356254 3.03394294
 3.03442499 3.03612117 3.03921791 3.03938313 3.04139566 3.0425322
 3.04638331 3.04795228 3.04846119 3.04976414 3.05033087 3.05163303
 3.05235788 3.05591942 3.06069045 3.06530157 3.07898768 3.08006775
 3.08390612 3.08429522 3.09815261 3.10679039 3.12046405 3.13836566
 3.14037737 3.14193676 3.1437635  3.14383479 3.14958342 3.15503229
 3.16323387 3.16435741 3.16701388 3.18088126 3.18573084 3.18573569
 3.1908277  3.19118749 3.1914691  3.19678572 3.19754732 3.20014672
 3.20508663 3.21142997 3.22067322 3.2267924  3.28504252 3.29069001
 3.35047894 3.35394193 3.36133725 3.36785048 3.36905808 3.37977751
 3.38245089 3.38695391 3.39125704 3.39168834 3.39505591 3.39515975
 3.39735546 3.40325772 3.40394647 3.40431003 3.40436979 3.40446269
 3.41100393 3.41120713 3.41293803 3.41740733 3.41741679 3.4175867
 3.42161567 3.42675331 3.42970452 3.43304212 3.43350272 3.43494791
 3.44255809 3.44782621 3.46762172 3.4726431  3.47516154 3.48904852
 3.50057448 3.50446708 3.53069097 3.55161646 3.58634378 3.60669379
 3.6101299  3.61235266 3.61556053 3.61992637 3.62847533 3.62904843
 3.65329104 3.65337965 3.65669709 3.67899336 3.69674882 3.70938254
 3.71156461 3.73294312 3.73950309 3.74239755 3.7521846  3.75579514
 3.75884653 3.7628065  3.76490056 3.77340682 3.77344225 3.77419136
 3.7747671  3.77534975 3.77778791 3.77836091 3.78024806 3.7806208
 3.78105803 3.78129101 3.78572993 3.78728837 3.78823372 3.7915391
 3.79190965 3.79398211 3.79506099 3.79851365 3.79860662 3.80230966
 3.80357399 3.80418494 3.80951272 3.81259448 3.81528046 3.81748698
 3.82862082 3.83097723 3.83670267 3.84027769 3.84157491 3.84600462
 3.85016979 3.85539101 3.87010553 3.91118655 3.95324637]

  warnings.warn(

2022-12-16 10:38:47,614:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.6950307  2.42082077 2.47327883 2.55709104 2.77291499 2.78231289
 2.78241831 2.78807813 2.79200995 2.79626063 2.80347289 2.8243389
 2.83090866 2.83534195 2.83644134 2.83679889 2.8368405  2.84316764
 2.84732613 2.84792634 2.84849432 2.85023128 2.85034887 2.85098586
 2.85345902 2.85833077 2.85953502 2.85985218 2.86158415 2.8622707
 2.8629117  2.86457564 2.865512   2.8708629  2.87860183 2.88166135
 2.8845177  2.88533086 2.89001883 2.89294619 2.90153537 2.90234854
 2.90324965 2.90384032 2.90459489 2.90540805 2.90628036 2.90653863
 2.90702526 2.90789184 2.90834254 2.9099217  2.91043088 2.91276231
 2.91587974 2.9166929  2.91722483 2.91938689 2.91975242 2.9199342
 2.92016434 2.92136962 2.9220953  2.9226869  2.92355631 2.92404294
 2.92536022 2.92634788 2.92710246 2.92750894 2.92766516 2.92841974
 2.92929205 2.93011895 2.93089289 2.93317847 2.9345087  2.9383873
 2.93970458 2.94069224 2.94144682 2.94183868 2.9418533  2.9427641
 2.94352952 2.94736838 2.94878185 2.95041174 2.95089613 2.95338751
 2.95413672 2.96276473 2.96714038 2.97509065 2.9771091  2.97896925
 2.97978241 2.98127419 2.98208735 2.98290108 2.98445914 2.99331361
 2.99369604 2.99380161 2.99412677 2.99447346 2.99637313 2.99643171
 2.99649297 2.99718629 2.99759822 2.9988035  3.00040124 3.00099018
 3.00147682 3.00329512 3.00378176 3.0040497  3.00453634 3.00494281
 3.00540865 3.00581512 3.00645468 3.00755282 3.00865218 3.01582118
 3.01812612 3.0188807  3.01928718 3.01975301 3.02329516 3.03268059
 3.04359008 3.04403206 3.04574344 3.05453475 3.05978616 3.06302644
 3.06572844 3.06665856 3.07023477 3.07370313 3.08101602 3.08510764
 3.08973911 3.09960327 3.10094019 3.10900537 3.11300136 3.11441158
 3.11915582 3.12069302 3.12587754 3.12795408 3.1281467  3.13270456
 3.13468904 3.1377595  3.14003034 3.14236911 3.14368683 3.14617463
 3.1493379  3.1506914  3.15451854 3.15506481 3.15840155 3.16304755
 3.16706714 3.16906131 3.18433996 3.18576354 3.19018697 3.19294452
 3.20091744 3.24673195 3.26236723 3.27197563 3.2852481  3.29470844
 3.29540794 3.31750983 3.31873663 3.32026077 3.32033006 3.32084845
 3.32218277 3.32295986 3.32411094 3.3243491  3.32698807 3.32955692
 3.33043912 3.33147312 3.33346618 3.33579098 3.33893495 3.35103263
 3.35188672 3.35315216 3.3547508  3.35496604 3.35832375 3.35852858
 3.36169926 3.36312936 3.36458535 3.37096509 3.37763605 3.37906898
 3.41617106 3.42626439 3.45891638 3.50424345 3.53493811 3.56712629
 3.57179112 3.57258768 3.58555918 3.60121725 3.62223186 3.62954976
 3.63197423 3.63308692 3.64738879 3.65997397 3.66965432 3.67705545
 3.68312961 3.68749649 3.6928736  3.69814584 3.73470167 3.74315915
 3.75307571 3.76401451 3.7695639  3.78605236 3.80687558 3.88299548
 3.96773865 3.97245416 3.98277571 4.0680357  4.11786744 4.21487288
 4.33150221]

  warnings.warn(

2022-12-16 10:38:47,624:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.00134151 2.31525723 2.41492272 2.67351301 2.80907115 2.83456276
 2.84546055 2.84881611 2.85279884 2.88417817 2.9001965  2.90315708
 2.93267047 2.93918423 2.94254291 2.94788497 2.95145071 2.95162122
 2.96498371 2.96631973 2.96852099 2.97020559 2.97030249 2.971583
 2.97158555 2.97162495 2.97168245 2.97240685 2.97604151 2.97641033
 2.97755036 2.97992737 2.9804748  2.98436066 2.98439588 2.98443782
 2.98445756 2.98552248 2.98620938 2.98663065 2.98681655 2.9868585
 2.98828174 2.98832368 2.98834772 2.98842059 2.99033895 2.99070241
 2.99074436 2.99079931 2.99084126 2.99170543 2.9918045  2.9919014
 2.9925643  2.99286725 2.99355415 2.99566845 2.99576535 2.99652025
 2.99729087 2.99783329 2.99804718 2.99808913 2.99814408 2.99818603
 2.99862567 2.99914926 2.99934947 3.00160249 3.00212096 3.00265668
 3.00329489 3.00478757 3.00501532 3.00522127 3.00684773 3.00766107
 3.00903444 3.00907639 3.00953289 3.00958774 3.01130875 3.01250365
 3.0129203  3.01292486 3.01296225 3.01305915 3.0144612  3.01519461
 3.01537715 3.02310379 3.02815893 3.0411422  3.04774186 3.05233796
 3.06356793 3.13739153 3.18190733 3.19534087 3.19548682 3.21716059
 3.26194286 3.26481992 3.27022091 3.27374939 3.27752887 3.29193339
 3.29343793 3.29416501 3.32129926 3.32692079 3.33023641 3.37025465
 3.38174766 3.38211465 3.41494863 3.41511573 3.41765215 3.42465878
 3.42786104 3.46445469 3.48631252 3.48731555 3.5172014  3.52933017
 3.53842864 3.5522789  3.55735339 3.55998469 3.56268421 3.5633847
 3.56377904 3.57074595 3.57221208 3.57426034 3.57660674 3.57758586
 3.57894791 3.58247504 3.58367755 3.58933022 3.58937217 3.58949306
 3.59012699 3.59088848 3.59161032 3.59186461 3.59220704 3.5929712
 3.59333929 3.5936814  3.59372335 3.59385407 3.594752   3.59602289
 3.59623599 3.59795884 3.60161582 3.60481594 3.60656669 3.60715584
 3.60950267 3.61239468 3.62584489 3.62689139 3.63112168 3.6311837
 3.65042728 3.65099335 3.72840665 3.77969185 3.80631036 3.82094043
 3.9565072  3.9741173  4.63448675 4.67244267 4.6762133  4.68088693
 4.68303306 4.68398643 4.68406352 4.68877847 4.69133097 4.71748429
 4.72719099 4.73174746 4.74449652 4.74552711 4.74587868 4.75784718
 4.76373089 4.76935243 4.7791947  4.78518776 4.79384767 4.80191155
 5.48969593]

  warnings.warn(

2022-12-16 10:38:47,710:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.11902167 2.14133103 2.15542714 2.17470151 2.20917261 2.23034395
 2.23039623 2.38224797 2.81011231 2.8690479  2.90477777 2.90810782
 2.91496058 2.91599379 2.92146531 2.92464119 2.94216769 2.94532369
 2.94629794 2.94773015 2.94908862 2.94924489 2.95053683 2.95106626
 2.95151543 2.95203892 2.95259902 2.9545422  2.95501286 2.95576797
 2.9561631  2.95632069 2.95698973 2.95738873 2.9589012  2.95924973
 2.9593591  2.9599192  2.96062552 2.96114901 2.96142791 2.96147366
 2.96364527 2.96412296 2.96770043 2.96793047 2.97045854 2.9754144
 2.97608411 2.97696468 2.97787888 2.98147972 2.98176813 2.98191126
 2.9822173  2.98237499 2.98248745 2.98274079 2.98318725 2.98330089
 2.9846249  2.98523704 2.98549718 2.98571473 2.98602958 2.98610557
 2.98729065 2.98736954 2.98744988 2.98753635 2.98779618 2.98785075
 2.98821282 2.98871464 2.9887999  2.98896609 2.98936944 2.98953748
 2.98981873 2.98997795 2.99006097 2.99006443 2.99037882 2.9904298
 2.99062107 2.99067233 2.99086318 2.99142328 2.99215088 2.99295787
 2.99303491 2.99339126 2.99350675 2.99355048 2.99359501 2.99395135
 2.99461083 2.99517093 2.99713891 2.997699   2.99818336 2.99876752
 3.00127153 3.0017226  3.00175608 3.00217125 3.00316872 3.00449105
 3.00747766 3.00751098 3.01105019 3.01215891 3.01381149 3.01418971
 3.01437158 3.01479785 3.01538411 3.01673145 3.01799252 3.01815175
 3.01823822 3.01855262 3.01871184 3.01891469 3.01895664 3.01905637
 3.0199529  3.02074408 3.02156505 3.02181075 3.02212515 3.02275676
 3.02431238 3.0253127  3.0258728  3.02871387 3.02888523 3.02944533
 3.03558933 3.03817954 3.0395707  3.04175207 3.04459399 3.04660063
 3.04820821 3.04907225 3.05875578 3.0619461  3.07242766 3.07336904
 3.11178362 3.11700023 3.13216545 3.14829917 3.15897079 3.19563592
 3.35655636 3.55854168 3.59642214 3.62067476 3.62236079 3.62780349
 3.63308031 3.6364358  3.63819689 3.64435243 3.64532562 3.64711947
 3.64889499 3.6652302  3.66620325 3.67806743 3.68498085 3.68616008
 3.6878961  3.70012176 3.70244846 3.71142556 3.71146252 3.71384341
 3.71585005 3.71608718 3.72168752 3.72276599 3.73036564 3.73117254
 3.73360931 3.73439361 3.74139298 3.75123994 3.76069154 3.76211814
 3.76247473 3.76578148 3.76671172 3.79276445 3.80036907 3.80908818
 3.81426928 3.81837526 3.81976447 3.82174081 3.83060567 3.83613075
 3.83935526 3.8407074  3.84382199 3.84765363 3.84846681 3.85025317
 3.85302617 3.85333056 3.85884498 3.85999735 3.86341655 3.86573864
 3.86656904 3.86675671 3.86813676 3.86900049 3.88544199 3.89945256
 3.90359473 3.91539379 3.91735579 3.92157737 3.92734885 3.94278281
 3.98650172 3.98740808 4.04666599 4.25110539]

  warnings.warn(

2022-12-16 10:38:47,797:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.9631439  2.40344948 2.47898978 2.74952015 2.76715263 2.80352265
 2.83030513 2.85870696 2.9053047  2.93688908 2.94319057 2.96701351
 2.9717475  2.97490694 2.97498359 2.97498963 2.97499317 2.97504859
 2.97505213 2.97505463 2.97505817 2.9751751  2.97518115 2.97532633
 2.97532884 2.97533238 2.9755792  2.9785284  2.98008138 2.98014638
 2.98110894 2.99193561 2.99194166 2.99264976 2.99442414 2.99491025
 2.99512043 2.99512294 2.99539715 2.99565701 2.99578728 3.00278452
 3.00279056 3.0027941  3.00284952 3.00285305 3.00285556 3.0028591
 3.00290582 3.00293221 3.00293825 3.00294179 3.00299721 3.00300075
 3.00300325 3.00300679 3.00312977 3.00327142 3.00327495 3.00327746
 3.003281   3.00586724 3.00860332 3.01014035 3.01579588 3.01635914
 3.01908712 3.01936132 3.01962266 3.01968766 3.01969094 3.01996187
 3.0199943  3.01999783 3.02052984 3.02059484 3.02059838 3.02072489
 3.02086905 3.02127624 3.02133166 3.02133771 3.02134124 3.02146804
 3.02160587 3.02274448 3.02580246 3.02722287 3.0301808  3.03041666
 3.03128771 3.0343493  3.03663799 3.03838822 3.03843029 3.03892929
 3.04103202 3.0419812  3.04220868 3.04654802 3.04682304 3.04703574
 3.04713245 3.04730994 3.04731348 3.04742713 3.04748859 3.04757128
 3.04757482 3.04763628 3.04763982 3.04791049 3.04791402 3.05378796
 3.05853559 3.0621265  3.06836219 3.06926217 3.07020082 3.073352
 3.09344823 3.10149979 3.12908404 3.13009675 3.13033866 3.13283666
 3.1376847  3.13954944 3.13973558 3.1402764  3.14731423 3.26054443
 3.32800995 3.33883714 3.34616834 3.35491224 3.35777158 3.36000931
 3.36133662 3.36408761 3.36657181 3.38160945 3.38387408 3.38532988
 3.38585252 3.39134925 3.39278053 3.39352743 3.40399192 3.40611784
 3.41087979 3.41183487 3.42007891 3.42280689 3.42314572 3.43056189
 3.43083609 3.43085096 3.43113127 3.43122556 3.4375265  3.44050415
 3.44185847 3.4483123  3.44844867 3.44856435 3.44899045 3.44991158
 3.45145141 3.45835147 3.4585588  3.45944854 3.46235726 3.46314133
 3.4648455  3.46486962 3.46503793 3.46592119 3.4664708  3.46986547
 3.47000183 3.47113978 3.47257912 3.47377138 3.47379218 3.47635555
 3.47640624 3.47894738 3.48476516 3.48635223 3.48680246 3.48742068
 3.48837913 3.4908242  3.49402681 3.52488454 3.53514351 3.54164325
 3.54841281 3.55540021 3.56136734 3.56783775 3.57256544 3.58633429
 3.58776975 3.59163063 3.59755767 3.61561072 3.62002726 3.62750338
 3.63575663 3.64577261 3.65097634 3.65273604 3.65490322 3.65857202
 3.66043436 3.66592738 3.67347045 3.67417463 3.69949283 3.70378236
 3.70621897 3.70926942 3.71921734 3.79083448 3.91463688 3.98620875
 4.08713551]

  warnings.warn(

2022-12-16 10:38:47,858:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.25443624 1.40579393 1.46735657 1.52140215 1.54169164 1.56772349
 1.5726553  1.58296478 2.17631937 2.58478008 2.82042023 2.88907267
 2.90121262 2.90434964 2.90897587 2.91256659 2.91302473 2.91313164
 2.91323675 2.91363817 2.91364451 2.91374962 2.91385653 2.91396164
 2.92077208 2.92241985 2.92503165 2.92541836 2.93784223 2.94143836
 2.94474324 2.94502406 2.94655295 2.94973305 2.95289836 2.95307223
 2.95466432 2.95686961 2.95833308 2.96141821 2.96289057 2.96404567
 2.96512975 2.96646512 2.96977532 2.97050021 2.97125147 2.97138346
 2.97210274 2.97282763 2.97654717 2.97721733 2.9772178  2.97732244
 2.97753452 2.97794222 2.97861285 2.98000138 2.98075952 2.98081761
 2.98148409 2.98179248 2.98225956 2.98231263 2.98311442 2.98368884
 2.98426467 2.98583231 2.98592852 2.98603363 2.98659868 2.98670379
 2.98732357 2.98742868 2.98764202 2.98836691 2.98903842 2.98964952
 2.98977878 2.99037441 2.99044894 2.99270818 2.9936322  2.99367462
 2.99367554 2.99387198 2.99409034 2.99430236 2.99432773 2.99434613
 2.99439951 2.99440747 2.99481523 2.99502725 2.99520036 2.99529377
 2.99530167 2.99540678 2.99565851 2.9957958  2.99580819 2.99587052
 2.99602655 2.99659541 2.99719085 2.99724737 2.99782277 2.99797226
 2.99854766 2.99903087 2.99911181 2.99913599 2.99915193 2.99952753
 2.99973243 2.99973955 2.99976492 2.99978197 2.99978332 2.99980734
 2.99984466 3.00010293 3.0001283  3.00019135 3.00019769 3.0003028
 3.00031495 3.00032818 3.00035737 3.00040971 3.00043508 3.00045348
 3.00050686 3.00051482 3.0005402  3.00070046 3.00070422 3.00076675
 3.00077309 3.00079847 3.00091624 3.00092258 3.00098511 3.00102769
 3.00108226 3.00110927 3.0011346  3.00115997 3.00117837 3.00123971
 3.00126508 3.00149798 3.00151731 3.00171    3.00287657 3.00336652
 3.00343982 3.00354673 3.00365184 3.00419631 3.00419652 3.00482405
 3.00533692 3.00545686 3.00554894 3.00566887 3.00591232 3.00674569
 3.00845875 3.00896823 3.01022157 3.01201062 3.01255446 3.01263836
 3.01322462 3.01629537 3.01654622 3.0166125  3.01696553 3.01717755
 3.01720292 3.01728266 3.01790243 3.01792781 3.01800755 3.01814272
 3.01820435 3.02291182 3.02682767 3.0278148  3.02835753 3.02951139
 3.03346136 3.03530236 3.03641037 3.03728221 3.03959113 3.04006481
 3.04031096 3.04107338 3.04250159 3.04338615 3.04539327 3.04568485
 3.04928682 3.04965567 3.05177967 3.05597859 3.05630834 3.05784597
 3.05827424 3.06064892 3.06213221 3.06466068 3.06475248 3.06485703
 3.06513166 3.0666125  3.06692593 3.06697684 3.06875933 3.07076936
 3.0728902  3.07457232 3.07570549 3.07601395 3.07640293 3.07688806
 3.07988568 3.08132288 3.08211004 3.08355343 3.09414493 3.096
 3.09841369 3.10611948 3.13049236 3.14005925 3.14918052 3.15237587
 3.16109681 3.16275857 3.16402537 3.16640644 3.16939343 3.17157811
 3.17321668 3.17654019 3.17709658 3.18634797 3.18759905 3.19124997
 3.19555643 3.19744629 3.19910522 3.20932179 3.21156081 3.21987129
 3.24616156 3.25274004 3.26174992 3.28113218 3.28621256 3.31341096
 3.33905193 3.35390335 3.36007999 3.36394928 3.38686145 3.38759895
 3.39153508 3.41758002 3.42324872 3.42705649 3.48650647 3.53556265
 3.58870451 3.65980959 3.68852836 3.80820127 3.82277595 3.82758774
 3.83340237 3.83401737 3.85367747 3.85889295 3.86411978 3.88177797
 3.88261733 3.88734894 3.90071119 3.91230736 3.91839983 3.92564625
 3.92752553 3.92755344 3.93638784 3.94138766 3.94603194 3.98678539
 4.02464563 4.03601058 4.05430923 4.07801977 4.15327527 4.15418223
 4.18669767]

  warnings.warn(

2022-12-16 10:38:47,935:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.82294357 2.83581792 2.91056383 2.94383711 2.95194607 2.95839681
 2.96163982 2.96248315 2.97139466 2.97245    2.97591025 2.97676268
 2.98350732 2.98638475 2.98701291 2.98715684 2.98743823 2.98744625
 2.98765913 2.98821032 2.98869714 2.98910326 2.98911128 2.99072774
 2.99073576 2.99088324 2.99276401 2.99314115 2.99330534 2.99342941
 2.99360517 2.99437726 2.99448288 2.9944909  2.99465865 2.99466667
 2.99471248 2.99496587 2.99525497 2.9952702  2.99543074 2.99543876
 2.99615593 2.99632368 2.9963317  2.99674815 2.99830159 2.99836021
 2.99892606 2.9991851  2.9999695  3.00387322 3.00481723 3.01694729
 3.01868309 3.02392483 3.02470471 3.02507019 3.03257538 3.03870207
 3.04304591 3.04642313 3.04725943 3.05369179 3.05527417 3.06203195
 3.06387085 3.06675268 3.0679986  3.07415833 3.07708539 3.08994492
 3.09770798 3.10155773 3.10440545 3.11620761 3.12585534 3.12655106
 3.13231463 3.14098665 3.14794528 3.15783423 3.18502518 3.186031
 3.19038378 3.20315738 3.20531311 3.20584408 3.20836949 3.21242398
 3.21423802 3.22166754 3.22871927 3.23141529 3.23452187 3.28513573
 3.29047311 3.35499171 3.35894327 3.37257704 3.3930535  3.40090926
 3.40290283 3.40454285 3.41273997 3.41288782 3.41470061 3.41774901
 3.42602051 3.42816834 3.42882744 3.4291817  3.43536547 3.43584421
 3.44197109 3.44224617 3.44623794 3.44793963 3.44994914 3.45150145
 3.45166999 3.45257    3.45357823 3.4554593  3.45714893 3.4602946
 3.46111639 3.46191965 3.46549123 3.47044311 3.47198242 3.47459658
 3.4755271  3.47557879 3.47583745 3.47721759 3.47787503 3.47938607
 3.48206018 3.48244423 3.48406355 3.48449719 3.48556778 3.4857702
 3.48606627 3.48887314 3.4890605  3.49117592 3.4915083  3.49167563
 3.49428468 3.49491518 3.4957659  3.49579797 3.49892456 3.4994577
 3.49991247 3.50229477 3.5043766  3.50679564 3.51134559 3.51171872
 3.51248427 3.51280207 3.5132428  3.51360183 3.5153886  3.51708752
 3.5171483  3.52891318 3.52983208 3.53192147 3.53232349 3.54168133
 3.54758833 3.54915014 3.56387436 3.57080911 3.57795537 3.57945646
 3.62930036 3.80575879 3.84703531 3.90709159 3.90876934 3.91015459
 3.94275658 3.98908305 4.06676675 4.12054834 4.12674318 4.17133079]

  warnings.warn(

2022-12-16 10:38:47,963:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.40410067 2.40609907 2.48777047 2.5679447  2.58632194 2.62983543
 2.68422163 2.69033528 2.73135524 2.74273888 2.7950057  2.80098597
 2.80497579 2.8191852  2.82489863 2.84797175 2.85869474 2.85972739
 2.86205165 2.8706476  2.8750847  2.87514582 2.89333624 2.89656422
 2.89989078 2.91341657 2.91632454 2.93995935 2.94027175 2.95230663
 2.95817304 2.96329317 2.9735724  2.97371367 2.97386301 2.9814026
 2.9817567  2.98228995 2.98427971 2.98614562 2.99078201 2.99092653
 2.992153   2.99237301 2.99425324 2.99439391 2.99447325 2.99465217
 2.99479669 2.995329   2.99536725 2.99547411 2.99551177 2.99584197
 2.99587962 2.99596806 2.99600571 2.99602414 2.99614638 2.99614698
 2.99618463 2.9962915  2.99632915 2.99651808 2.99669701 2.99680387
 2.99684152 2.99729119 2.99884562 3.00024318 3.00038385 3.0004221
 3.00046318 3.00056661 3.00060385 3.0006421  3.00078662 3.00093447
 3.00097555 3.00107228 3.00107899 3.00111623 3.00115448 3.00115684
 3.00129899 3.00158886 3.00162994 3.00177544 3.00180887 3.00223719
 3.00237787 3.00240293 3.00274957 3.00280206 3.0035334  3.00371232
 3.00401108 3.00415176 3.00419001 3.00433452 3.00484807 3.00502699
 3.00559703 3.00641442 3.00645207 3.00696444 3.00706221 3.00718878
 3.00720289 3.00901698 3.01003664 3.010618   3.01079692 3.010838
 3.01101693 3.01130929 3.01135038 3.0115293  3.01183879 3.01261202
 3.01339349 3.01357241 3.01371693 3.01388754 3.01408478 3.0142293
 3.01445744 3.01447655 3.01473917 3.01576404 3.01669464 3.01674374
 3.01761115 3.02305811 3.02366098 3.02428068 3.02445961 3.03623959
 3.0407348  3.04837452 3.05114526 3.05326429 3.05429896 3.05446057
 3.0556241  3.05598973 3.06104861 3.0621238  3.06365809 3.06859023
 3.06902479 3.06957784 3.07009493 3.07702199 3.08395831 3.08396463
 3.08398269 3.08409656 3.09332957 3.09493932 3.09893129 3.10086892
 3.1027574  3.10503449 3.10579586 3.11131649 3.11666547 3.11728993
 3.11734814 3.11841024 3.11863025 3.11987954 3.12138803 3.12549724
 3.12782422 3.12785841 3.1336965  3.13395243 3.13670823 3.14584045
 3.15227939 3.15325745 3.15579928 3.16502331 3.17026854 3.17070438
 3.17085973 3.17415897 3.174805   3.17540782 3.17903583 3.17912776
 3.18174758 3.18193454 3.1831737  3.186793   3.18699055 3.18739689
 3.18786829 3.18846333 3.19007236 3.19030685 3.19058474 3.19076605
 3.19363299 3.19469332 3.19501548 3.19578149 3.19642414 3.1971476
 3.19929549 3.20088631 3.20118892 3.21038097 3.22333378 3.22422145
 3.24812105 3.26197502 3.26474355 3.29751094 3.30223191 3.39818693
 3.39887709 3.40005212 3.40222402 3.40453959 3.40615149 3.40666387
 3.40766095 3.40817332 3.40882771 3.40971824 3.41064314 3.41343845
 3.41590439 3.46438559 3.50299116 3.54670902 3.57211091 3.57427365
 3.61564553 3.61599346 3.6194162  3.62173155 3.63605623 3.65579638
 3.67905562 3.68296401 3.68653841 3.70235964 3.70309761 3.70413081
 3.70688669 3.71104756 3.71207008 3.71288589 3.71836432 3.7234246
 3.73247438 3.73700667 3.73829663 3.73834808 3.73906393 3.74655693
 3.74837924 3.74847989 3.75729505 3.75916912 3.76460519 3.76934151
 3.77160105 3.77599071 3.77980076 3.78183793 3.78481303 3.80311216
 3.83746071 3.86531645 3.90388768 4.05483586 4.08850998 4.22068376]

  warnings.warn(

2022-12-16 10:38:49,067:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.95471316 2.07766098 2.08203959 2.50923441 2.62915288 2.72928301
 2.74910453 2.75049782 2.75060243 2.7526382  2.76619708 2.77065329
 2.77592013 2.79797755 2.80576636 2.80651583 2.81512087 2.81522487
 2.85529211 2.86270062 2.86443776 2.87577324 2.87764868 2.87811759
 2.89717065 2.92096374 2.9243752  2.92914406 2.92920287 2.94052052
 2.9417218  2.94337727 2.94426105 2.94510512 2.94828082 2.94945536
 2.95153265 2.95327361 2.95500146 2.95667196 2.95779122 2.9645267
 2.97398691 2.97509317 2.97682102 2.98094675 2.98372931 2.98402801
 2.98574273 2.98909913 2.9894297  2.99115004 2.99214874 2.99803396
 3.00034959 3.00272774 3.00417307 3.005156   3.00795689 3.0099128
 3.01012575 3.01173601 3.01484852 3.01549557 3.01582615 3.02263989
 3.02313316 3.02443041 3.02476098 3.02626244 3.02754316 3.02912418
 3.03056952 3.03074016 3.03130124 3.03139764 3.03155244 3.032465
 3.03992342 3.04231762 3.0438655  3.04569245 3.05279315 3.05772177
 3.05962883 3.0602863  3.06430302 3.06464788 3.06578296 3.06606195
 3.06899705 3.07081683 3.07091096 3.0785326  3.08121416 3.09604567
 3.11866899 3.12699897 3.13045769 3.14731591 3.16402294 3.19156248
 3.19191519 3.19639671 3.24705755 3.25619821 3.27863726 3.27985965
 3.28254778 3.28740993 3.29522238 3.29758522 3.31892389 3.39100456
 3.39786907 3.4226891  3.43056434 3.43227972 3.43830245 3.45891788
 3.46746107 3.49391754 3.50170153 3.54824131 3.55171794 3.56386401
 3.58490177 3.58538279 3.59826764 3.74538253 3.79202688 3.80691074
 3.81689109 3.85496337 3.87843014 3.87955054 3.88213282 3.89176074
 3.89416463 3.9006169  3.90103479 3.91772929 3.93460636 3.93462672
 3.93740636 3.9408075  3.94151175 3.95137138 3.95748011 3.95871887
 3.96732756 3.97371714 3.97689534 3.9828854  3.98872499 3.99111405
 4.00080852 4.01448767 4.01907408 4.02770911 4.03931371 4.11540584
 4.1740247  4.18080448 4.22754459 4.23752135 4.29660194]

  warnings.warn(

2022-12-16 10:38:49,097:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.77389568 2.77937758 2.83079897 2.92239858 2.93113183 2.93567298
 2.94581807 2.94626925 2.94835984 2.95361721 2.95383391 2.95466021
 2.95485696 2.95600108 2.95818472 2.95889324 2.95901724 2.95941209
 2.95969049 2.95986752 2.96097085 2.96142628 2.96148917 2.96156934
 2.96189978 2.96452059 2.96550038 2.96567741 2.96580142 2.96585682
 2.96603899 2.96746796 2.96837906 2.96850692 2.96868396 2.96880796
 2.96904554 2.96956033 2.96971014 2.96980287 2.97123939 2.97140898
 2.97325292 2.97360981 2.9737834  2.97461012 2.9748477  2.97607507
 2.97621136 2.97635346 2.9765305  2.97664011 2.97688271 2.9769185
 2.97709434 2.97709554 2.97802356 2.97808925 2.97816261 2.97838514
 2.97849186 2.97865429 2.97900945 2.97913345 2.97937103 2.97938119
 2.98005022 2.98217928 2.98230328 2.98254086 2.98376333 2.98400091
 2.98470943 2.98649245 2.98666949 2.98685842 2.98744742 2.98771597
 2.98807755 2.98954932 2.98980399 2.991014   2.99126789 2.99131657
 2.9914936  2.99185518 2.99330308 2.99358148 2.99375851 2.99432311
 2.99450014 2.99486172 2.99531727 2.99736294 2.99910887 2.99942256
 2.99959959 3.00011298 3.0004263  3.00059253 3.00061835 3.00066388
 3.00202754 3.00234857 3.00307974 3.00362736 3.00366271 3.00382916
 3.00383974 3.00420133 3.00426953 3.00482563 3.00494964 3.00518722
 3.00519738 3.00550951 3.00565981 3.00604221 3.00768355 3.00799546
 3.00835705 3.01020038 3.0109221  3.01106371 3.01156999 3.01230864
 3.01248567 3.01284725 3.01351707 3.01423628 3.0145058  3.01487969
 3.01498588 3.01923998 3.02302512 3.02387246 3.02487312 3.02826266
 3.02857001 3.03143573 3.03180828 3.03186066 3.03418445 3.03470454
 3.0348097  3.03507343 3.03558209 3.035598   3.03627687 3.03673206
 3.0371799  3.03730906 3.03783389 3.03862304 3.04019537 3.04021418
 3.04032452 3.0404683  3.04080204 3.04218285 3.04227378 3.04239209
 3.04255173 3.04290822 3.04329929 3.04334775 3.04484027 3.04490059
 3.0450335  3.04676923 3.04795209 3.05685194 3.05833648 3.06013653
 3.0608077  3.06295347 3.06448004 3.07569479 3.07636586 3.07645711
 3.07702358 3.08071464 3.08536106 3.08985377 3.09060705 3.09242621
 3.0956621  3.10176764 3.10861768 3.10954884 3.12177143 3.14041816
 3.1675094  3.25842224 3.27610483 3.31465546 3.38543557 3.85755374
 3.87438772 3.89535119 3.89863766 3.92533347 3.95067195 3.95129952
 3.96208306 3.96515588 4.0013758  4.00942393 4.04176433 4.04474575
 4.06256045 4.10164063 4.14871454 4.15826152 4.20998237 4.30136114]

  warnings.warn(

2022-12-16 10:38:49,098:INFO:Calculating mean and std
2022-12-16 10:38:49,099:INFO:Creating metrics dataframe
2022-12-16 10:38:49,104:INFO:Uploading results into container
2022-12-16 10:38:49,106:INFO:Uploading model into container now
2022-12-16 10:38:49,106:INFO:master_model_container: 33
2022-12-16 10:38:49,107:INFO:display_container: 2
2022-12-16 10:38:49,107:INFO:LGBMRegressor(random_state=5099)
2022-12-16 10:38:49,107:INFO:create_model() successfully completed......................................
2022-12-16 10:38:49,281:WARNING:create_model() for LGBMRegressor(random_state=5099) raised an exception or returned all 0.0, trying without fit_kwargs:
2022-12-16 10:38:49,282:WARNING:Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 795, in compare_models
    assert (
AssertionError

2022-12-16 10:38:49,282:INFO:Initializing create_model()
2022-12-16 10:38:49,282:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002281239F8E0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022810EC8B20>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:38:49,282:INFO:Checking exceptions
2022-12-16 10:38:49,286:INFO:Importing libraries
2022-12-16 10:38:49,287:INFO:Copying training dataset
2022-12-16 10:38:49,292:INFO:Defining folds
2022-12-16 10:38:49,293:INFO:Declaring metric variables
2022-12-16 10:38:49,293:INFO:Importing untrained model
2022-12-16 10:38:49,293:INFO:Light Gradient Boosting Machine Imported successfully
2022-12-16 10:38:49,294:INFO:Starting cross validation
2022-12-16 10:38:49,296:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:38:51,826:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.00134151 2.31525723 2.41492272 2.67351301 2.80907115 2.83456276
 2.84546055 2.84881611 2.85279884 2.88417817 2.9001965  2.90315708
 2.93267047 2.93918423 2.94254291 2.94788497 2.95145071 2.95162122
 2.96498371 2.96631973 2.96852099 2.97020559 2.97030249 2.971583
 2.97158555 2.97162495 2.97168245 2.97240685 2.97604151 2.97641033
 2.97755036 2.97992737 2.9804748  2.98436066 2.98439588 2.98443782
 2.98445756 2.98552248 2.98620938 2.98663065 2.98681655 2.9868585
 2.98828174 2.98832368 2.98834772 2.98842059 2.99033895 2.99070241
 2.99074436 2.99079931 2.99084126 2.99170543 2.9918045  2.9919014
 2.9925643  2.99286725 2.99355415 2.99566845 2.99576535 2.99652025
 2.99729087 2.99783329 2.99804718 2.99808913 2.99814408 2.99818603
 2.99862567 2.99914926 2.99934947 3.00160249 3.00212096 3.00265668
 3.00329489 3.00478757 3.00501532 3.00522127 3.00684773 3.00766107
 3.00903444 3.00907639 3.00953289 3.00958774 3.01130875 3.01250365
 3.0129203  3.01292486 3.01296225 3.01305915 3.0144612  3.01519461
 3.01537715 3.02310379 3.02815893 3.0411422  3.04774186 3.05233796
 3.06356793 3.13739153 3.18190733 3.19534087 3.19548682 3.21716059
 3.26194286 3.26481992 3.27022091 3.27374939 3.27752887 3.29193339
 3.29343793 3.29416501 3.32129926 3.32692079 3.33023641 3.37025465
 3.38174766 3.38211465 3.41494863 3.41511573 3.41765215 3.42465878
 3.42786104 3.46445469 3.48631252 3.48731555 3.5172014  3.52933017
 3.53842864 3.5522789  3.55735339 3.55998469 3.56268421 3.5633847
 3.56377904 3.57074595 3.57221208 3.57426034 3.57660674 3.57758586
 3.57894791 3.58247504 3.58367755 3.58933022 3.58937217 3.58949306
 3.59012699 3.59088848 3.59161032 3.59186461 3.59220704 3.5929712
 3.59333929 3.5936814  3.59372335 3.59385407 3.594752   3.59602289
 3.59623599 3.59795884 3.60161582 3.60481594 3.60656669 3.60715584
 3.60950267 3.61239468 3.62584489 3.62689139 3.63112168 3.6311837
 3.65042728 3.65099335 3.72840665 3.77969185 3.80631036 3.82094043
 3.9565072  3.9741173  4.63448675 4.67244267 4.6762133  4.68088693
 4.68303306 4.68398643 4.68406352 4.68877847 4.69133097 4.71748429
 4.72719099 4.73174746 4.74449652 4.74552711 4.74587868 4.75784718
 4.76373089 4.76935243 4.7791947  4.78518776 4.79384767 4.80191155
 5.48969593]

  warnings.warn(

2022-12-16 10:38:51,893:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.11902167 2.14133103 2.15542714 2.17470151 2.20917261 2.23034395
 2.23039623 2.38224797 2.81011231 2.8690479  2.90477777 2.90810782
 2.91496058 2.91599379 2.92146531 2.92464119 2.94216769 2.94532369
 2.94629794 2.94773015 2.94908862 2.94924489 2.95053683 2.95106626
 2.95151543 2.95203892 2.95259902 2.9545422  2.95501286 2.95576797
 2.9561631  2.95632069 2.95698973 2.95738873 2.9589012  2.95924973
 2.9593591  2.9599192  2.96062552 2.96114901 2.96142791 2.96147366
 2.96364527 2.96412296 2.96770043 2.96793047 2.97045854 2.9754144
 2.97608411 2.97696468 2.97787888 2.98147972 2.98176813 2.98191126
 2.9822173  2.98237499 2.98248745 2.98274079 2.98318725 2.98330089
 2.9846249  2.98523704 2.98549718 2.98571473 2.98602958 2.98610557
 2.98729065 2.98736954 2.98744988 2.98753635 2.98779618 2.98785075
 2.98821282 2.98871464 2.9887999  2.98896609 2.98936944 2.98953748
 2.98981873 2.98997795 2.99006097 2.99006443 2.99037882 2.9904298
 2.99062107 2.99067233 2.99086318 2.99142328 2.99215088 2.99295787
 2.99303491 2.99339126 2.99350675 2.99355048 2.99359501 2.99395135
 2.99461083 2.99517093 2.99713891 2.997699   2.99818336 2.99876752
 3.00127153 3.0017226  3.00175608 3.00217125 3.00316872 3.00449105
 3.00747766 3.00751098 3.01105019 3.01215891 3.01381149 3.01418971
 3.01437158 3.01479785 3.01538411 3.01673145 3.01799252 3.01815175
 3.01823822 3.01855262 3.01871184 3.01891469 3.01895664 3.01905637
 3.0199529  3.02074408 3.02156505 3.02181075 3.02212515 3.02275676
 3.02431238 3.0253127  3.0258728  3.02871387 3.02888523 3.02944533
 3.03558933 3.03817954 3.0395707  3.04175207 3.04459399 3.04660063
 3.04820821 3.04907225 3.05875578 3.0619461  3.07242766 3.07336904
 3.11178362 3.11700023 3.13216545 3.14829917 3.15897079 3.19563592
 3.35655636 3.55854168 3.59642214 3.62067476 3.62236079 3.62780349
 3.63308031 3.6364358  3.63819689 3.64435243 3.64532562 3.64711947
 3.64889499 3.6652302  3.66620325 3.67806743 3.68498085 3.68616008
 3.6878961  3.70012176 3.70244846 3.71142556 3.71146252 3.71384341
 3.71585005 3.71608718 3.72168752 3.72276599 3.73036564 3.73117254
 3.73360931 3.73439361 3.74139298 3.75123994 3.76069154 3.76211814
 3.76247473 3.76578148 3.76671172 3.79276445 3.80036907 3.80908818
 3.81426928 3.81837526 3.81976447 3.82174081 3.83060567 3.83613075
 3.83935526 3.8407074  3.84382199 3.84765363 3.84846681 3.85025317
 3.85302617 3.85333056 3.85884498 3.85999735 3.86341655 3.86573864
 3.86656904 3.86675671 3.86813676 3.86900049 3.88544199 3.89945256
 3.90359473 3.91539379 3.91735579 3.92157737 3.92734885 3.94278281
 3.98650172 3.98740808 4.04666599 4.25110539]

  warnings.warn(

2022-12-16 10:38:51,909:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.25443624 1.40579393 1.46735657 1.52140215 1.54169164 1.56772349
 1.5726553  1.58296478 2.17631937 2.58478008 2.82042023 2.88907267
 2.90121262 2.90434964 2.90897587 2.91256659 2.91302473 2.91313164
 2.91323675 2.91363817 2.91364451 2.91374962 2.91385653 2.91396164
 2.92077208 2.92241985 2.92503165 2.92541836 2.93784223 2.94143836
 2.94474324 2.94502406 2.94655295 2.94973305 2.95289836 2.95307223
 2.95466432 2.95686961 2.95833308 2.96141821 2.96289057 2.96404567
 2.96512975 2.96646512 2.96977532 2.97050021 2.97125147 2.97138346
 2.97210274 2.97282763 2.97654717 2.97721733 2.9772178  2.97732244
 2.97753452 2.97794222 2.97861285 2.98000138 2.98075952 2.98081761
 2.98148409 2.98179248 2.98225956 2.98231263 2.98311442 2.98368884
 2.98426467 2.98583231 2.98592852 2.98603363 2.98659868 2.98670379
 2.98732357 2.98742868 2.98764202 2.98836691 2.98903842 2.98964952
 2.98977878 2.99037441 2.99044894 2.99270818 2.9936322  2.99367462
 2.99367554 2.99387198 2.99409034 2.99430236 2.99432773 2.99434613
 2.99439951 2.99440747 2.99481523 2.99502725 2.99520036 2.99529377
 2.99530167 2.99540678 2.99565851 2.9957958  2.99580819 2.99587052
 2.99602655 2.99659541 2.99719085 2.99724737 2.99782277 2.99797226
 2.99854766 2.99903087 2.99911181 2.99913599 2.99915193 2.99952753
 2.99973243 2.99973955 2.99976492 2.99978197 2.99978332 2.99980734
 2.99984466 3.00010293 3.0001283  3.00019135 3.00019769 3.0003028
 3.00031495 3.00032818 3.00035737 3.00040971 3.00043508 3.00045348
 3.00050686 3.00051482 3.0005402  3.00070046 3.00070422 3.00076675
 3.00077309 3.00079847 3.00091624 3.00092258 3.00098511 3.00102769
 3.00108226 3.00110927 3.0011346  3.00115997 3.00117837 3.00123971
 3.00126508 3.00149798 3.00151731 3.00171    3.00287657 3.00336652
 3.00343982 3.00354673 3.00365184 3.00419631 3.00419652 3.00482405
 3.00533692 3.00545686 3.00554894 3.00566887 3.00591232 3.00674569
 3.00845875 3.00896823 3.01022157 3.01201062 3.01255446 3.01263836
 3.01322462 3.01629537 3.01654622 3.0166125  3.01696553 3.01717755
 3.01720292 3.01728266 3.01790243 3.01792781 3.01800755 3.01814272
 3.01820435 3.02291182 3.02682767 3.0278148  3.02835753 3.02951139
 3.03346136 3.03530236 3.03641037 3.03728221 3.03959113 3.04006481
 3.04031096 3.04107338 3.04250159 3.04338615 3.04539327 3.04568485
 3.04928682 3.04965567 3.05177967 3.05597859 3.05630834 3.05784597
 3.05827424 3.06064892 3.06213221 3.06466068 3.06475248 3.06485703
 3.06513166 3.0666125  3.06692593 3.06697684 3.06875933 3.07076936
 3.0728902  3.07457232 3.07570549 3.07601395 3.07640293 3.07688806
 3.07988568 3.08132288 3.08211004 3.08355343 3.09414493 3.096
 3.09841369 3.10611948 3.13049236 3.14005925 3.14918052 3.15237587
 3.16109681 3.16275857 3.16402537 3.16640644 3.16939343 3.17157811
 3.17321668 3.17654019 3.17709658 3.18634797 3.18759905 3.19124997
 3.19555643 3.19744629 3.19910522 3.20932179 3.21156081 3.21987129
 3.24616156 3.25274004 3.26174992 3.28113218 3.28621256 3.31341096
 3.33905193 3.35390335 3.36007999 3.36394928 3.38686145 3.38759895
 3.39153508 3.41758002 3.42324872 3.42705649 3.48650647 3.53556265
 3.58870451 3.65980959 3.68852836 3.80820127 3.82277595 3.82758774
 3.83340237 3.83401737 3.85367747 3.85889295 3.86411978 3.88177797
 3.88261733 3.88734894 3.90071119 3.91230736 3.91839983 3.92564625
 3.92752553 3.92755344 3.93638784 3.94138766 3.94603194 3.98678539
 4.02464563 4.03601058 4.05430923 4.07801977 4.15327527 4.15418223
 4.18669767]

  warnings.warn(

2022-12-16 10:38:51,947:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.6950307  2.42082077 2.47327883 2.55709104 2.77291499 2.78231289
 2.78241831 2.78807813 2.79200995 2.79626063 2.80347289 2.8243389
 2.83090866 2.83534195 2.83644134 2.83679889 2.8368405  2.84316764
 2.84732613 2.84792634 2.84849432 2.85023128 2.85034887 2.85098586
 2.85345902 2.85833077 2.85953502 2.85985218 2.86158415 2.8622707
 2.8629117  2.86457564 2.865512   2.8708629  2.87860183 2.88166135
 2.8845177  2.88533086 2.89001883 2.89294619 2.90153537 2.90234854
 2.90324965 2.90384032 2.90459489 2.90540805 2.90628036 2.90653863
 2.90702526 2.90789184 2.90834254 2.9099217  2.91043088 2.91276231
 2.91587974 2.9166929  2.91722483 2.91938689 2.91975242 2.9199342
 2.92016434 2.92136962 2.9220953  2.9226869  2.92355631 2.92404294
 2.92536022 2.92634788 2.92710246 2.92750894 2.92766516 2.92841974
 2.92929205 2.93011895 2.93089289 2.93317847 2.9345087  2.9383873
 2.93970458 2.94069224 2.94144682 2.94183868 2.9418533  2.9427641
 2.94352952 2.94736838 2.94878185 2.95041174 2.95089613 2.95338751
 2.95413672 2.96276473 2.96714038 2.97509065 2.9771091  2.97896925
 2.97978241 2.98127419 2.98208735 2.98290108 2.98445914 2.99331361
 2.99369604 2.99380161 2.99412677 2.99447346 2.99637313 2.99643171
 2.99649297 2.99718629 2.99759822 2.9988035  3.00040124 3.00099018
 3.00147682 3.00329512 3.00378176 3.0040497  3.00453634 3.00494281
 3.00540865 3.00581512 3.00645468 3.00755282 3.00865218 3.01582118
 3.01812612 3.0188807  3.01928718 3.01975301 3.02329516 3.03268059
 3.04359008 3.04403206 3.04574344 3.05453475 3.05978616 3.06302644
 3.06572844 3.06665856 3.07023477 3.07370313 3.08101602 3.08510764
 3.08973911 3.09960327 3.10094019 3.10900537 3.11300136 3.11441158
 3.11915582 3.12069302 3.12587754 3.12795408 3.1281467  3.13270456
 3.13468904 3.1377595  3.14003034 3.14236911 3.14368683 3.14617463
 3.1493379  3.1506914  3.15451854 3.15506481 3.15840155 3.16304755
 3.16706714 3.16906131 3.18433996 3.18576354 3.19018697 3.19294452
 3.20091744 3.24673195 3.26236723 3.27197563 3.2852481  3.29470844
 3.29540794 3.31750983 3.31873663 3.32026077 3.32033006 3.32084845
 3.32218277 3.32295986 3.32411094 3.3243491  3.32698807 3.32955692
 3.33043912 3.33147312 3.33346618 3.33579098 3.33893495 3.35103263
 3.35188672 3.35315216 3.3547508  3.35496604 3.35832375 3.35852858
 3.36169926 3.36312936 3.36458535 3.37096509 3.37763605 3.37906898
 3.41617106 3.42626439 3.45891638 3.50424345 3.53493811 3.56712629
 3.57179112 3.57258768 3.58555918 3.60121725 3.62223186 3.62954976
 3.63197423 3.63308692 3.64738879 3.65997397 3.66965432 3.67705545
 3.68312961 3.68749649 3.6928736  3.69814584 3.73470167 3.74315915
 3.75307571 3.76401451 3.7695639  3.78605236 3.80687558 3.88299548
 3.96773865 3.97245416 3.98277571 4.0680357  4.11786744 4.21487288
 4.33150221]

  warnings.warn(

2022-12-16 10:38:52,032:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.75604475 1.99794264 2.9006507  2.95051687 2.96074876 2.96719246
 2.971124   2.97838903 2.98187017 2.98216849 2.98278108 2.98282717
 2.98291721 2.9845533  2.98645701 2.99114956 2.99119565 2.99128568
 2.99455712 2.99469324 2.99482549 2.99560416 2.99565025 2.99574028
 2.99675437 2.99702143 2.99737638 2.99797118 2.99874175 3.0007913
 3.0029256  3.00306172 3.00324942 3.0038826  3.00397264 3.00401872
 3.00410876 3.00552603 3.00557729 3.00574486 3.01493098 3.0177166
 3.01836574 3.0190227  3.02797027 3.02803225 3.03356254 3.03394294
 3.03442499 3.03612117 3.03921791 3.03938313 3.04139566 3.0425322
 3.04638331 3.04795228 3.04846119 3.04976414 3.05033087 3.05163303
 3.05235788 3.05591942 3.06069045 3.06530157 3.07898768 3.08006775
 3.08390612 3.08429522 3.09815261 3.10679039 3.12046405 3.13836566
 3.14037737 3.14193676 3.1437635  3.14383479 3.14958342 3.15503229
 3.16323387 3.16435741 3.16701388 3.18088126 3.18573084 3.18573569
 3.1908277  3.19118749 3.1914691  3.19678572 3.19754732 3.20014672
 3.20508663 3.21142997 3.22067322 3.2267924  3.28504252 3.29069001
 3.35047894 3.35394193 3.36133725 3.36785048 3.36905808 3.37977751
 3.38245089 3.38695391 3.39125704 3.39168834 3.39505591 3.39515975
 3.39735546 3.40325772 3.40394647 3.40431003 3.40436979 3.40446269
 3.41100393 3.41120713 3.41293803 3.41740733 3.41741679 3.4175867
 3.42161567 3.42675331 3.42970452 3.43304212 3.43350272 3.43494791
 3.44255809 3.44782621 3.46762172 3.4726431  3.47516154 3.48904852
 3.50057448 3.50446708 3.53069097 3.55161646 3.58634378 3.60669379
 3.6101299  3.61235266 3.61556053 3.61992637 3.62847533 3.62904843
 3.65329104 3.65337965 3.65669709 3.67899336 3.69674882 3.70938254
 3.71156461 3.73294312 3.73950309 3.74239755 3.7521846  3.75579514
 3.75884653 3.7628065  3.76490056 3.77340682 3.77344225 3.77419136
 3.7747671  3.77534975 3.77778791 3.77836091 3.78024806 3.7806208
 3.78105803 3.78129101 3.78572993 3.78728837 3.78823372 3.7915391
 3.79190965 3.79398211 3.79506099 3.79851365 3.79860662 3.80230966
 3.80357399 3.80418494 3.80951272 3.81259448 3.81528046 3.81748698
 3.82862082 3.83097723 3.83670267 3.84027769 3.84157491 3.84600462
 3.85016979 3.85539101 3.87010553 3.91118655 3.95324637]

  warnings.warn(

2022-12-16 10:38:52,098:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.82294357 2.83581792 2.91056383 2.94383711 2.95194607 2.95839681
 2.96163982 2.96248315 2.97139466 2.97245    2.97591025 2.97676268
 2.98350732 2.98638475 2.98701291 2.98715684 2.98743823 2.98744625
 2.98765913 2.98821032 2.98869714 2.98910326 2.98911128 2.99072774
 2.99073576 2.99088324 2.99276401 2.99314115 2.99330534 2.99342941
 2.99360517 2.99437726 2.99448288 2.9944909  2.99465865 2.99466667
 2.99471248 2.99496587 2.99525497 2.9952702  2.99543074 2.99543876
 2.99615593 2.99632368 2.9963317  2.99674815 2.99830159 2.99836021
 2.99892606 2.9991851  2.9999695  3.00387322 3.00481723 3.01694729
 3.01868309 3.02392483 3.02470471 3.02507019 3.03257538 3.03870207
 3.04304591 3.04642313 3.04725943 3.05369179 3.05527417 3.06203195
 3.06387085 3.06675268 3.0679986  3.07415833 3.07708539 3.08994492
 3.09770798 3.10155773 3.10440545 3.11620761 3.12585534 3.12655106
 3.13231463 3.14098665 3.14794528 3.15783423 3.18502518 3.186031
 3.19038378 3.20315738 3.20531311 3.20584408 3.20836949 3.21242398
 3.21423802 3.22166754 3.22871927 3.23141529 3.23452187 3.28513573
 3.29047311 3.35499171 3.35894327 3.37257704 3.3930535  3.40090926
 3.40290283 3.40454285 3.41273997 3.41288782 3.41470061 3.41774901
 3.42602051 3.42816834 3.42882744 3.4291817  3.43536547 3.43584421
 3.44197109 3.44224617 3.44623794 3.44793963 3.44994914 3.45150145
 3.45166999 3.45257    3.45357823 3.4554593  3.45714893 3.4602946
 3.46111639 3.46191965 3.46549123 3.47044311 3.47198242 3.47459658
 3.4755271  3.47557879 3.47583745 3.47721759 3.47787503 3.47938607
 3.48206018 3.48244423 3.48406355 3.48449719 3.48556778 3.4857702
 3.48606627 3.48887314 3.4890605  3.49117592 3.4915083  3.49167563
 3.49428468 3.49491518 3.4957659  3.49579797 3.49892456 3.4994577
 3.49991247 3.50229477 3.5043766  3.50679564 3.51134559 3.51171872
 3.51248427 3.51280207 3.5132428  3.51360183 3.5153886  3.51708752
 3.5171483  3.52891318 3.52983208 3.53192147 3.53232349 3.54168133
 3.54758833 3.54915014 3.56387436 3.57080911 3.57795537 3.57945646
 3.62930036 3.80575879 3.84703531 3.90709159 3.90876934 3.91015459
 3.94275658 3.98908305 4.06676675 4.12054834 4.12674318 4.17133079]

  warnings.warn(

2022-12-16 10:38:52,113:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.40410067 2.40609907 2.48777047 2.5679447  2.58632194 2.62983543
 2.68422163 2.69033528 2.73135524 2.74273888 2.7950057  2.80098597
 2.80497579 2.8191852  2.82489863 2.84797175 2.85869474 2.85972739
 2.86205165 2.8706476  2.8750847  2.87514582 2.89333624 2.89656422
 2.89989078 2.91341657 2.91632454 2.93995935 2.94027175 2.95230663
 2.95817304 2.96329317 2.9735724  2.97371367 2.97386301 2.9814026
 2.9817567  2.98228995 2.98427971 2.98614562 2.99078201 2.99092653
 2.992153   2.99237301 2.99425324 2.99439391 2.99447325 2.99465217
 2.99479669 2.995329   2.99536725 2.99547411 2.99551177 2.99584197
 2.99587962 2.99596806 2.99600571 2.99602414 2.99614638 2.99614698
 2.99618463 2.9962915  2.99632915 2.99651808 2.99669701 2.99680387
 2.99684152 2.99729119 2.99884562 3.00024318 3.00038385 3.0004221
 3.00046318 3.00056661 3.00060385 3.0006421  3.00078662 3.00093447
 3.00097555 3.00107228 3.00107899 3.00111623 3.00115448 3.00115684
 3.00129899 3.00158886 3.00162994 3.00177544 3.00180887 3.00223719
 3.00237787 3.00240293 3.00274957 3.00280206 3.0035334  3.00371232
 3.00401108 3.00415176 3.00419001 3.00433452 3.00484807 3.00502699
 3.00559703 3.00641442 3.00645207 3.00696444 3.00706221 3.00718878
 3.00720289 3.00901698 3.01003664 3.010618   3.01079692 3.010838
 3.01101693 3.01130929 3.01135038 3.0115293  3.01183879 3.01261202
 3.01339349 3.01357241 3.01371693 3.01388754 3.01408478 3.0142293
 3.01445744 3.01447655 3.01473917 3.01576404 3.01669464 3.01674374
 3.01761115 3.02305811 3.02366098 3.02428068 3.02445961 3.03623959
 3.0407348  3.04837452 3.05114526 3.05326429 3.05429896 3.05446057
 3.0556241  3.05598973 3.06104861 3.0621238  3.06365809 3.06859023
 3.06902479 3.06957784 3.07009493 3.07702199 3.08395831 3.08396463
 3.08398269 3.08409656 3.09332957 3.09493932 3.09893129 3.10086892
 3.1027574  3.10503449 3.10579586 3.11131649 3.11666547 3.11728993
 3.11734814 3.11841024 3.11863025 3.11987954 3.12138803 3.12549724
 3.12782422 3.12785841 3.1336965  3.13395243 3.13670823 3.14584045
 3.15227939 3.15325745 3.15579928 3.16502331 3.17026854 3.17070438
 3.17085973 3.17415897 3.174805   3.17540782 3.17903583 3.17912776
 3.18174758 3.18193454 3.1831737  3.186793   3.18699055 3.18739689
 3.18786829 3.18846333 3.19007236 3.19030685 3.19058474 3.19076605
 3.19363299 3.19469332 3.19501548 3.19578149 3.19642414 3.1971476
 3.19929549 3.20088631 3.20118892 3.21038097 3.22333378 3.22422145
 3.24812105 3.26197502 3.26474355 3.29751094 3.30223191 3.39818693
 3.39887709 3.40005212 3.40222402 3.40453959 3.40615149 3.40666387
 3.40766095 3.40817332 3.40882771 3.40971824 3.41064314 3.41343845
 3.41590439 3.46438559 3.50299116 3.54670902 3.57211091 3.57427365
 3.61564553 3.61599346 3.6194162  3.62173155 3.63605623 3.65579638
 3.67905562 3.68296401 3.68653841 3.70235964 3.70309761 3.70413081
 3.70688669 3.71104756 3.71207008 3.71288589 3.71836432 3.7234246
 3.73247438 3.73700667 3.73829663 3.73834808 3.73906393 3.74655693
 3.74837924 3.74847989 3.75729505 3.75916912 3.76460519 3.76934151
 3.77160105 3.77599071 3.77980076 3.78183793 3.78481303 3.80311216
 3.83746071 3.86531645 3.90388768 4.05483586 4.08850998 4.22068376]

  warnings.warn(

2022-12-16 10:38:52,123:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.9631439  2.40344948 2.47898978 2.74952015 2.76715263 2.80352265
 2.83030513 2.85870696 2.9053047  2.93688908 2.94319057 2.96701351
 2.9717475  2.97490694 2.97498359 2.97498963 2.97499317 2.97504859
 2.97505213 2.97505463 2.97505817 2.9751751  2.97518115 2.97532633
 2.97532884 2.97533238 2.9755792  2.9785284  2.98008138 2.98014638
 2.98110894 2.99193561 2.99194166 2.99264976 2.99442414 2.99491025
 2.99512043 2.99512294 2.99539715 2.99565701 2.99578728 3.00278452
 3.00279056 3.0027941  3.00284952 3.00285305 3.00285556 3.0028591
 3.00290582 3.00293221 3.00293825 3.00294179 3.00299721 3.00300075
 3.00300325 3.00300679 3.00312977 3.00327142 3.00327495 3.00327746
 3.003281   3.00586724 3.00860332 3.01014035 3.01579588 3.01635914
 3.01908712 3.01936132 3.01962266 3.01968766 3.01969094 3.01996187
 3.0199943  3.01999783 3.02052984 3.02059484 3.02059838 3.02072489
 3.02086905 3.02127624 3.02133166 3.02133771 3.02134124 3.02146804
 3.02160587 3.02274448 3.02580246 3.02722287 3.0301808  3.03041666
 3.03128771 3.0343493  3.03663799 3.03838822 3.03843029 3.03892929
 3.04103202 3.0419812  3.04220868 3.04654802 3.04682304 3.04703574
 3.04713245 3.04730994 3.04731348 3.04742713 3.04748859 3.04757128
 3.04757482 3.04763628 3.04763982 3.04791049 3.04791402 3.05378796
 3.05853559 3.0621265  3.06836219 3.06926217 3.07020082 3.073352
 3.09344823 3.10149979 3.12908404 3.13009675 3.13033866 3.13283666
 3.1376847  3.13954944 3.13973558 3.1402764  3.14731423 3.26054443
 3.32800995 3.33883714 3.34616834 3.35491224 3.35777158 3.36000931
 3.36133662 3.36408761 3.36657181 3.38160945 3.38387408 3.38532988
 3.38585252 3.39134925 3.39278053 3.39352743 3.40399192 3.40611784
 3.41087979 3.41183487 3.42007891 3.42280689 3.42314572 3.43056189
 3.43083609 3.43085096 3.43113127 3.43122556 3.4375265  3.44050415
 3.44185847 3.4483123  3.44844867 3.44856435 3.44899045 3.44991158
 3.45145141 3.45835147 3.4585588  3.45944854 3.46235726 3.46314133
 3.4648455  3.46486962 3.46503793 3.46592119 3.4664708  3.46986547
 3.47000183 3.47113978 3.47257912 3.47377138 3.47379218 3.47635555
 3.47640624 3.47894738 3.48476516 3.48635223 3.48680246 3.48742068
 3.48837913 3.4908242  3.49402681 3.52488454 3.53514351 3.54164325
 3.54841281 3.55540021 3.56136734 3.56783775 3.57256544 3.58633429
 3.58776975 3.59163063 3.59755767 3.61561072 3.62002726 3.62750338
 3.63575663 3.64577261 3.65097634 3.65273604 3.65490322 3.65857202
 3.66043436 3.66592738 3.67347045 3.67417463 3.69949283 3.70378236
 3.70621897 3.70926942 3.71921734 3.79083448 3.91463688 3.98620875
 4.08713551]

  warnings.warn(

2022-12-16 10:38:53,202:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [1.95471316 2.07766098 2.08203959 2.50923441 2.62915288 2.72928301
 2.74910453 2.75049782 2.75060243 2.7526382  2.76619708 2.77065329
 2.77592013 2.79797755 2.80576636 2.80651583 2.81512087 2.81522487
 2.85529211 2.86270062 2.86443776 2.87577324 2.87764868 2.87811759
 2.89717065 2.92096374 2.9243752  2.92914406 2.92920287 2.94052052
 2.9417218  2.94337727 2.94426105 2.94510512 2.94828082 2.94945536
 2.95153265 2.95327361 2.95500146 2.95667196 2.95779122 2.9645267
 2.97398691 2.97509317 2.97682102 2.98094675 2.98372931 2.98402801
 2.98574273 2.98909913 2.9894297  2.99115004 2.99214874 2.99803396
 3.00034959 3.00272774 3.00417307 3.005156   3.00795689 3.0099128
 3.01012575 3.01173601 3.01484852 3.01549557 3.01582615 3.02263989
 3.02313316 3.02443041 3.02476098 3.02626244 3.02754316 3.02912418
 3.03056952 3.03074016 3.03130124 3.03139764 3.03155244 3.032465
 3.03992342 3.04231762 3.0438655  3.04569245 3.05279315 3.05772177
 3.05962883 3.0602863  3.06430302 3.06464788 3.06578296 3.06606195
 3.06899705 3.07081683 3.07091096 3.0785326  3.08121416 3.09604567
 3.11866899 3.12699897 3.13045769 3.14731591 3.16402294 3.19156248
 3.19191519 3.19639671 3.24705755 3.25619821 3.27863726 3.27985965
 3.28254778 3.28740993 3.29522238 3.29758522 3.31892389 3.39100456
 3.39786907 3.4226891  3.43056434 3.43227972 3.43830245 3.45891788
 3.46746107 3.49391754 3.50170153 3.54824131 3.55171794 3.56386401
 3.58490177 3.58538279 3.59826764 3.74538253 3.79202688 3.80691074
 3.81689109 3.85496337 3.87843014 3.87955054 3.88213282 3.89176074
 3.89416463 3.9006169  3.90103479 3.91772929 3.93460636 3.93462672
 3.93740636 3.9408075  3.94151175 3.95137138 3.95748011 3.95871887
 3.96732756 3.97371714 3.97689534 3.9828854  3.98872499 3.99111405
 4.00080852 4.01448767 4.01907408 4.02770911 4.03931371 4.11540584
 4.1740247  4.18080448 4.22754459 4.23752135 4.29660194]

  warnings.warn(

2022-12-16 10:38:53,211:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [2.77389568 2.77937758 2.83079897 2.92239858 2.93113183 2.93567298
 2.94581807 2.94626925 2.94835984 2.95361721 2.95383391 2.95466021
 2.95485696 2.95600108 2.95818472 2.95889324 2.95901724 2.95941209
 2.95969049 2.95986752 2.96097085 2.96142628 2.96148917 2.96156934
 2.96189978 2.96452059 2.96550038 2.96567741 2.96580142 2.96585682
 2.96603899 2.96746796 2.96837906 2.96850692 2.96868396 2.96880796
 2.96904554 2.96956033 2.96971014 2.96980287 2.97123939 2.97140898
 2.97325292 2.97360981 2.9737834  2.97461012 2.9748477  2.97607507
 2.97621136 2.97635346 2.9765305  2.97664011 2.97688271 2.9769185
 2.97709434 2.97709554 2.97802356 2.97808925 2.97816261 2.97838514
 2.97849186 2.97865429 2.97900945 2.97913345 2.97937103 2.97938119
 2.98005022 2.98217928 2.98230328 2.98254086 2.98376333 2.98400091
 2.98470943 2.98649245 2.98666949 2.98685842 2.98744742 2.98771597
 2.98807755 2.98954932 2.98980399 2.991014   2.99126789 2.99131657
 2.9914936  2.99185518 2.99330308 2.99358148 2.99375851 2.99432311
 2.99450014 2.99486172 2.99531727 2.99736294 2.99910887 2.99942256
 2.99959959 3.00011298 3.0004263  3.00059253 3.00061835 3.00066388
 3.00202754 3.00234857 3.00307974 3.00362736 3.00366271 3.00382916
 3.00383974 3.00420133 3.00426953 3.00482563 3.00494964 3.00518722
 3.00519738 3.00550951 3.00565981 3.00604221 3.00768355 3.00799546
 3.00835705 3.01020038 3.0109221  3.01106371 3.01156999 3.01230864
 3.01248567 3.01284725 3.01351707 3.01423628 3.0145058  3.01487969
 3.01498588 3.01923998 3.02302512 3.02387246 3.02487312 3.02826266
 3.02857001 3.03143573 3.03180828 3.03186066 3.03418445 3.03470454
 3.0348097  3.03507343 3.03558209 3.035598   3.03627687 3.03673206
 3.0371799  3.03730906 3.03783389 3.03862304 3.04019537 3.04021418
 3.04032452 3.0404683  3.04080204 3.04218285 3.04227378 3.04239209
 3.04255173 3.04290822 3.04329929 3.04334775 3.04484027 3.04490059
 3.0450335  3.04676923 3.04795209 3.05685194 3.05833648 3.06013653
 3.0608077  3.06295347 3.06448004 3.07569479 3.07636586 3.07645711
 3.07702358 3.08071464 3.08536106 3.08985377 3.09060705 3.09242621
 3.0956621  3.10176764 3.10861768 3.10954884 3.12177143 3.14041816
 3.1675094  3.25842224 3.27610483 3.31465546 3.38543557 3.85755374
 3.87438772 3.89535119 3.89863766 3.92533347 3.95067195 3.95129952
 3.96208306 3.96515588 4.0013758  4.00942393 4.04176433 4.04474575
 4.06256045 4.10164063 4.14871454 4.15826152 4.20998237 4.30136114]

  warnings.warn(

2022-12-16 10:38:53,213:INFO:Calculating mean and std
2022-12-16 10:38:53,214:INFO:Creating metrics dataframe
2022-12-16 10:38:53,219:INFO:Uploading results into container
2022-12-16 10:38:53,219:INFO:Uploading model into container now
2022-12-16 10:38:53,220:INFO:master_model_container: 34
2022-12-16 10:38:53,220:INFO:display_container: 2
2022-12-16 10:38:53,221:INFO:LGBMRegressor(random_state=5099)
2022-12-16 10:38:53,221:INFO:create_model() successfully completed......................................
2022-12-16 10:38:53,386:ERROR:create_model() for LGBMRegressor(random_state=5099) raised an exception or returned all 0.0:
2022-12-16 10:38:53,387:ERROR:Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 795, in compare_models
    assert (
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 811, in compare_models
    assert (
AssertionError

2022-12-16 10:38:53,387:INFO:Initializing Dummy Regressor
2022-12-16 10:38:53,387:INFO:Total runtime is 2.935481981436412 minutes
2022-12-16 10:38:53,387:INFO:SubProcess create_model() called ==================================
2022-12-16 10:38:53,388:INFO:Initializing create_model()
2022-12-16 10:38:53,388:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002281239F8E0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022810EC8B20>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:38:53,389:INFO:Checking exceptions
2022-12-16 10:38:53,394:INFO:Importing libraries
2022-12-16 10:38:53,395:INFO:Copying training dataset
2022-12-16 10:38:53,400:INFO:Defining folds
2022-12-16 10:38:53,400:INFO:Declaring metric variables
2022-12-16 10:38:53,400:INFO:Importing untrained model
2022-12-16 10:38:53,400:INFO:Dummy Regressor Imported successfully
2022-12-16 10:38:53,401:INFO:Starting cross validation
2022-12-16 10:38:53,403:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:38:55,493:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.26859131]

  warnings.warn(

2022-12-16 10:38:55,509:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.27146172]

  warnings.warn(

2022-12-16 10:38:55,525:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.2657559]

  warnings.warn(

2022-12-16 10:38:55,533:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.25673412]

  warnings.warn(

2022-12-16 10:38:55,639:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.26446707]

  warnings.warn(

2022-12-16 10:38:55,674:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.27104008]

  warnings.warn(

2022-12-16 10:38:55,694:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.26214718]

  warnings.warn(

2022-12-16 10:38:55,711:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.26511148]

  warnings.warn(

2022-12-16 10:38:56,721:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.26562701]

  warnings.warn(

2022-12-16 10:38:56,727:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.26072948]

  warnings.warn(

2022-12-16 10:38:56,728:INFO:Calculating mean and std
2022-12-16 10:38:56,729:INFO:Creating metrics dataframe
2022-12-16 10:38:56,733:INFO:Uploading results into container
2022-12-16 10:38:56,735:INFO:Uploading model into container now
2022-12-16 10:38:56,735:INFO:master_model_container: 35
2022-12-16 10:38:56,735:INFO:display_container: 2
2022-12-16 10:38:56,736:INFO:DummyRegressor()
2022-12-16 10:38:56,736:INFO:create_model() successfully completed......................................
2022-12-16 10:38:56,931:WARNING:create_model() for DummyRegressor() raised an exception or returned all 0.0, trying without fit_kwargs:
2022-12-16 10:38:56,931:WARNING:Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 795, in compare_models
    assert (
AssertionError

2022-12-16 10:38:56,932:INFO:Initializing create_model()
2022-12-16 10:38:56,932:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002281239F8E0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022810EC8B20>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:38:56,932:INFO:Checking exceptions
2022-12-16 10:38:56,937:INFO:Importing libraries
2022-12-16 10:38:56,937:INFO:Copying training dataset
2022-12-16 10:38:56,946:INFO:Defining folds
2022-12-16 10:38:56,946:INFO:Declaring metric variables
2022-12-16 10:38:56,947:INFO:Importing untrained model
2022-12-16 10:38:56,947:INFO:Dummy Regressor Imported successfully
2022-12-16 10:38:56,947:INFO:Starting cross validation
2022-12-16 10:38:56,950:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:38:59,123:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.27146172]

  warnings.warn(

2022-12-16 10:38:59,148:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.26859131]

  warnings.warn(

2022-12-16 10:38:59,199:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.2657559]

  warnings.warn(

2022-12-16 10:38:59,206:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.25673412]

  warnings.warn(

2022-12-16 10:38:59,353:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.27104008]

  warnings.warn(

2022-12-16 10:38:59,407:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.26511148]

  warnings.warn(

2022-12-16 10:38:59,409:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.26446707]

  warnings.warn(

2022-12-16 10:38:59,433:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.26214718]

  warnings.warn(

2022-12-16 10:39:00,648:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.26562701]

  warnings.warn(

2022-12-16 10:39:00,672:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 74, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 106, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 261, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 251, in predict
    y = _inverse_transform_one(transformer, y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 82, in _inverse_transform_one
    return transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 262, in inverse_transform
    output = self.transformer.inverse_transform(y)
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\preprocessing\_label.py", line 161, in inverse_transform
    raise ValueError("y contains previously unseen labels: %s" % str(diff))
ValueError: y contains previously unseen labels: [3.26072948]

  warnings.warn(

2022-12-16 10:39:00,673:INFO:Calculating mean and std
2022-12-16 10:39:00,674:INFO:Creating metrics dataframe
2022-12-16 10:39:00,678:INFO:Uploading results into container
2022-12-16 10:39:00,679:INFO:Uploading model into container now
2022-12-16 10:39:00,679:INFO:master_model_container: 36
2022-12-16 10:39:00,679:INFO:display_container: 2
2022-12-16 10:39:00,680:INFO:DummyRegressor()
2022-12-16 10:39:00,680:INFO:create_model() successfully completed......................................
2022-12-16 10:39:00,844:ERROR:create_model() for DummyRegressor() raised an exception or returned all 0.0:
2022-12-16 10:39:00,844:ERROR:Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 795, in compare_models
    assert (
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 811, in compare_models
    assert (
AssertionError

2022-12-16 10:39:00,845:INFO:master_model_container: 36
2022-12-16 10:39:00,846:INFO:display_container: 2
2022-12-16 10:39:00,846:INFO:[]
2022-12-16 10:39:00,846:INFO:compare_models() successfully completed......................................
2022-12-16 10:39:00,879:INFO:Initializing save_model()
2022-12-16 10:39:00,879:INFO:save_model(model=[], model_name=save_model, prep_pipe_=Pipeline(memory=Memory(location=C:\Users\S_05_\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Accident_severity'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Age_band_of_driver',
                                             'Sex_of_driver',
                                             'Veh...
                                    transformer=LeaveOneOutEncoder(cols=['Driving_experience',
                                                                         'Lanes_or_Medians',
                                                                         'Types_of_Junction',
                                                                         'Road_surface_type',
                                                                         'Weather_conditions',
                                                                         'Type_of_collision',
                                                                         'Vehicle_movement',
                                                                         'Pedestrian_movement',
                                                                         'Cause_of_accident'],
                                                                   handle_missing='return_nan',
                                                                   random_state=5099))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2022-12-16 10:39:00,879:INFO:Adding model into prep_pipe
2022-12-16 10:39:00,920:INFO:save_model.pkl saved in current working directory
2022-12-16 10:39:00,943:INFO:Pipeline(memory=Memory(location=C:\Users\S_05_\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Accident_severity'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Age_band_of_driver',
                                             'Sex_of_driver',
                                             'Veh...
                                    transformer=LeaveOneOutEncoder(cols=['Driving_experience',
                                                                         'Lanes_or_Medians',
                                                                         'Types_of_Junction',
                                                                         'Road_surface_type',
                                                                         'Weather_conditions',
                                                                         'Type_of_collision',
                                                                         'Vehicle_movement',
                                                                         'Pedestrian_movement',
                                                                         'Cause_of_accident'],
                                                                   handle_missing='return_nan',
                                                                   random_state=5099))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0))),
                ('trained_model', [])])
2022-12-16 10:39:00,943:INFO:save_model() successfully completed......................................
2022-12-16 10:41:01,024:INFO:PyCaret ClassificationExperiment
2022-12-16 10:41:01,025:INFO:Logging name: clf-default-name
2022-12-16 10:41:01,025:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2022-12-16 10:41:01,025:INFO:version 3.0.0.rc4
2022-12-16 10:41:01,025:INFO:Initializing setup()
2022-12-16 10:41:01,025:INFO:self.USI: ff24
2022-12-16 10:41:01,026:INFO:self.variable_keys: {'fix_imbalance', 'fold_groups_param', 'fold_shuffle_param', '_ml_usecase', 'display_container', 'n_jobs_param', 'exp_name_log', 'target_param', 'pipeline', 'seed', 'exp_id', '_all_models_internal', 'X_test', 'X_train', '_all_metrics', 'gpu_param', 'y_train', 'y_test', '_is_multiclass', 'y', 'logging_param', 'master_model_container', '_available_plots', 'html_param', 'X', '_all_models', 'memory', 'USI', 'log_plots_param', '_gpu_n_jobs_param', 'variable_keys', 'idx', 'fold_generator', 'data'}
2022-12-16 10:41:01,026:INFO:Checking environment
2022-12-16 10:41:01,026:INFO:python_version: 3.10.7
2022-12-16 10:41:01,026:INFO:python_build: ('tags/v3.10.7:6cc6b13', 'Sep  5 2022 14:08:36')
2022-12-16 10:41:01,026:INFO:machine: AMD64
2022-12-16 10:41:01,026:INFO:platform: Windows-10-10.0.22621-SP0
2022-12-16 10:41:01,026:INFO:Memory: svmem(total=8361132032, available=1056264192, percent=87.4, used=7304867840, free=1056264192)
2022-12-16 10:41:01,026:INFO:Physical Core: 4
2022-12-16 10:41:01,026:INFO:Logical Core: 8
2022-12-16 10:41:01,026:INFO:Checking libraries
2022-12-16 10:41:01,026:INFO:System:
2022-12-16 10:41:01,026:INFO:    python: 3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]
2022-12-16 10:41:01,026:INFO:executable: C:\Users\S_05_\AppData\Local\Programs\Python\Python310\python.exe
2022-12-16 10:41:01,026:INFO:   machine: Windows-10-10.0.22621-SP0
2022-12-16 10:41:01,026:INFO:PyCaret required dependencies:
2022-12-16 10:41:01,027:INFO:                 pip: 22.3.1
2022-12-16 10:41:01,027:INFO:          setuptools: 63.2.0
2022-12-16 10:41:01,027:INFO:             pycaret: 3.0.0rc4
2022-12-16 10:41:01,027:INFO:             IPython: 8.6.0
2022-12-16 10:41:01,027:INFO:          ipywidgets: 8.0.3
2022-12-16 10:41:01,027:INFO:                tqdm: 4.64.1
2022-12-16 10:41:01,027:INFO:               numpy: 1.22.4
2022-12-16 10:41:01,028:INFO:              pandas: 1.4.4
2022-12-16 10:41:01,028:INFO:              jinja2: 3.1.2
2022-12-16 10:41:01,028:INFO:               scipy: 1.8.1
2022-12-16 10:41:01,028:INFO:              joblib: 1.2.0
2022-12-16 10:41:01,028:INFO:             sklearn: 1.1.3
2022-12-16 10:41:01,028:INFO:                pyod: 1.0.6
2022-12-16 10:41:01,028:INFO:            imblearn: 0.10.0
2022-12-16 10:41:01,028:INFO:   category_encoders: 2.5.1.post0
2022-12-16 10:41:01,029:INFO:            lightgbm: 3.3.3
2022-12-16 10:41:01,029:INFO:               numba: 0.55.2
2022-12-16 10:41:01,029:INFO:            requests: 2.28.1
2022-12-16 10:41:01,029:INFO:          matplotlib: 3.6.2
2022-12-16 10:41:01,029:INFO:          scikitplot: 0.3.7
2022-12-16 10:41:01,029:INFO:         yellowbrick: 1.5
2022-12-16 10:41:01,029:INFO:              plotly: 5.11.0
2022-12-16 10:41:01,029:INFO:             kaleido: 0.2.1
2022-12-16 10:41:01,029:INFO:         statsmodels: 0.13.5
2022-12-16 10:41:01,029:INFO:              sktime: 0.13.4
2022-12-16 10:41:01,029:INFO:               tbats: 1.1.2
2022-12-16 10:41:01,029:INFO:            pmdarima: 1.8.5
2022-12-16 10:41:01,029:INFO:              psutil: 5.9.3
2022-12-16 10:41:01,029:INFO:PyCaret optional dependencies:
2022-12-16 10:41:01,030:INFO:                shap: Not installed
2022-12-16 10:41:01,030:INFO:           interpret: Not installed
2022-12-16 10:41:01,030:INFO:                umap: Not installed
2022-12-16 10:41:01,030:INFO:    pandas_profiling: 3.5.0
2022-12-16 10:41:01,030:INFO:  explainerdashboard: Not installed
2022-12-16 10:41:01,030:INFO:             autoviz: Not installed
2022-12-16 10:41:01,030:INFO:           fairlearn: Not installed
2022-12-16 10:41:01,030:INFO:             xgboost: Not installed
2022-12-16 10:41:01,030:INFO:            catboost: Not installed
2022-12-16 10:41:01,030:INFO:              kmodes: Not installed
2022-12-16 10:41:01,031:INFO:             mlxtend: Not installed
2022-12-16 10:41:01,031:INFO:       statsforecast: Not installed
2022-12-16 10:41:01,031:INFO:        tune_sklearn: Not installed
2022-12-16 10:41:01,031:INFO:                 ray: Not installed
2022-12-16 10:41:01,031:INFO:            hyperopt: Not installed
2022-12-16 10:41:01,031:INFO:              optuna: Not installed
2022-12-16 10:41:01,031:INFO:               skopt: Not installed
2022-12-16 10:41:01,031:INFO:              mlflow: Not installed
2022-12-16 10:41:01,031:INFO:              gradio: Not installed
2022-12-16 10:41:01,031:INFO:             fastapi: Not installed
2022-12-16 10:41:01,031:INFO:             uvicorn: Not installed
2022-12-16 10:41:01,032:INFO:              m2cgen: Not installed
2022-12-16 10:41:01,032:INFO:           evidently: Not installed
2022-12-16 10:41:01,032:INFO:                nltk: Not installed
2022-12-16 10:41:01,032:INFO:            pyLDAvis: Not installed
2022-12-16 10:41:01,032:INFO:              gensim: Not installed
2022-12-16 10:41:01,032:INFO:               spacy: Not installed
2022-12-16 10:41:01,032:INFO:           wordcloud: Not installed
2022-12-16 10:41:01,032:INFO:            textblob: Not installed
2022-12-16 10:41:01,032:INFO:               fugue: Not installed
2022-12-16 10:41:01,032:INFO:           streamlit: 1.15.2
2022-12-16 10:41:01,032:INFO:             prophet: Not installed
2022-12-16 10:41:01,032:INFO:None
2022-12-16 10:41:01,033:INFO:Set up data.
2022-12-16 10:41:01,084:INFO:Set up train/test split.
2022-12-16 10:41:01,124:INFO:Set up index.
2022-12-16 10:41:01,125:INFO:Assigning column types.
2022-12-16 10:41:01,130:INFO:Set up folding strategy.
2022-12-16 10:41:01,131:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-12-16 10:41:01,208:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-16 10:41:01,220:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2022-12-16 10:41:01,264:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:41:01,266:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:41:01,351:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-16 10:41:01,352:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2022-12-16 10:41:01,382:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:41:01,383:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:41:01,383:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-12-16 10:41:01,487:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2022-12-16 10:41:01,521:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:41:01,521:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:41:01,569:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2022-12-16 10:41:01,606:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:41:01,607:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:41:01,607:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2022-12-16 10:41:01,700:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:41:01,700:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:41:01,782:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:41:01,783:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:41:01,784:INFO:Preparing preprocessing pipeline...
2022-12-16 10:41:01,785:INFO:Set up label encoding.
2022-12-16 10:41:01,785:INFO:Set up simple imputation.
2022-12-16 10:41:01,790:INFO:Set up encoding of categorical features.
2022-12-16 10:41:01,790:INFO:Set up variance threshold.
2022-12-16 10:41:04,327:INFO:Finished creating preprocessing pipeline.
2022-12-16 10:41:04,341:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\S_05_\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=['Accident_severity'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_val...
                                                                         'Weather_conditions',
                                                                         'Type_of_collision',
                                                                         'Vehicle_movement',
                                                                         'Pedestrian_movement',
                                                                         'Cause_of_accident'],
                                                                   drop_invariant=False,
                                                                   handle_missing='return_nan',
                                                                   handle_unknown='value',
                                                                   random_state=1931,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('low_variance',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=VarianceThreshold(threshold=0)))],
         verbose=False)
2022-12-16 10:41:04,341:INFO:Creating final display dataframe.
2022-12-16 10:41:13,495:INFO:Setup display_container:                     Description                                        Value
0                    Session id                                         1931
1                        Target                      Vehicle_driver_relation
2                   Target type                                   Multiclass
3                Target mapping  Employee: 0, Other: 1, Owner: 2, Unknown: 3
4           Original data shape                                  (12316, 15)
5        Transformed data shape                                  (12316, 24)
6   Transformed train set shape                                   (8621, 24)
7    Transformed test set shape                                   (3695, 24)
8              Numeric features                                            1
9          Categorical features                                           13
10                   Preprocess                                         True
11              Imputation type                                       simple
12           Numeric imputation                                         mean
13       Categorical imputation                                     constant
14     Maximum one-hot encoding                                            5
15              Encoding method                                         None
16       Low variance threshold                                            0
17               Fold Generator                              StratifiedKFold
18                  Fold Number                                           10
19                     CPU Jobs                                           -1
20                      Use GPU                                        False
21               Log Experiment                                        False
22              Experiment Name                             clf-default-name
23                          USI                                         ff24
2022-12-16 10:41:13,593:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:41:13,593:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:41:13,668:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:41:13,669:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 10:41:13,679:INFO:setup() successfully completed in 12.66s...............
2022-12-16 10:41:13,684:INFO:Initializing compare_models()
2022-12-16 10:41:13,684:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002281239E9B0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002281239E9B0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2022-12-16 10:41:13,684:INFO:Checking exceptions
2022-12-16 10:41:13,695:INFO:Preparing display monitor
2022-12-16 10:41:13,698:INFO:Initializing Logistic Regression
2022-12-16 10:41:13,698:INFO:Total runtime is 0.0 minutes
2022-12-16 10:41:13,699:INFO:SubProcess create_model() called ==================================
2022-12-16 10:41:13,699:INFO:Initializing create_model()
2022-12-16 10:41:13,699:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002281239E9B0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002280DD28280>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:41:13,699:INFO:Checking exceptions
2022-12-16 10:41:13,706:INFO:Importing libraries
2022-12-16 10:41:13,706:INFO:Copying training dataset
2022-12-16 10:41:13,713:INFO:Defining folds
2022-12-16 10:41:13,713:INFO:Declaring metric variables
2022-12-16 10:41:13,714:INFO:Importing untrained model
2022-12-16 10:41:13,714:INFO:Logistic Regression Imported successfully
2022-12-16 10:41:13,715:INFO:Starting cross validation
2022-12-16 10:41:13,721:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:41:14,799:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-12-16 10:41:14,832:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-12-16 10:41:15,212:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-12-16 10:41:15,563:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 1.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-12-16 10:41:15,595:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 1.26s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-12-16 10:41:15,646:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 1.31s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-12-16 10:41:15,822:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 1.47s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-12-16 10:41:18,440:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-12-16 10:41:18,467:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-12-16 10:41:18,469:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-12-16 10:41:18,499:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-12-16 10:41:18,772:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-12-16 10:41:18,792:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-12-16 10:41:18,893:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-12-16 10:41:18,907:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-12-16 10:41:20,882:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 1.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-12-16 10:41:20,956:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-12-16 10:41:21,174:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-12-16 10:41:21,356:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-12-16 10:41:21,366:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 1.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-12-16 10:41:21,500:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-12-16 10:41:21,665:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-12-16 10:41:21,670:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-12-16 10:41:25,933:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:25,946:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:25,954:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:41:25,960:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:26,015:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:26,028:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:26,035:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:41:26,041:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:26,337:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:26,350:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:26,355:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:41:26,360:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:26,405:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:26,419:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:26,424:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:26,425:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:41:26,429:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:26,436:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:26,440:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:41:26,444:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:26,525:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:26,545:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:26,551:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:41:26,556:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:26,616:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:26,623:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:26,627:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:41:26,634:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:26,778:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:26,790:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:26,797:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:41:26,804:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:30,747:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:30,751:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:30,753:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:41:30,754:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:30,783:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:30,786:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:30,788:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:41:30,789:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:30,795:INFO:Calculating mean and std
2022-12-16 10:41:30,796:INFO:Creating metrics dataframe
2022-12-16 10:41:30,799:INFO:Uploading results into container
2022-12-16 10:41:30,799:INFO:Uploading model into container now
2022-12-16 10:41:30,800:INFO:master_model_container: 1
2022-12-16 10:41:30,800:INFO:display_container: 2
2022-12-16 10:41:30,800:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1931, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2022-12-16 10:41:30,800:INFO:create_model() successfully completed......................................
2022-12-16 10:41:30,938:INFO:SubProcess create_model() end ==================================
2022-12-16 10:41:30,939:INFO:Creating metrics dataframe
2022-12-16 10:41:30,946:INFO:Initializing K Neighbors Classifier
2022-12-16 10:41:30,946:INFO:Total runtime is 0.28745691378911337 minutes
2022-12-16 10:41:30,946:INFO:SubProcess create_model() called ==================================
2022-12-16 10:41:30,946:INFO:Initializing create_model()
2022-12-16 10:41:30,946:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002281239E9B0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002280DD28280>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:41:30,946:INFO:Checking exceptions
2022-12-16 10:41:30,949:INFO:Importing libraries
2022-12-16 10:41:30,949:INFO:Copying training dataset
2022-12-16 10:41:30,953:INFO:Defining folds
2022-12-16 10:41:30,953:INFO:Declaring metric variables
2022-12-16 10:41:30,953:INFO:Importing untrained model
2022-12-16 10:41:30,954:INFO:K Neighbors Classifier Imported successfully
2022-12-16 10:41:30,954:INFO:Starting cross validation
2022-12-16 10:41:30,955:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:41:35,550:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:35,563:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:35,569:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:41:35,576:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:35,633:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:35,646:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:35,664:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:35,716:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:35,731:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:35,740:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:41:35,761:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:35,790:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:35,807:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:35,818:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:35,888:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:35,889:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:35,902:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:35,903:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:35,908:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:41:35,909:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:41:35,919:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:35,926:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:36,025:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:36,042:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:36,049:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:41:36,056:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:36,065:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:36,080:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:36,087:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:41:36,094:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:37,896:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:37,908:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:37,913:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:41:37,918:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:37,958:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:37,968:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:37,974:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:41:37,977:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:37,993:INFO:Calculating mean and std
2022-12-16 10:41:37,995:INFO:Creating metrics dataframe
2022-12-16 10:41:38,003:INFO:Uploading results into container
2022-12-16 10:41:38,005:INFO:Uploading model into container now
2022-12-16 10:41:38,005:INFO:master_model_container: 2
2022-12-16 10:41:38,005:INFO:display_container: 2
2022-12-16 10:41:38,006:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2022-12-16 10:41:38,006:INFO:create_model() successfully completed......................................
2022-12-16 10:41:38,248:INFO:SubProcess create_model() end ==================================
2022-12-16 10:41:38,248:INFO:Creating metrics dataframe
2022-12-16 10:41:38,258:INFO:Initializing Naive Bayes
2022-12-16 10:41:38,259:INFO:Total runtime is 0.4093348781267802 minutes
2022-12-16 10:41:38,259:INFO:SubProcess create_model() called ==================================
2022-12-16 10:41:38,259:INFO:Initializing create_model()
2022-12-16 10:41:38,260:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002281239E9B0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002280DD28280>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:41:38,260:INFO:Checking exceptions
2022-12-16 10:41:38,264:INFO:Importing libraries
2022-12-16 10:41:38,265:INFO:Copying training dataset
2022-12-16 10:41:38,274:INFO:Defining folds
2022-12-16 10:41:38,274:INFO:Declaring metric variables
2022-12-16 10:41:38,274:INFO:Importing untrained model
2022-12-16 10:41:38,274:INFO:Naive Bayes Imported successfully
2022-12-16 10:41:38,275:INFO:Starting cross validation
2022-12-16 10:41:38,278:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:41:42,136:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:42,164:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:42,169:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:42,186:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:42,194:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:42,206:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:42,273:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:42,291:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:42,329:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:42,395:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:42,420:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:42,438:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:42,442:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:42,465:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:42,489:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:42,561:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:42,586:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:42,605:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:42,654:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:42,675:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:42,688:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:42,689:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:42,709:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:42,730:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:44,695:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:44,715:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:44,726:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:44,757:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:44,778:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:44,785:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:41:44,789:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:44,814:INFO:Calculating mean and std
2022-12-16 10:41:44,816:INFO:Creating metrics dataframe
2022-12-16 10:41:44,839:INFO:Uploading results into container
2022-12-16 10:41:44,842:INFO:Uploading model into container now
2022-12-16 10:41:44,843:INFO:master_model_container: 3
2022-12-16 10:41:44,844:INFO:display_container: 2
2022-12-16 10:41:44,845:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2022-12-16 10:41:44,845:INFO:create_model() successfully completed......................................
2022-12-16 10:41:45,214:INFO:SubProcess create_model() end ==================================
2022-12-16 10:41:45,215:INFO:Creating metrics dataframe
2022-12-16 10:41:45,235:INFO:Initializing Decision Tree Classifier
2022-12-16 10:41:45,236:INFO:Total runtime is 0.5256290634473165 minutes
2022-12-16 10:41:45,236:INFO:SubProcess create_model() called ==================================
2022-12-16 10:41:45,238:INFO:Initializing create_model()
2022-12-16 10:41:45,238:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002281239E9B0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002280DD28280>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:41:45,238:INFO:Checking exceptions
2022-12-16 10:41:45,249:INFO:Importing libraries
2022-12-16 10:41:45,250:INFO:Copying training dataset
2022-12-16 10:41:45,267:INFO:Defining folds
2022-12-16 10:41:45,267:INFO:Declaring metric variables
2022-12-16 10:41:45,268:INFO:Importing untrained model
2022-12-16 10:41:45,270:INFO:Decision Tree Classifier Imported successfully
2022-12-16 10:41:45,270:INFO:Starting cross validation
2022-12-16 10:41:45,274:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:41:48,837:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:48,853:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:48,859:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:41:48,865:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:48,896:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:48,917:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:48,926:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:41:48,936:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:49,097:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:49,114:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:49,120:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:41:49,126:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:49,132:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:49,167:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:49,190:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:41:49,199:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:49,702:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:49,716:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:49,727:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:41:49,743:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:49,817:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:49,831:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:49,843:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:41:49,852:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:50,011:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:50,025:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:50,031:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:41:50,041:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:50,135:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:50,159:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:50,168:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:41:50,173:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:51,578:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:51,591:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:51,598:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:51,606:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:51,607:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:41:51,613:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:51,614:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:41:51,623:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:51,647:INFO:Calculating mean and std
2022-12-16 10:41:51,648:INFO:Creating metrics dataframe
2022-12-16 10:41:51,658:INFO:Uploading results into container
2022-12-16 10:41:51,661:INFO:Uploading model into container now
2022-12-16 10:41:51,662:INFO:master_model_container: 4
2022-12-16 10:41:51,662:INFO:display_container: 2
2022-12-16 10:41:51,664:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1931, splitter='best')
2022-12-16 10:41:51,664:INFO:create_model() successfully completed......................................
2022-12-16 10:41:51,897:INFO:SubProcess create_model() end ==================================
2022-12-16 10:41:51,898:INFO:Creating metrics dataframe
2022-12-16 10:41:51,906:INFO:Initializing SVM - Linear Kernel
2022-12-16 10:41:51,906:INFO:Total runtime is 0.6368049542109172 minutes
2022-12-16 10:41:51,907:INFO:SubProcess create_model() called ==================================
2022-12-16 10:41:51,907:INFO:Initializing create_model()
2022-12-16 10:41:51,907:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002281239E9B0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002280DD28280>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:41:51,907:INFO:Checking exceptions
2022-12-16 10:41:51,911:INFO:Importing libraries
2022-12-16 10:41:51,911:INFO:Copying training dataset
2022-12-16 10:41:51,920:INFO:Defining folds
2022-12-16 10:41:51,920:INFO:Declaring metric variables
2022-12-16 10:41:51,920:INFO:Importing untrained model
2022-12-16 10:41:51,921:INFO:SVM - Linear Kernel Imported successfully
2022-12-16 10:41:51,921:INFO:Starting cross validation
2022-12-16 10:41:51,924:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:41:55,253:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:55,266:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:55,273:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:41:55,314:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:55,444:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:55,472:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:55,477:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:41:55,485:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:55,607:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:55,676:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:55,683:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:41:55,694:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:55,761:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:55,777:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:55,784:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:41:55,798:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:56,037:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:56,055:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:56,062:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:41:56,073:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:56,136:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:56,151:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:56,161:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:41:56,170:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:56,179:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:56,194:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:56,202:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:41:56,211:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:56,258:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:56,272:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:56,278:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:41:56,284:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:57,745:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:57,763:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:57,772:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:41:57,778:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:57,819:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:57,831:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:57,846:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:41:57,865:INFO:Calculating mean and std
2022-12-16 10:41:57,866:INFO:Creating metrics dataframe
2022-12-16 10:41:57,877:INFO:Uploading results into container
2022-12-16 10:41:57,878:INFO:Uploading model into container now
2022-12-16 10:41:57,879:INFO:master_model_container: 5
2022-12-16 10:41:57,879:INFO:display_container: 2
2022-12-16 10:41:57,880:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1931, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2022-12-16 10:41:57,880:INFO:create_model() successfully completed......................................
2022-12-16 10:41:58,295:INFO:SubProcess create_model() end ==================================
2022-12-16 10:41:58,295:INFO:Creating metrics dataframe
2022-12-16 10:41:58,315:INFO:Initializing Ridge Classifier
2022-12-16 10:41:58,315:INFO:Total runtime is 0.7436171015103659 minutes
2022-12-16 10:41:58,316:INFO:SubProcess create_model() called ==================================
2022-12-16 10:41:58,318:INFO:Initializing create_model()
2022-12-16 10:41:58,318:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002281239E9B0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002280DD28280>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:41:58,319:INFO:Checking exceptions
2022-12-16 10:41:58,328:INFO:Importing libraries
2022-12-16 10:41:58,328:INFO:Copying training dataset
2022-12-16 10:41:58,345:INFO:Defining folds
2022-12-16 10:41:58,345:INFO:Declaring metric variables
2022-12-16 10:41:58,346:INFO:Importing untrained model
2022-12-16 10:41:58,347:INFO:Ridge Classifier Imported successfully
2022-12-16 10:41:58,348:INFO:Starting cross validation
2022-12-16 10:41:58,354:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:42:01,057:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:01,065:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:01,068:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:01,077:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:01,085:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:01,087:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:01,093:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:01,175:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:01,188:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:01,195:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:01,202:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:01,241:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:01,256:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:01,263:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:01,272:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:01,730:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:01,744:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:01,758:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:01,768:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:01,855:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:01,869:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:01,874:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:01,881:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:01,889:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:01,892:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:01,897:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:01,908:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:02,027:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:02,040:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:02,043:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:02,046:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:02,739:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:02,745:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:02,750:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:02,755:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:02,799:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:02,808:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:02,813:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:02,817:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:02,832:INFO:Calculating mean and std
2022-12-16 10:42:02,833:INFO:Creating metrics dataframe
2022-12-16 10:42:02,840:INFO:Uploading results into container
2022-12-16 10:42:02,841:INFO:Uploading model into container now
2022-12-16 10:42:02,842:INFO:master_model_container: 6
2022-12-16 10:42:02,842:INFO:display_container: 2
2022-12-16 10:42:02,842:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=1931, solver='auto', tol=0.001)
2022-12-16 10:42:02,843:INFO:create_model() successfully completed......................................
2022-12-16 10:42:03,045:INFO:SubProcess create_model() end ==================================
2022-12-16 10:42:03,045:INFO:Creating metrics dataframe
2022-12-16 10:42:03,051:INFO:Initializing Random Forest Classifier
2022-12-16 10:42:03,052:INFO:Total runtime is 0.8225696523984274 minutes
2022-12-16 10:42:03,053:INFO:SubProcess create_model() called ==================================
2022-12-16 10:42:03,053:INFO:Initializing create_model()
2022-12-16 10:42:03,053:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002281239E9B0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002280DD28280>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:42:03,053:INFO:Checking exceptions
2022-12-16 10:42:03,057:INFO:Importing libraries
2022-12-16 10:42:03,057:INFO:Copying training dataset
2022-12-16 10:42:03,062:INFO:Defining folds
2022-12-16 10:42:03,062:INFO:Declaring metric variables
2022-12-16 10:42:03,063:INFO:Importing untrained model
2022-12-16 10:42:03,063:INFO:Random Forest Classifier Imported successfully
2022-12-16 10:42:03,063:INFO:Starting cross validation
2022-12-16 10:42:03,065:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:42:07,678:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:07,682:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:07,711:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:07,716:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:07,729:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:07,733:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:07,740:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:07,755:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:07,758:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:07,772:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:07,783:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:07,795:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:07,983:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:08,014:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:08,022:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:08,030:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:08,295:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:08,313:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:08,321:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:08,327:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:08,467:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:08,485:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:08,494:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:08,499:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:08,549:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:08,564:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:08,570:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:08,576:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:08,670:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:08,680:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:08,688:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:08,692:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:10,311:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:10,315:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:10,320:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:10,323:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:10,324:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:10,326:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:10,327:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:10,329:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:10,341:INFO:Calculating mean and std
2022-12-16 10:42:10,342:INFO:Creating metrics dataframe
2022-12-16 10:42:10,348:INFO:Uploading results into container
2022-12-16 10:42:10,349:INFO:Uploading model into container now
2022-12-16 10:42:10,350:INFO:master_model_container: 7
2022-12-16 10:42:10,350:INFO:display_container: 2
2022-12-16 10:42:10,352:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1931, verbose=0, warm_start=False)
2022-12-16 10:42:10,352:INFO:create_model() successfully completed......................................
2022-12-16 10:42:10,555:INFO:SubProcess create_model() end ==================================
2022-12-16 10:42:10,556:INFO:Creating metrics dataframe
2022-12-16 10:42:10,562:INFO:Initializing Quadratic Discriminant Analysis
2022-12-16 10:42:10,563:INFO:Total runtime is 0.9477509379386903 minutes
2022-12-16 10:42:10,563:INFO:SubProcess create_model() called ==================================
2022-12-16 10:42:10,563:INFO:Initializing create_model()
2022-12-16 10:42:10,563:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002281239E9B0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002280DD28280>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:42:10,563:INFO:Checking exceptions
2022-12-16 10:42:10,566:INFO:Importing libraries
2022-12-16 10:42:10,566:INFO:Copying training dataset
2022-12-16 10:42:10,576:INFO:Defining folds
2022-12-16 10:42:10,576:INFO:Declaring metric variables
2022-12-16 10:42:10,576:INFO:Importing untrained model
2022-12-16 10:42:10,576:INFO:Quadratic Discriminant Analysis Imported successfully
2022-12-16 10:42:10,577:INFO:Starting cross validation
2022-12-16 10:42:10,578:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:42:12,599:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:887: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2022-12-16 10:42:12,605:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:887: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2022-12-16 10:42:12,643:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:887: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2022-12-16 10:42:12,756:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:887: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2022-12-16 10:42:12,992:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:887: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2022-12-16 10:42:13,176:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:887: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2022-12-16 10:42:13,353:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:887: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2022-12-16 10:42:13,415:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:13,432:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:13,438:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:887: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2022-12-16 10:42:13,445:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:13,543:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:13,556:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:13,572:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:13,629:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:13,643:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:13,659:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:13,672:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:13,677:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:13,699:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:13,804:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:13,818:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:13,831:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:13,929:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:13,941:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:13,955:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:14,112:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:14,125:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:14,135:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:14,178:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:14,190:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:14,204:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:14,739:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:887: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2022-12-16 10:42:14,816:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:887: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2022-12-16 10:42:15,084:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:15,092:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:15,098:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:15,161:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:15,169:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:15,176:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:15,185:INFO:Calculating mean and std
2022-12-16 10:42:15,188:INFO:Creating metrics dataframe
2022-12-16 10:42:15,194:INFO:Uploading results into container
2022-12-16 10:42:15,195:INFO:Uploading model into container now
2022-12-16 10:42:15,195:INFO:master_model_container: 8
2022-12-16 10:42:15,195:INFO:display_container: 2
2022-12-16 10:42:15,196:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2022-12-16 10:42:15,196:INFO:create_model() successfully completed......................................
2022-12-16 10:42:15,394:INFO:SubProcess create_model() end ==================================
2022-12-16 10:42:15,394:INFO:Creating metrics dataframe
2022-12-16 10:42:15,399:INFO:Initializing Ada Boost Classifier
2022-12-16 10:42:15,400:INFO:Total runtime is 1.0283593893051148 minutes
2022-12-16 10:42:15,400:INFO:SubProcess create_model() called ==================================
2022-12-16 10:42:15,400:INFO:Initializing create_model()
2022-12-16 10:42:15,400:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002281239E9B0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002280DD28280>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:42:15,400:INFO:Checking exceptions
2022-12-16 10:42:15,406:INFO:Importing libraries
2022-12-16 10:42:15,406:INFO:Copying training dataset
2022-12-16 10:42:15,413:INFO:Defining folds
2022-12-16 10:42:15,413:INFO:Declaring metric variables
2022-12-16 10:42:15,414:INFO:Importing untrained model
2022-12-16 10:42:15,414:INFO:Ada Boost Classifier Imported successfully
2022-12-16 10:42:15,414:INFO:Starting cross validation
2022-12-16 10:42:15,416:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:42:19,463:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:19,472:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:19,477:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:19,482:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:19,486:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:19,493:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:19,498:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:19,499:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:19,730:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:19,746:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:19,755:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:19,770:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:19,992:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:20,007:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:20,013:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:20,020:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:20,074:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:20,090:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:20,097:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:20,108:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:20,290:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:20,305:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:20,311:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:20,316:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:20,475:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:20,490:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:20,494:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:20,497:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:20,569:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:20,579:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:20,586:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:20,590:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:21,933:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:21,943:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:21,948:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:22,011:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:22,019:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:22,024:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:22,026:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:22,039:INFO:Calculating mean and std
2022-12-16 10:42:22,040:INFO:Creating metrics dataframe
2022-12-16 10:42:22,044:INFO:Uploading results into container
2022-12-16 10:42:22,045:INFO:Uploading model into container now
2022-12-16 10:42:22,046:INFO:master_model_container: 9
2022-12-16 10:42:22,046:INFO:display_container: 2
2022-12-16 10:42:22,046:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=1931)
2022-12-16 10:42:22,046:INFO:create_model() successfully completed......................................
2022-12-16 10:42:22,322:INFO:SubProcess create_model() end ==================================
2022-12-16 10:42:22,323:INFO:Creating metrics dataframe
2022-12-16 10:42:22,331:INFO:Initializing Gradient Boosting Classifier
2022-12-16 10:42:22,331:INFO:Total runtime is 1.1438881834348045 minutes
2022-12-16 10:42:22,331:INFO:SubProcess create_model() called ==================================
2022-12-16 10:42:22,332:INFO:Initializing create_model()
2022-12-16 10:42:22,332:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002281239E9B0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002280DD28280>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:42:22,332:INFO:Checking exceptions
2022-12-16 10:42:22,338:INFO:Importing libraries
2022-12-16 10:42:22,339:INFO:Copying training dataset
2022-12-16 10:42:22,345:INFO:Defining folds
2022-12-16 10:42:22,345:INFO:Declaring metric variables
2022-12-16 10:42:22,345:INFO:Importing untrained model
2022-12-16 10:42:22,346:INFO:Gradient Boosting Classifier Imported successfully
2022-12-16 10:42:22,346:INFO:Starting cross validation
2022-12-16 10:42:22,348:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:42:35,455:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:35,468:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:35,476:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:35,482:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:35,537:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:35,563:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:35,571:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:35,577:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:35,746:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:35,759:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:35,765:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:35,772:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:37,243:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:37,258:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:37,264:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:37,277:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:38,637:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:38,646:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:38,651:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:38,655:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:38,945:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:38,954:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:38,960:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:38,965:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:39,007:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:39,012:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:39,016:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:39,021:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:39,090:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:39,098:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:39,103:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:39,108:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:43,938:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:43,942:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:43,947:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:43,951:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:44,184:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:44,188:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:44,190:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:44,192:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:44,199:INFO:Calculating mean and std
2022-12-16 10:42:44,201:INFO:Creating metrics dataframe
2022-12-16 10:42:44,208:INFO:Uploading results into container
2022-12-16 10:42:44,209:INFO:Uploading model into container now
2022-12-16 10:42:44,210:INFO:master_model_container: 10
2022-12-16 10:42:44,210:INFO:display_container: 2
2022-12-16 10:42:44,211:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1931, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2022-12-16 10:42:44,211:INFO:create_model() successfully completed......................................
2022-12-16 10:42:44,406:INFO:SubProcess create_model() end ==================================
2022-12-16 10:42:44,407:INFO:Creating metrics dataframe
2022-12-16 10:42:44,419:INFO:Initializing Linear Discriminant Analysis
2022-12-16 10:42:44,419:INFO:Total runtime is 1.5120169957478842 minutes
2022-12-16 10:42:44,420:INFO:SubProcess create_model() called ==================================
2022-12-16 10:42:44,420:INFO:Initializing create_model()
2022-12-16 10:42:44,420:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002281239E9B0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002280DD28280>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:42:44,420:INFO:Checking exceptions
2022-12-16 10:42:44,425:INFO:Importing libraries
2022-12-16 10:42:44,426:INFO:Copying training dataset
2022-12-16 10:42:44,433:INFO:Defining folds
2022-12-16 10:42:44,434:INFO:Declaring metric variables
2022-12-16 10:42:44,434:INFO:Importing untrained model
2022-12-16 10:42:44,436:INFO:Linear Discriminant Analysis Imported successfully
2022-12-16 10:42:44,436:INFO:Starting cross validation
2022-12-16 10:42:44,438:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:42:46,704:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:46,704:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:46,715:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:46,717:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:46,720:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:46,723:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:46,726:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:46,729:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:46,744:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:46,751:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:46,760:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:46,769:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:46,769:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:46,776:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:46,777:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:46,787:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:47,020:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:47,024:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:47,030:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:47,036:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:47,038:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:47,041:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:47,043:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:47,043:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:47,048:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:47,048:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:47,049:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:47,055:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:47,069:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:47,088:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:47,094:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:47,099:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:48,578:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:48,587:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:48,591:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:48,594:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:48,595:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:48,603:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:48,606:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:48,610:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:48,621:INFO:Calculating mean and std
2022-12-16 10:42:48,622:INFO:Creating metrics dataframe
2022-12-16 10:42:48,628:INFO:Uploading results into container
2022-12-16 10:42:48,629:INFO:Uploading model into container now
2022-12-16 10:42:48,630:INFO:master_model_container: 11
2022-12-16 10:42:48,630:INFO:display_container: 2
2022-12-16 10:42:48,630:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2022-12-16 10:42:48,631:INFO:create_model() successfully completed......................................
2022-12-16 10:42:48,846:INFO:SubProcess create_model() end ==================================
2022-12-16 10:42:48,846:INFO:Creating metrics dataframe
2022-12-16 10:42:48,855:INFO:Initializing Extra Trees Classifier
2022-12-16 10:42:48,855:INFO:Total runtime is 1.5859506964683534 minutes
2022-12-16 10:42:48,856:INFO:SubProcess create_model() called ==================================
2022-12-16 10:42:48,856:INFO:Initializing create_model()
2022-12-16 10:42:48,856:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002281239E9B0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002280DD28280>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:42:48,856:INFO:Checking exceptions
2022-12-16 10:42:48,860:INFO:Importing libraries
2022-12-16 10:42:48,860:INFO:Copying training dataset
2022-12-16 10:42:48,869:INFO:Defining folds
2022-12-16 10:42:48,869:INFO:Declaring metric variables
2022-12-16 10:42:48,869:INFO:Importing untrained model
2022-12-16 10:42:48,870:INFO:Extra Trees Classifier Imported successfully
2022-12-16 10:42:48,871:INFO:Starting cross validation
2022-12-16 10:42:48,874:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:42:54,139:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:54,144:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:54,164:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:54,173:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:54,176:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:54,182:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:54,185:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:54,192:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:54,197:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:54,200:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:54,208:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:54,223:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:54,238:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:54,244:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:54,245:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:54,283:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:54,467:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:54,476:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:54,506:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:54,532:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:54,532:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:54,543:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:54,547:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:54,556:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:54,557:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:54,573:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:54,581:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:54,595:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:54,750:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:54,763:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:54,768:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:54,775:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:57,145:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:57,153:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:57,156:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:57,156:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:57,159:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:57,162:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:57,166:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:42:57,169:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:42:57,181:INFO:Calculating mean and std
2022-12-16 10:42:57,182:INFO:Creating metrics dataframe
2022-12-16 10:42:57,188:INFO:Uploading results into container
2022-12-16 10:42:57,190:INFO:Uploading model into container now
2022-12-16 10:42:57,191:INFO:master_model_container: 12
2022-12-16 10:42:57,191:INFO:display_container: 2
2022-12-16 10:42:57,192:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=1931, verbose=0, warm_start=False)
2022-12-16 10:42:57,193:INFO:create_model() successfully completed......................................
2022-12-16 10:42:57,378:INFO:SubProcess create_model() end ==================================
2022-12-16 10:42:57,378:INFO:Creating metrics dataframe
2022-12-16 10:42:57,384:INFO:Initializing Light Gradient Boosting Machine
2022-12-16 10:42:57,384:INFO:Total runtime is 1.7281013687451683 minutes
2022-12-16 10:42:57,385:INFO:SubProcess create_model() called ==================================
2022-12-16 10:42:57,385:INFO:Initializing create_model()
2022-12-16 10:42:57,385:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002281239E9B0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002280DD28280>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:42:57,385:INFO:Checking exceptions
2022-12-16 10:42:57,388:INFO:Importing libraries
2022-12-16 10:42:57,388:INFO:Copying training dataset
2022-12-16 10:42:57,395:INFO:Defining folds
2022-12-16 10:42:57,395:INFO:Declaring metric variables
2022-12-16 10:42:57,395:INFO:Importing untrained model
2022-12-16 10:42:57,396:INFO:Light Gradient Boosting Machine Imported successfully
2022-12-16 10:42:57,396:INFO:Starting cross validation
2022-12-16 10:42:57,400:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:43:01,186:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:01,199:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:01,206:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:43:01,214:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:01,230:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:01,243:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:01,246:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:01,250:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:43:01,256:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:01,258:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:01,268:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:01,272:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:43:01,275:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:01,278:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:01,279:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:01,280:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:01,282:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:43:01,286:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:43:01,288:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:01,292:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:01,293:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:01,299:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:43:01,299:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:01,304:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:01,310:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:01,316:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:43:01,318:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:01,323:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:01,330:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:01,336:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:43:01,341:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:02,844:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:02,846:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:02,849:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:02,850:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:02,851:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:43:02,853:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:43:02,854:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:02,855:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:02,863:INFO:Calculating mean and std
2022-12-16 10:43:02,864:INFO:Creating metrics dataframe
2022-12-16 10:43:02,868:INFO:Uploading results into container
2022-12-16 10:43:02,868:INFO:Uploading model into container now
2022-12-16 10:43:02,869:INFO:master_model_container: 13
2022-12-16 10:43:02,869:INFO:display_container: 2
2022-12-16 10:43:02,869:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1931, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2022-12-16 10:43:02,869:INFO:create_model() successfully completed......................................
2022-12-16 10:43:03,024:INFO:SubProcess create_model() end ==================================
2022-12-16 10:43:03,024:INFO:Creating metrics dataframe
2022-12-16 10:43:03,030:INFO:Initializing Dummy Classifier
2022-12-16 10:43:03,030:INFO:Total runtime is 1.8221995671590172 minutes
2022-12-16 10:43:03,030:INFO:SubProcess create_model() called ==================================
2022-12-16 10:43:03,030:INFO:Initializing create_model()
2022-12-16 10:43:03,030:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002281239E9B0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002280DD28280>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:43:03,030:INFO:Checking exceptions
2022-12-16 10:43:03,033:INFO:Importing libraries
2022-12-16 10:43:03,033:INFO:Copying training dataset
2022-12-16 10:43:03,039:INFO:Defining folds
2022-12-16 10:43:03,039:INFO:Declaring metric variables
2022-12-16 10:43:03,039:INFO:Importing untrained model
2022-12-16 10:43:03,039:INFO:Dummy Classifier Imported successfully
2022-12-16 10:43:03,040:INFO:Starting cross validation
2022-12-16 10:43:03,041:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 10:43:05,396:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:05,407:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:05,413:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:43:05,419:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:05,451:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:05,463:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:05,468:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:43:05,474:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:05,487:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:05,494:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:05,499:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:05,506:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:43:05,508:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:05,512:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:05,515:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:43:05,522:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:05,578:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:05,592:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:05,599:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:43:05,620:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:05,677:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:05,677:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:05,679:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:05,683:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:43:05,683:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:43:05,686:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:43:05,689:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:05,689:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:05,692:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:06,632:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:06,636:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:06,639:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:43:06,641:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:06,663:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:06,668:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:06,670:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 10:43:06,672:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 10:43:06,680:INFO:Calculating mean and std
2022-12-16 10:43:06,681:INFO:Creating metrics dataframe
2022-12-16 10:43:06,685:INFO:Uploading results into container
2022-12-16 10:43:06,686:INFO:Uploading model into container now
2022-12-16 10:43:06,686:INFO:master_model_container: 14
2022-12-16 10:43:06,686:INFO:display_container: 2
2022-12-16 10:43:06,686:INFO:DummyClassifier(constant=None, random_state=1931, strategy='prior')
2022-12-16 10:43:06,687:INFO:create_model() successfully completed......................................
2022-12-16 10:43:06,832:INFO:SubProcess create_model() end ==================================
2022-12-16 10:43:06,832:INFO:Creating metrics dataframe
2022-12-16 10:43:06,841:INFO:Initializing create_model()
2022-12-16 10:43:06,841:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002281239E9B0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=1931, solver='auto', tol=0.001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-12-16 10:43:06,841:INFO:Checking exceptions
2022-12-16 10:43:06,845:INFO:Importing libraries
2022-12-16 10:43:06,845:INFO:Copying training dataset
2022-12-16 10:43:06,849:INFO:Defining folds
2022-12-16 10:43:06,849:INFO:Declaring metric variables
2022-12-16 10:43:06,849:INFO:Importing untrained model
2022-12-16 10:43:06,849:INFO:Declaring custom model
2022-12-16 10:43:06,850:INFO:Ridge Classifier Imported successfully
2022-12-16 10:43:06,851:INFO:Cross validation set to False
2022-12-16 10:43:06,852:INFO:Fitting Model
2022-12-16 10:43:08,678:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=1931, solver='auto', tol=0.001)
2022-12-16 10:43:08,678:INFO:create_model() successfully completed......................................
2022-12-16 10:43:08,832:INFO:master_model_container: 14
2022-12-16 10:43:08,832:INFO:display_container: 2
2022-12-16 10:43:08,833:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=1931, solver='auto', tol=0.001)
2022-12-16 10:43:08,833:INFO:compare_models() successfully completed......................................
2022-12-16 10:43:08,849:INFO:Initializing save_model()
2022-12-16 10:43:08,849:INFO:save_model(model=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=1931, solver='auto', tol=0.001), model_name=save_model, prep_pipe_=Pipeline(memory=Memory(location=C:\Users\S_05_\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=['Accident_severity'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_val...
                                                                         'Weather_conditions',
                                                                         'Type_of_collision',
                                                                         'Vehicle_movement',
                                                                         'Pedestrian_movement',
                                                                         'Cause_of_accident'],
                                                                   drop_invariant=False,
                                                                   handle_missing='return_nan',
                                                                   handle_unknown='value',
                                                                   random_state=1931,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('low_variance',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=VarianceThreshold(threshold=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2022-12-16 10:43:08,850:INFO:Adding model into prep_pipe
2022-12-16 10:43:08,984:INFO:save_model.pkl saved in current working directory
2022-12-16 10:43:09,013:INFO:Pipeline(memory=Memory(location=C:\Users\S_05_\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=['Accident_severity'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_val...
                                                                   random_state=1931,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('low_variance',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=VarianceThreshold(threshold=0))),
                ('trained_model',
                 RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True,
                                 fit_intercept=True, max_iter=None,
                                 normalize='deprecated', positive=False,
                                 random_state=1931, solver='auto',
                                 tol=0.001))],
         verbose=False)
2022-12-16 10:43:09,014:INFO:save_model() successfully completed......................................
2022-12-16 10:49:10,295:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-12-16 10:49:10,296:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-12-16 10:49:10,296:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-12-16 10:49:10,296:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-12-16 10:49:11,901:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2022-12-16 11:00:01,908:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-12-16 11:00:01,908:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-12-16 11:00:01,908:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-12-16 11:00:01,908:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-12-16 11:00:03,398:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2022-12-16 11:02:17,341:INFO:PyCaret ClassificationExperiment
2022-12-16 11:02:17,341:INFO:Logging name: clf-default-name
2022-12-16 11:02:17,341:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2022-12-16 11:02:17,342:INFO:version 3.0.0.rc4
2022-12-16 11:02:17,342:INFO:Initializing setup()
2022-12-16 11:02:17,342:INFO:self.USI: 169e
2022-12-16 11:02:17,342:INFO:self.variable_keys: {'memory', 'log_plots_param', 'fix_imbalance', '_available_plots', 'y_test', 'exp_name_log', '_all_models_internal', 'X', 'fold_shuffle_param', '_ml_usecase', '_all_models', '_all_metrics', 'X_train', 'idx', 'X_test', 'display_container', 'logging_param', '_is_multiclass', 'y', 'fold_groups_param', '_gpu_n_jobs_param', 'target_param', 'y_train', 'master_model_container', 'gpu_param', 'data', 'variable_keys', 'exp_id', 'fold_generator', 'pipeline', 'html_param', 'n_jobs_param', 'USI', 'seed'}
2022-12-16 11:02:17,342:INFO:Checking environment
2022-12-16 11:02:17,342:INFO:python_version: 3.10.7
2022-12-16 11:02:17,342:INFO:python_build: ('tags/v3.10.7:6cc6b13', 'Sep  5 2022 14:08:36')
2022-12-16 11:02:17,343:INFO:machine: AMD64
2022-12-16 11:02:17,367:INFO:platform: Windows-10-10.0.22621-SP0
2022-12-16 11:02:17,367:INFO:Memory: svmem(total=8361132032, available=1238937600, percent=85.2, used=7122194432, free=1238937600)
2022-12-16 11:02:17,367:INFO:Physical Core: 4
2022-12-16 11:02:17,367:INFO:Logical Core: 8
2022-12-16 11:02:17,368:INFO:Checking libraries
2022-12-16 11:02:17,368:INFO:System:
2022-12-16 11:02:17,368:INFO:    python: 3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]
2022-12-16 11:02:17,368:INFO:executable: C:\Users\S_05_\AppData\Local\Programs\Python\Python310\python.exe
2022-12-16 11:02:17,368:INFO:   machine: Windows-10-10.0.22621-SP0
2022-12-16 11:02:17,368:INFO:PyCaret required dependencies:
2022-12-16 11:02:17,368:INFO:                 pip: 22.3.1
2022-12-16 11:02:17,368:INFO:          setuptools: 63.2.0
2022-12-16 11:02:17,368:INFO:             pycaret: 3.0.0rc4
2022-12-16 11:02:17,368:INFO:             IPython: 8.6.0
2022-12-16 11:02:17,368:INFO:          ipywidgets: 8.0.3
2022-12-16 11:02:17,368:INFO:                tqdm: 4.64.1
2022-12-16 11:02:17,368:INFO:               numpy: 1.22.4
2022-12-16 11:02:17,368:INFO:              pandas: 1.4.4
2022-12-16 11:02:17,368:INFO:              jinja2: 3.1.2
2022-12-16 11:02:17,368:INFO:               scipy: 1.8.1
2022-12-16 11:02:17,368:INFO:              joblib: 1.2.0
2022-12-16 11:02:17,368:INFO:             sklearn: 1.1.3
2022-12-16 11:02:17,368:INFO:                pyod: 1.0.6
2022-12-16 11:02:17,369:INFO:            imblearn: 0.10.0
2022-12-16 11:02:17,369:INFO:   category_encoders: 2.5.1.post0
2022-12-16 11:02:17,369:INFO:            lightgbm: 3.3.3
2022-12-16 11:02:17,369:INFO:               numba: 0.55.2
2022-12-16 11:02:17,369:INFO:            requests: 2.28.1
2022-12-16 11:02:17,369:INFO:          matplotlib: 3.6.2
2022-12-16 11:02:17,369:INFO:          scikitplot: 0.3.7
2022-12-16 11:02:17,369:INFO:         yellowbrick: 1.5
2022-12-16 11:02:17,369:INFO:              plotly: 5.11.0
2022-12-16 11:02:17,369:INFO:             kaleido: 0.2.1
2022-12-16 11:02:17,369:INFO:         statsmodels: 0.13.5
2022-12-16 11:02:17,369:INFO:              sktime: 0.13.4
2022-12-16 11:02:17,369:INFO:               tbats: 1.1.2
2022-12-16 11:02:17,369:INFO:            pmdarima: 1.8.5
2022-12-16 11:02:17,369:INFO:              psutil: 5.9.3
2022-12-16 11:02:17,369:INFO:PyCaret optional dependencies:
2022-12-16 11:02:17,401:INFO:                shap: Not installed
2022-12-16 11:02:17,401:INFO:           interpret: Not installed
2022-12-16 11:02:17,401:INFO:                umap: Not installed
2022-12-16 11:02:17,401:INFO:    pandas_profiling: 3.5.0
2022-12-16 11:02:17,401:INFO:  explainerdashboard: Not installed
2022-12-16 11:02:17,401:INFO:             autoviz: Not installed
2022-12-16 11:02:17,401:INFO:           fairlearn: Not installed
2022-12-16 11:02:17,401:INFO:             xgboost: Not installed
2022-12-16 11:02:17,401:INFO:            catboost: Not installed
2022-12-16 11:02:17,401:INFO:              kmodes: Not installed
2022-12-16 11:02:17,401:INFO:             mlxtend: Not installed
2022-12-16 11:02:17,401:INFO:       statsforecast: Not installed
2022-12-16 11:02:17,401:INFO:        tune_sklearn: Not installed
2022-12-16 11:02:17,401:INFO:                 ray: Not installed
2022-12-16 11:02:17,401:INFO:            hyperopt: Not installed
2022-12-16 11:02:17,401:INFO:              optuna: Not installed
2022-12-16 11:02:17,401:INFO:               skopt: Not installed
2022-12-16 11:02:17,401:INFO:              mlflow: Not installed
2022-12-16 11:02:17,401:INFO:              gradio: Not installed
2022-12-16 11:02:17,402:INFO:             fastapi: Not installed
2022-12-16 11:02:17,402:INFO:             uvicorn: Not installed
2022-12-16 11:02:17,402:INFO:              m2cgen: Not installed
2022-12-16 11:02:17,402:INFO:           evidently: Not installed
2022-12-16 11:02:17,402:INFO:                nltk: Not installed
2022-12-16 11:02:17,402:INFO:            pyLDAvis: Not installed
2022-12-16 11:02:17,402:INFO:              gensim: Not installed
2022-12-16 11:02:17,402:INFO:               spacy: Not installed
2022-12-16 11:02:17,402:INFO:           wordcloud: Not installed
2022-12-16 11:02:17,402:INFO:            textblob: Not installed
2022-12-16 11:02:17,402:INFO:               fugue: Not installed
2022-12-16 11:02:17,402:INFO:           streamlit: 1.15.2
2022-12-16 11:02:17,402:INFO:             prophet: Not installed
2022-12-16 11:02:17,402:INFO:None
2022-12-16 11:02:17,402:INFO:Set up data.
2022-12-16 11:02:17,436:INFO:Set up train/test split.
2022-12-16 11:02:17,465:INFO:Set up index.
2022-12-16 11:02:17,467:INFO:Assigning column types.
2022-12-16 11:02:17,473:INFO:Set up folding strategy.
2022-12-16 11:02:17,473:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-12-16 11:02:17,567:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-16 11:02:17,573:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2022-12-16 11:02:17,636:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 11:02:17,676:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 11:02:17,757:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-16 11:02:17,759:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2022-12-16 11:02:17,818:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 11:02:17,818:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 11:02:17,819:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-12-16 11:02:17,866:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2022-12-16 11:02:18,249:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 11:02:18,250:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 11:02:18,316:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2022-12-16 11:02:18,358:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 11:02:18,358:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 11:02:18,358:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2022-12-16 11:02:18,483:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 11:02:18,483:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 11:02:18,594:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 11:02:18,594:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 11:02:18,595:INFO:Preparing preprocessing pipeline...
2022-12-16 11:02:18,606:INFO:Set up label encoding.
2022-12-16 11:02:18,606:INFO:Set up simple imputation.
2022-12-16 11:02:18,615:INFO:Set up encoding of categorical features.
2022-12-16 11:02:18,616:INFO:Set up variance threshold.
2022-12-16 11:02:21,671:INFO:Finished creating preprocessing pipeline.
2022-12-16 11:02:21,692:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\S_05_\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=['Accident_severity'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_val...
                                                                         'Weather_conditions',
                                                                         'Type_of_collision',
                                                                         'Vehicle_movement',
                                                                         'Pedestrian_movement',
                                                                         'Cause_of_accident'],
                                                                   drop_invariant=False,
                                                                   handle_missing='return_nan',
                                                                   handle_unknown='value',
                                                                   random_state=2294,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('low_variance',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=VarianceThreshold(threshold=0)))],
         verbose=False)
2022-12-16 11:02:21,692:INFO:Creating final display dataframe.
2022-12-16 11:02:28,521:INFO:Setup display_container:                     Description                           Value
0                    Session id                            2294
1                        Target                   Sex_of_driver
2                   Target type                      Multiclass
3                Target mapping  Female: 0, Male: 1, Unknown: 2
4           Original data shape                     (12316, 15)
5        Transformed data shape                     (12316, 25)
6   Transformed train set shape                      (8621, 25)
7    Transformed test set shape                      (3695, 25)
8              Numeric features                               1
9          Categorical features                              13
10                   Preprocess                            True
11              Imputation type                          simple
12           Numeric imputation                            mean
13       Categorical imputation                        constant
14     Maximum one-hot encoding                               5
15              Encoding method                            None
16       Low variance threshold                               0
17               Fold Generator                 StratifiedKFold
18                  Fold Number                              10
19                     CPU Jobs                              -1
20                      Use GPU                           False
21               Log Experiment                           False
22              Experiment Name                clf-default-name
23                          USI                            169e
2022-12-16 11:02:28,624:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 11:02:28,625:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 11:02:28,705:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 11:02:28,705:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-16 11:02:28,716:INFO:setup() successfully completed in 11.38s...............
2022-12-16 11:02:28,720:INFO:Initializing compare_models()
2022-12-16 11:02:28,721:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002086D017EE0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002086D017EE0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2022-12-16 11:02:28,721:INFO:Checking exceptions
2022-12-16 11:02:28,729:INFO:Preparing display monitor
2022-12-16 11:02:28,736:INFO:Initializing Logistic Regression
2022-12-16 11:02:28,736:INFO:Total runtime is 0.0 minutes
2022-12-16 11:02:28,736:INFO:SubProcess create_model() called ==================================
2022-12-16 11:02:28,737:INFO:Initializing create_model()
2022-12-16 11:02:28,737:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002086D017EE0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002086CFD3B50>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 11:02:28,737:INFO:Checking exceptions
2022-12-16 11:02:28,740:INFO:Importing libraries
2022-12-16 11:02:28,740:INFO:Copying training dataset
2022-12-16 11:02:28,744:INFO:Defining folds
2022-12-16 11:02:28,744:INFO:Declaring metric variables
2022-12-16 11:02:28,744:INFO:Importing untrained model
2022-12-16 11:02:28,745:INFO:Logistic Regression Imported successfully
2022-12-16 11:02:28,745:INFO:Starting cross validation
2022-12-16 11:02:28,747:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 11:02:34,533:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-12-16 11:02:34,571:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-12-16 11:02:34,576:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-12-16 11:02:34,624:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-12-16 11:02:34,702:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-12-16 11:02:34,705:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-12-16 11:02:34,722:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-12-16 11:02:34,804:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-12-16 11:02:36,645:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-12-16 11:02:36,658:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-12-16 11:02:36,727:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-12-16 11:02:36,830:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-12-16 11:02:36,832:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-12-16 11:02:36,868:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-12-16 11:02:36,884:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-12-16 11:02:36,955:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py:192: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2022-12-16 11:02:40,636:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:40,655:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:40,669:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:02:40,676:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:41,018:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:41,034:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:41,042:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:02:41,048:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:41,133:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:41,145:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:41,153:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:02:41,159:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:41,167:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:41,179:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:41,186:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:02:41,192:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:41,193:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:41,208:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:41,217:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:02:41,224:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:41,265:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:41,278:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:41,287:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:02:41,297:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:41,472:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:41,483:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:41,487:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:41,491:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:02:41,496:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:41,498:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:41,507:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:02:41,517:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:45,844:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:45,848:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:45,849:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:45,852:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:02:45,853:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:45,854:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:45,855:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:02:45,858:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:45,866:INFO:Calculating mean and std
2022-12-16 11:02:45,867:INFO:Creating metrics dataframe
2022-12-16 11:02:45,871:INFO:Uploading results into container
2022-12-16 11:02:45,872:INFO:Uploading model into container now
2022-12-16 11:02:45,872:INFO:master_model_container: 1
2022-12-16 11:02:45,873:INFO:display_container: 2
2022-12-16 11:02:45,873:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2294, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2022-12-16 11:02:45,873:INFO:create_model() successfully completed......................................
2022-12-16 11:02:46,052:INFO:SubProcess create_model() end ==================================
2022-12-16 11:02:46,052:INFO:Creating metrics dataframe
2022-12-16 11:02:46,058:INFO:Initializing K Neighbors Classifier
2022-12-16 11:02:46,058:INFO:Total runtime is 0.2886996825536092 minutes
2022-12-16 11:02:46,058:INFO:SubProcess create_model() called ==================================
2022-12-16 11:02:46,059:INFO:Initializing create_model()
2022-12-16 11:02:46,059:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002086D017EE0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002086CFD3B50>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 11:02:46,059:INFO:Checking exceptions
2022-12-16 11:02:46,062:INFO:Importing libraries
2022-12-16 11:02:46,062:INFO:Copying training dataset
2022-12-16 11:02:46,067:INFO:Defining folds
2022-12-16 11:02:46,067:INFO:Declaring metric variables
2022-12-16 11:02:46,067:INFO:Importing untrained model
2022-12-16 11:02:46,068:INFO:K Neighbors Classifier Imported successfully
2022-12-16 11:02:46,068:INFO:Starting cross validation
2022-12-16 11:02:46,070:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 11:02:49,858:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:49,871:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:49,878:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:02:49,879:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:49,883:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:49,892:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:49,895:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:49,902:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:02:49,907:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:49,909:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:49,920:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:49,921:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:49,930:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:02:49,933:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:49,938:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:50,019:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:50,030:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:50,032:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:50,038:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:02:50,041:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:50,044:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:50,047:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:02:50,070:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:50,118:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:50,166:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:50,167:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:50,173:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:02:50,173:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:02:50,177:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:50,177:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:51,369:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:51,374:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:51,376:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:02:51,378:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:51,401:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:51,405:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:51,408:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:02:51,410:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:51,418:INFO:Calculating mean and std
2022-12-16 11:02:51,419:INFO:Creating metrics dataframe
2022-12-16 11:02:51,424:INFO:Uploading results into container
2022-12-16 11:02:51,424:INFO:Uploading model into container now
2022-12-16 11:02:51,425:INFO:master_model_container: 2
2022-12-16 11:02:51,425:INFO:display_container: 2
2022-12-16 11:02:51,425:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2022-12-16 11:02:51,426:INFO:create_model() successfully completed......................................
2022-12-16 11:02:51,576:INFO:SubProcess create_model() end ==================================
2022-12-16 11:02:51,576:INFO:Creating metrics dataframe
2022-12-16 11:02:51,582:INFO:Initializing Naive Bayes
2022-12-16 11:02:51,582:INFO:Total runtime is 0.3807680209477743 minutes
2022-12-16 11:02:51,582:INFO:SubProcess create_model() called ==================================
2022-12-16 11:02:51,582:INFO:Initializing create_model()
2022-12-16 11:02:51,582:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002086D017EE0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002086CFD3B50>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 11:02:51,583:INFO:Checking exceptions
2022-12-16 11:02:51,585:INFO:Importing libraries
2022-12-16 11:02:51,585:INFO:Copying training dataset
2022-12-16 11:02:51,590:INFO:Defining folds
2022-12-16 11:02:51,590:INFO:Declaring metric variables
2022-12-16 11:02:51,590:INFO:Importing untrained model
2022-12-16 11:02:51,590:INFO:Naive Bayes Imported successfully
2022-12-16 11:02:51,591:INFO:Starting cross validation
2022-12-16 11:02:51,592:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 11:02:54,105:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:54,154:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:54,170:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:54,280:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:54,315:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:54,324:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:54,779:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:54,780:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:54,780:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:54,781:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:54,781:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:54,781:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:54,786:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:54,786:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:54,787:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:54,787:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:54,787:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:54,788:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:55,605:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:55,611:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:55,612:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:55,616:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:55,617:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:55,622:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:55,630:INFO:Calculating mean and std
2022-12-16 11:02:55,631:INFO:Creating metrics dataframe
2022-12-16 11:02:55,636:INFO:Uploading results into container
2022-12-16 11:02:55,637:INFO:Uploading model into container now
2022-12-16 11:02:55,638:INFO:master_model_container: 3
2022-12-16 11:02:55,638:INFO:display_container: 2
2022-12-16 11:02:55,638:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2022-12-16 11:02:55,638:INFO:create_model() successfully completed......................................
2022-12-16 11:02:55,780:INFO:SubProcess create_model() end ==================================
2022-12-16 11:02:55,780:INFO:Creating metrics dataframe
2022-12-16 11:02:55,786:INFO:Initializing Decision Tree Classifier
2022-12-16 11:02:55,786:INFO:Total runtime is 0.45083538293838504 minutes
2022-12-16 11:02:55,787:INFO:SubProcess create_model() called ==================================
2022-12-16 11:02:55,787:INFO:Initializing create_model()
2022-12-16 11:02:55,787:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002086D017EE0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002086CFD3B50>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 11:02:55,787:INFO:Checking exceptions
2022-12-16 11:02:55,793:INFO:Importing libraries
2022-12-16 11:02:55,793:INFO:Copying training dataset
2022-12-16 11:02:55,799:INFO:Defining folds
2022-12-16 11:02:55,799:INFO:Declaring metric variables
2022-12-16 11:02:55,799:INFO:Importing untrained model
2022-12-16 11:02:55,799:INFO:Decision Tree Classifier Imported successfully
2022-12-16 11:02:55,800:INFO:Starting cross validation
2022-12-16 11:02:55,801:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 11:02:58,315:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:58,320:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:58,327:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:58,335:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:58,337:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:58,338:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:58,340:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:58,344:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:02:58,349:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:58,351:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:58,351:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:58,355:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:02:58,357:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:02:58,361:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:58,384:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:58,465:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:58,482:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:58,491:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:02:58,497:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:58,518:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:58,518:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:58,530:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:58,530:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:58,536:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:02:58,536:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:02:58,541:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:58,542:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:58,553:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:58,561:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:58,564:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:02:58,567:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:59,488:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:59,493:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:59,495:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:02:59,497:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:59,505:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:59,512:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:59,515:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:02:59,517:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:02:59,525:INFO:Calculating mean and std
2022-12-16 11:02:59,527:INFO:Creating metrics dataframe
2022-12-16 11:02:59,530:INFO:Uploading results into container
2022-12-16 11:02:59,531:INFO:Uploading model into container now
2022-12-16 11:02:59,531:INFO:master_model_container: 4
2022-12-16 11:02:59,531:INFO:display_container: 2
2022-12-16 11:02:59,532:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2294, splitter='best')
2022-12-16 11:02:59,532:INFO:create_model() successfully completed......................................
2022-12-16 11:02:59,666:INFO:SubProcess create_model() end ==================================
2022-12-16 11:02:59,666:INFO:Creating metrics dataframe
2022-12-16 11:02:59,671:INFO:Initializing SVM - Linear Kernel
2022-12-16 11:02:59,671:INFO:Total runtime is 0.515585732460022 minutes
2022-12-16 11:02:59,672:INFO:SubProcess create_model() called ==================================
2022-12-16 11:02:59,672:INFO:Initializing create_model()
2022-12-16 11:02:59,672:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002086D017EE0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002086CFD3B50>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 11:02:59,672:INFO:Checking exceptions
2022-12-16 11:02:59,675:INFO:Importing libraries
2022-12-16 11:02:59,675:INFO:Copying training dataset
2022-12-16 11:02:59,680:INFO:Defining folds
2022-12-16 11:02:59,680:INFO:Declaring metric variables
2022-12-16 11:02:59,680:INFO:Importing untrained model
2022-12-16 11:02:59,680:INFO:SVM - Linear Kernel Imported successfully
2022-12-16 11:02:59,681:INFO:Starting cross validation
2022-12-16 11:02:59,682:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 11:03:01,980:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:01,991:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:01,992:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:02,000:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:02,004:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:02,006:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:02,009:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:02,016:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:02,017:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:02,029:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:02,035:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:02,041:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:02,097:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:02,108:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:02,114:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:02,120:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:02,176:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:02,184:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:02,187:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:02,190:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:02,215:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:02,227:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:02,231:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:02,238:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:02,292:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:02,299:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:02,305:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:02,311:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:02,343:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:02,353:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:02,358:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:02,363:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:03,099:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:03,104:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:03,107:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:03,109:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:03,125:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:03,130:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:03,132:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:03,135:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:03,142:INFO:Calculating mean and std
2022-12-16 11:03:03,143:INFO:Creating metrics dataframe
2022-12-16 11:03:03,147:INFO:Uploading results into container
2022-12-16 11:03:03,148:INFO:Uploading model into container now
2022-12-16 11:03:03,148:INFO:master_model_container: 5
2022-12-16 11:03:03,148:INFO:display_container: 2
2022-12-16 11:03:03,149:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2294, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2022-12-16 11:03:03,149:INFO:create_model() successfully completed......................................
2022-12-16 11:03:03,298:INFO:SubProcess create_model() end ==================================
2022-12-16 11:03:03,298:INFO:Creating metrics dataframe
2022-12-16 11:03:03,304:INFO:Initializing Ridge Classifier
2022-12-16 11:03:03,304:INFO:Total runtime is 0.5761363228162131 minutes
2022-12-16 11:03:03,305:INFO:SubProcess create_model() called ==================================
2022-12-16 11:03:03,305:INFO:Initializing create_model()
2022-12-16 11:03:03,305:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002086D017EE0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002086CFD3B50>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 11:03:03,305:INFO:Checking exceptions
2022-12-16 11:03:03,308:INFO:Importing libraries
2022-12-16 11:03:03,308:INFO:Copying training dataset
2022-12-16 11:03:03,313:INFO:Defining folds
2022-12-16 11:03:03,313:INFO:Declaring metric variables
2022-12-16 11:03:03,314:INFO:Importing untrained model
2022-12-16 11:03:03,314:INFO:Ridge Classifier Imported successfully
2022-12-16 11:03:03,314:INFO:Starting cross validation
2022-12-16 11:03:03,316:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 11:03:05,435:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:05,444:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:05,446:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:05,452:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:05,455:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:05,458:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:05,461:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:05,466:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:05,495:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:05,528:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:05,537:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:05,540:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:05,543:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:05,546:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:05,548:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:05,552:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:05,554:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:05,568:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:05,574:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:05,580:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:05,596:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:05,608:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:05,615:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:05,617:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:05,623:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:05,626:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:05,632:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:05,634:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:05,636:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:05,645:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:05,651:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:05,655:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:06,467:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:06,471:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:06,474:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:06,476:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:06,495:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:06,499:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:06,501:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:06,504:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:06,511:INFO:Calculating mean and std
2022-12-16 11:03:06,512:INFO:Creating metrics dataframe
2022-12-16 11:03:06,516:INFO:Uploading results into container
2022-12-16 11:03:06,517:INFO:Uploading model into container now
2022-12-16 11:03:06,518:INFO:master_model_container: 6
2022-12-16 11:03:06,518:INFO:display_container: 2
2022-12-16 11:03:06,518:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=2294, solver='auto', tol=0.001)
2022-12-16 11:03:06,518:INFO:create_model() successfully completed......................................
2022-12-16 11:03:06,661:INFO:SubProcess create_model() end ==================================
2022-12-16 11:03:06,661:INFO:Creating metrics dataframe
2022-12-16 11:03:06,666:INFO:Initializing Random Forest Classifier
2022-12-16 11:03:06,667:INFO:Total runtime is 0.6321800470352174 minutes
2022-12-16 11:03:06,667:INFO:SubProcess create_model() called ==================================
2022-12-16 11:03:06,667:INFO:Initializing create_model()
2022-12-16 11:03:06,667:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002086D017EE0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002086CFD3B50>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 11:03:06,667:INFO:Checking exceptions
2022-12-16 11:03:06,670:INFO:Importing libraries
2022-12-16 11:03:06,670:INFO:Copying training dataset
2022-12-16 11:03:06,675:INFO:Defining folds
2022-12-16 11:03:06,675:INFO:Declaring metric variables
2022-12-16 11:03:06,675:INFO:Importing untrained model
2022-12-16 11:03:06,676:INFO:Random Forest Classifier Imported successfully
2022-12-16 11:03:06,676:INFO:Starting cross validation
2022-12-16 11:03:06,678:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 11:03:10,364:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:10,371:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:10,376:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:10,383:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:10,384:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:10,388:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:10,392:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:10,398:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:10,472:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:10,484:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:10,490:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:10,496:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:10,607:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:10,608:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:10,608:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:10,609:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:10,617:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:10,618:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:10,621:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:10,623:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:10,623:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:10,623:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:10,627:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:10,628:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:10,628:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:10,628:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:10,633:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:10,634:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:10,744:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:10,751:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:10,754:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:10,757:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:12,025:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:12,031:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:12,033:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:12,036:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:12,068:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:12,076:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:12,080:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:12,084:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:12,094:INFO:Calculating mean and std
2022-12-16 11:03:12,095:INFO:Creating metrics dataframe
2022-12-16 11:03:12,100:INFO:Uploading results into container
2022-12-16 11:03:12,101:INFO:Uploading model into container now
2022-12-16 11:03:12,102:INFO:master_model_container: 7
2022-12-16 11:03:12,102:INFO:display_container: 2
2022-12-16 11:03:12,102:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2294, verbose=0, warm_start=False)
2022-12-16 11:03:12,102:INFO:create_model() successfully completed......................................
2022-12-16 11:03:12,257:INFO:SubProcess create_model() end ==================================
2022-12-16 11:03:12,257:INFO:Creating metrics dataframe
2022-12-16 11:03:12,263:INFO:Initializing Quadratic Discriminant Analysis
2022-12-16 11:03:12,263:INFO:Total runtime is 0.7254554351170859 minutes
2022-12-16 11:03:12,263:INFO:SubProcess create_model() called ==================================
2022-12-16 11:03:12,263:INFO:Initializing create_model()
2022-12-16 11:03:12,263:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002086D017EE0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002086CFD3B50>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 11:03:12,263:INFO:Checking exceptions
2022-12-16 11:03:12,266:INFO:Importing libraries
2022-12-16 11:03:12,266:INFO:Copying training dataset
2022-12-16 11:03:12,271:INFO:Defining folds
2022-12-16 11:03:12,271:INFO:Declaring metric variables
2022-12-16 11:03:12,271:INFO:Importing untrained model
2022-12-16 11:03:12,272:INFO:Quadratic Discriminant Analysis Imported successfully
2022-12-16 11:03:12,272:INFO:Starting cross validation
2022-12-16 11:03:12,274:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 11:03:14,009:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:887: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2022-12-16 11:03:14,009:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:887: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2022-12-16 11:03:14,011:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:887: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2022-12-16 11:03:14,022:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:887: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2022-12-16 11:03:14,177:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:887: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2022-12-16 11:03:14,225:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:887: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2022-12-16 11:03:14,251:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:887: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2022-12-16 11:03:14,280:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:887: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2022-12-16 11:03:14,757:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:14,768:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:14,779:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:14,861:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:14,875:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:14,890:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:14,893:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:14,907:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:14,919:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:14,927:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:14,937:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:14,940:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:14,953:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:14,955:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:14,970:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:14,978:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:14,990:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:14,993:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:14,997:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:15,001:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:15,005:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:15,013:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:15,016:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:15,028:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:15,694:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:887: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2022-12-16 11:03:15,740:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:887: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2022-12-16 11:03:16,014:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:16,015:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:16,019:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:16,023:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:16,023:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:16,029:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:16,037:INFO:Calculating mean and std
2022-12-16 11:03:16,038:INFO:Creating metrics dataframe
2022-12-16 11:03:16,044:INFO:Uploading results into container
2022-12-16 11:03:16,045:INFO:Uploading model into container now
2022-12-16 11:03:16,045:INFO:master_model_container: 8
2022-12-16 11:03:16,045:INFO:display_container: 2
2022-12-16 11:03:16,046:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2022-12-16 11:03:16,046:INFO:create_model() successfully completed......................................
2022-12-16 11:03:16,190:INFO:SubProcess create_model() end ==================================
2022-12-16 11:03:16,190:INFO:Creating metrics dataframe
2022-12-16 11:03:16,196:INFO:Initializing Ada Boost Classifier
2022-12-16 11:03:16,196:INFO:Total runtime is 0.7909937381744385 minutes
2022-12-16 11:03:16,196:INFO:SubProcess create_model() called ==================================
2022-12-16 11:03:16,196:INFO:Initializing create_model()
2022-12-16 11:03:16,196:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002086D017EE0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002086CFD3B50>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 11:03:16,196:INFO:Checking exceptions
2022-12-16 11:03:16,199:INFO:Importing libraries
2022-12-16 11:03:16,199:INFO:Copying training dataset
2022-12-16 11:03:16,204:INFO:Defining folds
2022-12-16 11:03:16,204:INFO:Declaring metric variables
2022-12-16 11:03:16,204:INFO:Importing untrained model
2022-12-16 11:03:16,204:INFO:Ada Boost Classifier Imported successfully
2022-12-16 11:03:16,205:INFO:Starting cross validation
2022-12-16 11:03:16,206:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 11:03:19,476:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:19,481:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:19,487:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:19,493:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:19,493:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:19,500:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:19,501:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:19,506:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:19,609:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:19,622:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:19,630:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:19,637:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:19,669:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:19,680:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:19,686:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:19,692:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:19,727:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:19,738:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:19,745:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:19,754:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:19,760:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:19,764:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:19,768:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:19,773:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:19,782:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:19,785:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:19,788:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:19,807:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:19,818:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:19,823:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:19,828:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:21,068:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:21,073:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:21,075:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:21,077:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:21,078:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:21,081:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:21,084:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:21,086:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:21,094:INFO:Calculating mean and std
2022-12-16 11:03:21,095:INFO:Creating metrics dataframe
2022-12-16 11:03:21,099:INFO:Uploading results into container
2022-12-16 11:03:21,099:INFO:Uploading model into container now
2022-12-16 11:03:21,100:INFO:master_model_container: 9
2022-12-16 11:03:21,100:INFO:display_container: 2
2022-12-16 11:03:21,100:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2294)
2022-12-16 11:03:21,100:INFO:create_model() successfully completed......................................
2022-12-16 11:03:21,235:INFO:SubProcess create_model() end ==================================
2022-12-16 11:03:21,236:INFO:Creating metrics dataframe
2022-12-16 11:03:21,241:INFO:Initializing Gradient Boosting Classifier
2022-12-16 11:03:21,241:INFO:Total runtime is 0.8750782410303752 minutes
2022-12-16 11:03:21,241:INFO:SubProcess create_model() called ==================================
2022-12-16 11:03:21,241:INFO:Initializing create_model()
2022-12-16 11:03:21,241:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002086D017EE0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002086CFD3B50>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 11:03:21,241:INFO:Checking exceptions
2022-12-16 11:03:21,244:INFO:Importing libraries
2022-12-16 11:03:21,244:INFO:Copying training dataset
2022-12-16 11:03:21,249:INFO:Defining folds
2022-12-16 11:03:21,249:INFO:Declaring metric variables
2022-12-16 11:03:21,249:INFO:Importing untrained model
2022-12-16 11:03:21,249:INFO:Gradient Boosting Classifier Imported successfully
2022-12-16 11:03:21,250:INFO:Starting cross validation
2022-12-16 11:03:21,252:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 11:03:30,018:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:30,021:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:30,029:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:30,035:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:30,040:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:30,044:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:30,053:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:30,058:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:30,083:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:30,083:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:30,093:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:30,100:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:30,100:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:30,106:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:30,108:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:30,797:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:30,802:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:30,806:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:30,809:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:30,813:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:30,813:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:30,818:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:30,824:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:30,831:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:30,839:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:30,841:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:30,846:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:30,849:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:30,852:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:30,853:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:30,858:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:34,447:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:34,451:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:34,454:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:34,456:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:34,477:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:34,481:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:34,484:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:34,486:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:34,493:INFO:Calculating mean and std
2022-12-16 11:03:34,494:INFO:Creating metrics dataframe
2022-12-16 11:03:34,499:INFO:Uploading results into container
2022-12-16 11:03:34,500:INFO:Uploading model into container now
2022-12-16 11:03:34,500:INFO:master_model_container: 10
2022-12-16 11:03:34,500:INFO:display_container: 2
2022-12-16 11:03:34,501:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2294, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2022-12-16 11:03:34,501:INFO:create_model() successfully completed......................................
2022-12-16 11:03:34,636:INFO:SubProcess create_model() end ==================================
2022-12-16 11:03:34,637:INFO:Creating metrics dataframe
2022-12-16 11:03:34,642:INFO:Initializing Linear Discriminant Analysis
2022-12-16 11:03:34,642:INFO:Total runtime is 1.0984331329663595 minutes
2022-12-16 11:03:34,642:INFO:SubProcess create_model() called ==================================
2022-12-16 11:03:34,643:INFO:Initializing create_model()
2022-12-16 11:03:34,643:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002086D017EE0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002086CFD3B50>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 11:03:34,643:INFO:Checking exceptions
2022-12-16 11:03:34,646:INFO:Importing libraries
2022-12-16 11:03:34,646:INFO:Copying training dataset
2022-12-16 11:03:34,651:INFO:Defining folds
2022-12-16 11:03:34,651:INFO:Declaring metric variables
2022-12-16 11:03:34,652:INFO:Importing untrained model
2022-12-16 11:03:34,652:INFO:Linear Discriminant Analysis Imported successfully
2022-12-16 11:03:34,652:INFO:Starting cross validation
2022-12-16 11:03:34,654:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 11:03:37,137:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:37,164:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:37,171:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:37,177:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:37,186:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:37,197:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:37,200:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:37,209:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:37,211:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:37,217:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:37,218:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:37,223:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:37,252:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:37,263:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:37,270:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:37,275:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:37,343:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:37,349:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:37,353:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:37,355:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:37,359:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:37,359:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:37,363:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:37,365:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:37,374:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:37,384:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:37,386:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:37,389:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:37,394:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:37,397:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:37,403:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:37,408:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:38,355:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:38,358:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:38,360:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:38,362:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:38,363:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:38,364:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:38,365:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:38,368:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:38,375:INFO:Calculating mean and std
2022-12-16 11:03:38,377:INFO:Creating metrics dataframe
2022-12-16 11:03:38,381:INFO:Uploading results into container
2022-12-16 11:03:38,381:INFO:Uploading model into container now
2022-12-16 11:03:38,382:INFO:master_model_container: 11
2022-12-16 11:03:38,382:INFO:display_container: 2
2022-12-16 11:03:38,382:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2022-12-16 11:03:38,382:INFO:create_model() successfully completed......................................
2022-12-16 11:03:38,518:INFO:SubProcess create_model() end ==================================
2022-12-16 11:03:38,518:INFO:Creating metrics dataframe
2022-12-16 11:03:38,523:INFO:Initializing Extra Trees Classifier
2022-12-16 11:03:38,524:INFO:Total runtime is 1.163135532538096 minutes
2022-12-16 11:03:38,524:INFO:SubProcess create_model() called ==================================
2022-12-16 11:03:38,524:INFO:Initializing create_model()
2022-12-16 11:03:38,524:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002086D017EE0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002086CFD3B50>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 11:03:38,524:INFO:Checking exceptions
2022-12-16 11:03:38,527:INFO:Importing libraries
2022-12-16 11:03:38,527:INFO:Copying training dataset
2022-12-16 11:03:38,532:INFO:Defining folds
2022-12-16 11:03:38,532:INFO:Declaring metric variables
2022-12-16 11:03:38,532:INFO:Importing untrained model
2022-12-16 11:03:38,533:INFO:Extra Trees Classifier Imported successfully
2022-12-16 11:03:38,533:INFO:Starting cross validation
2022-12-16 11:03:38,535:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 11:03:42,867:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:42,880:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:42,881:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:42,885:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:42,887:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:42,893:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:42,896:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:42,897:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:42,901:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:42,902:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:42,905:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:42,907:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:42,907:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:42,919:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:42,925:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:42,930:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:43,166:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:43,174:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:43,179:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:43,186:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

 msg_start, len(result))

2022-12-16 11:03:43,191:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:43,193:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:43,197:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:43,220:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:43,228:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:43,232:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:43,232:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:43,236:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:43,238:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:43,241:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:43,244:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:44,667:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:44,671:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:44,673:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:44,676:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:44,676:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:44,678:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:44,678:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:44,681:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:44,689:INFO:Calculating mean and std
2022-12-16 11:03:44,691:INFO:Creating metrics dataframe
2022-12-16 11:03:44,695:INFO:Uploading results into container
2022-12-16 11:03:44,696:INFO:Uploading model into container now
2022-12-16 11:03:44,697:INFO:master_model_container: 12
2022-12-16 11:03:44,697:INFO:display_container: 2
2022-12-16 11:03:44,697:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=2294, verbose=0, warm_start=False)
2022-12-16 11:03:44,697:INFO:create_model() successfully completed......................................
2022-12-16 11:03:44,851:INFO:SubProcess create_model() end ==================================
2022-12-16 11:03:44,851:INFO:Creating metrics dataframe
2022-12-16 11:03:44,857:INFO:Initializing Light Gradient Boosting Machine
2022-12-16 11:03:44,857:INFO:Total runtime is 1.2686911940574646 minutes
2022-12-16 11:03:44,858:INFO:SubProcess create_model() called ==================================
2022-12-16 11:03:44,858:INFO:Initializing create_model()
2022-12-16 11:03:44,858:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002086D017EE0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002086CFD3B50>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 11:03:44,858:INFO:Checking exceptions
2022-12-16 11:03:44,862:INFO:Importing libraries
2022-12-16 11:03:44,862:INFO:Copying training dataset
2022-12-16 11:03:44,867:INFO:Defining folds
2022-12-16 11:03:44,867:INFO:Declaring metric variables
2022-12-16 11:03:44,867:INFO:Importing untrained model
2022-12-16 11:03:44,867:INFO:Light Gradient Boosting Machine Imported successfully
2022-12-16 11:03:44,868:INFO:Starting cross validation
2022-12-16 11:03:44,869:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 11:03:48,159:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:48,170:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:48,176:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:48,181:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:48,230:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:48,243:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:48,249:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:48,254:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:48,254:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:48,259:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:48,265:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:48,303:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:48,321:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:48,330:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:48,332:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:48,336:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:48,344:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:48,352:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:48,353:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:48,358:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:48,362:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:48,366:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:48,371:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:48,400:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:48,408:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:48,409:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:48,412:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:48,416:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:48,418:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:48,422:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:48,426:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:49,681:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:49,685:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:49,688:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:49,690:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:49,705:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:49,710:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:49,712:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:49,714:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:49,721:INFO:Calculating mean and std
2022-12-16 11:03:49,723:INFO:Creating metrics dataframe
2022-12-16 11:03:49,727:INFO:Uploading results into container
2022-12-16 11:03:49,727:INFO:Uploading model into container now
2022-12-16 11:03:49,728:INFO:master_model_container: 13
2022-12-16 11:03:49,728:INFO:display_container: 2
2022-12-16 11:03:49,728:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2294, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2022-12-16 11:03:49,728:INFO:create_model() successfully completed......................................
2022-12-16 11:03:49,872:INFO:SubProcess create_model() end ==================================
2022-12-16 11:03:49,872:INFO:Creating metrics dataframe
2022-12-16 11:03:49,879:INFO:Initializing Dummy Classifier
2022-12-16 11:03:49,879:INFO:Total runtime is 1.3523815751075745 minutes
2022-12-16 11:03:49,880:INFO:SubProcess create_model() called ==================================
2022-12-16 11:03:49,880:INFO:Initializing create_model()
2022-12-16 11:03:49,880:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002086D017EE0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002086CFD3B50>, model_only=True, return_train_score=False, kwargs={})
2022-12-16 11:03:49,880:INFO:Checking exceptions
2022-12-16 11:03:49,882:INFO:Importing libraries
2022-12-16 11:03:49,883:INFO:Copying training dataset
2022-12-16 11:03:49,887:INFO:Defining folds
2022-12-16 11:03:49,888:INFO:Declaring metric variables
2022-12-16 11:03:49,888:INFO:Importing untrained model
2022-12-16 11:03:49,888:INFO:Dummy Classifier Imported successfully
2022-12-16 11:03:49,888:INFO:Starting cross validation
2022-12-16 11:03:49,890:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-16 11:03:52,241:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:52,264:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:52,270:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:52,277:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:52,283:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:52,297:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:52,304:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:52,310:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:52,357:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:52,371:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:52,378:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:52,384:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:52,396:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:52,408:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:52,415:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:52,422:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:52,505:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:52,516:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:52,521:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:52,527:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:52,550:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:52,552:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:52,560:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:52,561:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:52,565:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:52,568:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:52,571:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:52,575:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:52,651:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:52,661:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:52,666:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:52,671:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:53,499:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:53,499:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:53,503:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:53,503:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:53,505:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:53,506:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2022-12-16 11:03:53,508:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:53,508:WARNING:C:\Users\S_05_\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1386: UserWarning: Note that pos_label (set to 'Unknown') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2022-12-16 11:03:53,515:INFO:Calculating mean and std
2022-12-16 11:03:53,516:INFO:Creating metrics dataframe
2022-12-16 11:03:53,521:INFO:Uploading results into container
2022-12-16 11:03:53,521:INFO:Uploading model into container now
2022-12-16 11:03:53,522:INFO:master_model_container: 14
2022-12-16 11:03:53,522:INFO:display_container: 2
2022-12-16 11:03:53,522:INFO:DummyClassifier(constant=None, random_state=2294, strategy='prior')
2022-12-16 11:03:53,522:INFO:create_model() successfully completed......................................
2022-12-16 11:03:53,678:INFO:SubProcess create_model() end ==================================
2022-12-16 11:03:53,678:INFO:Creating metrics dataframe
2022-12-16 11:03:53,689:INFO:Initializing create_model()
2022-12-16 11:03:53,689:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002086D017EE0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2294, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-12-16 11:03:53,689:INFO:Checking exceptions
2022-12-16 11:03:53,693:INFO:Importing libraries
2022-12-16 11:03:53,693:INFO:Copying training dataset
2022-12-16 11:03:53,700:INFO:Defining folds
2022-12-16 11:03:53,700:INFO:Declaring metric variables
2022-12-16 11:03:53,700:INFO:Importing untrained model
2022-12-16 11:03:53,700:INFO:Declaring custom model
2022-12-16 11:03:53,702:INFO:Logistic Regression Imported successfully
2022-12-16 11:03:53,704:INFO:Cross validation set to False
2022-12-16 11:03:53,704:INFO:Fitting Model
2022-12-16 11:03:56,363:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2294, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2022-12-16 11:03:56,364:INFO:create_model() successfully completed......................................
2022-12-16 11:03:56,508:INFO:master_model_container: 14
2022-12-16 11:03:56,509:INFO:display_container: 2
2022-12-16 11:03:56,509:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2294, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2022-12-16 11:03:56,509:INFO:compare_models() successfully completed......................................
2022-12-16 11:03:56,528:INFO:Initializing save_model()
2022-12-16 11:03:56,528:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2294, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=best_model, prep_pipe_=Pipeline(memory=Memory(location=C:\Users\S_05_\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=['Accident_severity'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_val...
                                                                         'Weather_conditions',
                                                                         'Type_of_collision',
                                                                         'Vehicle_movement',
                                                                         'Pedestrian_movement',
                                                                         'Cause_of_accident'],
                                                                   drop_invariant=False,
                                                                   handle_missing='return_nan',
                                                                   handle_unknown='value',
                                                                   random_state=2294,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('low_variance',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=VarianceThreshold(threshold=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2022-12-16 11:03:56,528:INFO:Adding model into prep_pipe
2022-12-16 11:03:56,550:INFO:best_model.pkl saved in current working directory
2022-12-16 11:03:56,561:INFO:Pipeline(memory=Memory(location=C:\Users\S_05_\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=['Accident_severity'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_val...
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=VarianceThreshold(threshold=0))),
                ('trained_model',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=2294,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2022-12-16 11:03:56,561:INFO:save_model() successfully completed......................................
